title	id	updated	published	summary	primary_category
ArXiv Query: search_query=all:sustainability&id_list=&start=0&max_results=1000	http://arxiv.org/api/N2hxL8BqnV5qruINSW4ewUTiYJc	2023-03-20T00:00:00-04:00		nan	
"Efficient adiabatic demagnetization refrigeration to below 50 mK with
  UHV compatible Ytterbium diphosphates $A$YbP$_2$O$_7$ ($A=$Na, K)"	http://arxiv.org/abs/2303.09991v1	2023-03-17T14:06:40Z	2023-03-17T14:06:40Z	  Attaining milli-Kelvin temperatures is often a prerequisite for the study of novel quantum phenomena and the operation of quantum devices. Adiabatic demagnetization refrigeration (ADR) is an effective, easy and sustainable alternative to evaporation or dilution cooling with the rare and super-expensive $^3$He. Paramagnetic salts, traditionally used for mK-ADR, suffer from chemical instability related to crystal water. We report synthesis, characterization as well as low-temperature magnetization and specific heat measurements of two new UHV compatible candidate materials NaYbP$_2$O$_7$ and KYbP$_2$O$_7$. Utilizing the PPMS at 2 K, the ADR of sintered pellets with Ag powder admixture starting at 5 T yields base temperatures (warm-up times) of 45 mK (55 min) and 37 mK (35 min) for NaYbP$_2$O$_7$ and KYbP$_2$O$_7$, respectively, slightly advantageous to KBaYb(BO$_3$)$_2$ (45 mK and 40 min) studied under similar conditions. 	
A Resilient Power Distribution System using P2P Energy Sharing	http://arxiv.org/abs/2303.09471v1	2023-03-16T16:47:12Z	2023-03-16T16:47:12Z	  The adoption of distributed energy resources (DERs) such as solar panels and wind turbines is transforming the traditional energy grid into a more decentralized system, where microgrids are emerging as a key concept. Peer-to-Peer (P2P) energy sharing in microgrids enhances the efficiency and flexibility of the overall system by allowing the exchange of surplus energy and better management of energy resources. This work analyzes the impact of P2P energy sharing for three cases - within a microgrid, with neighboring microgrids, and all microgrids combined together in a distribution system. A standard IEEE 123 node test feeder integrated with renewable energy sources is partitioned into microgrids. For P2P energy sharing between microgrids, the results show significant benefits in cost, reduced energy dependence on the grid, and a significant improvement in the system's resilience. We also predicted the energy requirement for a microgrid to evaluate energy resilience for the control and operation of the microgrid. Overall, the analysis provides valuable insights into the performance and sustainability of microgrids with P2P energy sharing. 	
"Failure precursors and failure mechanisms in hierarchically patterned
  paper sheets in tensile and creep loading"	http://arxiv.org/abs/2303.09214v1	2023-03-16T10:42:18Z	2023-03-16T10:42:18Z	  Quasi-brittle materials endowed with (statistically) self-similar hierarcical microstructures show distinct failure patterns that deviate from the standard scenario of damage accumulation followed by crack nucleation-and-growth. Here we study the failure of paper sheets with hierarchical slice patterns as well as non-hierarchical and unpatterned reference samples, considering both uncracked samples and samples containing a macroscopic crack. Failure is studied under displacement-controlled tensile loading as well as under creep conditions. Acoustic emission records and surface strain patterns are recorded alongside stress-strain and creep curves. The measurements demonstrate that hierarchical patterning efficiently mitigates against strain localization and crack propagation. In tensile loading, this results in a significantly increased residual strength of cracked samples. Under creep conditions, for a given range of lifetimes hierarchically patterned samples are found to sustain larger creep strains at higher stress levels; their creep curves show unusual behavior characterized by multiple creep rate minima due to the repeated arrest of emergent localization bands. 	
"Capacity Analysis and Rate Maximization Design in RIS-Aided Uplink
  Multi-User MIMO"	http://arxiv.org/abs/2303.09140v1	2023-03-16T08:07:00Z	2023-03-16T08:07:00Z	  Reconfigurable intelligent surface (RIS) has recently drawn intensive attention due to its potential of simultaneously realizing high spectral and energy efficiency in a sustainable way. This paper focuses on the design of efficient transmission methods to maximize the uplink sum throughput in a RIS-aided multi-user multi-input multi-output (MU-MIMO) system. To provide an insightful basis, the channel capacity of RIS-aided MU-MIMO is theoretically analyzed. Then, the conventional transmission schemes based on orthogonal multiple access are presented as the baseline. From the information-theoretic perspective, we propose two novel schemes, i.e., \textit{joint transmission} based on the semidefinite relaxation of quadratic optimization problems and \textit{opportunistic transmission} relying on the best user selection. The superiority of the proposed schemes over the conventional ones in terms of achievable rates is justified through simulation results. 	
"Lessons Learnt from a Multimodal Learning Analytics Deployment
  In-the-wild"	http://arxiv.org/abs/2303.09099v1	2023-03-16T06:05:24Z	2023-03-16T06:05:24Z	"  Multimodal Learning Analytics (MMLA) innovations make use of rapidly evolving sensing and artificial intelligence algorithms to collect rich data about learning activities that unfold in physical learning spaces. The analysis of these data is opening exciting new avenues for both studying and supporting learning. Yet, practical and logistical challenges commonly appear while deploying MMLA innovations ""in-the-wild"". These can span from technical issues related to enhancing the learning space with sensing capabilities, to the increased complexity of teachers' tasks and informed consent. These practicalities have been rarely discussed. This paper addresses this gap by presenting a set of lessons learnt from a 2-year human-centred MMLA in-the-wild study conducted with 399 students and 17 educators. The lessons learnt were synthesised into topics related to i) technological/physical aspects of the deployment; ii) multimodal data and interfaces; iii) the design process; iv) participation, ethics and privacy; and v) the sustainability of the deployment. "	
Unifying flavors of fault tolerance with the ZX calculus	http://arxiv.org/abs/2303.08829v1	2023-03-15T18:00:00Z	2023-03-15T18:00:00Z	  There are several models of quantum computation which exhibit shared fundamental fault-tolerance properties. This article makes commonalities explicit by presenting these different models in a unifying framework based on the ZX calculus. We focus on models of topological fault tolerance - specifically surface codes - including circuit-based, measurement-based and fusion-based quantum computation, as well as the recently introduced model of Floquet codes. We find that all of these models can be viewed as different flavors of the same underlying stabilizer fault-tolerance structure, and sustain this through a set of local equivalence transformations which allow mapping between flavors. We anticipate that this unifying perspective will pave the way to transferring progress among the different views of stabilizer fault-tolerance and help researchers familiar with one model easily understand others. 	
Wilson matrix kernel for lattice QCD on A64FX architecture	http://arxiv.org/abs/2303.08609v1	2023-03-15T13:30:09Z	2023-03-15T13:30:09Z	  We study the implementation of the even-odd Wilson fermion matrix for lattice QCD simulations on the A64FX architecture. Efficient coding of the stencil operation is investigated for two-dimensional packing to SIMD vectors. We measure the sustained performance on the supercomputer Fugaku at RIKEN R-CCS and show the profiler result of our code, which may signal an unexpected source of slow-down in addition to the detailed efficiency of each part of the code. 	
"RIS-Enabled Smart Wireless Environments: Deployment Scenarios, Network
  Architecture, Bandwidth and Area of Influence"	http://arxiv.org/abs/2303.08505v1	2023-03-15T10:29:33Z	2023-03-15T10:29:33Z	  Reconfigurable Intelligent Surfaces (RISs) constitute the key enabler for programmable electromagnetic propagation environments, and are lately being considered as a candidate physical-layer technology for the demanding connectivity, reliability, localization, and sustainability requirements of next generation wireless networks. In this paper, we first present the deployment scenarios for RIS-enabled smart wireless environments that have been recently designed within the ongoing European Union Horizon 2020 RISE-6G project, as well as a network architecture integrating RISs with existing standardized interfaces. We identify various RIS deployment strategies and sketch the core architectural requirements in terms of RIS control and signaling, depending on the RIS hardware architectures and respective capabilities. Furthermore, we introduce and discuss, with the aid of simulations and reflectarray measurements, two novel metrics that emerge in the context of RIS-empowered wireless systems: the RIS bandwidth and area of influence. Their extensive investigation corroborates the need for careful deployment and planning of the RIS technology in future networks. 	
"Altruistic and Profit-oriented: Making Sense of Roles in Web3 Community
  from Airdrop Perspective"	http://arxiv.org/abs/2303.08457v1	2023-03-15T09:01:43Z	2023-03-15T09:01:43Z	  Regardless of which community, incentivizing users is a necessity for well-sustainable operations. In the blockchain-backed Web3 communities, known for their transparency and security, airdrop serves as a widespread incentive mechanism for allocating capital and power. However, it remains a controversy on how to justify airdrop to incentive and empower the decentralized governance. In this paper, we use ParaSwap as an example to propose a role taxonomy methodology through a data-driven study to understand the characteristic of community members and the effectiveness of airdrop. We find that users receive more rewards tend to take positive actions towards the community. We summarize several arbitrage patterns and confirm the current detection is not sufficient in screening out airdrop hunters. In conjunction with the results, we discuss from the aspects of interaction, financialization, and system design to conclude the challenges and possible research directions for decentralized communities. 	
"Dynamics of Voltage Driven Self-Sustained Oscillations in NdNiO$_3$
  Neuristors"	http://arxiv.org/abs/2303.09394v1	2023-03-15T07:37:57Z	2023-03-15T07:37:57Z	  Active memristor elements, also called neuristors, are self-oscillating devices that are very good approximations to biological neuronal functionality and are crucial to the development of low-power neuromorphic hardware. Materials that show conduction mechanisms that depend superlinearly with temperature can lead to negative differential resistance (NDR) regimes, which may further be engineered as self-oscillators. Thermal runaway, insulator to metal phase transitions (IMT) can lead to such superlinearity and are being extensively studied in systems such as TaO$_x$, NbO$_x$ and VO$_2$. However, ReNiO$_3$ systems that offer large tunability in metal-insulator transition temperatures are less explored so far. Here we demonstrate all-or-nothing neuron-like self-oscillations at MHz frequency and low temperatures on thin films of NdNiO$_3$, a model charge transfer insulator, and their frequency coding behavior. We study the temperature dependence of NDR and show that it vanishes even at temperatures below the IMT temperature. We also show that the threshold voltages scale with device size and that a simple electrothermal device model captures all these salient features. In contrast to existing models, our model correctly predicts the independence of oscillation amplitude with the applied voltage, offering crucial insights about the nature of fixed points in the NDR region, and the dynamics of non-linear oscillations about them. KEYWORDS: NDR, oscillations, thermal model. 	
"Machine Learning Approaches in Agile Manufacturing with Recycled
  Materials for Sustainability"	http://arxiv.org/abs/2303.08291v1	2023-03-15T00:39:31Z	2023-03-15T00:39:31Z	  It is important to develop sustainable processes in materials science and manufacturing that are environmentally friendly. AI can play a significant role in decision support here as evident from our earlier research leading to tools developed using our proposed machine learning based approaches. Such tools served the purpose of computational estimation and expert systems. This research addresses environmental sustainability in materials science via decision support in agile manufacturing using recycled and reclaimed materials. It is a safe and responsible way to turn a specific waste stream to value-added products. We propose to use data-driven methods in AI by applying machine learning models for predictive analysis to guide decision support in manufacturing. This includes harnessing artificial neural networks to study parameters affecting heat treatment of materials and impacts on their properties; deep learning via advances such as convolutional neural networks to explore grain size detection; and other classifiers such as Random Forests to analyze phrase fraction detection. Results with all these methods seem promising to embark on further work, e.g. ANN yields accuracy around 90\% for predicting micro-structure development as per quench tempering, a heat treatment process. Future work entails several challenges: investigating various computer vision models (VGG, ResNet etc.) to find optimal accuracy, efficiency and robustness adequate for sustainable processes; creating domain-specific tools using machine learning for decision support in agile manufacturing; and assessing impacts on sustainability with metrics incorporating the appropriate use of recycled materials as well as the effectiveness of developed products. Our work makes impacts on green technology for smart manufacturing, and is motivated by related work in the highly interesting realm of AI for materials science. 	
Rules of Engagement: Why and How Companies Participate in OSS	http://arxiv.org/abs/2303.08266v1	2023-03-14T22:45:44Z	2023-03-14T22:45:44Z	  Company engagement in open source (OSS) is now the new norm. From large technology companies to startups, companies are participating in the OSS ecosystem by open-sourcing their technology, sponsoring projects through funding or paid developer time. However, our understanding of the OSS ecosystem is rooted in the 'old world' model where individual contributors sustain OSS projects. In this work, we create a more comprehensive understanding of the hybrid OSS landscape by investigating what motivates companies to contribute and how they contribute to OSS. We conducted interviews with 20 participants who have different roles (e.g., CEO, OSPO Lead, Ecosystem Strategist) at 17 different companies of different sizes from large companies (e.g. Microsoft, RedHat, Google, Spotify) to startups. Data from semi-structured interviews reveal that company motivations can be categorized into four levels (Founders' Vision, Reputation, Business Advantage, and Reciprocity) and companies participate through different mechanisms (e.g., Developers' Time, Mentoring Time, Advocacy & Promotion Time), each of which tie to the different types of motivations. We hope our findings nudge more companies to participate in the OSS ecosystem, helping make it robust, diverse, and sustainable. 	
"On the contribution of the Hall term in small-scale magnetohydrodynamic
  dynamo"	http://arxiv.org/abs/2303.07857v1	2023-03-14T12:48:45Z	2023-03-14T12:48:45Z	  A detailed study of small-scale Hall magnetohydrodynamic dynamo has been performed both analytically and numerically. Assuming the magnetic field and the current to be separate fields, the contribution of the Hall term has been decomposed into two parts and their individual contributions have been studied separately. Calculating the scale-separated transfer rates described in Dar \textit{et. al.} (Physica D, 157 (207), 2001), it is found that the small-scale current fields are the primary contributors in sustaining large scale magnetic fields. Furthermore, the nature of the scale-to-scale fluxes are found to be globally intact with the ion inertial scale. 	
Glassy materials for Silicon-based solar panels: present and future	http://arxiv.org/abs/2303.07829v1	2023-03-14T12:06:51Z	2023-03-14T12:06:51Z	  About 2/3 of a commercial solar panel's weight is glass. This material should provide mechanical, chemical, and UV protection, contributing to the device's overall net energy production. Here we discuss some current trends in glassy materials for Silicon photovoltaics. The search for environmentally friendly glasses and new features such as anti-reflection, self-cleaning, and spectral conversion is reviewed. A conceptual model to compare UV-blocking and spectral converter materials is proposed, and the potential of these features to improve solar power production and its sustainability are discussed. 	
"Changes in mobility choices during the first wave of the COVID-19
  pandemic: a comparison between Italy and Sweden"	http://arxiv.org/abs/2303.07803v1	2023-03-14T11:19:26Z	2023-03-14T11:19:26Z	  The spread of COVID-19 disease affected people's lives worldwide, particularly their travel behaviours and how they performed daily activities. During the first wave of the pandemic, spring 2020, countries adopted different strategies to contain the spread of the virus. The aim of this paper is to analyse the changes in mobility behaviours, focusing on the sustainability level of modal choices caused by the pandemic in two countries with different containment policies in place: Italy and Sweden. Survey data uncovered which transport means was the most used for three different trip purposes (grocery shopping, non-grocery shopping and commuting) both before and during the first wave of the pandemic. The variation in the sustainability level of modal choices was then observed through descriptive statistics and significance tests. By estimating three multinomial logistic regression models, one for each trip purpose, we tried to identify which factors, beyond the country, affected the variation in the sustainability level of the modal choice with the beginning of the pandemic. Results show a greater reduction in mobility among the Italian sample compared to the Swedish one, especially for public transit, and a major inclination by Swedes in travelling by foot and by bike compared to Italians, also due to the greater possibility of making trips during the first wave of the pandemic. Finally, perceived safety on public transit seems to have no significant effects on the variation in the sustainability level of the modal choice with the beginning of restrictions. Our results can be used as a starting point for a discussion on how the COVID-19 pandemic affected attitudes and preferences towards the different travel alternatives. Also, in this work we highlighted how people reacted in different ways to an unprecedented situation in two Countries with opposite containment strategies in place. 	
"A Commons-Compatible Implementation of the Sharing Economy:
  Blockchain-Based Open Source Mediation"	http://arxiv.org/abs/2303.07786v1	2023-03-14T10:56:50Z	2023-03-14T10:56:50Z	  The network economical sharing economy, with direct exchange as a core characteristic, is implemented both, on a commons and platform economical basis. This is due to a gain in importance of trust, collaborative consumption and democratic management as well as technological progress, in the form of near zero marginal costs, open source contributions and digital transformation. Concurrent to these commons-based drivers, the grey area between commerce and private exchange is used to exploit work, safety and tax regulations by central platform economists. Instead of central intermediators, the blockchain technology makes decentralized consensus finding, using Proof-of-Work (PoW) within a self-sustaining Peer-to-Peer network, possible. Therefore, a blockchain-based open source mediation seems to offer a commons-compatible implementation of the sharing economy. This thesis is investigated through a qualitative case study of Sardex and Interlace with their blockchain application, based on expert interviews and a structured content analysis. To detect the most commons-compatible implementation, the different implementation options through conventional platform intermediators, an open source blockchain with PoW as well as Interlaces' permissioned blockchain approach, are compared. The following confrontation is based on deductive criteria, which illustrates the inherent characteristics of a commons-based sharing economy. 	
Entangled time-crystal phase in an open quantum light-matter system	http://arxiv.org/abs/2303.07725v1	2023-03-14T09:15:50Z	2023-03-14T09:15:50Z	  Time-crystals are nonequilibrium many-body phases in which the state of the system dynamically approaches a limit cycle. While these phases are recently in the focus of intensive research, it is still far from clear whether they can host quantum correlations. In fact, mostly classical correlations have been observed so far and time-crystals appear to be effectively classical high-entropy phases. Here, we consider the nonequilibrium behavior of an open quantum light-matter system, realizable in current experiments, which maps onto a paradigmatic time-crystal model after an adiabatic elimination of the light field. The system displays a bistable regime, with coexistent time-crystal and stationary phases, terminating at a tricritical point from which a second-order phase transition line departs. While light and matter are uncorrelated in the stationary phase, the time-crystal phase features bipartite correlations, both of quantum and classical nature. Our work unveils that time-crystal phases in collective open quantum systems can sustain quantum correlations, including entanglement, and are thus more than effectively classical many-body phases. 	
"Carbon-Neutralized Joint User Association and Base Station Switching for
  Green Cellular Networks"	http://arxiv.org/abs/2303.07702v1	2023-03-14T08:40:01Z	2023-03-14T08:40:01Z	  Mitigating climate change and its impacts is one of the sustainable development goals (SDGs) required by United Nations for an urgent action. Increasing carbon emissions due to human activities is the root cause to climate change. Telecommunication networks that provide service connectivity to mobile users contribute great amount of carbon emissions by consuming lots of non-renewable energy sources. Beyond the improvement on energy efficiency, to reduce the carbon footprint, telecom operators are increasing their adoption of renewable energy (e.g., wind power). The high variability of renewable energy in time and location; however, creates difficulties for operators when utilizing renewables for the reduction of carbon emissions. In this paper, we consider a heterogeneous network consisted of one macro base station (MBS) and multiple small base stations (SBSs) where each base station (BS) is powered by both of renewable and non-renewable energy. Different from the prior works that target on the total power consumption, we propose a novel scheme to minimize the carbon footprint of networks by dynamically switching the ON/OFF modes of SBSs and adjusting the association between users and BSs to access renewables as much as possible. Our numerical analysis shows that the proposed scheme significantly reduces up to 86% of the nonrenewable energy consumption compared to two representative baselines. 	
Architext: Language-Driven Generative Architecture Design	http://arxiv.org/abs/2303.07519v2	2023-03-15T16:07:05Z	2023-03-13T23:11:05Z	  Architectural design is a highly complex practice that involves a wide diversity of disciplines, technologies, proprietary design software, expertise, and an almost infinite number of constraints, across a vast array of design tasks. Enabling intuitive, accessible, and scalable design processes is an important step towards performance-driven and sustainable design for all. To that end, we introduce Architext, a novel semantic generation assistive tool. Architext enables design generation with only natural language prompts, given to large-scale Language Models, as input. We conduct a thorough quantitative evaluation of Architext's downstream task performance, focusing on semantic accuracy and diversity for a number of pre-trained language models ranging from 120 million to 6 billion parameters. Architext models are able to learn the specific design task, generating valid residential layouts at a near 100% rate. Accuracy shows great improvement when scaling the models, with the largest model (GPT-J) yielding impressive accuracy ranging between 25% to over 80% for different prompt categories. We open source the finetuned Architext models and our synthetic dataset, hoping to inspire experimentation in this exciting area of design research. 	
Optimization of the location and design of urban green spaces	http://arxiv.org/abs/2303.07202v1	2023-03-13T15:37:21Z	2023-03-13T15:37:21Z	  The recent promotion of sustainable urban planning combined with a growing need for public interventions to improve well-being and health have led to an increased collective interest for green spaces in and around cities. In particular, parks have proven a wide range of benefits in urban areas. This also means inequities in park accessibility may contribute to health inequities. In this work, we showcase the application of classic tools from Operations Research to assist decision-makers to improve parks' accessibility, distribution and design. Given the context of public decision-making, we are particularly concerned with equity and environmental justice, and are focused on an advanced assessment of users' behavior through a spatial interaction model. We present a two-stage fair facility location and design model, which serves as a template model to assist public decision-makers at the city-level for the planning of urban green spaces. The first-stage of the optimization model is about the optimal city-budget allocation to neighborhoods based on a data exposing inequality attributes. The second-stage seeks the optimal location and design of parks for each neighborhood, and the objective consists of maximizing the total expected probability of individuals visiting parks. We show how to reformulate the latter as a mixed-integer linear program. We further introduce a clustering method to reduce the size of the problem and determine a close to optimal solution within reasonable time. The model is tested using the case study of the city of Montreal and comparative results are discussed in detail to justify the performance of the model. 	
Mobile Mapping Mesh Change Detection and Update	http://arxiv.org/abs/2303.07182v1	2023-03-13T15:24:06Z	2023-03-13T15:24:06Z	  Mobile mapping, in particular, Mobile Lidar Scanning (MLS) is increasingly widespread to monitor and map urban scenes at city scale with unprecedented resolution and accuracy. The resulting point cloud sampling of the scene geometry can be meshed in order to create a continuous representation for different applications: visualization, simulation, navigation, etc. Because of the highly dynamic nature of these urban scenes, long term mapping should rely on frequent map updates. A trivial solution is to simply replace old data with newer data each time a new acquisition is made. However it has two drawbacks: 1) the old data may be of higher quality (resolution, precision) than the new and 2) the coverage of the scene might be different in various acquisitions, including varying occlusions. In this paper, we propose a fully automatic pipeline to address these two issues by formulating the problem of merging meshes with different quality, coverage and acquisition time. Our method is based on a combined distance and visibility based change detection, a time series analysis to assess the sustainability of changes, a mesh mosaicking based on a global boolean optimization and finally a stitching of the resulting mesh pieces boundaries with triangle strips. Finally, our method is demonstrated on Robotcar and Stereopolis datasets. 	
"Spontaneous flows and dynamics of full-integer topological defects in
  polar active matter"	http://arxiv.org/abs/2303.07063v1	2023-03-13T12:37:20Z	2023-03-13T12:37:20Z	  Polar active matter of self-propelled particles sustain spontaneous flows through the full-integer topological defects. We study theoretically the effect of both polar and dipolar active forces on the flow profile around $\pm 1$ defects and their interaction in the presence of both viscosity and frictional dissipation. The vorticity induced by the active stress is non-zero at the $+1$ defect contributing to the active torque acting on the defect. A near-core flow reversal is predicted in absence of hydrodynamic screening (zero friction) as observed in numerical simulations. While $\pm 1$ defects are sources of spontaneous flows due to active stresses, they become sinks of flows induced by the polar active forces. We show analytically that the flow velocity induced by polar active forces increases away from a $\pm 1$ defect towards the uniform far-field, while its associated vorticity field decays as $1/r$ in the far-field. In the friction-dominated regime, we demonstrate that the flow induced by polar active forces enhances defect pair annihilation, and depends only on the orientation between a pair of oppositely charged defects relative to the orientation of the background polarization field. Interestingly, we find that this annihilation dynamics through mutual defect-defect interactions is distance independent, in contradiction with the effect of dipolar active forces which decay inversely proportional to the defect separation distance. As such, our analyses reveals a new, truly long-ranged mechanism for the pairwise interaction of oppositely-charged topological defects in polar active matter. 	
"Energy Management System for a Low Voltage Direct Current Microgrid:
  Modeling and experimental validation"	http://arxiv.org/abs/2303.06997v1	2023-03-13T10:52:37Z	2023-03-13T10:52:37Z	  In the field of microgrids with a significant integration of Renewable Energy Sources, the efficient and practical power storage systems requirement is causing DC microgrids to gain increasing attention. However, uncertainties in power generation and load consumption along with the fluctuations of electricity prices require the design of a reliable control architecture and a robust energy management system for enhancing the power quality and its sustainability, while minimizing the associated costs. This paper presents a mixed approach illustrating both simulation and experimental results of a grid-connected DC microgrid which includes a photovoltaic power source and a battery storage system. Special emphasis is placed on the minimization of the total operating cost of the microgrid while considering the battery degradation cost and the electricity tariff. Thereby, an optimal energy management system is proposed for Energy Storage Systems scheduling and enabling the minimization of the electricity bill based on simple models. Simultaneously, the differences between simulation and laboratory performances are highlighted. 	
Improved refrigeration in presence of non-Markovian spin-environment	http://arxiv.org/abs/2303.06712v1	2023-03-12T17:28:35Z	2023-03-12T17:28:35Z	  We explore a small quantum refrigerator consisting of three qubits each of which are kept in contact with an environment. We consider two settings: one is when there is necessarily transient cooling and the other is when both steady-state and transient cooling prevail. We show that there can be significant advantages than the Markovian environments case for both these settings in the transient regime and also in equilibrium if we replace the bath attached to the cold qubit by a non-Markovian reservoir. We also consider refrigeration with more than one non-Markovian bath of the three-qubit refrigerating device. Curiously, a steady temperature is reached only if there are at least two Markovian environments, although there are distinct envelopes of the temperature oscillations in all cases. We compare the device connected to one or more non-Markovian reservoirs with the case of all Markovian environs, as also with two- and single-qubit self-sustained devices connected to one or more non-Markovian baths. We propose a measure to quantify the amount of non-Markovianity in the systems. Finally, the refrigerator models are studied in presence of Markovian noise, and we analyse the response on the refrigeration of the noise strength. In particular, we find the noise strength until which refrigeration remains possible. 	
"Frugal Computing -- On the need for low-carbon and sustainable computing
  and the path towards zero-carbon computing"	http://arxiv.org/abs/2303.06642v1	2023-03-12T12:02:21Z	2023-03-12T12:02:21Z	  The current emissions from computing are almost 4% of the world total. This is already more than emissions from the airline industry and are projected to rise steeply over the next two decades. By 2040 emissions from computing alone will account for more than half of the emissions budget to keep global warming below 1.5$^\circ$C. Consequently, this growth in computing emissions is unsustainable. The emissions from production of computing devices exceed the emissions from operating them, so even if devices are more energy efficient producing more of them will make the emissions problem worse. Therefore we must extend the useful life of our computing devices. As a society we need to start treating computational resources as finite and precious, to be utilised only when necessary, and as effectively as possible. We need frugal computing: achieving our aims with less energy and material. 	
"The impacts of remote work on travel: insights from nearly three years
  of monthly surveys"	http://arxiv.org/abs/2303.06186v1	2023-03-10T19:40:50Z	2023-03-10T19:40:50Z	"  Remote work has expanded dramatically since 2020, upending longstanding travel patterns and behavior. More fundamentally, the flexibility for remote workers to choose when and where to work has created much stronger connections between travel behavior and organizational behavior. This paper uses a large and comprehensive monthly longitudinal survey over nearly three years to identify new trends in work location choice, mode choice and departure time of remote workers. The travel behavior of remote workers is found to be highly associated with employer characteristics, task characteristics, employer remote work policies, coordination between colleagues and attitudes towards remote work. Approximately one third of all remote work hours are shown to take place outside of the home, accounting for over one third of all commuting trips. These commutes to ""third places"" are shorter, less likely to occur during peak periods, and more likely to use sustainable travel modes than commutes to an employer's primary workplace. Hybrid work arrangements are also associated with a greater number of non-work trips than fully remote and fully in-person arrangements. Implications of this research for policy makers, shared mobility provides and land use planning are discussed. "	
Unifying Grokking and Double Descent	http://arxiv.org/abs/2303.06173v1	2023-03-10T19:16:53Z	2023-03-10T19:16:53Z	  A principled understanding of generalization in deep learning may require unifying disparate observations under a single conceptual framework. Previous work has studied \emph{grokking}, a training dynamic in which a sustained period of near-perfect training performance and near-chance test performance is eventually followed by generalization, as well as the superficially similar \emph{double descent}. These topics have so far been studied in isolation. We hypothesize that grokking and double descent can be understood as instances of the same learning dynamics within a framework of pattern learning speeds. We propose that this framework also applies when varying model capacity instead of optimization steps, and provide the first demonstration of model-wise grokking. 	
"Reinforcement Learning Versus Model Predictive Control on Greenhouse
  Climate Control"	http://arxiv.org/abs/2303.06110v1	2023-03-10T17:59:51Z	2023-03-10T17:59:51Z	  Greenhouse is an important protected horticulture system for feeding the world with enough fresh food. However, to maintain an ideal growing climate in a greenhouse requires resources and operational costs. In order to achieve economical and sustainable crop growth, efficient climate control of greenhouse production becomes essential. Model Predictive Control (MPC) is the most commonly used approach in the scientific literature for greenhouse climate control. However, with the developments of sensing and computing techniques, reinforcement learning (RL) is getting increasing attention recently. With each control method having its own way to state the control problem, define control goals, and seek for optimal control actions, MPC and RL are representatives of model-based and learning-based control approaches, respectively. Although researchers have applied certain forms of MPC and RL to control the greenhouse climate, very few effort has been allocated to analyze connections, differences, pros and cons between MPC and RL either from a mathematical or performance perspective. Therefore, this paper will 1) propose MPC and RL approaches for greenhouse climate control in an unified framework; 2) analyze connections and differences between MPC and RL from a mathematical perspective; 3) compare performance of MPC and RL in a simulation study and afterwards present and interpret comparative results into insights for the application of the different control approaches in different scenarios. 	
Sustainability Analysis Framework for On-Demand Public Transit Systems	http://arxiv.org/abs/2303.06007v1	2023-03-10T16:09:51Z	2023-03-10T16:09:51Z	  There is an increased interest from transit agencies to replace fixed-route transit services with on-demand public transits (ODT). However, it is still unclear when and where such a service is efficient and sustainable. To this end, we provide a comprehensive framework for assessing the sustainability of ODT systems from the perspective of overall efficiency, environmental footprint, and social equity and inclusion. The proposed framework is illustrated by applying it to the Town of Innisfil, Ontario, where an ODT system has been implemented since 2017. It can be concluded that when there is adequate supply and no surge pricing, crowdsourced ODTs are the most cost-effective transit system when the demand is below 3.37 riders/km2/day. With surge pricing applied to crowdsourced ODTs, hybrid systems become the most cost-effective transit solution when demand ranges between 1.18 and 3.37 riders/km2/day. The use of private vehicles is more environmentally sustainable than providing public transit service at all demand levels below 3.37 riders/km2/day. However, the electrification of the public transit fleet along with optimized charging strategies can reduce total yearly GHG emissions by more than 98%. Furthermore, transit systems have similar equity distributions for waiting and in-vehicle travel times. 	
"Monitoring Gender Gaps via LinkedIn Advertising Estimates: the case
  study of Italy"	http://arxiv.org/abs/2303.05862v1	2023-03-10T11:32:45Z	2023-03-10T11:32:45Z	  Women remain underrepresented in the labour market. Although significant advancements are being made to increase female participation in the workforce, the gender gap is still far from being bridged. We contribute to the growing literature on gender inequalities in the labour market, evaluating the potential of the LinkedIn estimates to monitor the evolution of the gender gaps sustainably, complementing the official data sources. In particular, assessing the labour market patterns at a subnational level in Italy. Our findings show that the LinkedIn estimates accurately capture the gender disparities in Italy regarding sociodemographic attributes such as gender, age, geographic location, seniority, and industry category. At the same time, we assess data biases such as the digitalisation gap, which impacts the representativity of the workforce in an imbalanced manner, confirming that women are under-represented in Southern Italy. Additionally to confirming the gender disparities to the official census, LinkedIn estimates are a valuable tool to provide dynamic insights; we showed an immigration flow of highly skilled women, predominantly from the South. Digital surveillance of gender inequalities with detailed and timely data is particularly significant to enable policymakers to tailor impactful campaigns. 	
"Driving action on the climate crisis through Astronomers for Planet
  Earth and beyond"	http://arxiv.org/abs/2303.05259v1	2023-03-09T13:53:18Z	2023-03-09T13:53:18Z	  While an astronomer's job is typically to look out from Earth, the seriousness of the climate crisis has meant a shift in many astronomers' focus. Astronomers are starting to consider how our resource requirements may contribute to this crisis and how we may better conduct our research in a more environmentally sustainable fashion. Astronomers for Planet Earth is an international organisation (more than 1,700 members from over 70 countries as of November 2022) that seeks to answer the call for sustainability to be at the heart of astronomers' practices. In this article, we review the organisation's history, summarising the proactive, collaborative efforts and research into astronomy sustainability conducted by its members. We update the state of affairs with respect to the carbon footprint of astronomy research, noting an improvement in renewable energy powering supercomputing facilities in Australia, reducing that component of our footprint by a factor of 2--3. We discuss how, despite accelerated changes made throughout the pandemic, we still must address the format of our meetings. Using recent annual meetings of the Australian and European astronomical societies as examples, we demonstrate that the more online-focussed a meeting is, the greater its attendance and the lower its emissions. 	
"Real-time scheduling of renewable power systems through planning-based
  reinforcement learning"	http://arxiv.org/abs/2303.05205v2	2023-03-13T08:06:17Z	2023-03-09T12:19:20Z	  The growing renewable energy sources have posed significant challenges to traditional power scheduling. It is difficult for operators to obtain accurate day-ahead forecasts of renewable generation, thereby requiring the future scheduling system to make real-time scheduling decisions aligning with ultra-short-term forecasts. Restricted by the computation speed, traditional optimization-based methods can not solve this problem. Recent developments in reinforcement learning (RL) have demonstrated the potential to solve this challenge. However, the existing RL methods are inadequate in terms of constraint complexity, algorithm performance, and environment fidelity. We are the first to propose a systematic solution based on the state-of-the-art reinforcement learning algorithm and the real power grid environment. The proposed approach enables planning and finer time resolution adjustments of power generators, including unit commitment and economic dispatch, thus increasing the grid's ability to admit more renewable energy. The well-trained scheduling agent significantly reduces renewable curtailment and load shedding, which are issues arising from traditional scheduling's reliance on inaccurate day-ahead forecasts. High-frequency control decisions exploit the existing units' flexibility, reducing the power grid's dependence on hardware transformations and saving investment and operating costs, as demonstrated in experimental results. This research exhibits the potential of reinforcement learning in promoting low-carbon and intelligent power systems and represents a solid step toward sustainable electricity generation. 	
Socioeconomics of Urban Travel in the U.S.: Evidence from the 2017 NHTS	http://arxiv.org/abs/2303.04812v1	2023-03-08T02:16:22Z	2023-03-08T02:16:22Z	  Using the 2017 National Household Travel Survey (NHTS), this study analyzes America's urban travel trends compared with earlier nationwide travel surveys, and examines the variations in travel behaviors among a range of socioeconomic groups. The most noticeable trend for the 2017 NHTS is that although private automobiles continue to be the dominant travel mode in American cities, the share of car trips has slightly and steadily decreased since its peak in 2001. In contrast, the share of transit, non-motorized, and taxicab (including ride-hailing) trips has steadily increased. Besides this overall trend, there are important variations in travel behaviors across income, home ownership, ethnicity, gender, age, and life-cycle stages. Although the trends in transit development, shared mobility, e-commerce, and lifestyle changes offer optimism about American cities becoming more multimodal, policymakers should consider these differences in socioeconomic factors and try to provide more equitable access to sustainable mobility across different socioeconomic groups. 	
Machine Learning Models Capture Plasmon Dynamics in Ag Nanoparticles	http://arxiv.org/abs/2303.04318v1	2023-03-08T01:37:26Z	2023-03-08T01:37:26Z	  Highly energetic electron-hole pairs (hot carriers) formed from plasmon decay in metallic nanostructures promise sustainable pathways for energy-harvesting devices. However, efficient collection before thermalization remains an obstacle for realization of their full energy generating potential. Addressing this challenge requires detailed understanding of physical processes from plasmon excitation in metal to their collection in a molecule or a semiconductor, where atomistic theoretical investigation may be particularly beneficial. Unfortunately, first-principles theoretical modeling of these processes is extremely costly, limiting the analysis to systems with a few 100s of atoms. Recent advances in machine learned interatomic potentials suggest that dynamics can be accelerated with surrogate models which replace the full solution of the Schroedinger Equation. Here, we modify an existing neural network, Hierarchically Interacting Particle Neural Network (HIP-NN), to predict plasmon dynamics in Ag nanoparticles. We demonstrate the model's capability to accurately predict plasmon dynamics in large nanoparticles of up to 561 atoms not present in the training dataset. More importantly, with machine learning models we gain a speed-up of about 200 times as compared with the rt-TDDFT calculations when predicting important physical quantities such as dynamic dipole moments in Ag55 and about 4000 times for extended nanoparticles that are 10 times larger. This underscores the promise of future machine learning accelerated electron/nuclear dynamics simulations for understanding fundamental properties of plasmon-driven hot carrier devices. 	
"Direct numerical simulations of turbulent mixing driven by the Faraday
  instability in rotating miscible fluids"	http://arxiv.org/abs/2303.03940v1	2023-03-07T14:50:30Z	2023-03-07T14:50:30Z	  The effect of the rotation on the turbulent mixing of two miscible fluids of small contrasting density, induced by Faraday instability, is investigated using direct numerical simulations (DNS). We quantify the irreversible mixing which depicts the conversion of the available potential energy (APE) to the background potential energy (BPE) through irreversible mixing rate $\mathcal{M}$. We demonstrate that at lower forcing amplitudes, the turbulent kinetic energy ($t.k.e.$) increases with an increase in the Coriolis frequency $f$ till $\left(f/\omega\right)^2<0.25$, where $\omega$ is the forcing frequency, during the sub-harmonic instability phase. This enhancement of $t.k.e.$ is attributed to the excitement of more unstable modes. The irreversible mixing sustains for an extended period with increasing $\left(f/\omega\right)^2$ till $0.25$ owing to the prolonged sub-harmonic instability phase and eventually ceases with instability saturation. When $\left(f/\omega\right)^2 > 0.25$, the Coriolis force significantly delays the onset of the sub-harmonic instabilities. The strong rotational effects result in lower turbulence because the bulk of the APE expends to BPE, decreasing APE that converts back to $t.k.e.$ reservoir for $\left(f/\omega\right)^2 > 0.25$. Since the instability never saturates for $\left(f/\omega\right)^2 > 0.25$, conversion of APE to BPE via $\mathcal{M}$ continues, and we find prolonged irreversible mixing. At higher forcing amplitudes, the instability delaying effect of rotation is negligible, and the turbulence is less intense and short-lived. Therefore, the irreversible mixing phenomenon also ends quickly for $\left(f/\omega\right)^2<0.25$. However, when $\left(f/\omega\right)^2>0.25$, a continuous irreversible mixing is observed. 	
"An approximation of populations on a habitat with large carrying
  capacity"	http://arxiv.org/abs/2303.03735v1	2023-03-07T08:51:16Z	2023-03-07T08:51:16Z	  We consider stochastic dynamics of a population which starts from a small colony on a habitat with large but limited carrying capacity. A common heuristics suggests that such population grows initially as a Galton-Watson branching process and then its size follows an almost deterministic path until reaching its maximum, sustainable by the habitat. In this paper we put forward an alternative and, in fact, more accurate approximation which suggests that the population size behaves as a special nonlinear transformation of the Galton Watson process from the very beginning. 	
Population III X-ray Binaries and their Impact on the Early Universe	http://arxiv.org/abs/2303.03435v1	2023-03-06T19:01:07Z	2023-03-06T19:01:07Z	  The first population of X-ray binaries (XRBs) is expected to affect the thermal and ionization states of the gas in the early Universe. Although these X-ray sources are predicted to have important implications for high-redshift observable signals, such as the hydrogen 21-cm signal from cosmic dawn and the cosmic X-ray background, their properties are poorly explored, leaving theoretical models largely uninformed. In this paper we model a population of X-ray binaries arising from zero metallicity stars. We explore how their properties depend on the adopted initial mass function (IMF) of primordial stars, finding a strong effect on their number and X-ray production efficiency. We also present scaling relations between XRBs and their X-ray emission with the local star formation rate, which can be used in sub-grid models in numerical simulations to improve the X-ray feedback prescriptions. Specifically, we find that the uniformity and strength of the X-ray feedback in the intergalactic medium is strongly dependant on the IMF. Bottom-heavy IMFs result in a smoother distribution of XRBs, but have a luminosity orders of magnitude lower than more top-heavy IMFs. Top-heavy IMFs lead to more spatially uneven, albeit strong, X-ray emission. An intermediate IMF has a strong X-ray feedback while sustaining an even emission across the intergalactic medium. These differences in X-ray feedback could be probed in the future with measurements of the cosmic dawn 21-cm line of neutral hydrogen, which offers us a new way of constraining population III IMF. 	
"Spectrally resolved cosmic rays -- III. Dynamical impact and properties
  of the circumgalactic medium"	http://arxiv.org/abs/2303.03417v1	2023-03-06T19:00:03Z	2023-03-06T19:00:03Z	  Cosmic rays (CRs) are dynamically important for the formation and evolution of galaxies by regulating star formation and by powering galactic outflows. However, to what extent CRs regulate galaxy formation depends on the coupling strength of CRs with the ambient plasma and the effective CR transport speed along the magnetic field. Moreover, both properties sensitively depend on the CR momentum, which is largely unexplored in three-dimensional hydrodynamical simulations. We perform magneto-hydrodynamical simulations of entire galaxies with masses ranging from $10^{10}$ to $10^{12}\,\mathrm{M}_\odot$ and compare dynamically coupled CRs in the grey approximation with a spectrally resolved model that includes CR momenta from $0.1\,\mathrm{GeV}~c^{-1}$ to $100\,\mathrm{TeV}~c^{-1}$. We find that hadronic cooling of CRs dominates over Alfv\'{e}n cooling, with the latter emulating CR losses as a result of streaming of CRs down their pressure gradient. While star formation rates and galaxy morphologies are only mildly affected by the spectral CR modelling, mass loading factors of galactic outflows can differ by up to a factor of four in dwarf galaxies. All simulated low-mass halos ($M=10^{10}$, $10^{11}$, and $3\times10^{11}\,\mathrm{M}_\odot$) drive strong outflows, where CR transport is temporally dominated by advection. In contrast, the Milky Way-mass galaxy with $M=10^{12}\,\mathrm{M}_\odot$ does not drive sustained outflows, so that CR transport is entirely dominated by diffusion. The effective energy weighted diffusion coefficients vary by two orders of magnitude from the canonical energy-weighted values of $\langle{D}\rangle_{e_\mathrm{cr}}\sim10^{28}\,\mathrm{cm^2\,s^{-1}}$ in the disc up to $3\times10^{29}\,\mathrm{cm^2\,s^{-1}}$ in the circumgalactic medium, where we observe substantial temperature and CR pressure differences between our grey and spectral CR models. 	
"ChatGPT is on the horizon: Could a large language model be all we need
  for Intelligent Transportation?"	http://arxiv.org/abs/2303.05382v1	2023-03-06T16:36:17Z	2023-03-06T16:36:17Z	  ChatGPT, developed by OpenAI, is one of the largest Large Language Models (LLM) with over 175 billion parameters. ChatGPT has demonstrated the impressive capabilities of LLM, particularly in the field of natural language processing (NLP). With the emergence of the discussion and application of LLM in various research or engineering domains, it is time to envision how LLM may revolutionize the way we approach intelligent transportation systems. This paper explores the future applications of LLM in addressing key transportation problems. By leveraging LLM and a cross-modal encoder, an intelligent system can handle traffic data from various modalities and execute transportation operations through a single LLM. NLP, combined with cross-modal processing, is investigated with its potential applications in transportation. To demonstrate this potential, a smartphone-based crash report auto-generation and analysis framework is presented as a use case. Despite the potential benefits, challenges related to data privacy, data quality, and model bias must be considered. Overall, the use of LLM in intelligent transport systems holds promise for more efficient, intelligent, and sustainable transportation systems that improve the lives of people around the world. 	
"Using a Variational Autoencoder to Learn Valid Search Spaces of Safely
  Monitored Autonomous Robots for Last-Mile Delivery"	http://arxiv.org/abs/2303.03211v1	2023-03-06T15:13:35Z	2023-03-06T15:13:35Z	  The use of autonomous robots for delivery of goods to customers is an exciting new way to provide a reliable and sustainable service. However, in the real world, autonomous robots still require human supervision for safety reasons. We tackle the realworld problem of optimizing autonomous robot timings to maximize deliveries, while ensuring that there are never too many robots running simultaneously so that they can be monitored safely. We assess the use of a recent hybrid machine-learningoptimization approach COIL (constrained optimization in learned latent space) and compare it with a baseline genetic algorithm for the purposes of exploring variations of this problem. We also investigate new methods for improving the speed and efficiency of COIL. We show that only COIL can find valid solutions where appropriate numbers of robots run simultaneously for all problem variations tested. We also show that when COIL has learned its latent representation, it can optimize 10% faster than the GA, making it a good choice for daily re-optimization of robots where delivery requests for each day are allocated to robots while maintaining safe numbers of robots running at once. 	
"U-Park: A User-Centric Smart Parking Recommendation System for Electric
  Shared Micromobility Services"	http://arxiv.org/abs/2303.03152v1	2023-03-06T14:09:27Z	2023-03-06T14:09:27Z	  At present, electric shared micromobility services (ESMS) have become an important part of the mobility as a service (MaaS) paradigm for sustainable transportation systems. However, current ESMS suffer from critical design issues such as a lack of integration, transparency and user-centric approaches, resulting in high operational costs and poor service quality. A key operational challenge in ESMS is related to parking, particularly how to ensure a shared vehicle has a parking space when the user is approaching the destination. For instance, our recent study illustrated that up to 12.9% of shared E-bike users in Dublin, Ireland cannot park their E-bikes properly due to a lack of planning and user-centric guidance. To address this challenge, in this paper we propose U-Park, a user-centric smart parking recommendation system for ESMS aiming at making personalised recommendations to ESMS users by considering a given user's historical mobility data, current trip trajectory and parking space availability. We propose the system architecture, implement it, and evaluate its performance based on a real-world dataset from an Irish-based shared E-bike company, Moby bikes. Our results illustrate that U-Park can effectively predict a user's destination in a shared E-bike system with around 97.33% accuracy without direct user inputs, and such results can be subsequently used to recommend the best parking station for the user depending on the availability of predicted parking spaces. Finally, a blockchain-empowered module is blended to manage various transactions due to its advantage in safety and transparency in this process, including prepays and parking fines. 	
"Can occupant behaviors affect urban energy planning? Distributed
  stochastic optimization for energy communities"	http://arxiv.org/abs/2303.03006v1	2023-03-06T10:16:33Z	2023-03-06T10:16:33Z	  To meet carbon emission reduction goals in line with the Paris agreement, planning resilient and sustainable energy systems has never been more important. In the building sector, particularly, strategic urban energy planning engenders large optimization problems across multiple spatiotemporal scales leading to necessary system scope simplifications. This has resulted in disconnected system scales, namely, building occupants and smart-city energy networks. This paper intends on bridging these disjointed scales to secure both resilient and more energy-efficient urban planning thanks to a holistic approach. The intent is to assess the aggregated impact of user behavior stochasticities on optimal urban energy planning. To this end, a stochastic energy community sizing and operation problem is designed, encompassing multi-level utilities founded on energy hub concepts for improved energy and carbon emission efficiencies. To secure the scalability of our approach, an organic spatial problem distribution suitable for field deployment is put forth, validated by a proof of concept. Uncertainty factors affecting urban energy planning are particularly examined through a local sensitivity analysis, namely, economic, climate, and occupant-behavior uncertainties. Founded on historical measurements a typical Dutch energy community composed of 41 residential buildings is designed. Results disclose a fast-converging distributed stochastic problem, where boilers are showcased as the preferred heating utility, and distributed renewable energy and storage systems were identified as unprofitable for the community. Occupant behavior was particularly exposed as the leading uncertainty factor impacting energy community planning. This demonstrates the relevance and value of our approach in connecting occupants to cities for improved, and more resilient, urban energy planning strategies. 	
Artificial Intelligence: 70 Years Down the Road	http://arxiv.org/abs/2303.02819v1	2023-03-06T01:19:25Z	2023-03-06T01:19:25Z	  Artificial intelligence (AI) has a history of nearly a century from its inception to the present day. We have summarized the development trends and discovered universal rules, including both success and failure. We have analyzed the reasons from both technical and philosophical perspectives to help understand the reasons behind the past failures and current successes of AI, and to provide a basis for thinking and exploring future development. Specifically, we have found that the development of AI in different fields, including computer vision, natural language processing, and machine learning, follows a pattern from rules to statistics to data-driven methods. In the face of past failures and current successes, we need to think systematically about the reasons behind them. Given the unity of AI between natural and social sciences, it is necessary to incorporate philosophical thinking to understand and solve AI problems, and we believe that starting from the dialectical method of Marx is a feasible path. We have concluded that the sustainable development direction of AI should be human-machine collaboration and a technology path centered on computing power. Finally, we have summarized the impact of AI on society from this trend. 	
"Unidirectional Droplet Propulsion onto Gradient Brushes without External
  Energy Supply"	http://arxiv.org/abs/2303.02652v1	2023-03-05T11:59:37Z	2023-03-05T11:59:37Z	  Using extensive molecular dynamics simulation of a coarse-grained model, we demonstrate the possibility of sustained unidirectional motion (durotaxis) of droplets without external energy supply when placed on a polymer brush substrate with stiffness gradient in a certain direction. The governing key parameters for the specific substrate design studied, which determine the durotaxis efficiency, are found to be the grafting density of the brush and the droplet adhesion to the brush surface, whereas the strength of the stiffness gradient, the viscosity of the droplet, or the length of the polymer chains of the brush have only a minor effect on the process. It is shown that this durotaxial motion is driven by the steady increase of the interfacial energy between droplet and brush as the droplet moves from softer to stiffer parts of the substrate whereby the mean driving force gradually declines with decreasing roughness of the brush surface. We anticipate that our findings indicate further possibilities in the area of nanoscale motion without external energy supply. 	
"Chasing Low-Carbon Electricity for Practical and Sustainable DNN
  Training"	http://arxiv.org/abs/2303.02508v1	2023-03-04T21:33:29Z	2023-03-04T21:33:29Z	  Deep learning has experienced significant growth in recent years, resulting in increased energy consumption and carbon emission from the use of GPUs for training deep neural networks (DNNs). Answering the call for sustainability, conventional solutions have attempted to move training jobs to locations or time frames with lower carbon intensity. However, moving jobs to other locations may not always be feasible due to large dataset sizes or data regulations. Moreover, postponing training can negatively impact application service quality because the DNNs backing the service are not updated in a timely fashion. In this work, we present a practical solution that reduces the carbon footprint of DNN training without migrating or postponing jobs. Specifically, our solution observes real-time carbon intensity shifts during training and controls the energy consumption of GPUs, thereby reducing carbon footprint while maintaining training performance. Furthermore, in order to proactively adapt to shifting carbon intensity, we propose a lightweight machine learning algorithm that predicts the carbon intensity of the upcoming time frame. Our solution, Chase, reduces the total carbon footprint of training ResNet-50 on ImageNet by 13.6% while only increasing training time by 2.5%. 	
"Highly Efficient Hydrogen Storage of Sc Decorated Biphenylene Monolayer
  near Ambient-temperature: An Ab-initio Simulation"	http://arxiv.org/abs/2303.02345v1	2023-03-04T07:22:38Z	2023-03-04T07:22:38Z	  The energy demands for the growing development of society need to be catered with alternative and green fuels like hydrogen energy for a lasting and sustainable culture. One essential component of the hydrogen economy is the efficiency of its storage. We have studied the hydrogen-storage capability on a recently synthesized Biphenylene (BPh) decorated with Sc using the first-principles density functional theory (DFT) and ab-initio molecular dynamics (AIMD) techniques. Scandium attaches BPh sheet strongly with binding energy -3.84 eV, and single Sc decorated on BPh can absorb a maximum of five H$_2$ molecules resulting in a high gravimetric weight percentage of 11.07, which is significantly higher than DoE's ultimate criteria (6.5 wt%). Using van't Hoff equation, strongly and weakly attached hydrogens correspond to desorption temperatures of 200 K and 397 K with an average of 305 K. The high binding of Sc to BPh is due to charge donation of 3d orbital of Sc to 2p orbital of C. The interactions between absorbed H$_2$ and BPh+Sc are due to charge transfer from 3d-orbital of Sc to ${\sigma}$* bond of H$_2$ molecules and backdonation from ${\sigma}$ bond of H$_2$ to empty 3d-orbital of Sc known as Kubas type interaction. Furthermore, phonon and AIMD simulation confirm BPh+Sc stability, and the presence of an energy barrier shows no probability of Sc-Sc clustering on BPh. So theoretically stable BPh+Sc showing high gravimetric weight percentage with an average 305 K desorption temperature, might be a potential candidate for solidstage hydrogen devices. 	
"Quantum sensing of paramagnetic spins in liquids with spin qubits in
  hexagonal boron nitride"	http://arxiv.org/abs/2303.02326v1	2023-03-04T05:11:56Z	2023-03-04T05:11:56Z	  Paramagnetic ions and radicals play essential roles in biology and medicine, but detecting these species requires a highly sensitive and ambient-operable sensor. Optically addressable spin color centers in 3D semiconductors have been used for detecting paramagnetic spins as they are sensitive to the spin magnetic noise. However, the distance between spin color centers and target spins is limited due to the difficulty of creating high-quality spin defects near the surface of 3D materials. Here, we show that spin qubits in hexagonal boron nitride (hBN), a layered van der Waals (vdW) material, can serve as a promising sensor for nanoscale detection of paramagnetic spins in liquids. We first create shallow spin defects in close proximity to the hBN surface, which sustain high-contrast optically detected magnetic resonance (ODMR) in liquids. Then we demonstrate sensing spin noise of paramagnetic ions in water based on spin relaxation measurements. Finally, we show that paramagnetic ions can reduce the contrast of spin-dependent fluorescence, enabling efficient detection by continuous wave ODMR. Our results demonstrate the potential of ultrathin hBN quantum sensors for chemical and biological applications. 	
"Affordable Artificial Intelligence -- Augmenting Farmer Knowledge with
  AI"	http://arxiv.org/abs/2303.06049v1	2023-03-04T02:29:52Z	2023-03-04T02:29:52Z	  Farms produce hundreds of thousands of data points on the ground daily. Farming technique which combines farming practices with the insights uncovered in these data points using AI technology is called precision farming. Precision farming technology augments and extends farmers' deep knowledge about their land, making production more sustainable and profitable. As part of the larger effort at Microsoft for empowering agricultural labor force to be more productive and sustainable, this paper presents the AI technology for predicting micro-climate conditions on the farm.   This article is a chapter in publication by Food and Agriculture Organization of the United Nations and International Telecommunication Union Bangkok, 2021. This publication on artificial intelligence (AI) for agriculture is the fifth in the E-agriculture in Action series, launched in 2016 and jointly produced by FAO and ITU. It aims to raise awareness about existing AI applications in agriculture and to inspire stakeholders to develop and replicate the new ones. Improvement of capacity and tools for capturing and processing data and substantial advances in the field of machine learning open new horizons for data-driven solutions that can support decision-making, facilitate supervision and monitoring, improve the timeliness and effectiveness of safety measures (e.g. use of pesticides), and support automation of many resource-consuming tasks in agriculture. This publication presents the reader with a collection of informative applications highlighting various ways AI is used in agriculture and offering valuable insights on the implementation process, success factors, and lessons learnt. 	
OASIS: Automated Assessment of Urban Pedestrian Paths at Scale	http://arxiv.org/abs/2303.02287v1	2023-03-04T01:32:59Z	2023-03-04T01:32:59Z	  The inspection of the Public Right of Way (PROW) for accessibility barriers is necessary for monitoring and maintaining the built environment for communities' walkability, rollability, safety, active transportation, and sustainability. However, an inspection of the PROW, by surveyors or crowds, is laborious, inconsistent, costly, and unscalable. The core of smart city developments involves the application of information technologies toward municipal assets assessment and management. Sidewalks, in comparison to automobile roads, have not been regularly integrated into information systems to optimize or inform civic services. We develop an Open Automated Sidewalks Inspection System (OASIS), a free and open-source automated mapping system, to extract sidewalk network data using mobile physical devices. OASIS leverages advances in neural networks, image sensing, location-based methods, and compact hardware to perform sidewalk segmentation and mapping along with the identification of barriers to generate a GIS pedestrian transportation layer that is available for routing as well as analytic and operational reports. We describe a prototype system trained and tested with imagery collected in real-world settings, alongside human surveyors who are part of the local transit pathway review team. Pilots show promising precision and recall for path mapping (0.94, 0.98 respectively). Moreover, surveyor teams' functional efficiency increased in the field. By design, OASIS takes adoption aspects into consideration to ensure the system could be easily integrated with governmental pathway review teams' workflows, and that the outcome data would be interoperable with public data commons. 	
Stochastic models of ventilation driven by opposing wind and buoyancy	http://arxiv.org/abs/2303.02068v1	2023-03-03T16:35:37Z	2023-03-03T16:35:37Z	  Stochastic versions of a classical model for natural ventilation are proposed and investigated to demonstrate the effect of random fluctuations on stability and predictability. In a stochastic context, the well-known deterministic result that ventilation driven by the competing effects of buoyancy and wind admits multiple steady states can be misleading, due to two distinct phenomena. First, with fluctuations in the buoyancy exchanged with an external environment, such systems eventually reside in the vicinity of global minima of their potential, rather than local minima associated with meta-stable equilibria. In the particular context of one heated space with a leeward low-level and windward high-level opening, a sustained buoyancy-driven flow opposing the wind direction is unlikely for wind strengths that exceed a statistically critical value, which is slightly larger than the critical value of the wind strength at which bifurcation in the deterministic system occurs. Second, fluctuations in the applied wind modify the topology of the system's potential due to the nonlinear role that wind strength has in the equation for buoyancy conservation. Sufficiently large fluctuations in the wind rule out the possibility of ventilation opposing the wind direction at large base wind strengths. Although the phenomena described above might be perceived as making prediction easier, the results also highlight that certainty in the eventual state of the system goes hand in hand with uncertainty associated with longer transient effects. The work addresses growing interest in applying stochastic analysis to problems relating to building ventilation and urban fluid mechanics by describing a mathematically accessible example of the `stochasticisation' of a canonical deterministic model, while highlighting the subtleties and challenges of developing stochastic models for ventilation in the future. 	
The barriers to sustainable risk transfer in the cyber-insurance market	http://arxiv.org/abs/2303.02061v1	2023-03-03T16:29:16Z	2023-03-03T16:29:16Z	  Smooth risk transfer is a key condition for the development of an insurance market that is well-functioning and sustainable. The constantly evolving nature of cyber-threats and lack of public data sharing means the economic conditions required for quoted cyber-insurance premiums to be considered efficient are highly unlikely to be met. This paper develops Monte Carlo simulations of an artificial cyber-insurance market and compares the efficient and inefficient outcomes based on the informational setup between the market participants. The existence of diverse loss distributions is justified by the dynamic nature of cyber-threats and the absence of any reliable and centralised incident reporting. We show that the limited involvement of reinsurers when loss expectations are not shared leads to increased premia and lower overall capacity. This suggests that the sustainability of the cyber-insurance market requires both better data sharing and external sources of risk tolerant capital. 	
"Light-induced coherent interlayer transport in stripe-ordered ${\rm
  La}_{1.6-x}{\rm Nd}_{0.4}{\rm Sr}_{x}{\rm CuO}_{4}$"	http://arxiv.org/abs/2303.01961v1	2023-03-03T14:35:03Z	2023-03-03T14:35:03Z	  We have investigated the photoexcited transient responses of stripe-ordered phase in a cuprate superconductor, ${\rm La}_{1.6-x}{\rm Nd}_{0.4}{\rm Sr}_{x}{\rm CuO}_{4}~(x = 0.12)$ using optical-pump terahertz (THz)-probe spectroscopy. Upon the near-infrared photoexcitation with the electric field polarized along the $c$-axis, a clear plasma edge appears in the THz reflection spectrum along the $c$-axis with its position nearly coinciding with the Josephson plasma resonance of similarly doped ${\rm La}_{2-x}{\rm Sr}_{x}{\rm CuO}_{4}~(x = 0.125)$ in the low-temperature superconducting phase. The appearance of light-induced plasma edge sustains up to the onset temperature of the charge-stripe order, indicating the inherent interplay between the light-induced phase and the charge-stripe order. The optical conductivity spectrum of the light-induced state is mostly reproduced by the Drude model with a scattering rate as small as a few meV, and its imaginary part does not exhibit $1/{\omega}$-divergence behavior in any temporal region after the photoexcitation. We discuss the possible origin of the observed coherent interlayer transport behavior as manifested by the narrow Drude response in the THz reflectivity along the $c$-axis. 	
"Unappreciated cross-helicity effects in plasma physics: Anti-diffusion
  effects in dynamo and momentum transport"	http://arxiv.org/abs/2303.01834v1	2023-03-03T10:34:00Z	2023-03-03T10:34:00Z	  The cross helicity (velocity--magnetic-field correlation) effects in the magnetic-field induction and momentum transport in the magnetohydrodynamic (MHD) turbulence are investigated with the aid of the multiple-scale renormalized perturbation expansion analysis. The outline of the theory is presented with reference to the role of the cross-interaction response functions between the velocity and magnetic field. In this formulation, the expressions of the turbulent fluxes: the turbulent electromotive force (EMF) in the mean induction equation and the Reynolds and turbulent Maxwell stresses in the momentum equation are obtained. Related to the expression of EMF, the physical origin of the cross-helicity effect in dynamos, as well as other dynamo effects, is discussed. In order to understand the actual role of the turbulent cross helicity, its transport equations is considered. Several generation mechanisms of cross helicity are discussed with illustrative examples. On the basis of the cross-helicity production mechanisms, its effect in stellar dynamos is discussed. The role of cross helicity in the momentum transport and global flow generation is also argued. Characteristic features of turbulence effects in fast reconnection are reviewed with special emphasis on the role of cross helicity in localizing the effective resistivity. Finally, a remark is addressed on an approach that elucidates the structure generation and sustainment in extremely strong turbulence. An appropriate formulation for the anti-diffusion effect, which acts against the usual diffusion effect, is needed. Turbulence modeling approach based on such an analytical formulation is also argued in comparison with the conventional heuristic modeling. The importance of the self-consistent framework treating the non-linear interaction between the mean field and turbulence is stressed as well. 	
A Concise and Formal Definition of RAF Sets and the RAF Algorithm	http://arxiv.org/abs/2303.01809v1	2023-03-03T09:31:29Z	2023-03-03T09:31:29Z	  Autocatalytic sets are self-catalyzing and self-sustaining chemical reaction networks that are believed to have played an important role in the origin of life. They have been studied extensively both theoretically as well as experimentally. This short note provides (1) a complete and formal definition of autocatalytic sets (or RAF sets), and (2) an efficient algorithm to detect such sets in arbitrary reaction networks. Although both have been presented in various forms in earlier publications, this note serves as a concise and convenient reference. 	
"A chemotaxis reaction-diffusion model for Multiple Sclerosis with Allee
  effect"	http://arxiv.org/abs/2303.01764v1	2023-03-03T08:06:51Z	2023-03-03T08:06:51Z	  In this paper, we study a modification of the mathematical model describing inflammation and demyelination patterns in the brain caused by Multiple Sclerosis proposed in [Lombardo et al. (2017), Journal of Mathematical Biology, 75, 373--417]. In particular, we hypothesize a minimal amount of macrophages to be able to start and sustain the inflammatory response. Thus, the model function for macrophage activation includes an Allee effect. We investigate the emergence of Turing patterns by combining linearised and weakly nonlinear analysis, bifurcation diagrams and numerical simulations, focusing on the comparison with the previous model. 	
"EigenMPC: An Eigenmanifold-Inspired Model-Predictive Control Framework
  for Exciting Efficient Oscillations in Mechanical Systems"	http://arxiv.org/abs/2303.01705v1	2023-03-03T04:12:48Z	2023-03-03T04:12:48Z	  This paper proposes a Nonlinear Model-Predictive Control (NMPC) method capable of finding and converging to energy-efficient regular oscillations, which require no control action to be sustained. The approach builds up on the recently developed Eigenmanifold theory, which defines the sets of line-shaped oscillations of a robot as an invariant two-dimensional submanifold of its state space. By defining the control problem as a nonlinear program (NLP), the controller is able to deal with constraints in the state and control variables and be energy-efficient not only in its final trajectory but also during the convergence phase. An initial implementation of this approach is proposed, analyzed, and tested in simulation. 	
Ejecta from the DART-produced active asteroid Dimorphos	http://arxiv.org/abs/2303.01700v1	2023-03-03T04:04:33Z	2023-03-03T04:04:33Z	  Some active asteroids have been proposed to be the result of impact events. Because active asteroids are generally discovered serendipitously only after their tail formation, the process of the impact ejecta evolving into a tail has never been directly observed. NASA's Double Asteroid Redirection Test (DART) mission, apart from having successfully changed the orbital period of Dimorphos, demonstrated the activation process of an asteroid from an impact under precisely known impact conditions. Here we report the observations of the DART impact ejecta with the Hubble Space Telescope (HST) from impact time T+15 minutes to T+18.5 days at spatial resolutions of ~2.1 km per pixel. Our observations reveal a complex evolution of ejecta, which is first dominated by the gravitational interaction between the Didymos binary system and the ejected dust and later by solar radiation pressure. The lowest-speed ejecta dispersed via a sustained tail that displayed a consistent morphology with previously observed asteroid tails thought to be produced by impact. The ejecta evolution following DART's controlled impact experiment thus provides a framework for understanding the fundamental mechanisms acting on asteroids disrupted by natural impact. 	
MiShape: 3D Shape Modelling of Mitochondria in Microscopy	http://arxiv.org/abs/2303.01546v1	2023-03-02T19:21:21Z	2023-03-02T19:21:21Z	  Fluorescence microscopy is a quintessential tool for observing cells and understanding the underlying mechanisms of life-sustaining processes of all living organisms. The problem of extracting 3D shape of mitochondria from fluorescence microscopy images remains unsolved due to the complex and varied shapes expressed by mitochondria and the poor resolving capacity of these microscopes. We propose an approach to bridge this gap by learning a shape prior for mitochondria termed as MiShape, by leveraging high-resolution electron microscopy data. MiShape is a generative model learned using implicit representations of mitochondrial shapes. It provides a shape distribution that can be used to generate infinite realistic mitochondrial shapes. We demonstrate the representation power of MiShape and its utility for 3D shape reconstruction given a single 2D fluorescence image or a small 3D stack of 2D slices. We also showcase applications of our method by deriving simulated fluorescence microscope datasets that have realistic 3D ground truths for the problem of 2D segmentation and microscope-to-microscope transformation. 	
BikeDNA: A Tool for Bicycle Infrastructure Data & Network Assessment	http://arxiv.org/abs/2303.01223v1	2023-03-02T13:06:59Z	2023-03-02T13:06:59Z	  High-quality data on existing bicycle infrastructure are a requirement for evidence-based bicycle network planning, which supports a green transition of human mobility. However, this requirement is rarely met: Data from governmental agencies or crowdsourced projects like OpenStreetMap often suffer from unknown, heterogeneous, or low quality. Currently available tools for road network data quality assessment often fail to account for network topology, spatial heterogeneity, and bicycle-specific data characteristics. To fill these gaps, we introduce BikeDNA, an open-source tool for reproducible quality assessment tailored to bicycle infrastructure data with a focus on network structure and connectivity. BikeDNA performs either a standalone analysis of one data set or a comparative analysis between OpenStreetMap and a reference data set, including feature matching. Data quality metrics are considered both globally for the entire study area and locally on grid cell level, thus exposing spatial variation in data quality. Interactive maps and HTML/PDF reports are generated to facilitate the visual exploration and communication of results. BikeDNA supports quality assessments of bicycle infrastructure data for a wide range of applications -- from urban planning to OpenStreetMap data improvement or network research for sustainable mobility. 	
Quenching star formation with low-luminosity AGN winds	http://arxiv.org/abs/2303.00826v1	2023-03-01T21:24:57Z	2023-03-01T21:24:57Z	  We present a simple model for low-luminosity active galactic nucleus (LLAGN) feedback through thermal winds produced by a hot accretion flow. The wind carries considerable energy and deposits it on the host galaxy at kiloparsec scales and beyond, heating the galactic gas thereby quenching star formation. Our model predicts that the typical LLAGN can quench more than $10\%$ of star formation in its host galaxy. We find that long-lived LLAGN winds from supermassive black holes (SMBH) with masses $\geq 10^8 M_{\odot}$ and mass accretion rates $\dot{M} > 10^{-3}\dot{M}_{\rm Edd}$ can prevent gas collapse and significantly quench galactic star formation compared to a scenario without AGN, if the wind persists over 1 Myr. For sustained wind production over timescales of 10 Myr or longer, SMBHs with $10^8 M_{\odot}$ or larger masses have important feedback effects with $\dot{M} > 10^{-4} \dot{M}_{\rm Edd}$. 	
An Overview: Steady-State Quantum Entanglement via Reservoir Engineering	http://arxiv.org/abs/2303.00490v1	2023-03-01T13:26:05Z	2023-03-01T13:26:05Z	  We present a short overview of quantum entanglement generation and preservation in a steady state. In addition to the focus on quantum entanglement stabilization, we briefly discuss the same objective for steady-state quantum coherence. The overview classifies the approaches into two main categories: hybrid drive and dissipation methods and purely dissipative schemes. Furthermore, purely dissipative schemes are discussed under two subclasses of equilibrium and nonequilibrium environments. The significance of the dissipative route to sustained quantum entanglement and challenges against it are pointed out. Besides the value of steady-state entanglement for existing quantum technologies, quantum computation, communication, sensing, and simulation, its unique opportunities for emerging and future quantum technology applications, particularly quantum heat engines and quantum energy processing, are discussed. 	
Green Hydrogen Cost-Potentials for Global Trade	http://arxiv.org/abs/2303.00314v1	2023-03-01T08:19:48Z	2023-03-01T08:19:48Z	  Green hydrogen is expected to be traded globally in future greenhouse gas neutral energy systems. However, there is still a lack of temporally- and spatially-explicit cost-potentials for green hydrogen considering the full process chain, which are necessary for creating effective global strategies. Therefore, this study provides such detailed cost-potential-curves for 28 selected countries worldwide until 2050, using an optimizing energy systems approach based on open-field PV and onshore wind. The results reveal huge hydrogen potentials (>1,500 PWh/a) and 86 PWh/a at costs below 2 EUR/kg in 2050, dominated by solar-rich countries in Africa and the Middle East. Decentralized PV-based hydrogen production, even in wind-rich countries, is always preferred. Supplying sustainable water for hydrogen production is needed while having minor impact on hydrogen cost. Additional costs for imports from democratic regions only total 7%. Hence, such regions could boost the geostrategic security of supply for greenhouse gas neutral energy systems. 	
"Comet P/2021 HS (PANSTARRS) and the Challenge of Detecting Low-Activity
  Comets"	http://arxiv.org/abs/2303.00221v1	2023-03-01T03:59:30Z	2023-03-01T03:59:30Z	  Jupiter-family comet (JFC) P/2021 HS (PANSTARRS) only exhibits a coma within a few weeks of its perihelion passage at 0.8~au, which is atypical for a comet. Here we present an investigation into the underlying cause using serendipitous survey detections as well as targeted observations. We find that the detection of the activity is caused by an extremely faint coma being enhanced by forward scattering effect due to the comet reaching a phase angle of $\sim140^\circ$. The coma morphology is consistent with sustained, sublimation-driven activity produced by a small active area, $\sim700~\mathrm{m^2}$, one of the smallest values ever measured on a comet. The phase function of the nucleus shows a phase coefficient of $0.035\pm0.002~\mathrm{mag/deg}$, implying an absolute magnitude of $H=18.31\pm0.04$ and a phase slope of $G=-0.13$, with color consistent with typical JFC nuclei. Thermal observations suggest a nucleus diameter of 0.6--1.1~km, implying an optical albedo of 0.04--0.23 which is higher than typical cometary nuclei. An unsuccessful search for dust trail and meteor activity confirms minimal dust deposit along the orbit, totaling $\lesssim10^8$~kg. As P/2021 HS is dynamically unstable, similar to typical JFCs, we speculate that it has an origin in the trans-Neptunian region, and that its extreme depletion of volatiles is caused by a large number of previous passages to the inner Solar System. The dramatic discovery of the cometary nature of P/2021 HS highlights the challenges of detecting comets with extremely low activity levels. Observations at high phase angle where forward scattering is pronounced will help identify such comets. 	
"Analysis of Cooperative and Non-Cooperative Architectures for
  Multi-Plane On-Orbit Refueling"	http://arxiv.org/abs/2302.14563v1	2023-02-28T13:38:55Z	2023-02-28T13:38:55Z	  As many satellite constellations are proposed, deployed, and operated, their maintenance becomes increasingly important to provide satisfactory services; therefore, on-orbit refueling to spacecraft has become one of the most promising technologies for realizing more sustainable space development. This paper develops an analytical model to examine two types of mission architectures for multi-target on-orbit refueling missions: a non-cooperative architecture and a cooperative architecture. In the (rather conventional) non-cooperative refueling architecture, a servicer spacecraft visits passive targets one by one, whereas, in the cooperative refueling architecture, both the servicer and the targets can actively maneuver to complete refueling cooperatively. This paper analytically compares the fuel mass required in each architecture to support the decision-making process of mission architects. Furthermore, the condition under which the cooperative architecture becomes more efficient than the non-cooperative architecture is analytically derived. The sensitivities of this condition against key mission parameters, such as the number of targets and their inclination, are also analyzed through a case study of multi-plane multi-target on-orbit refueling in low Earth orbits. 	
"Energy Efficiency and Throughput of Random Access Protocols for
  RIS-Aided IoT Networks"	http://arxiv.org/abs/2302.14453v1	2023-02-28T09:58:13Z	2023-02-28T09:58:13Z	  Green Internet of Things (IoT) aims to enable a sustainable smart world by making energy efficiency (EE) the main performance indicator for IoT hardware and software. With respect to network design, this implies in developing energy-efficient communication protocols and network architectures adapted to the ubiquitousness of the IoT machine-type devices (MTDs) and the sporadic traffic generated by them, keeping a low power consumption at the MTDs-side. In this sense, reconfigurable intelligent surfaces (RISs) have presented the capacity of significantly improving the network coverage using mostly passive reflecting elements, drastically reducing the power expenditure. In this paper, we develop a realistic power consumption model and an expression for the overall system EE for RIS-aided IoT networks that adopt a two time-scale random access (RA) protocol to handle the uplink transmissions. Specifically, during each time slot of the RA protocol, the RIS covers a specific area of interest in the communication cell with a predefined set of phase-shift configurations, changing the channel qualities of the contending MTDs. Numerical results comparing the RA protocol performance reveal that access policies that exploit information of the channel qualities are suitable for green IoT networks, simultaneously attaining competitive EE and throughput combined with low power consumption at the MTDs-side. 	
"WhereWulff: A semi-autonomous workflow for systematic catalyst surface
  reactivity under reaction conditions"	http://arxiv.org/abs/2302.14103v1	2023-02-27T19:29:41Z	2023-02-27T19:29:41Z	  This paper introduces WhereWulff, a semi-autonomous workflow for modeling the reactivity of catalyst surfaces. The workflow begins with a bulk optimization task that takes an initial bulk structure, and returns the optimized bulk geometry and magnetic state, including stability under reaction conditions. The stable bulk structure is the input to a surface chemistry task that enumerates surfaces up to a user-specified maximum Miller index, computes relaxed surface energies for those surfaces, and then prioritizes those for subsequent adsorption energy calculations based on their contribution to the Wulff construction shape. The workflow handles computational resource constraints such as limited wall-time as well as automated job submission and analysis. We illustrate the workflow for oxygen evolution (OER) intermediates on two double perovskites. WhereWulff nearly halved the number of Density Functional Theory (DFT) calculations from ~ 240 to ~ 132 by prioritizing terminations, up to a maximum Miller index of 1, based on surface stability. Additionally, it automatically handled the 180 additional re-submission jobs required to successfully converge 120+ atoms systems under a 48-hour wall-time cluster constraint. There are four main use cases that we envision for WhereWulff: (1) as a first-principles source of truth to validate and update a closed-loop self-sustaining materials discovery pipeline, (2) as a data generation tool, (3) as an educational tool, allowing users (e.g. experimentalists) unfamiliar with OER modeling to probe materials they might be interested in before doing further in-domain analyses, (4) and finally as a starting point for users to extend with reactions other than OER, as part of a collaborative software community. 	
"A-BASE-DE-PROS: una implementacin prctica de los Objetivos de
  Desarrollo Sostenible en la Universidad Politcnica de Madrid"	http://arxiv.org/abs/2302.13740v1	2023-02-27T13:05:26Z	2023-02-27T13:05:26Z	  The influence of the Sustainable Development Goals (SDGs) has been widely spread over the last years, establishing new public and privat policies. Education has also been experiencing this change by aligning with the previous goals. In this chapter, we briefly summarize the main activities conducted under the Grant APS22.2003 'Service-based learning of the SDGs related to a responsible production and consumption (A-BASE-DE-PROS)', which uses the SDG 12 as a guide line to raise the awareness of the importance of the 2030 Agenda among undergraduate and secondary-school students. In general, the service-based learning has increased the knowledge of the SDGs among the students. Furthermore, most of the (university and secondary) students found the service-learning 	
"Deterministic and stochastic coarsening control in optically-addressed
  spatial light modulators subject to optical feedback"	http://arxiv.org/abs/2302.13636v1	2023-02-27T10:04:13Z	2023-02-27T10:04:13Z	  Phase separation accompanied by further domain growth and coarsening is a phenomenon common to a broad variety of dynamical systems. In this connection, controlling such processes represents a relevant interdisciplinary problem. Using methods of numerical modelling, we demonstrate two approaches for the coarsening control in bistable systems based on the example of a spatially-extended model describing an optically-addressed spatial light modulator with two color illumination subject to optical feedback. The first method implies varying system parameters such that the system evolves as the pitchfork or saddle-node normal forms. The second method leverages noise whose intensity is used as an additional system parameter. Both, deterministic and stochastic schemes allow to control the direction and speed of the fronts separating spatial domains. The considered stochastic control represents a particular case of the noise-sustained front propagation in bistable systems and involves the properties of the optical system under study. In contrast, the proposed deterministic control technique can be applied to bistable systems of different nature. 	
"Evanescent Gels: Competition Between Sticker Dynamics and Single Chain
  Relaxation"	http://arxiv.org/abs/2302.13623v1	2023-02-27T09:47:19Z	2023-02-27T09:47:19Z	"  Solutions of polymer chains are modelled using non-equilibrium Brownian dynamics simulations, with physically associative beads which form reversible crosslinks to establish a system-spanning physical gel network. Rheological properties such as zero-shear viscosity and relaxation modulus are investigated systematically as functions of polymer concentration and binding energy between associative sites. It is shown that a system-spanning network can form regardless of binding energy at sufficiently high concentration. However, the contribution to the stress sustained by this physical network can decay faster than other relaxation processes, even single chain relaxations. If the polymer relaxation time scales overlap with short-lived associations, the mechanical response of a gel becomes ""evanescent"", decaying before it can be rheologically observed, even though the network is instantaneously mechanically rigid. In our simulations, the concentration of elastically active chains and the dynamic modulii are computed independently. This makes it possible to combine structural and rheological information to identify the concentration at which the sol-gel transition occurs as a function of binding energy. Further, it is shown that the competition of scales between the dissociation time and the single-polymer relaxation time determines if the gel is in the evanescent regime. "	
"Knowledge-infused Contrastive Learning for Urban Imagery-based
  Socioeconomic Prediction"	http://arxiv.org/abs/2302.13094v1	2023-02-25T14:53:17Z	2023-02-25T14:53:17Z	  Monitoring sustainable development goals requires accurate and timely socioeconomic statistics, while ubiquitous and frequently-updated urban imagery in web like satellite/street view images has emerged as an important source for socioeconomic prediction. Especially, recent studies turn to self-supervised contrastive learning with manually designed similarity metrics for urban imagery representation learning and further socioeconomic prediction, which however suffers from effectiveness and robustness issues. To address such issues, in this paper, we propose a Knowledge-infused Contrastive Learning (KnowCL) model for urban imagery-based socioeconomic prediction. Specifically, we firstly introduce knowledge graph (KG) to effectively model the urban knowledge in spatiality, mobility, etc., and then build neural network based encoders to learn representations of an urban image in associated semantic and visual spaces, respectively. Finally, we design a cross-modality based contrastive learning framework with a novel image-KG contrastive loss, which maximizes the mutual information between semantic and visual representations for knowledge infusion. Extensive experiments of applying the learnt visual representations for socioeconomic prediction on three datasets demonstrate the superior performance of KnowCL with over 30\% improvements on $R^2$ compared with baselines. Especially, our proposed KnowCL model can apply to both satellite and street imagery with both effectiveness and transferability achieved, which provides insights into urban imagery-based socioeconomic prediction. 	
"In Search of Deep Learning Architectures for Load Forecasting: A
  Comparative Analysis and the Impact of the Covid-19 Pandemic on Model
  Performance"	http://arxiv.org/abs/2302.13046v1	2023-02-25T10:08:23Z	2023-02-25T10:08:23Z	  In power grids, short-term load forecasting (STLF) is crucial as it contributes to the optimization of their reliability, emissions, and costs, while it enables the participation of energy companies in the energy market. STLF is a challenging task, due to the complex demand of active and reactive power from multiple types of electrical loads and their dependence on numerous exogenous variables. Amongst them, special circumstances, such as the COVID-19 pandemic, can often be the reason behind distribution shifts of load series. This work conducts a comparative study of Deep Learning (DL) architectures, namely Neural Basis Expansion Analysis Time Series Forecasting (N-BEATS), Long Short-Term Memory (LSTM), and Temporal Convolutional Networks (TCN), with respect to forecasting accuracy and training sustainability, meanwhile examining their out-of-distribution generalization capabilities during the COVID-19 pandemic era. A Pattern Sequence Forecasting (PSF) model is used as baseline. The case study focuses on day-ahead forecasts for the Portuguese national 15-minute resolution net load time series. The results can be leveraged by energy companies and network operators (i) to reinforce their forecasting toolkit with state-of-the-art DL models; (ii) to become aware of the serious consequences of crisis events on model performance; (iii) as a high-level model evaluation, deployment, and sustainability guide within a smart grid context. 	
"Strain-adjustable reflectivity of polyurethane nanofiber membrane for
  thermal management applications"	http://arxiv.org/abs/2302.13043v2	2023-02-28T10:42:51Z	2023-02-25T09:54:33Z	  Passive radiative cooling technologies are highly attractive in pursuing sustainable development. However, current cooling materials are often static, which makes it difficult to cope with the varying needs of all-weather thermal comfort management. Herein, a strategy is designed to obtain flexible thermoplastic polyurethane nanofiber (Es-TPU) membranes via electrospinning, realizing reversible in-situ solvent-free switching between radiative cooling and solar heating through changes in its optical reflectivity by stretching. In its radiative cooling state (0% strain), the Es-TPU membrane shows a high and angular-independent reflectance of 95.6% in the 0.25-2.5 {\mu}m wavelength range and an infrared emissivity of 93.3% in the atmospheric transparency window (8-13 {\mu}m), reaching a temperature drop of 10 {\deg}C at midday, with a corresponding cooling power of 118.25 W/m2. The excellent mechanical properties of the Es-TPU membrane allows the continuous adjustment of reflectivity by reversibly stretching it, reaching a reflectivity of 61.1% ({\Delta}R=34.5%) under an elongation strain of 80%, leading to a net temperature increase of 9.5 {\deg}C above ambient of an absorbing substrate and an equivalent power of 220.34 W/m2 in this solar heating mode. The strong haze, hydrophobicity and outstanding aging resistance exhibited by this scalable membrane hold promise for achieving uniform illumination with tunable strength and efficient thermal management in practical applications. 	
Impact of Thermal Variability on SOC Estimation Algorithms	http://arxiv.org/abs/2302.12978v1	2023-02-25T04:13:28Z	2023-02-25T04:13:28Z	  While the efficiency of renewable energy components like inverters and PV panels is at an all-time high, there are still research gaps for batteries. Lithium-ion batteries have a lot of potential, but there are still some problems that need fixing, such as thermal management. Because of this, the battery management system accomplishes its goal. In order for a battery management system (BMS) to function properly, it must make accurate estimates of all relevant parameters, including state of health, state of charge, and temperature; however, for the purposes of this article, we will only discuss SOC. The goal of this article is to estimate the SOC of a lithium-ion battery at different temperatures. Comparing the Extended Kalam filter algorithm to coulomb counting at various temperatures concludes this exhaustive investigation. The graphene battery has the highest SOC when operated at the optimal temperature, as determined by extensive analysis and correlation between SOC and temperature is not linear 	
Electric Vehicle E-hailing Fleet Dispatching and Charge Scheduling	http://arxiv.org/abs/2302.12650v1	2023-02-24T14:17:27Z	2023-02-24T14:17:27Z	  With recent developments in vehicle and battery technologies, electric vehicles (EVs) are rapidly getting established as a sustainable alternative to traditional fossil-fuel vehicles. This has made the large-scale electrification of ride-sourcing operations a practical viability, providing an opportunity for a leap toward urban sustainability goals. Despite having a similar driving range to fossil-fuel vehicles, EVs are disadvantaged by their long charging times which compromises the total fleet service time. To efficiently manage an EV fleet, the operator needs to address the charge scheduling problem as part of the dispatch strategy. This paper introduces a probabilistic matching method which evaluates the optimal trip and charging decisions for a fully electrified e-hailing fleet, with the goal of maximising the operator's expected market profit. In the midst of the technological transition towards autonomous vehicles, it is also critical to include stochastic driver behaviours in transport models as presented in this paper. Since drivers may either comply with trip dispatching or choose to reject a charging trip order considering the additional fees, contrary to the commonly assumed fleet autonomy, the proposed method designs an incentivisation scheme (charging discounts) to encourage driver compliance so that the planned charging trips and the associated profit can be realised. 	
"""An Adapt-or-Die Type of Situation"": Perception, Adoption, and Use of
  Text-To-Image-Generation AI by Game Industry Professionals"	http://arxiv.org/abs/2302.12601v2	2023-02-27T15:29:22Z	2023-02-24T12:38:27Z	  Text-to-image generation (TTIG) models, a recent addition to creative AI, can generate images based on a text description. These models have begun to rival the work of professional creatives, and sparked discussions on the future of creative work, loss of jobs, and copyright issues, amongst other important implications. To support the sustainable adoption of TTIG, we must provide rich, reliable and transparent insights into how professionals perceive, adopt and use TTIG. Crucially though, the public debate is shallow, narrow and lacking transparency, while academic work has focused on studying the use of TTIG in a general artist population, but not on the perceptions and attitudes of professionals in a specific industry. In this paper, we contribute a qualitative, exploratory interview study on TTIG in the Finnish videogame industry. Through a Template Analysis on semi-structured interviews with 14 game professionals, we reveal 12 overarching themes, structured into 49 sub-themes on professionals' perception, adoption and use of TTIG systems in games industry practice. Experiencing (yet another) change of roles and creative processes, our participants' reflections can inform discussions within the industry, be used by policymakers to inform urgently needed legislation, and support researchers in games, HCI and AI to support the sustainable, professional use of TTIG to benefit people and games as cultural artefacts. 	
A hidden shock powering the peak of SN 2020faa	http://arxiv.org/abs/2302.12527v1	2023-02-24T09:23:29Z	2023-02-24T09:23:29Z	  The link between the fate of most massive stars and the resulting supernova (SN) explosion is still debated, also because of the ambiguity of the light curve powering mechanisms. When they explode as SNe, the light curve luminosity is typically sustained by a central engine (radioactive decay, magnetar spin-down, or fallback accretion). However, since massive stars eject considerable amounts of material during their evolution, there can be significant contribution from interaction with the previously-ejected circumstellar medium (CSM). Reconstructing the progenitor configuration at the time of explosion requires a detailed analysis of the long-term photometric and spectroscopic evolution of the related transient. In this paper we present the results of our follow-up campaign of SN 2020faa that, because of the high luminosity and peculiar slow light curve, is candidate for having a massive progenitor. We present the spectro-photometric dataset and investigate different options to explain the unusual observed properties. We compute the bolometric luminosity of the supernova and the evolution of its temperature, radius, and expansion velocity. We also fit the observed light curve with a multi-component model to infer information on the progenitor and the explosion mechanism. Reasonable parameters are inferred for SN 2020faa with a magnetar of energy Ep = 1.5(+0.5,-0.2) x 10^50 erg and spin-down time t(spin)=15+/-1 d, a shell mass M(shell) = 2.4(+0.5,-0.4) Msun and kinetic energy Ekin(shell) = 0.9(+0.5,-0.3) x 10^51 erg, and a core with M(core) = 21.5(+1.4,-0.7) Msun and Ekin(core) = 3.9(+0.1,-0.4) x 10^51 erg. In addition, we need an extra source to power the luminosity of the second peak. We find that hidden interaction with either a CSM disc or with delayed, choked jets is a viable mechanism to supply the required energy. 	
Multiverse Predictions for Habitability: Planetary Characteristics	http://arxiv.org/abs/2302.12376v1	2023-02-24T00:46:17Z	2023-02-24T00:46:17Z	  Recent detections of potentially habitable exoplanets around sunlike stars demand increased exploration of the physical conditions that can sustain life, by whatever methods available. Insight into these conditions can be gained by considering the multiverse hypothesis; in a multiverse setting, the probability of living in our universe depends on assumptions made about the factors affecting habitability. Various proposed habitability criteria can be systematically considered to rate each on the basis of their compatibility with the multiverse, generating predictions which can both guide expectations for life's occurrence and test the multiverse hypothesis. Here, we evaluate several aspects of planetary habitability, and show that the multiverse does indeed induce strong preferences among them. We find that the notion that a large moon is necessary for habitability is untenable in the multiverse scenario, as in the majority of parameter space, moons are not necessary to maintain stable obliquity. Further, we consider various proposed mechanisms for water delivery to the early Earth, including delivery from asteroids, both during giant planet formation and a grand tack, delivery from comets, and oxidation of a primary atmosphere by a magma ocean. We find that, depending on assumptions for how habitability depends on water content, some of these proposed mechanisms are disfavored in the multiverse scenario by Bayes factors of up to several hundred. 	
Nonisothermal evaporation	http://arxiv.org/abs/2302.12348v1	2023-02-23T21:58:46Z	2023-02-23T21:58:46Z	  Evaporation of a liquid layer on a substrate is examined without the often-used isothermality assumption -- i.e., temperature variations are accounted for. Qualitative estimates show that nonisothermality makes the evaporation rate depend on the conditions the substrate is maintained at. If it is thermally insulated, evaporative cooling dramatically slows evaporation down; the evaporation rate tends to zero with time and cannot be determined by measuring the external parameters only. If, however, the substrate is maintained at a fixed temperature, the heat flux coming from below sustains evaporation at a finite rate -- deducible from the fluid's characteristics, relative humidity, and the layer's depth (whose importance has not been recognized before). The qualitative predictions are quantified using the diffuse-interface model applied to a liquid evaporating into its own vapor. 	
"From Circuits to SoC Processors: Arithmetic Approximation Techniques &
  Embedded Computing Methodologies for DSP Acceleration"	http://arxiv.org/abs/2302.12194v1	2023-02-23T17:37:10Z	2023-02-23T17:37:10Z	  The computing industry is forced to find alternative design approaches and computing platforms to sustain increased power efficiency, while providing sufficient performance. Among the examined solutions, Approximate Computing, Hardware Acceleration, and Heterogeneous Computing have gained great momentum. In this Dissertation, we introduce design solutions and methodologies, built on top of the preceding computing paradigms, for the development of energy-efficient DSP and AI accelerators. In particular, we adopt the promising paradigm of Approximate Computing and apply new approximation techniques in the design of arithmetic circuits. The proposed arithmetic approximation techniques involve bit-level optimizations, inexact operand encodings, and skipping of computations, while they are applied in both fixed- and floating-point arithmetic. We also conduct an extensive exploration on combinations among the approximation techniques and propose a low-overhead scheme for seamlessly adjusting the approximation degree of our circuits at runtime. Based on our methodology, these arithmetic approximation techniques are then combined with hardware design techniques to implement approximate ASIC- and FPGA-based DSP and AI accelerators. Moreover, we propose methodologies for the efficient mapping of DSP/AI kernels on distinctive embedded devices, i.e., the space-grade FPGAs and the heterogeneous VPUs. On the one hand, we cope with the decreased flexibility of the space-grade technology and the technical challenges that arise in new FPGA tools. On the other hand, we unlock the full potential of heterogeneity by exploiting all the diverse processors and memories. Based on our methodology, we efficiently map computer vision algorithms onto the radiation-hardened NanoXplore's FPGAs and accelerate DSP & CNN kernels on Intel's Myriad VPUs. 	
"A Generalized Accelerated Failure Time Model to Predict Restoration Time
  from Power Outages"	http://arxiv.org/abs/2302.12157v1	2023-02-23T16:41:41Z	2023-02-23T16:41:41Z	  Major disasters such as wildfire, tornado, hurricane, tropical storm, flooding cause disruptions in infrastructure systems such as power outage, disruption to water supply system, wastewater management, telecommunication failures, and transportation facilities. Disruptions in electricity infrastructures has a negative impact on every sector of a region, such as education, medical services, financial, recreation. In this study, we introduce a novel approach to investigate the factors which can be associated with longer restoration time of power service after a hurricane. We consider three types of factors (hazard characteristics, built-environment characteristics, and socio-demographic factors) that might be associated with longer restoration times of power outages during a hurricane. Considering restoration time as the dependent variable and utilizing a comprehensive set of county-level data, we have estimated a Generalized Accelerated Failure Time (GAFT) that accounts for spatial dependence among observations for time to event data. Considering spatial correlation in time to event data has improved the model fit by 12%. Using GAFT model and Hurricane Irma as a case study, we examined: (1) differences in electric power outages and restoration rates among different types of power companies: investor-owned power companies, rural and municipal cooperatives; (2) the relationship between the duration of power outage and power system variables, and socioeconomic attributes. We have found that factors such as maximum sustained wind speed, percentage of customers facing power outage, percentage of customers served by investor-owned power company, median household income, and number of power plants are strongly associated with restoration time. This paper identifies the key factors in predicting the restoration time of hurricane-induced power outages. 	
"The Story of QoS Prediction in Vehicular Communication: From Radio
  Environment Statistics to Network-Access Throughput Prediction"	http://arxiv.org/abs/2302.11966v1	2023-02-23T12:29:20Z	2023-02-23T12:29:20Z	  As cellular networks evolve towards the 6th Generation (6G), Machine Learning (ML) is seen as a key enabling technology to improve the capabilities of the network. ML provides a methodology for predictive systems, which, in turn, can make networks become proactive. This proactive behavior of the network can be leveraged to sustain, for example, a specific Quality of Service (QoS) requirement. With predictive Quality of Service (pQoS), a wide variety of new use cases, both safety- and entertainment-related, are emerging, especially in the automotive sector. Therefore, in this work, we consider maximum throughput prediction enhancing, for example, streaming or HD mapping applications. We discuss the entire ML workflow highlighting less regarded aspects such as the detailed sampling procedures, the in-depth analysis of the dataset characteristics, the effects of splits in the provided results, and the data availability. Reliable ML models need to face a lot of challenges during their lifecycle. We highlight how confidence can be built on ML technologies by better understanding the underlying characteristics of the collected data. We discuss feature engineering and the effects of different splits for the training processes, showcasing that random splits might overestimate performance by more than twofold. Moreover, we investigate diverse sets of input features, where network information proved to be most effective, cutting the error by half. Part of our contribution is the validation of multiple ML models within diverse scenarios. We also use Explainable AI (XAI) to show that ML can learn underlying principles of wireless networks without being explicitly programmed. Our data is collected from a deployed network that was under full control of the measurement team and covered different vehicular scenarios and radio environments. 	
Yukawa-Casimir wormholes in f(Q) gravity	http://arxiv.org/abs/2303.04641v1	2023-02-23T10:05:31Z	2023-02-23T10:05:31Z	  Casimir energy is always suggested as a possible source to create a traversable wormhole. It is also used to demonstrate the existence of negative energy, which can be created in a lab. To generalize, this idea, Yukawa modification of Casimir source has been considered in Remo Garattini (Eur. Phys. J. C 81 no.9, 824, 2021). In this work, we explore the Yukawa Casimir wormholes in symmetric teleparallel gravity. We have taken four different forms of $f(Q)$ to obtain wormhole solutions powered by the original Casimir energy source and Yukawa modification of the Casimir energy source. In power law form $f(Q)= \alpha Q^2 + \beta$ and quadratic form $f(Q)= \alpha Q^2 + \beta Q + \gamma$, where $\alpha, \beta, \gamma$ are constants and $Q$ is non-metricity scalar, we analyze that wormhole throat is filled with non-exotic matter. We find self-sustained traversable wormholes in the Casimir source where null energy conditions are violated in all specific forms of $f(Q)$, while after Yukawa modification it is observed that violation of null energy conditions is restricted to some regions in the vicinity of the throat. 	
"Solitonic self-sustained charge and energy transport on the
  superconducting cylinder"	http://arxiv.org/abs/2302.11664v1	2023-02-22T21:40:05Z	2023-02-22T21:40:05Z	  We present an exact time-dependent solution for a charged scalar field on a two-dimensional cylinder, that can be interpreted as representing a long-standing excitation on a $s$-wave superconducting state, which propagates along a nanotube constructed out of twisted bilayer graphene. The solution has a topological charge characterized by an integer number, which counts the winding of the Higgs phase winds around the cylinder. The resulting electric current generates its own electromagnetic field in a self-consistent way, without the need of any external fields to keep it alive. 	
"Sequential Re-estimation Learning of Optimal Individualized Treatment
  Rules Among Ordinal Treatments with Application to Recommended Intervals
  Between Blood Donations"	http://arxiv.org/abs/2302.11638v1	2023-02-22T20:29:03Z	2023-02-22T20:29:03Z	"  Personalized medicine has gained much popularity recently as a way of providing better healthcare by tailoring treatments to suit individuals. Our research, motivated by the UK INTERVAL blood donation trial, focuses on estimating the optimal individualized treatment rule (ITR) in the ordinal treatment-arms setting. Restrictions on minimum lengths between whole blood donations exist to safeguard donor health and quality of blood received. However, the evidence-base for these limits is lacking. Moreover, in England, the blood service is interested in making blood donation both safe and sustainable by integrating multi-marker data from INTERVAL and developing personalized donation strategies. As the three inter-donation interval options in INTERVAL have clear orderings, we propose a sequential re-estimation learning method that effectively incorporates ""treatment"" orderings when identifying optimal ITRs. Furthermore, we incorporate variable selection into our method for both linear and nonlinear decision rules to handle situations with (noise) covariates irrelevant for decision-making. Simulations demonstrate its superior performance over existing methods that assume multiple nominal treatments by achieving smaller misclassification rates and larger value functions. Application to a much-in-demand donor subgroup shows that the estimated optimal ITR achieves both the highest utilities and largest proportions of donors assigned to the safest inter-donation interval option in INTERVAL. "	
"Synchronization approach to achieving maximum power and thermal
  efficiency for weakly-coupled low-temperature-differential Stirling engines"	http://arxiv.org/abs/2302.11308v1	2023-02-22T11:45:35Z	2023-02-22T11:45:35Z	  Low-temperature-differential (LTD) Stirling engines are heat engines that can operate autonomously with a slight temperature difference between low-temperature heat reservoirs and are thus expected to contribute to a sustainable society. A minimal dynamical-system model with only two variables has been proposed to explain the principle of autonomous rotational motion caused by temperature differences, and the maximum efficiency of the engine was formulated [Y. Izumida, Eurohys. Lett. 121, 50004 (2018); Phys. Rev. E 102, 012142 (2020)]. This paper aims to clarify the coupling effects on the dynamics, power, and thermal efficiency of a pair of weakly coupled LTD Stirling engines and formulate the maximum thermal efficiency of the coupled system in the quasilinear response regime. We show that different kinds of bifurcations occur in the forward and backward processes, and the dependence of frequency difference on the coupling strength is characterized by a hysteresis. Then, by generalizing thermodynamic fluxes and forces and their quasilinear relations for engines under weak coupling, we show that the coupling improves the power exerted against the load torques and the thermal efficiency. We further show that their maximum values are achieved when the engines are synchronized. As in the case of the frequency difference, the dependence of thermal efficiency on the coupling strength is also characterized by a hysteresis. Finally, the load torque that achieves the maximum thermal efficiency of the coupled system is formulated. 	
Aligning Explainable AI and the Law: The European Perspective	http://arxiv.org/abs/2302.10766v2	2023-02-22T16:26:49Z	2023-02-21T16:06:48Z	  The European Union has proposed the Artificial Intelligence Act intending to regulate AI systems, especially those used in high-risk, safety-critical applications such as healthcare. Among the Act's articles are detailed requirements for transparency and explainability. The field of explainable AI (XAI) offers technologies that could address many of these requirements. However, there are significant differences between the solutions offered by XAI and the requirements of the AI Act, for instance, the lack of an explicit definition of transparency. We argue that collaboration is essential between lawyers and XAI researchers to address these differences. To establish common ground, we give an overview of XAI and its legal relevance followed by a reading of the transparency and explainability requirements of the AI Act and the related General Data Protection Regulation (GDPR). We then discuss four main topics where the differences could induce issues. Specifically, the legal status of XAI, the lack of a definition of transparency, issues around conformity assessments, and the use of XAI for dataset-related transparency. We hope that increased clarity will promote interdisciplinary research between the law and XAI and support the creation of a sustainable regulation that fosters responsible innovation. 	
Future Aware Pricing and Matching for Sustainable On-demand Ride Pooling	http://arxiv.org/abs/2302.10510v1	2023-02-21T08:24:35Z	2023-02-21T08:24:35Z	  The popularity of on-demand ride pooling is owing to the benefits offered to customers (lower prices), taxi drivers (higher revenue), environment (lower carbon footprint due to fewer vehicles) and aggregation companies like Uber (higher revenue). To achieve these benefits, two key interlinked challenges have to be solved effectively: (a) pricing -- setting prices to customer requests for taxis; and (b) matching -- assignment of customers (that accepted the prices) to taxis/cars. Traditionally, both these challenges have been studied individually and using myopic approaches (considering only current requests), without considering the impact of current matching on addressing future requests. In this paper, we develop a novel framework that handles the pricing and matching problems together, while also considering the future impact of the pricing and matching decisions. In our experimental results on a real-world taxi dataset, we demonstrate that our framework can significantly improve revenue (up to 17\% and on average 6.4\%) in a sustainable manner by reducing the number of vehicles (up to 14\% and on average 10.6\%) required to obtain a given fixed revenue and the overall distance travelled by vehicles (up to 11.1\% and on average 3.7\%). That is to say, we are able to provide an ideal win-win scenario for all stakeholders (customers, drivers, aggregator, environment) involved by obtaining higher revenue for customers, drivers, aggregator (ride pooling company) while being good for the environment (due to fewer number of vehicles on the road and lesser fuel consumed). 	
"Democratizing Making: Scaffolding Participation Using e-Waste to Engage
  Under-resourced Communities in Technology Design"	http://arxiv.org/abs/2302.10402v1	2023-02-21T02:27:43Z	2023-02-21T02:27:43Z	  Maker culture and DIY practices are central to democratizing the design of technology; enabling non-designers (future end-users) to actively participate in the design process. However, little is known about how individuals from under-resourced communities and low socioeconomic status (SES) backgrounds, can practically leverage maker practices to design technology, creating value for themselves or their communities. To investigate this, we collaborated with an e-waste recycling centre, involving 24 participants (staff and low-SES volunteers) in two participatory maker workshop activities. Participants were provided with a generative e-waste toolkit, through which they repurposed e-waste materials and developed novel technology prototypes that created value from their perspectives and agendas. Our findings unpack three factors that influenced their making: balancing personal and community needs; incorporating convenience and productivity; and re-thinking sustainability and connection; and discuss strategies for scaffolding participation and engagement of under-resourced communities in making using an e-waste generative toolkit to democratize technology design. 	
"Towards a Sustainable Internet-of-Underwater-Things based on AUVs,
  SWIPT, and Reinforcement Learning"	http://arxiv.org/abs/2302.10368v1	2023-02-21T00:01:47Z	2023-02-21T00:01:47Z	  Life on earth depends on healthy oceans, which supply a large percentage of the planet's oxygen, food, and energy. However, the oceans are under threat from climate change, which is devastating the marine ecosystem and the economic and social systems that depend on it. The Internet-of-underwater-things (IoUTs), a global interconnection of underwater objects, enables round-the-clock monitoring of the oceans. It provides high-resolution data for training machine learning (ML) algorithms for rapidly evaluating potential climate change solutions and speeding up decision-making. The sensors in conventional IoUTs are battery-powered, which limits their lifetime, and constitutes environmental hazards when they die. In this paper, we propose a sustainable scheme to improve the throughput and lifetime of underwater networks, enabling them to potentially operate indefinitely. The scheme is based on simultaneous wireless information and power transfer (SWIPT) from an autonomous underwater vehicle (AUV) used for data collection. We model the problem of jointly maximising throughput and harvested power as a Markov Decision Process (MDP), and develop a model-free reinforcement learning (RL) algorithm as a solution. The model's reward function incentivises the AUV to find optimal trajectories that maximise throughput and power transfer to the underwater nodes while minimising energy consumption. To the best of our knowledge, this is the first attempt at using RL to ensure sustainable underwater networks via SWIPT. The scheme is implemented in an open 3D RL environment specifically developed in MATLAB for this study. The performance results show up 207% improvement in energy efficiency compared to those of a random trajectory scheme used as a baseline model. 	
"Multi-generational labour markets: data-driven discovery of
  multi-perspective system parameters using machine learning"	http://arxiv.org/abs/2302.10146v1	2023-02-20T18:25:10Z	2023-02-20T18:25:10Z	  Economic issues, such as inflation, energy costs, taxes, and interest rates, are a constant presence in our daily lives and have been exacerbated by global events such as pandemics, environmental disasters, and wars. A sustained history of financial crises reveals significant weaknesses and vulnerabilities in the foundations of modern economies. Another significant issue currently is people quitting their jobs in large numbers. Moreover, many organizations have a diverse workforce comprising multiple generations posing new challenges. Transformative approaches in economics and labour markets are needed to protect our societies, economies, and planet. In this work, we use big data and machine learning methods to discover multi-perspective parameters for multi-generational labour markets. The parameters for the academic perspective are discovered using 35,000 article abstracts from the Web of Science for the period 1958-2022 and for the professionals' perspective using 57,000 LinkedIn posts from 2022. We discover a total of 28 parameters and categorised them into 5 macro-parameters, Learning & Skills, Employment Sectors, Consumer Industries, Learning & Employment Issues, and Generations-specific Issues. A complete machine learning software tool is developed for data-driven parameter discovery. A variety of quantitative and visualisation methods are applied and multiple taxonomies are extracted to explore multi-generational labour markets. A knowledge structure and literature review of multi-generational labour markets using over 100 research articles is provided. It is expected that this work will enhance the theory and practice of AI-based methods for knowledge discovery and system parameter discovery to develop autonomous capabilities and systems and promote novel approaches to labour economics and markets, leading to the development of sustainable societies and economies. 	
"A Sidecar Separator Can Convert a Single-Talker Speech Recognition
  System to a Multi-Talker One"	http://arxiv.org/abs/2302.09908v2	2023-03-05T23:10:24Z	2023-02-20T11:09:37Z	  Although automatic speech recognition (ASR) can perform well in common non-overlapping environments, sustaining performance in multi-talker overlapping speech recognition remains challenging. Recent research revealed that ASR model's encoder captures different levels of information with different layers -- the lower layers tend to have more acoustic information, and the upper layers more linguistic. This inspires us to develop a Sidecar separator to empower a well-trained ASR model for multi-talker scenarios by separating the mixed speech embedding between two suitable layers. We experimented with a wav2vec 2.0-based ASR model with a Sidecar mounted. By freezing the parameters of the original model and training only the Sidecar (8.7 M, 8.4% of all parameters), the proposed approach outperforms the previous state-of-the-art by a large margin for the 2-speaker mixed LibriMix dataset, reaching a word error rate (WER) of 10.36%; and obtains comparable results (7.56%) for LibriSpeechMix dataset when limited training. 	
"Eco-evolutionary Dynamics of Non-episodic Neuroevolution in Large
  Multi-agent Environments"	http://arxiv.org/abs/2302.09334v2	2023-03-16T11:21:54Z	2023-02-18T13:57:27Z	  Neuroevolution (NE) has recently proven a competitive alternative to learning by gradient descent in reinforcement learning tasks. However, the majority of NE methods and associated simulation environments differ crucially from biological evolution: the environment is reset to initial conditions at the end of each generation, whereas natural environments are continuously modified by their inhabitants; agents reproduce based on their ability to maximize rewards within a population, while biological organisms reproduce and die based on internal physiological variables that depend on their resource consumption; simulation environments are primarily single-agent while the biological world is inherently multi-agent and evolves alongside the population. In this work we present a method for continuously evolving adaptive agents without any environment or population reset. The environment is a large grid world with complex spatiotemporal resource generation, containing many agents that are each controlled by an evolvable recurrent neural network and locally reproduce based on their internal physiology. The entire system is implemented in JAX, allowing very fast simulation on a GPU. We show that NE can operate in an ecologically-valid non-episodic multi-agent setting, finding sustainable collective foraging strategies in the presence of a complex interplay between ecological and evolutionary dynamics. 	
Sub-Natural Linewidth Superradiant Lasing with Cold $^{88}$Sr Atoms	http://arxiv.org/abs/2302.08977v1	2023-02-17T16:34:18Z	2023-02-17T16:34:18Z	  Superradiant lasers operate in the bad-cavity regime, where the phase coherence is stored in the spin state of an atomic medium rather than in the intracavity electric field. Such lasers use collective effects to sustain lasing and could potentially reach considerably lower linewidths than a conventional laser. Here, we investigate the properties of superradiant lasing in an ensemble of ultracold $^{88}$Sr atoms inside an optical cavity. We extend the superradiant emission on the 7.5 kHz wide $^3P_1$ $\rightarrow$ $^1S_0$ intercombination line to several milliseconds, and observe steady parameters suitable for emulating the performance of a continuous superradiant laser by fine tuning the repumping rates. We reach a lasing linewidth of 820 Hz for 1.1 ms of lasing, nearly an order of magnitude lower than the natural linewidth 	
Quasi-classical Langmuir wave collapse in a magnetic field	http://arxiv.org/abs/2302.08972v1	2023-02-17T16:19:03Z	2023-02-17T16:19:03Z	  The anisotropy due to a magnetic field is shown to result in significant changes in Langmuir collapse. Using a variational approach, the quasi-classical collapse phenomenon is investigated analytically.   A hierarchy of quasi-classical collapses is determined, along with the structure of a field in the proximity of a stationary singularity that is sustained by the continuous absorption of wave energy from a wave packet. 	
"Coherence build up and laser thresholds from nanolasers to macroscopic
  lasers"	http://arxiv.org/abs/2302.08824v1	2023-02-17T11:46:04Z	2023-02-17T11:46:04Z	  We detail the derivation of nanolaser models that include coherent and incoherent variables and predict the existence of a laser threshold, irrespective of cavity size and emitter number, for both single- and multi-electron systems. The growth in photon number in the lasing mode is driven by an increase in correlation between absorption and emission processes, leading to the onset of self-sustained stimulated emission (laser threshold), followed, in turn, by a correlation decrease and ending with the dominance of coherent emission. The first-order coherence $g^{(1)}$ steadily increases, as the pump grows towards the laser threshold value, and reaches unity at or beyond threshold. The transition toward coherent emission becomes increasingly sharp as the number of emitters and of the coupled electromagnetic cavity modes increase, continuously connecting, in the thermodynamic limit, the physics of nano- and macroscopic lasers at threshold. Our predictions are in remarkable agreement with experiments whose first-order coherence measurements have so far been explained only phenomenologically. A consistent evaluation of different threshold indicators provides a tool for a correct interpretation of experimental measurements at the onset of laser action. 	
"A Next-Generation Digital Procurement Workspace Focusing on Information
  Integration, Automation, Analytics, and Sustainability"	http://arxiv.org/abs/2303.03882v1	2023-02-17T09:46:44Z	2023-02-17T09:46:44Z	  Recent events such as wars, sanctions, pandemics, and climate change have shown the importance of proper supply network management. A key step in managing supply networks is procurement. We present an approach for realizing a next-generation procurement workspace that aims to facilitate resilience and sustainability. To achieve this, the approach encompasses a novel way of information integration, automation tools as well as analytical techniques. As a result, the procurement can be viewed from the perspective of the environmental impact, comprising and aggregating sustainability scores along the supply chain. We suggest and present an implementation of our approach, which is meanwhile used in a global Fortune 500 company. We further present the results of an empirical evaluation study, where we performed in-depth interviews with the stakeholders of the novel procurement platform to validate its adequacy, usability, and innovativeness. 	
"CarbonScaler: Leveraging Cloud Workload Elasticity for Optimizing
  Carbon-Efficiency"	http://arxiv.org/abs/2302.08681v1	2023-02-17T04:12:52Z	2023-02-17T04:12:52Z	  Cloud platforms are increasingly emphasizing sustainable operations in order to reduce their operational carbon footprint. One approach for reducing emissions is to exploit the temporal flexibility inherent in many cloud workloads by executing them in time periods with the greenest electricity supply and suspending them at other times. Since such suspend-resume approaches can incur long delays in job completion times, we present a new approach that exploits the workload elasticity of batch workloads in the cloud to optimize their carbon emissions. Our approach is based on the notion of carbon scaling, similar to cloud autoscaling, where a job's server allocations are varied dynamically based on fluctuations in the carbon cost of the grid's electricity supply. We present an optimal greedy algorithm for minimizing a job's emissions through carbon scaling and implement a prototype of our \systemName system in Kubernetes using its autoscaling capabilities, along with an analytic tool to guide the carbon-efficient deployment of batch applications in the cloud. We evaluate CarbonScaler using real-world machine learning training and MPI jobs on a commercial cloud platform and show that \systemName can yield up to 50\% carbon savings over a carbon agnostic execution and up to 35% over the state-of-the-art suspend resume policies. 	
All-Electrical Skyrmionic Bits in a Chiral Magnetic Tunnel Junction	http://arxiv.org/abs/2302.08020v1	2023-02-16T01:40:20Z	2023-02-16T01:40:20Z	  Topological spin textures such as magnetic skyrmions hold considerable promise as robust, nanometre-scale, mobile bits for sustainable computing. A longstanding roadblock to unleashing their potential is the absence of a device enabling deterministic electrical readout of individual spin textures. Here we present the wafer-scale realization of a nanoscale chiral magnetic tunnel junction (MTJ) hosting a single, ambient skyrmion. Using a suite of electrical and multi-modal imaging techniques, we show that the MTJ nucleates skyrmions of fixed polarity, whose large readout signal - 20-70% relative to uniform states - corresponds directly to skyrmion size. Further, the MTJ exploits complementary mechanisms to stabilize distinctly sized skyrmions at zero field, thereby realizing three nonvolatile electrical states. Crucially, it can write and delete skyrmions using current densities 1,000 times lower than state-of-the-art. These results provide a platform to incorporate readout and manipulation of skyrmionic bits across myriad device architectures, and a springboard to harness chiral spin textures for multi-bit memory and unconventional computing. 	
Coherent Microwave Emission of a Gain-Driven Polariton	http://arxiv.org/abs/2302.08904v1	2023-02-15T19:35:53Z	2023-02-15T19:35:53Z	  By developing a gain-embedded cavity magnonics platform, we create gain-driven polariton (GDP) that is activated by an amplified electromagnetic field. Distinct effects of gain-driven light-matter interaction, such as polariton auto-oscillations, polariton phase singularity, self-selection of a polariton bright mode, and gain-induced magnon-photon synchronization, are theoretically studied and experimentally manifested. Utilizing the gain-sustained photon coherence of the GDP, we demonstrate polariton-based coherent microwave amplication (~ 40 dB) and achieve high-quality coherent microwave emission (Q > 10^9). 	
"The discovery of blue-cored dwarf early-type galaxies in isolated
  environments"	http://arxiv.org/abs/2302.07808v1	2023-02-15T17:48:10Z	2023-02-15T17:48:10Z	  The presence of blue-cored dwarf early-type galaxies (dE(bc)s) in high-density environments supports the scenario of the transformation of infalling late-type galaxies into quiescent dwarf early-type galaxies by environmental effects. While low-density environments lacking environmental processes could not be relevant to the formation of dE(bc)s, we discovered a large sample of rare dE(bc)s in isolated environments at z < 0.01 using the NASA-Sloan Atlas catalog. Thirty-two isolated dE(bc)s were identified by visual inspection of the Sloan Digital Sky Survey images and g - r color profiles. We found that (1) isolated dE(bc)s exhibit similar structural parameters to dE(bc)s in the Virgo cluster; (2) based on the ultraviolet-r color-magnitude relation, color gradients, and optical emission lines of dE(bc)s, isolated dE(bc)s show more vigorous, centrally concentrated SF compared to their counterparts in the Virgo cluster; (3) at a given stellar mass, isolated dE(bc)s tend to have a larger fraction of gas mass than their Virgo counterparts. We discuss a scenario of episodic SF sustained by gas accretion, suggested by Sanchez Almeida et al., in which the star-bursting blue compact dwarf galaxy (BCD)-quiescent BCD (QBCD) cycle can be repeated during the Hubble time. We suggest that, in this cadence, isolated dE(bc)s might be QBCDs at pre- or post-BCD stages. Our results imply that dE(bc)s comprise a mixture of objects with two types of origins, nature or nurture, depending on their environment. 	
"Optimal Cruise Airspeed for Hybrid-Electric and Electric Aircraft:
  Applications to Air Mobility"	http://arxiv.org/abs/2302.07358v1	2023-02-14T21:44:09Z	2023-02-14T21:44:09Z	  Electric and hybrid-electric aircraft can help our society transition towards more sustainable aviation and lower greenhouse gas (GHG) emissions. This paper provides solutions to minimize the direct operating cost (DOC) for hybrid-electric aircraft. The solution is the positive real root of a quintic polynomial which is derived using Pontryagin's minimum principle. By properly selecting a hybridization factor, one can also find the cruise airspeed corresponding to the minimum DOC of an electric aircraft. The optimal airspeed is integrated into the Rapidly-exploring Random Trees Star (RRT*) path planning algorithm. The minimum DOC solutions are investigated in a hybrid-electric international travel scenario and the path planning approach is applied to an electric aircraft city scenario. 	
"An Experimental Study of Byzantine-Robust Aggregation Schemes in
  Federated Learning"	http://arxiv.org/abs/2302.07173v1	2023-02-14T16:36:38Z	2023-02-14T16:36:38Z	  Byzantine-robust federated learning aims at mitigating Byzantine failures during the federated training process, where malicious participants may upload arbitrary local updates to the central server to degrade the performance of the global model. In recent years, several robust aggregation schemes have been proposed to defend against malicious updates from Byzantine clients and improve the robustness of federated learning. These solutions were claimed to be Byzantine-robust, under certain assumptions. Other than that, new attack strategies are emerging, striving to circumvent the defense schemes. However, there is a lack of systematic comparison and empirical study thereof. In this paper, we conduct an experimental study of Byzantine-robust aggregation schemes under different attacks using two popular algorithms in federated learning, FedSGD and FedAvg . We first survey existing Byzantine attack strategies and Byzantine-robust aggregation schemes that aim to defend against Byzantine attacks. We also propose a new scheme, ClippedClustering , to enhance the robustness of a clustering-based scheme by automatically clipping the updates. Then we provide an experimental evaluation of eight aggregation schemes in the scenario of five different Byzantine attacks. Our results show that these aggregation schemes sustain relatively high accuracy in some cases but are ineffective in others. In particular, our proposed ClippedClustering successfully defends against most attacks under independent and IID local datasets. However, when the local datasets are Non-IID, the performance of all the aggregation schemes significantly decreases. With Non-IID data, some of these aggregation schemes fail even in the complete absence of Byzantine clients. We conclude that the robustness of all the aggregation schemes is limited, highlighting the need for new defense strategies, in particular for Non-IID datasets. 	
"Pressure-tunable magnetic topological phases in magnetic topological
  insulator MnSb4Te7"	http://arxiv.org/abs/2302.07113v1	2023-02-14T15:16:03Z	2023-02-14T15:16:03Z	  Magnetic topological insulators, possessing both magnetic order and topological electronic structure, provides an excellent platform to research unusual physical properties. Here, we report a high-pressure study on the anomalous Hall effect of magnetic TI MnSb4Te7 through transports measurements combined with first-principle theoretical calculations. We discover that the ground state of MnSb4Te7 experiences a magnetic phase transition from the A-type antiferromagnetic state to ferromagnetic dominating state at 3.78 GPa, although its crystal sustains a rhombohedral phase under high pressures up to 8 GPa. The anomalous Hall conductance {\sigma}xyA keeps around 10 {\Omega}-1 cm-1, dominated by the intrinsic mechanism even after the magnetic phase transition. The results shed light on the intriguing magnetism in MnSb4Te7 and pave the way for further studies of the relationship between topology and magnetism in topological materials. 	
Optimal Transport for Change Detection on LiDAR Point Clouds	http://arxiv.org/abs/2302.07025v1	2023-02-14T13:08:07Z	2023-02-14T13:08:07Z	  The detection of changes occurring in multi-temporal remote sensing data plays a crucial role in monitoring several aspects of real life, such as disasters, deforestation, and urban planning. In the latter context, identifying both newly built and demolished buildings is essential to help landscape and city managers to promote sustainable development. While the use of airborne LiDAR point clouds has become widespread in urban change detection, the most common approaches require the transformation of a point cloud into a regular grid of interpolated height measurements, i.e. Digital Elevation Model (DEM). However, the DEM's interpolation step causes an information loss related to the height of the objects, affecting the detection capability of building changes, where the high resolution of LiDAR point clouds in the third dimension would be the most beneficial. Notwithstanding recent attempts to detect changes directly on point clouds using either a distance-based computation method or a semantic segmentation pre-processing step, only the M3C2 distance computation-based approach can identify both positive and negative changes, which is of paramount importance in urban planning. Motivated by the previous arguments, we introduce a principled change detection pipeline, based on optimal transport, capable of distinguishing between newly built buildings (positive changes) and demolished ones (negative changes). In this work, we propose to use unbalanced optimal transport to cope with the creation and destruction of mass related to building changes occurring in a bi-temporal pair of LiDAR point clouds. We demonstrate the efficacy of our approach on the only publicly available airborne LiDAR dataset for change detection by showing superior performance over the M3C2 and the previous optimal transport-based method presented by Nicolas Courty et al.at IGARSS 2016. 	
"Colossal reversible barocaloric effects in a plastic crystal mediated by
  lattice vibrations and ion diffusion"	http://arxiv.org/abs/2302.06993v1	2023-02-14T11:56:06Z	2023-02-14T11:56:06Z	  Solid-state methods for cooling and heating promise a more sustainable alternative to current compression cycles of greenhouse gases and inefficient fuel-burning heaters. Barocaloric effects (BCE) driven by hydrostatic pressure ($p$) are especially encouraging in terms of large adiabatic temperature changes ($|\Delta T| \sim 10$ K) and colossal isothermal entropy changes ($|\Delta S| \sim 100$ JK$^{-1}$kg$^{-1}$). However, BCE typically require large pressure shifts due to irreversibility issues, and sizeable $|\Delta T|$ and $|\Delta S|$ seldom are realized in a same material. Here, we demonstrate the existence of colossal and reversible BCE in LiCB$_{11}$H$_{12}$, a well-known solid electrolyte, near its order-disorder phase transition at $\approx 380$ K. Specifically, for $\Delta p \approx 0.23$ $(0.10)$ GPa we measured $|\Delta S_{\rm rev}| = 280$ $(200)$ JK$^{-1}$kg$^{-1}$ and $|\Delta T_{\rm rev}| = 32$ $(10)$ K, which individually rival with state-of-the-art barocaloric shifts obtained under similar pressure conditions. Furthermore, over a wide temperature range, pressure shifts of the order of $0.1$ GPa yield huge reversible barocaloric strengths of $\approx 2$ JK$^{-1}$kg$^{-1}$MPa$^{-1}$. Molecular dynamics simulations were carried out to quantify the role of lattice vibrations, molecular reorientations and ion diffusion on the disclosed colossal BCE. Interestingly, lattice vibrations were found to contribute the most to $|\Delta S|$ while the diffusion of lithium ions, despite adding up only slightly to the accompanying entropy change, was crucial in enabling the molecular order-disorder phase transition. Our work expands the knowledge on plastic crystals and should motivate the investigation of BCE in a variety of solid electrolytes displaying ion diffusion and concomitant molecular orientational disorder. 	
On the importance of AI research beyond disciplines	http://arxiv.org/abs/2302.06655v1	2023-02-13T19:39:37Z	2023-02-13T19:39:37Z	  As the impact of AI on various scientific fields is increasing, it is crucial to embrace interdisciplinary knowledge to understand the impact of technology on society. The goal is to foster a research environment beyond disciplines that values diversity and creates, critiques and develops new conceptual and theoretical frameworks. Even though research beyond disciplines is essential for understanding complex societal issues and creating positive impact it is notoriously difficult to evaluate and is often not recognized by current academic career progression. The motivation for this paper is to engage in broad discussion across disciplines and identify guiding principles fir AI research beyond disciplines in a structured and inclusive way, revealing new perspectives and contributing to societal and human wellbeing and sustainability. 	
Fourier Neural Operator for Plasma Modelling	http://arxiv.org/abs/2302.06542v1	2023-02-13T17:35:31Z	2023-02-13T17:35:31Z	  Predicting plasma evolution within a Tokamak is crucial to building a sustainable fusion reactor. Whether in the simulation space or within the experimental domain, the capability to forecast the spatio-temporal evolution of plasma field variables rapidly and accurately could improve active control methods on current tokamak devices and future fusion reactors. In this work, we demonstrate the utility of using Fourier Neural Operator (FNO) to model the plasma evolution in simulations and experiments. Our work shows that the FNO is capable of predicting magnetohydrodynamic models governing the plasma dynamics, 6 orders of magnitude faster than the traditional numerical solver, while maintaining considerable accuracy (NMSE $\sim 10^{-5})$. Our work also benchmarks the performance of the FNO against other standard surrogate models such as Conv-LSTM and U-Net and demonstrate that the FNO takes significantly less time to train, requires less parameters and outperforms other models. We extend the FNO approach to model the plasma evolution observed by the cameras positioned within the MAST spherical tokamak. We illustrate its capability in forecasting the formation of filaments within the plasma as well as the heat deposits. The FNO deployed to model the camera is capable of forecasting the full length of the plasma shot within half the time of the shot duration. 	
"Density jump as a function of magnetic field strength for parallel
  collisionless shocks with anisotropic upstream pressure"	http://arxiv.org/abs/2302.06521v1	2023-02-13T17:06:37Z	2023-02-13T17:06:37Z	  The properties of collisionless shocks are frequently assessed in the magnetohydrodynamics (MHD) model. Yet, in a collisionless plasma, an ambient magnetic field can sustain a stable anisotropy in the upstream or the downstream, resulting in a departure from the MHD predicted behavior. We present a model allowing to derive the downstream anisotropy, hence the shock density jump, in terms of the upstream quantities. For simplicity, the case of a parallel shock in pair plasma is considered. Contrary to previous works where the upstream was assumed isotropic, here the upstream anisotropy $A=T_\perp/T_\parallel$ is a free parameter. The strong sonic shock regime is formally identical to the isotropic upstream case. Yet, for intermediate sonic Mach numbers, a variety of behaviors appear as a result of the anisotropy of the upstream. 	
On the 3D turbulence regime in a Tokamak plasma edge	http://arxiv.org/abs/2302.06480v1	2023-02-13T15:56:26Z	2023-02-13T15:56:26Z	  We derive a reduced model for the electrostatic turbulence in a Tokamak edge, when dealing with a resistive plasma and neglecting the spatial gradient of the background density which triggers the linear drift wave response. The obtained dynamics, de facto equivalent to a Hasegawa-Wakatani model, is characterized by a constitutive relation between the electric potential Laplacian and the density, which allows to deal with a single 3D equation governing the electric potential fluctuations. We study the evolution of the model, by separating the $n=0$ ($n$ indicating toroidal-like number) mode from all the other ones. Then, we linearize the dynamics of the $n\neq 0$ modes around the steady 2D spectrum, which describes the spectral features of the electrostatic 2D turbulence. We theoretically and numerically demonstrate the existence of decaying branch of the 3D turbulence, having such a 2D steady spectrum as a natural attractor. This result suggests that the basic constituent of the self-sustained non-linear drift response in the plasma edge has to be individualized in the non-linear 2D electrostatic turbulence. 	
"Divide and Save: Splitting Workload Among Containers in an Edge Device
  to Save Energy and Time"	http://arxiv.org/abs/2302.06478v1	2023-02-13T15:55:38Z	2023-02-13T15:55:38Z	  The increasing demand for edge computing is leading to a rise in energy consumption from edge devices, which can have significant environmental and financial implications. To address this, in this paper we present a novel method to enhance the energy efficiency while speeding up computations by distributing the workload among multiple containers in an edge device. Experiments are conducted on two Nvidia Jetson edge boards, the TX2 and the AGX Orin, exploring how using a different number of containers can affect the energy consumption and the computational time for an inference task. To demonstrate the effectiveness of our splitting approach, a video object detection task is conducted using an embedded version of the state-of-the-art YOLO algorithm, quantifying the energy and the time savings achieved compared to doing the computations on a single container. The proposed method can help mitigate the environmental and economic consequences of high energy consumption in edge computing, by providing a more sustainable approach to managing the workload of edge devices. 	
"Optimal Charging Profile Design for Solar-Powered Sustainable UAV
  Communication Networks"	http://arxiv.org/abs/2302.06092v1	2023-02-13T04:23:34Z	2023-02-13T04:23:34Z	"  This work studies optimal solar charging for solar-powered self-sustainable UAV communication networks, considering the day-scale time-variability of solar radiation and user service demand. The objective is to optimally trade off between the user coverage performance and the net energy loss of the network by proactively assigning UAVs to serve, charge, or land. Specifically, the studied problem is first formulated into a time-coupled mixed-integer non-convex optimization problem, and further decoupled into two sub-problems for tractability. To solve the challenge caused by time-coupling, deep reinforcement learning (DRL) algorithms are respectively designed for the two sub-problems. Particularly, a relaxation mechanism is put forward to overcome the ""dimension curse"" incurred by the large discrete action space in the second sub-problem. At last, simulation results demonstrate the efficacy of our designed DRL algorithms in trading off the communication performance against the net energy loss, and the impact of different parameters on the tradeoff performance. "	
"Machine Learning Assisted Bad Data Detection for High-throughput
  Substation Communication"	http://arxiv.org/abs/2302.05949v1	2023-02-12T16:12:50Z	2023-02-12T16:12:50Z	  Electrical substations are becoming more prone to cyber-attacks due to increasing digitalization. Prevailing defense measures based on cyber rules are often inadequate to detect attacks that use legitimate-looking measurements. In this work, we design and implement a bad data detection solution for electrical substations called ResiGate, that effectively combines a physics-based approach and a machine-learning-based approach to provide substantial speed-up in high-throughput substation communication scenarios, while still maintaining high detection accuracy and confidence. While many existing physics-based schemes are designed for deployment in control centers (due to their high computational requirement), ResiGate is designed as a security appliance that can be deployed on low-cost industrial computers at the edge of the smart grid so that it can detect local substation-level attacks in a timely manner. A key challenge for this is to continuously run the computationally demanding physics-based analysis to monitor the measurement data frequently transmitted in a typical substation. To provide high throughput without sacrificing accuracy, ResiGate uses machine learning to effectively filter out most of the non-suspicious (normal) data and thereby reducing the overall computational load, allowing efficient performance even with a high volume of network traffic. We implement ResiGate on a low-cost industrial computer and our experiments confirm that ResiGate can detect attacks with zero error while sustaining a high throughput. 	
"Investigation of Enhanced Inertial Navigation Algorithms by Functional
  Iteration"	http://arxiv.org/abs/2302.05855v1	2023-02-12T04:41:59Z	2023-02-12T04:41:59Z	  The defects of the traditional strapdown inertial navigation algorithms become well acknowledged and the enhanced traditional algorithms were quite recently proposed trying to mitigate both theoretical and algorithmic defects. In this paper, the accuracies of the traditional algorithms, the enhanced algorithms, and the velocity algorithm based on the velocity translation vector are re-investigated in the common case of two samples, for the first time against the true reference provided by the functional iteration approach that has provable convergence and essentially reduces the noncommutativity errors to machine precision. Notably, the analyses by the help of MATLAB symbolic toolbox reveal the marginal effect of the enhanced algorithms, and the error orders of all algorithms analyzed against functional iteration are consistent with the existing literatures. Numerical results under coning motions agree with analyses that the enhanced algorithms have little significant accuracy improvement over the traditional algorithms, while the functional iteration approach possesses significant accuracy superiority even in sustained lowly dynamic conditions. 	
"Grey Wolf Optimizer and Whale Optimization Algorithm for Stochastic
  Inventory Management of Reusable Products in a two-level Supply Chain"	http://arxiv.org/abs/2302.05796v1	2023-02-11T22:18:00Z	2023-02-11T22:18:00Z	  Product reuse and recovery is an efficient tool that helps companies to simultaneously address economic and environmental dimensions of sustainability. This paper presents a novel problem for stock management of reusable products in a single-vendor, multi-product, multi-retailer network. Several constraints, such as the maximum budget, storage capacity, number of orders, etc., are considered in their stochastic form to provide a more realistic framework. The presented problem is formulated as a constrained nonlinear mathematical model. The chance-constrained programming method is suggested to deal with the constraints' uncertainty. Regarding the nonlinearity of the model, grey wolf optimizer (GWO) and whale optimization algorithm (WOA) as two novel metaheuristics are presented as solution approaches, and the sequential quadratic programming (SQP) exact algorithm validates their performance. The parameters of algorithms are calibrated using the Taguchi method for the design of experiments. Extensive analysis is established by solving several numerical results in different sizes and utilizing several comparison measures. Also, the results are compared statistically using proper parametric and non-parametric tests. The analysis of the results shows a significant difference between the algorithms, and GWO has a better performance for solving the presented problem. In addition, both algorithms perform well in searching the solution space, where the GWO and WOA differences with the optimal solution of the SQP algorithm are negligible. 	
"Locating the Sources of Sub-synchronous Oscillations Induced by the
  Control of Voltage Source Converters Based on Energy Structure and
  Nonlinearity Detection"	http://arxiv.org/abs/2302.05736v2	2023-02-17T16:04:04Z	2023-02-11T16:22:55Z	  The oscillation phenomena associated with the control of voltage source converters (VSCs) are widely concerning, and locating the source of these oscillations is crucial to suppressing them; therefore, this paper presents a locating scheme, based on the energy structure and nonlinearity detection. On the one hand, the energy structure, which conforms with the principle of the energy-based method and dissipativity theory, is constructed to describe the transient energy flow for VSCs, and on this basis, a defined characteristic quantity is implemented to narrow the scope of oscillation source location; on the other hand, according to the self-sustained oscillation characteristics of VSCs, an index for nonlinearity detection is applied to locate the VSCs which produce the oscillation energy. The combination of the energy structure and nonlinearity detection could distinguish the contributions of different VSCs to the oscillation. The results of a case study implemented by the PSCAD/EMTDC simulation validate the proposed scheme. 	
"Improvement in the Performance and Efficiency on Self-Deficient
  CaTiO$_3$: Towards Sustainable and Affordable New-Generation Solar Cells"	http://arxiv.org/abs/2302.05679v1	2023-02-11T12:27:46Z	2023-02-11T12:27:46Z	"  Thin films of pure and self-deficient calcium titanites i.e., CaTiO$_3$, Ca$_{1-\alpha}$TiO$_3$, CaTi$_{1-\beta}$O$_3$ and CaTiO$_{3-\gamma}$ have been deposited on ITO substrate using dip coating method. X-ray diffraction and Scanning electron Microscopy (SEM) analysis confirm the structural and morphology of all deposited thin films. Photocurrent measurement has been done, and it is observed that during the incidence of UV light on the as-prepared device (i.e., in the ""ON"" state), a significant increase in photocurrent (IUV) at zero voltage was observed in case of O deficient CaTiO$_3$, while in case of Ti and Ca deficient thin films smaller values of photocurrents were seen. Responsivity and detectivity of deposited thin films of all self-deficient CaTiO3 were found to be maximum in the UV region while they also showed smaller contributions in the visible range possibly due to the presence of self-deficiency. The self-deficient sample exhibits lower resistance (higher recombination rate) than the pure sample at low voltage, but at higher voltage, it is almost identical. Furthermore, theoretical calculations have been performed using the first-principles density-functional theory to validate the experimental findings on self-deficient CaTiO$_3$. Incident-photon-to-current efficiency (IPCE) and current density have also been measured for all deficient CaTiO$_3$ samples. Maximum IPCE have been found in the range 25%-28% for Ti and O deficient samples in the UV range (280- 400 nm). We argue that first-principles DFT calculations combined with the experimental measurements on self-deficient CaTiO$_3$ thin films offer a reliable way to enhance the performance of perovskite-based solar devices. "	
"A LED-based Functional Light Source for the Characterization of Thin
  Film Solar Cells"	http://arxiv.org/abs/2302.05377v2	2023-02-15T18:35:01Z	2023-02-10T16:57:53Z	  A light source of selective functionalities of wavelengths, illumination periods, and intensities is desirable for investigating performance parameters as well as the quality of different layers and interfaces of solar cells. Conventional light sources used for these types of research are expensive, space-consuming, cumbersome to work with, and have limited functionalities. We have developed a light source with variable wavelength, intensity, and illumination period to address these issues using an illumination period control unit, voltage regulator, neutral density filter, alterable light emitting diodes, etc. As a proof-of-concept, we employed our constructed light source to investigate the intensity, wavelength, illumination period modulated photovoltaic, and impedance properties of inorganic thin film solar cells such as cadmium telluride (CdTe) and copper zinc tin sulfide (CZTS) using lights of wavelength 410, 520, and 635 nm. We hope to use this light source for photophysical and photochemical studies of metal oxide materials used for renewable energy research. 	
"Star forming brightest cluster galaxies at $z\sim0.4$ in KiDS. Further
  studies of cold gas and stellar properties"	http://arxiv.org/abs/2302.05360v1	2023-02-10T16:20:56Z	2023-02-10T16:20:56Z	  Brightest cluster galaxies (BCGs) are among the most massive galaxies in the Universe. Their star formation (SF) history and stellar mass assembly are debated. Recent studies suggest the presence of an emerging population of intermediate-$z$ star forming and gas-rich BCGs, where the molecular gas reservoirs are impacted by strong environmental processing. We have selected three among the most star-forming $z\sim0.4$ BCGs in the Kilo-Degree Survey (KiDS), and observed them with the IRAM 30m telescope in the first three CO transitions. We found double-horn CO(1$\rightarrow$0) and CO(3$\rightarrow$2) emission for the KiDS 1433 BCG, yielding a large molecular gas reservoir with $M_{H_2}=(5.9\pm1.2)\times10^{10}~M_\odot$ and a high gas-to-stellar mass ratio $M_{H_2}/M_\star=(0.32^{+0.12}_{-0.10})$. We increase the limited sample of distant BCGs with detections in multiple CO transitions. The double-horn emission for the KiDS 1433 BCG implies a low gas concentration, while a modeling of the spectra yields an extended molecular gas reservoir, with a characteristic radius of $\sim$(5-7) kpc, which is reminiscent of a mature extended-disk phase observed in some local BCGs. For the other two BCGs we are able to set upper limits of $M_{H_2}/M_\star<0.07$ and $<0.23$, which are among the lowest for distant BCGs. We then combined our observations with available stellar, SF, and dust properties of the targeted BCGs, and compared them with $\sim100$ distant cluster galaxies, including additional intermediate-$z$ BCGs, with observations in CO from the literature. The molecular gas properties of star forming BCGs are heterogeneous. On one side, gas-rich BCGs show extended gas reservoirs, which sustain the significant SF activity, which is reminiscent of recent gas infall. Conversely, the existence of similarly star forming, but gas-poor, BCGs suggest that gas depletion precedes SF quenching. 	
"Toward Human-Centered Responsible Artificial Intelligence: A Review of
  CHI Research and Industry Toolkits"	http://arxiv.org/abs/2302.05284v2	2023-02-26T17:57:36Z	2023-02-10T14:47:33Z	  As Artificial Intelligence (AI) continues to advance rapidly, it becomes increasingly important to consider AI's ethical and societal implications. In this paper, we present a bottom-up mapping of the current state of research in Human-Centered Responsible AI (HCR-AI) by thematically reviewing and analyzing 27 CHI research papers and 19 toolkits from industry and academia. Our results show that the current research in HCR-AI places a heavy emphasis on explainability, fairness, privacy, and security. We also found that there is space to research accountability in AI and build usable tools for non-experts to audit AI. While the CHI community has started to champion the well-being of individuals directly or indirectly impacted by AI, more research and toolkits are still required to address the long-term effects of AI on individuals, societies, and natural resources (human flourishing and sustainability). 	
N/MEMS Biosensors: An Introduction	http://arxiv.org/abs/2302.06507v1	2023-02-10T11:01:47Z	2023-02-10T11:01:47Z	  In the 21st century, biosensors have gathered much wider attention than ever before, irrespective of the technology that promises to bring them forward. With the recent COVID-19 outbreak, the concern and efforts to restore global health and well-being are rising at an unprecedented rate. A requirement to develop precise, fast, point-of-care, reliable, easily disposable/reproducible and low-cost diagnostic tools have ascended. Biosensors form a primary element of hand-held medical kits, tools, products, and/or instruments. They have a very wide range of applications such as nearby environmental checks, detecting the onset of a disease, food quality, drug discovery, medicine dose control, and many more. Thischapter explains how Nano/Micro-Electro-Mechanical Systems (N/MEMS) can be enabling technology towards a sustainable, scalable, ultra-miniaturized, easy-to-use, energy efficient, and integrated bio/chemical sensing system. This study provides a deeper insight into the fundamentals, recent advances, and potential end applications of N/MEMS sensors and integrated systems to detect and measure the concentration of biological and/or chemical analytes. Transduction principle/s, materials, efficient designs including readout technique, and sensor performance are explained. This is followed by a discussion on how N/MEMS biosensors continue to evolve. The challenges and possible opportunities are also discussed. 	
"Towards Fully Passive Plug and Play Time-Bin Quantum Key Distribution
  over Multi-Mode Channels"	http://arxiv.org/abs/2302.05038v1	2023-02-10T03:53:21Z	2023-02-10T03:53:21Z	  Phase stabilization of distant quantum time-bin interferometers can be a major challenge for quantum communication networks, and is typically achieved by exchanging reference optical signals, which can be particularly challenging for free-space communication channels. We demonstrate a novel solution that utilizes reference frame independent time-bin quantum key distribution that completely avoids the need for active relative phase stabilization of the remote interferometers. We realized a proof of concept experiment using a source of hybrid entanglement with polarization and time-bin, and show a sustained asymptotic secure key rate of greater than 0.06 bits/coincidence over a 15m multi-mode fiber optical channel. This is achieved without the use of mode filtering, adaptive optics, active basis selection, nor active phase alignment. This system can therefore be considered a passive plug and play self-compensating solution that is suitable for spatially multi-mode channels, and improves the viability of time-bin quantum communication links over challenging channels such as airborne, ground to space, and multi-mode fibers. 	
"Variant Plateau Law in Atomically Thin Transition Metal Dichalcogenide
  Dome Networks"	http://arxiv.org/abs/2302.05003v2	2023-02-13T07:47:05Z	2023-02-10T01:19:04Z	  Since its fundamental inception from soap bubbles, Plateau law has sparked extensive research in equilibrated states. However, most studies primarily relied on liquids, foams or cellular structures, whereas its applicability has yet to be explored in nano-scale solid films. Here, we observed a variant Plateau law in networks of atomically thin domes made of solid two-dimensional (2D) transition metal dichalcogenides (TMDs). Discrete layer-dependent van der Waals (vdWs) interaction energies were experimentally and theoretically obtained for domes protruding in different TMD layers. Significant surface tension differences from layer-dependent vdWs interaction energies manifest in a variant of this fundamental law. Meanwhile, the remarkable mechanical properties, gas impermeability and interlayer vdWs interaction energy of TMD films enable domes and the networks to sustain high gas pressure and exist in a fundamentally variant nature for several years. Our findings pave the way towards exploring variant discretised states with applications in opto-electro-mechanical devices. 	
"Presence of liquid water during the evolution of exomoons orbiting
  ejected free-floating planets"	http://arxiv.org/abs/2302.04946v1	2023-02-09T21:32:11Z	2023-02-09T21:32:11Z	  Free-floating planets (FFPs) can result from dynamical scattering processes happening in the first few million years of a planetary system's life. Several models predict the possibility, for these isolated planetary-mass objects, to retain exomoons after their ejection. The tidal heating mechanism and the presence of an atmosphere with a relatively high optical thickness may support the formation and maintenance of oceans of liquid water on the surface of these satellites. In order to study the timescales over which liquid water can be maintained, we perform dynamical simulations of the ejection process and infer the resulting statistics of the population of surviving exomoons around free-floating planets. The subsequent tidal evolution of the moons' orbital parameters is a pivotal step to determine when the orbits will circularize, with a consequential decay of the tidal heating. We find that close-in ($a \lesssim 25 $R$_{\rm J}$) Earth-mass moons with CO$_2$-dominated atmospheres could retain liquid water on their surfaces for long timescales, depending on the mass of the atmospheric envelope and the surface pressure assumed. Massive atmospheres are needed to trap the heat produced by tidal friction that makes these moons habitable. For Earth-like pressure conditions ($p_0$ = 1 bar), satellites could sustain liquid water on their surfaces up to 52 Myr. For higher surface pressures (10 and 100 bar), moons could be habitable up to 276 Myr and 1.6 Gyr, respectively. Close-in satellites experience habitable conditions for long timescales, and during the ejection of the FFP remain bound with the escaping planet, being less affected by the close encounter. 	
Biomimetic Micropillar Wick for Enhanced Thin-Film Evaporation	http://arxiv.org/abs/2302.04573v1	2023-02-09T11:24:40Z	2023-02-09T11:24:40Z	  Sustainable liquid cooling solutions are recognized as the future of thermal management in the chip industry. Among them, the phase change heat transfer devices such as heat pipes and vapour chambers have shown tremendous potential. These devices rely on the physics of capillary-driven thin-film evaporation which is inherently coupled with the design and optimization of the evaporator wicks used in these devices. Here, we introduce a biomimetic evaporator wick design inspired by the peristome of the Nepenthes alata that can achieve significantly enhanced evaporative cooling. It consists of array of micropillars with multiple wedges along the sidewall of each micropillar. The efficacy of the wedged micropillar is evaluated based on a validated numerical model on the metrics of dryout heat flux and effective heat transfer coefficient. The wedge angle is chosen such that wedged micropillars cause liquid filaments to rise along the micropillar vertical walls. This results in a significant increase in thin-film area for evaporation. Additionally, the large mean curvature of the liquid meniscus produces strong capillary pumping pressure and simultaneously, the wedges increase the overall permeability of the wick. Consequently, our model predicts that the wedged micropillar wick can attain ~234% enhancement of dryout heat flux compared to a conventional cylindrical micropillar wick of similar geometrical dimensions. Moreover, the wedged micropillars can also attain higher effective heat transfer coefficient under dryout conditions thus outperforming the cylindrical micropillar in terms of heat transfer efficiency. Our study provide insight into the design and capability of the biomimetic wedged micropillars as an efficient evaporator wick for various thin-film evaporation applications. 	
GFM: Building Geospatial Foundation Models via Continual Pretraining	http://arxiv.org/abs/2302.04476v1	2023-02-09T07:39:02Z	2023-02-09T07:39:02Z	  Geospatial technologies are becoming increasingly essential in our world for a large range of tasks, such as earth monitoring and natural disaster response. To help improve the applicability and performance of deep learning models on these geospatial tasks, various works have pursued the idea of a geospatial foundation model, i.e., training networks from scratch on a large corpus of remote sensing imagery. However, this approach often requires a significant amount of data and training time to achieve suitable performance, especially when employing large state-of-the-art transformer models.   In light of these challenges, we investigate a sustainable approach to building geospatial foundation models. In our investigations, we discover two important factors in the process. First, we find that the selection of pretraining data matters, even within the geospatial domain. We therefore gather a concise yet effective dataset for pretraining. Second, we find that available pretrained models on diverse datasets like ImageNet-22k should not be ignored when building geospatial foundation models, as their representations are still surprisingly effective. Rather, by leveraging their representations, we can build strong models for geospatial applications in a sustainable manner. To this end, we formulate a multi-objective continual pretraining approach for training sustainable geospatial foundation models. We experiment on a wide variety of downstream datasets and tasks, achieving strong performance across the board in comparison to ImageNet baselines and state-of-the-art geospatial pretrained models. 	
Minimal entropy production in the presence of anisotropic fluctuations	http://arxiv.org/abs/2302.04401v1	2023-02-09T01:58:42Z	2023-02-09T01:58:42Z	  Anisotropy in temperature, chemical potential, or ion concentration, provides the fuel that feeds dynamical processes that sustain life. At the same time, anisotropy is a root cause of incurred losses manifested as entropy production. In this work we consider a rudimentary model of an overdamped stochastic thermodynamic system in an anisotropic temperature heat bath, and study minimum entropy production when driving the system between thermodynamic states in finite time. While entropy production in isotropic temperature environments can be expressed in terms of the length (in the Wasserstein-2 metric) traversed by the thermodynamic state of the system, anisotropy complicates substantially the mechanism of entropy production since, besides dissipation, seepage of energy between ambient anisotropic heat sources by way of the system dynamics is often a major contributing factor. A key result of the paper is to show that in the presence of anisotropy, minimization of entropy production can once again be expressed via a modified Optimal Mass Transport (OMT) problem. However, in contrast to the isotropic situation that leads to a classical OMT problem and a Wasserstein length, entropy production may not be identically zero when the thermodynamic state remains unchanged (unless one has control over non-conservative forces); this is due to the fact that maintaining a Non-Equilibrium Steady-State (NESS) incurs an intrinsic entropic cost that can be traced back to a seepage of heat between heat baths. As alluded to, NESSs represent hallmarks of life, since living matter by necessity operates far from equilibrium. Therefore, the question studied herein, to characterize minimal entropy production in anisotropic environments, appears of central importance in biological processes and on how such processes may have evolved to optimize for available usage of resources. 	
"Dual-interest Factorization-heads Attention for Sequential
  Recommendation"	http://arxiv.org/abs/2302.03965v3	2023-02-10T15:14:07Z	2023-02-08T09:42:45Z	  Accurate user interest modeling is vital for recommendation scenarios. One of the effective solutions is the sequential recommendation that relies on click behaviors, but this is not elegant in the video feed recommendation where users are passive in receiving the streaming contents and return skip or no-skip behaviors. Here skip and no-skip behaviors can be treated as negative and positive feedback, respectively. With the mixture of positive and negative feedback, it is challenging to capture the transition pattern of behavioral sequence. To do so, FeedRec has exploited a shared vanilla Transformer, which may be inelegant because head interaction of multi-heads attention does not consider different types of feedback. In this paper, we propose Dual-interest Factorization-heads Attention for Sequential Recommendation (short for DFAR) consisting of feedback-aware encoding layer, dual-interest disentangling layer and prediction layer. In the feedback-aware encoding layer, we first suppose each head of multi-heads attention can capture specific feedback relations. Then we further propose factorization-heads attention which can mask specific head interaction and inject feedback information so as to factorize the relation between different types of feedback. Additionally, we propose a dual-interest disentangling layer to decouple positive and negative interests before performing disentanglement on their representations. Finally, we evolve the positive and negative interests by corresponding towers whose outputs are contrastive by BPR loss. Experiments on two real-world datasets show the superiority of our proposed method against state-of-the-art baselines. Further ablation study and visualization also sustain its effectiveness. We release the source code here: https://github.com/tsinghua-fib-lab/WWW2023-DFAR. 	
"GRB 221009A: Discovery of an Exceptionally Rare Nearby and Energetic
  Gamma-Ray Burst"	http://arxiv.org/abs/2302.03642v1	2023-02-07T17:48:40Z	2023-02-07T17:48:40Z	  We report the discovery of the unusually bright long-duration gamma-ray burst (GRB), GRB 221009A, as observed by the Neil Gehrels Swift Observatory (Swift), Monitor of All-sky X-ray Image (MAXI), and Neutron Star Interior Composition Explorer Mission (NICER). This energetic GRB was located relatively nearby (z = 0.151), allowing for sustained observations of the afterglow. The large X-ray luminosity and low Galactic latitude (b = 4.3 degrees) make GRB 221009A a powerful probe of dust in the Milky Way. Using echo tomography we map the line-of-sight dust distribution and find evidence for significant column densities at large distances (~> 10kpc). We present analysis of the light curves and spectra at X-ray and UV/optical wavelengths, and find that the X-ray afterglow of GRB 221009A is more than an order of magnitude brighter at T0 + 4.5 ks than any previous GRB observed by Swift. In its rest frame GRB 221009A is at the high end of the afterglow luminosity distribution, but not uniquely so. In a simulation of randomly generated bursts, only 1 in 10^4 long GRBs were as energetic as GRB 221009A; such a large E_gamma,iso implies a narrow jet structure, but the afterglow light curve is inconsistent with simple top-hat jet models. Using the sample of Swift GRBs with redshifts, we estimate that GRBs as energetic and nearby as GRB 221009A occur at a rate of ~<1 per 1000 yr - making this a truly remarkable opportunity unlikely to be repeated in our lifetime. 	
"Design of an Energy-Aware Cartesian Impedance Controller for
  Collaborative Disassembly"	http://arxiv.org/abs/2302.03587v2	2023-02-09T09:42:58Z	2023-02-07T16:54:51Z	  Human-robot collaborative disassembly is an emerging trend in the sustainable recycling process of electronic and mechanical products. It requires the use of advanced technologies to assist workers in repetitive physical tasks and deal with creaky and potentially damaged components. Nevertheless, when disassembling worn-out or damaged components, unexpected robot behaviors may emerge, so harmless and symbiotic physical interaction with humans and the environment becomes paramount. This work addresses this challenge at the control level by ensuring safe and passive behaviors in unplanned interactions and contact losses. The proposed algorithm capitalizes on an energy-aware Cartesian impedance controller, which features energy scaling and damping injection, and an augmented energy tank, which limits the power flow from the controller to the robot. The controller is evaluated in a real-world flawed unscrewing task with a Franka Emika Panda and is compared to a standard impedance controller and a hybrid force-impedance controller. The results demonstrate the high potential of the algorithm in human-robot collaborative disassembly tasks. 	
"Amplification of the phosphorescent emission guided by a pulsed laser
  stripe"	http://arxiv.org/abs/2302.03538v2	2023-02-17T17:16:29Z	2023-02-07T15:44:35Z	  Phosphorescent emissions at room temperature from solid-state self sustained film fabricated using phenazine derivative molecules blended in a solution of poly(methyl methacrylate) were investigated at steady-state experimental conditions. Stripe excitation by a pulsed laser at different levels of intensities and different lengths of stripes, originates a guided emission up to the edge of the film, enabling us to assume higher gain characteristics for triplet states of the medium, due to the relatively higher contribution of the total integrated area for the phosphorescent part of the emission spectra. 	
"On the occurrence of buoyancy-induced oscillatory growth instability in
  directional solidification of alloys"	http://arxiv.org/abs/2302.03427v1	2023-02-07T12:25:40Z	2023-02-07T12:25:40Z	  Recent solidification experiments identified an oscillatory growth instability during directional solidification of Ni-based superalloy CMSX4 under a given range of cooling rates. From a modeling perspective, the quantitative simulation of dendritic growth under convective conditions remains challenging, due to the multiple length scales involved. Using the dendritic needle network (DNN) model, coupled with an efficient Navier-Stokes solver, we reproduced the buoyancy-induced growth oscillations observed in CMSX4 directional solidification. These previous results have shown that, for a given alloy and temperature gradient, oscillations occur in a narrow range of cooling rates (or pulling velocity, $V_p$) and that the selected primary dendrite arm spacing ($\Lambda$) plays a crucial role in the activation of the flow leading to oscillations. Here, we show that the oscillatory behavior may be generalized to other binary alloys within an appropriate range of $(V_p,\Lambda)$ by reproducing it for an Al-4at.%Cu alloy. We perform a mapping of oscillatory states as a function of $V_p$ and $\Lambda$, and identify the regions of occurrence of different behaviors (e.g., sustained or damped oscillations) and their effect on the oscillation characteristics. Our results suggest a minimum of $V_p$ for the occurrence of oscillations and confirm the correlation between the oscillation type (namely: damped, sustained, or noisy) with the ratio of average fluid velocity $\overline V$ over $V_p$. We describe the different observed growth regimes and highlight similarities and contrasts with our previous results for a CMSX4 alloy. 	
Data augmentation for battery materials using lattice scaling	http://arxiv.org/abs/2302.03356v1	2023-02-07T10:01:42Z	2023-02-07T10:01:42Z	  A significant step forward in Lithium-ion batteries (LIBs) developments can only be achieved by proposing mold-breaking research based on selecting the best materials for the cell components, optimizing cell manufacture, anticipating the degradation mechanisms of the LIBs, and consolidating the regeneration processes of damaged batteries. LIBs with longer recycling life, better safety, and the ability to be reused will establish sustainable state-of-the-art batteries with maximum energy efficiency, low costs, and minimal CO2 emissions within a circular economy, promoting sustainability in areas as relevant as electromobility and portable electronics. Recently, there has been increasing interest in applying Artificial Intelligence (AI) techniques and their subclasses to better predict novel materials with designed properties. This collection of methods has already obtained considerable success, having been used to predict numerous physical properties of materials. However, compared to other fields, the materials data are typically much smaller and sometimes more diverse, which undoubtedly affects the construction and effectiveness of AI models. At present, several Data Augmentation (DA) methods have been proposed in materials science based on flipping, rotating, and distorting the unit cells of materials, which have been demonstrated to be very efficient in increasing the size and quality of data. Here we present an even more effective new method of Data Augmentation based on the lattice scaling of crystal structures. In the lattice scaling DA method, the unit cell is perturbed, undergoing an increase and decrease of the unit cell volume in an isotropic or anisotropic way. This transformation is particularly pertinent for battery components since volume changes of up to 5% have been reported for the insertion-based LIBs during cycling. 	
"Time-variant Seismic Resilience Analysis Model for Water Distribution
  Systems"	http://arxiv.org/abs/2302.03254v1	2023-02-07T04:51:28Z	2023-02-07T04:51:28Z	  Water distribution systems (WDS) sustained severe damage in the past earthquakes. While previous studies investigated the seismic performance of buried water pipelines, the effects of corrosion on the pipeline seismic performance were ignored. The presence of corrosion on metallic pipeline walls aggravates seismic damage level because corrosion significantly reduces the pipeline strength. Most of the existing buried pipelines in the United States are aged and non-ductile metallic pipelines, which are vulnerable to seismic loading. To ensure continuous and smooth water supply to communities during and after earthquakes, it is necessary to evaluate the system-level seismic performance of WDS considering the aging effect in corroded pipelines. The current study develops a new framework of estimating the seismic resilience of WDS considering the time-variant effect of corrosion. The study formulates an approach that : (1) determines the seismic failure probability of pipeline using an extended American Lifelines Alliance (ALA) model that account for the effects of time-dependent corrosion; and (2) estimates system-level seismic performance based on pipeline reliability and edge betweenness centrality. The proposed approach is illustrated with a scenario earthquake hazard for mid-size WDS. The outcomes of the study reveal that the presence of corrosion on pipelines significantly reduces the system-level seismic performance of WDS. Most cast iron pipes have 100 years lifetime, system-level seismic resilience may decrease by 81% at high seismic wave intensity. 	
"Vibration-suppressed toolpath generation for kinematic and energy
  performance optimization in large dimension additive manufacturing"	http://arxiv.org/abs/2302.03226v1	2023-02-07T03:21:14Z	2023-02-07T03:21:14Z	  Product quality and sustainability in large dimension additive manufacturing (LDAM) highly rely on the kinematic and energy performance of LDAM systems. However, the mechanical vibration occurring in the fabrication process hinders the further development of AM technology in industrial manufacturing. To this end, a kinematic and energy performance optimization method for LDAM via vibration-suppressed toolpath generation (VTG) is put forward. Kinematic modeling of LDAM system and related energy consumption modeling are first constructed to reveal that the toolpath of servo system assumes the main responsibility for kinematic and energy performance in LDAM. The vibration-suppressed toolpath generation (VTG) method is thus proposed to customize servo trajectory for kinematic and energy performance optimization in LDAM. Extensive numerical and physical experiments are conducted on the W16 cylinder, including the measurement and analysis of the mechanical vibration amplitude, and assessment of the surface roughness before and after using the proposed VGT. These experimental results demonstrate that our VGT is able to simultaneously achieve kinematic and energy performance optimization in LDAM, even though the fabricated part owns aberrant and complex morphology. 	
"High Resolution Global Precipitation Downscaling with Latent Gaussian
  Models and Nonstationary SPDE Structure"	http://arxiv.org/abs/2302.03148v1	2023-02-06T22:53:38Z	2023-02-06T22:53:38Z	  Obtaining high-resolution maps of precipitation data can provide key insights to stakeholders to assess a sustainable access to water resources at urban scale. Mapping a nonstationary, sparse process such as precipitation at very high spatial resolution requires the interpolation of global datasets at the location where ground stations are available with statistical models able to capture complex non-Gaussian global space-time dependence structures. In this work, we propose a new approach based on capturing the spatial dependence of a latent Gaussian process via a locally deformed Stochastic Partial Differential Equation (SPDE) with a buffer allowing for a different spatial structure across land and sea. The finite volume approximation of the SPDE, coupled with Integrated Nested Laplace Approximation ensures feasible Bayesian inference for tens of millions of observations. The simulation studies showcase the improved predictability of the proposed approach against stationary and no-buffer alternatives. The proposed approach is then used to yield high resolution simulations of daily precipitation across the United States. 	
"Cooperverse: A Mobile-Edge-Cloud Framework for Universal Cooperative
  Perception with Mixed Connectivity and Automation"	http://arxiv.org/abs/2302.03128v1	2023-02-06T21:30:08Z	2023-02-06T21:30:08Z	  Cooperative perception (CP) is attracting increasing attention and is regarded as the core foundation to support cooperative driving automation, a potential key solution to addressing the safety, mobility, and sustainability issues of contemporary transportation systems. However, current research on CP is still at the beginning stages where a systematic problem formulation of CP is still missing, acting as the essential guideline of the system design of a CP system under real-world situations. In this paper, we formulate a universal CP system into an optimization problem and a mobile-edge-cloud framework called Cooperverse. This system addresses CP in a mixed connectivity and automation environment. A Dynamic Feature Sharing (DFS) methodology is introduced to support this CP system under certain constraints and a Random Priority Filtering (RPF) method is proposed to conduct DFS with high performance. Experiments have been conducted based on a high-fidelity CP platform, and the results show that the Cooperverse framework is effective for dynamic node engagement and the proposed DFS methodology can improve system CP performance by 14.5% and the RPF method can reduce the communication cost for mobile nodes by 90% with only 1.7% drop for average precision. 	
ConvoWaste: An Automatic Waste Segregation Machine Using Deep Learning	http://arxiv.org/abs/2302.02976v1	2023-02-06T18:08:33Z	2023-02-06T18:08:33Z	  Nowadays, proper urban waste management is one of the biggest concerns for maintaining a green and clean environment. An automatic waste segregation system can be a viable solution to improve the sustainability of the country and boost the circular economy. This paper proposes a machine to segregate waste into different parts with the help of a smart object detection algorithm using ConvoWaste in the field of deep convolutional neural networks (DCNN) and image processing techniques. In this paper, deep learning and image processing techniques are applied to precisely classify the waste, and the detected waste is placed inside the corresponding bins with the help of a servo motor-based system. This machine has the provision to notify the responsible authority regarding the waste level of the bins and the time to trash out the bins filled with garbage by using the ultrasonic sensors placed in each bin and the dual-band GSM-based communication technology. The entire system is controlled remotely through an Android app in order to dump the separated waste in the desired place thanks to its automation properties. The use of this system can aid in the process of recycling resources that were initially destined to become waste, utilizing natural resources, and turning these resources back into usable products. Thus, the system helps fulfill the criteria of a circular economy through resource optimization and extraction. Finally, the system is designed to provide services at a low cost while maintaining a high level of accuracy in terms of technological advancement in the field of artificial intelligence (AI). We have gotten 98% accuracy for our ConvoWaste deep learning model. 	
The interactions of the elliptical instability and convection	http://arxiv.org/abs/2302.02912v1	2023-02-06T16:32:07Z	2023-02-06T16:32:07Z	  The elliptical instability is an instability of elliptical streamlines, which can be excited by large-scale tidal flows in rotating fluid bodies, and excites inertial waves if the dimensionless tidal amplitude ($\epsilon$) is sufficiently large. It operates in convection zones but its interactions with turbulent convection have not been studied in this context. We perform an extensive suite of Cartesian hydrodynamical simulations in wide boxes to explore the interactions of the elliptical instability and Rayleigh-B\'enard convection. We find that geostrophic vortices generated by the elliptical instability dominate the flow, with energies far exceeding those of the inertial waves. Furthermore, we find that the elliptical instability can operate with convection, but it is suppressed for sufficiently strong convection, primarily by convectively-driven large-scale vortices. We examine the flow in Fourier space, allowing us to determine the energetically dominant frequencies and wavenumbers. We find that power primarily concentrates in geostrophic vortices, in wavenumbers that are convectively unstable, and along the inertial wave dispersion relation, even in non-elliptically deformed convective flows. Examining linear growth rates on a convective background, we find that convective large-scale vortices suppress the elliptical instability in the same way as the geostrophic vortices created by the elliptical instability itself. Finally, convective motions act as an effective viscosity on large-scale tidal flows, providing a sustained energy transfer (scaling as $\epsilon^2$). Furthermore, we find that the energy transfer resulting from bursts of elliptical instability, when it operates, is consistent with the $\epsilon^3$ scaling found in prior work. 	
"Label Assisted Autoencoder for Anomaly Detection in Power Generation
  Plants"	http://arxiv.org/abs/2302.02896v1	2023-02-06T16:03:38Z	2023-02-06T16:03:38Z	  One of the critical factors that drive the economic development of a country and guarantee the sustainability of its industries is the constant availability of electricity. This is usually provided by the national electric grid. However, in developing countries where companies are emerging on a constant basis including telecommunication industries, those are still experiencing a non-stable electricity supply. Therefore, they have to rely on generators to guarantee their full functionality. Those generators depend on fuel to function and the rate of consumption gets usually high, if not monitored properly. Monitoring operation is usually carried out by a (non-expert) human. In some cases, this could be a tedious process, as some companies have reported an exaggerated high consumption rate. This work proposes a label assisted autoencoder for anomaly detection in the fuel consumed by power generating plants. In addition to the autoencoder model, we added a labelling assistance module that checks if an observation is labelled, the label is used to check the veracity of the corresponding anomaly classification given a threshold. A consensus is then reached on whether training should stop or whether the threshold should be updated or the training should continue with the search for hyper-parameters. Results show that the proposed model is highly efficient for reading anomalies with a detection accuracy of $97.20\%$ which outperforms the existing model of $96.1\%$ accuracy trained on the same dataset. In addition, the proposed model is able to classify the anomalies according to their degree of severity. 	
"Good practices for clinical data warehouse implementation: a case study
  in France"	http://arxiv.org/abs/2302.07074v2	2023-03-07T08:35:36Z	2023-02-06T13:38:12Z	  Real World Data (RWD) bears great promises to improve the quality of care. However, specific infrastructures and methodologies are required to derive robust knowledge and brings innovations to the patient. Drawing upon the national case study of the 32 French regional and university hospitals governance, we highlight key aspects of modern Clinical Data Warehouses (CDWs): governance, transparency, types of data, data reuse, technical tools, documentation and data quality control processes. Semi-structured interviews as well as a review of reported studies on French CDWs were conducted in a semi-structured manner from March to November 2022. Out of 32 regional and university hospitals in France, 14 have a CDW in production, 5 are experimenting, 5 have a prospective CDW project, 8 did not have any CDW project at the time of writing. The implementation of CDW in France dates from 2011 and accelerated in the late 2020. From this case study, we draw some general guidelines for CDWs. The actual orientation of CDWs towards research requires efforts in governance stabilization, standardization of data schema and development in data quality and data documentation. Particular attention must be paid to the sustainability of the warehouse teams and to the multi-level governance. The transparency of the studies and the tools of transformation of the data must improve to allow successful multi-centric data reuses as well as innovations in routine care. 	
Ultrafast entropy production in pump-probe experiments	http://arxiv.org/abs/2302.02716v1	2023-02-06T11:44:14Z	2023-02-06T11:44:14Z	  The ultrafast control of materials has opened the possibility to investigate non-equilibrium states of matter with striking properties, provided the sample of interest can sustain the strong fields often required. Hence, understanding ultrafast thermodynamic processes within the material are key. While slow processes lead to quasi-static changes in equilibrium, we focus here on the opposite limit of extremely short time scales, where the system rapidly approaches a non-equilibrium regime. Thermodynamic processes under fast driving were considered before, e.g. in arXiv:2210.11975, but have never been brought into connection with controlled experiments. Here, we derive a mesoscopic model for the entropy production due to non-equilibrium phonons excited by a THz laser pulse. While entropy cannot be measured directly, we show that the spectral entropy production can be obtained from experimentally observable quantities, which we illustrate using time-resolved X-ray scattering data for SrTiO$_3$. Further, we compute the spectral entropy production as a function of frequency for SrTiO$_3$ and KTaO$_3$ for various temperatures. Finally, we predict that the power spectrum of the displacement-displacement correlation function exhibits a broad peak besides the eigenmode-resonance, which is associated with entropy production. 	
"Crowd-sensing commuting patterns using multi-source wireless data: a
  case of Helsinki commuter trains"	http://arxiv.org/abs/2302.02661v1	2023-02-06T09:59:33Z	2023-02-06T09:59:33Z	  Understanding the mobility patterns of commuter train passengers is crucial for developing efficient and sustainable transportation systems in urban areas. Traditional technologies, such as Automated Passenger Counters (APC) can measure the aggregated numbers of passengers entering and exiting trains, however, they do not provide detailed information nor passenger movements beyond the train itself. To overcome this limitation we investigate the potential combination of traditional APC with an emerging source capable of collecting detailed mobility demand data. This new data source derives from the pilot project TravelSense, led by the Helsinki Regional Transport Authority (HSL), which utilizes Bluetooth beacons and HSL's mobile phone ticket application to track anonymous passenger multimodal trajectories from origin to destination. By combining TravelSense data with APC we are able to better understand the structure of train users' journeys by identifying the origin and destination locations, modes of transport used to access commuter train stations, and boarding and alighting numbers at each station. These insights can assist public transport planning decisions and ultimately help to contribute to the goal of sustainable cities and communities by promoting the use of seamless and environmentally friendly transportation options. 	
"An Online Model-Following Projection Mechanism Using Reinforcement
  Learning"	http://arxiv.org/abs/2302.02493v1	2023-02-05T21:55:03Z	2023-02-05T21:55:03Z	  In this paper, we propose a model-free adaptive learning solution for a model-following control problem. This approach employs policy iteration, to find an optimal adaptive control solution. It utilizes a moving finite-horizon of model-following error measurements. In addition, the control strategy is designed by using a projection mechanism that employs Lagrange dynamics. It allows for real-time tuning of derived actor-critic structures to find the optimal model-following strategy and sustain optimized adaptation performance. Finally, the efficacy of the proposed framework is emphasized through a comparison with sliding mode and high-order model-free adaptive control approaches. Keywords: Model Reference Adaptive Systems, Reinforcement Learning, adaptive critics, control system, stochastic, nonlinear system 	
Resilient Consensus Sustained Collaboratively	http://arxiv.org/abs/2302.02325v2	2023-02-07T04:25:49Z	2023-02-05T07:33:57Z	  The recent growth of blockchain technology has accelerated research on decentralized platforms. Initial such platforms decide on what should be added to the ledger based on the Proof-of-Work (PoW) consensus protocol. PoW protocol requires its participants to perform massive computations and leads to massive energy wastage. Existing solutions to replace the PoW protocol make use of the Proof-of-Stake (PoS) protocol or classical fault-tolerant consensus protocols. However, the safety of the ledger created by these protocols is at the mercy of the long-term safe-keeping of the private keys of participants subject to long-range attacks. To ameliorate this situation, we present the design of our novel HybridChain architecture, which requires each client transaction to undergo two consensus protocols: a fault-tolerant consensus followed by our novel Power-of-Collaboration (PoC) protocol. Despite this, we observe that our HybridChain system outperforms state-of-the-art blockchain systems yielding up to 2000x higher throughput and 10^5 times less energy costs. 	
"Plasma Agriculture: A green technology to attain the sustainable
  agriculture goal"	http://arxiv.org/abs/2302.02273v1	2023-02-05T01:07:24Z	2023-02-05T01:07:24Z	  The agriculture sector has many issues such as reductions of agricultural lands, growing population, health issues arising due to the use of synthetic fertilizers and pesticides, reduction in soil health due to extreme use of synthetic chemicals during farming, etc. The quality and quantity of foods required for living things are affected by many factors like scarcity of nutrient-rich soils, lack of suitable fertilizers, harmful insects and bugs, climate change, etc. There is a requirement to supply the proper nutrients to plants/crops for obtaining a high crop yield. Synthetic chemical fertilizers provide nutrients (macro and micro) to plants for their growth and development but the excess use of them is not good for a healthy lifestyle as well as for the environment. In recent years, non-thermal plasma (NTP) is considered as an advanced green technology for enhancing productivity in agriculture sectors. In this report, we provided the details of nutrients and their functions in the growth and development of plants/crops. How plasma technology can resolve many future challenges in the agriculture sector is discussed in detail. A few experiments on seed germination and plant growth (root and shoot length) were performed in the laboratory to explore the effect of plasma-activated water on the growth and development of plants. These primary results demonstrate the great potential of plasma technology in the agriculture sector. 	
"Towards a modeling, optimization and predictive control framework for
  fed-batch metabolic cybergenetics"	http://arxiv.org/abs/2302.02177v1	2023-02-04T15:04:26Z	2023-02-04T15:04:26Z	  Biotechnology offers many opportunities for the sustainable manufacturing of valuable products. The toolbox to optimize bioprocesses includes \textit{extracellular} process elements such as the bioreactor design and mode of operation, medium formulation, culture conditions, feeding rates, etc. However, these elements are frequently insufficient for achieving optimal process performance or precise product composition. One can use metabolic and genetic engineering methods for optimization at the intracellular level. Nevertheless, those are often of static nature, failing when applied to dynamic processes or if disturbances occur. Furthermore, many bioprocesses are optimized empirically and implemented with little-to-no feedback control to counteract disturbances. The concept of cybergenetics has opened new possibilities to optimize bioprocesses by enabling online modulation of the gene expression of metabolism-relevant proteins via external inputs (e.g., light intensity in optogenetics). Here, we fuse cybergenetics with model-based optimization and predictive control for optimizing dynamic bioprocesses. To do so, we propose to use dynamic constraint-based models that integrate the dynamics of metabolic reactions, resource allocation, and inducible gene expression. We formulate a model-based optimal control problem to find the optimal process inputs. Furthermore, we propose using model predictive control to address uncertainties via online feedback. We focus on fed-batch processes, where the substrate feeding rate is an additional optimization variable. As a simulation example, we show the optogenetic control of the ATPase enzyme complex for dynamic modulation of enforced ATP wasting to adjust product yield and productivity. 	
"A full transit of $^2$ Lupi d and the search for an exomoon in its
  Hill sphere with CHEOPS"	http://arxiv.org/abs/2302.01853v1	2023-02-03T16:55:31Z	2023-02-03T16:55:31Z	  The planetary system around the naked-eye star $\nu^2$ Lupi (HD 136352; TOI-2011) is composed of three exoplanets with masses of 4.7, 11.2, and 8.6 Earth masses. The TESS and CHEOPS missions revealed that all three planets are transiting and have radii straddling the radius gap separating volatile-rich and volatile-poor super-earths. Only a partial transit of planet d had been covered so we re-observed an inferior conjunction of the long-period 8.6 Earth-mass exoplanet $\nu^2$ Lup d with the CHEOPS space telescope. We confirmed its transiting nature by covering its whole 9.1 h transit for the first time. We refined the planet transit ephemeris to P = 107.1361 (+0.0019/-0.0022) days and Tc = 2,459,009.7759 (+0.0101/-0.0096) BJD_TDB, improving by ~40 times on the previously reported transit timing uncertainty. This refined ephemeris will enable further follow-up of this outstanding long-period transiting planet to search for atmospheric signatures or explore the planet's Hill sphere in search for an exomoon. In fact, the CHEOPS observations also cover the transit of a large fraction of the planet's Hill sphere, which is as large as the Earth's, opening the tantalising possibility of catching transiting exomoons. We conducted a search for exomoon signals in this single-epoch light curve but found no conclusive photometric signature of additional transiting bodies larger than Mars. Yet, only a sustained follow-up of $\nu^2$ Lup d transits will warrant a comprehensive search for a moon around this outstanding exoplanet. 	
"Structural Robustness of Complex Networks: A Survey of A Posteriori
  Measures"	http://arxiv.org/abs/2302.03745v1	2023-02-03T13:59:49Z	2023-02-03T13:59:49Z	  Network robustness is critical for various industrial and social networks against malicious attacks, which has various meanings in different research contexts and here it refers to the ability of a network to sustain its functionality when a fraction of the network fail to work due to attacks. The rapid development of complex networks research indicates special interest and great concern about the network robustness, which is essential for further analyzing and optimizing network structures towards engineering applications. This comprehensive survey distills the important findings and developments of network robustness research, focusing on the a posteriori structural robustness measures for single-layer static networks. Specifically, the a posteriori robustness measures are reviewed from four perspectives: 1) network functionality, including connectivity, controllability and communication ability, as well as their extensions; 2) malicious attacks, including conventional and computation-based attack strategies; 3) robustness estimation methods using either analytical approximation or machine learning-based prediction; 4) network robustness optimization. Based on the existing measures, a practical threshold of network destruction is introduced, with the suggestion that network robustness should be measured only before reaching the threshold of destruction. Then, a posteriori and a priori measures are compared experimentally, revealing the advantages of the a posteriori measures. Finally, prospective research directions with respect to a posteriori robustness measures are recommended. 	
"Orthogonal-Time-Frequency-Space Signal Design for Integrated Data and
  Energy Transfer: Benefits from Doppler Offsets"	http://arxiv.org/abs/2302.01697v1	2023-02-03T12:51:16Z	2023-02-03T12:51:16Z	  Integrated data and energy transfer (IDET) is an advanced technology for enabling energy sustainability for massively deployed low-power electronic consumption components. However, the existing work of IDET using the orthogonal-frequency-division-multiplexing (OFDM) waveforms is designed for static scenarios, which would be severely affected by the destructive Doppler offset in high-mobility scenarios. Therefore, we proposed an IDET system based on orthogonal-time-frequency-space (OTFS) waveforms with the imperfect channel assumption, which is capable of counteracting the Doppler offset in high-mobility scenarios. At the transmitter, the OTFS-IDET system superimposes the random data signals and deterministic energy signals in the delay-Doppler (DD) domain with optimally designed amplitudes. The receiver optimally splits the received signal in the power domain for achieving the best IDET performance. After formulating a non-convex optimisation problem, it is transformed into a geometric programming (GP) problem through inequality relaxations to obtain the optimal solution. The simulation demonstrates that a higher amount of energy can be harvested when employing our proposed OTFS-IDET waveforms than the conventional OFDM-IDET ones in high mobility scenarios. 	
"Rate-limiting recovery processes in neurotransmission under sustained
  stimulation"	http://arxiv.org/abs/2302.01635v1	2023-02-03T10:05:52Z	2023-02-03T10:05:52Z	  At chemical synapses, an arriving electric signal induces the fusion of vesicles with the presynaptic membrane, thereby releasing neurotransmitters into the synaptic cleft. After a fusion event, both the release site and the vesicle undergo a recovery process before becoming available for reuse again. Of central interest is the question which of the two restoration steps acts as the limiting factor during neurotransmission under high-frequency sustained stimulation. In order to investigate this question, we introduce a novel non-linear reaction network which involves explicit recovery steps for both the vesicles and the release sites, and includes the induced time-dependent output current. The associated reaction dynamics are formulated by means of ordinary differential equations (ODEs), as well as via the associated stochastic jump process. While the stochastic jump model describes a single release site, the average over many release sites is close to the ODE solution and shares its periodic structure. The reason for this can be traced back to the insight that recovery dynamics of vesicles and release sites are statistically almost independent. A sensitivity analysis on the recovery rates based on the ODE formulation reveals that neither the vesicle nor the release site recovery step can be identified as the essential rate-limiting step but that the rate-limiting feature changes over the course of stimulation. Under sustained stimulation the dynamics given by the ODEs exhibit transient changes leading from an initial depression of the postsynaptic response to an asymptotic periodic orbit, while the individual trajectories of the stochastic jump model lack the oscillatory behavior and asymptotic periodicity of the ODE-solution. 	
"The nature of dynamic local order in CH$_3$NH$_3$PbI$_3$ and
  CH$_3$NH$_3$PbBr$_3$"	http://arxiv.org/abs/2302.01559v1	2023-02-03T05:52:52Z	2023-02-03T05:52:52Z	  Hybrid lead halide perovskites (LHPs) are a class of semiconductor with novel properties that are distinctively governed by structural fluctuations. Diffraction experiments sensitive to average, long-range order reveal a cubic structure in the device-relevant, high-temperature phase. Local probes find additional short-range order with lower symmetry that may govern the structure-function relationships of LHPs. However, the dimensionality, participating atoms, and dynamics of this short-range order are unresolved, impeding our understanding of technologically relevant properties including long carrier lifetimes and facile halide migration. Here, we determine the true structure of two prototypical hybrid LHPs, CH$_3$NH$_3$PbI$_3$ and CH$_3$NH$_3$PbBr$_3$, using a combination of single-crystal X-ray and neutron diffuse scattering, neutron inelastic spectroscopy, and molecular dynamics simulations. The remarkable collective dynamics we found are not suggested by previous studies and consist of a network of local two-dimensional, circular pancake-like regions of dynamically tilting lead halide octahedra (lower symmetry) that induce longer range intermolecular correlations within the CH$_3$NH$_3^+$ sublattice. The dynamic local structure can introduce transient ferroelectric or antiferroelectric domains that increase charge carrier lifetimes, and strongly affect the halide migration, a poorly understood degradation mechanism. Our approach of co-analyzing single-crystal X-ray and neutron diffuse scattering data with MD simulations will provide unparalleled insights into the structure of hybrid materials and materials with engineered disorder. 	
"Symmetry-reduced low-dimensional representation of large-scale dynamics
  in the asymptotic suction boundary layer"	http://arxiv.org/abs/2302.01273v1	2023-02-02T18:04:15Z	2023-02-02T18:04:15Z	  An important feature of turbulent boundary layers are persistent large-scale coherent structures in the flow. Here, we use Dynamic Mode Decomposition (DMD), a data-driven technique designed to detect spatio-temporal coherence, to construct optimal low-dimensional representations of such large-scale dynamics in the asymptotic suction boundary layer (ASBL). In the ASBL, fluid is removed by suction through the bottom wall, resulting in a constant boundary layer thickness in streamwise direction. That is, the streamwise advection of coherent structures by the mean flow ceases to be of dynamical importance and can be interpreted as a continuous shift symmetry in streamwise direction. However, this results in technical difficulties, as DMD is known to perform poorly in presence of continuous symmetries. We address this issue using symmetry-reduced DMD (Marensi et al., J. Fluid Mech. 721, A10 (2023)), and find the large-scale dynamics of the ASBL to be low-dimensional indeed and potentially self-sustained, featuring ejection and sweeping events at large scale. Interactions with near-wall structures are captured when including only a few more modes. 	
"Neuro Symbolic Continual Learning: Knowledge, Reasoning Shortcuts and
  Concept Rehearsal"	http://arxiv.org/abs/2302.01242v1	2023-02-02T17:24:43Z	2023-02-02T17:24:43Z	  We introduce Neuro-Symbolic Continual Learning, where a model has to solve a sequence of neuro-symbolic tasks, that is, it has to map sub-symbolic inputs to high-level concepts and compute predictions by reasoning consistently with prior knowledge. Our key observation is that neuro-symbolic tasks, although different, often share concepts whose semantics remains stable over time. Traditional approaches fall short: existing continual strategies ignore knowledge altogether, while stock neuro-symbolic architectures suffer from catastrophic forgetting. We show that leveraging prior knowledge by combining neuro-symbolic architectures with continual strategies does help avoid catastrophic forgetting, but also that doing so can yield models affected by reasoning shortcuts. These undermine the semantics of the acquired concepts, even when detailed prior knowledge is provided upfront and inference is exact, and in turn continual performance. To overcome these issues, we introduce COOL, a COncept-level cOntinual Learning strategy tailored for neuro-symbolic continual problems that acquires high-quality concepts and remembers them over time. Our experiments on three novel benchmarks highlights how COOL attains sustained high performance on neuro-symbolic continual learning tasks in which other strategies fail. 	
"Biophysical aspects of neurocognitive modeling with long-term sustained
  temperature variations"	http://arxiv.org/abs/2302.01019v1	2023-02-02T11:14:43Z	2023-02-02T11:14:43Z	  Long-term focused attention with visualization and breathing exercises is at the core of various Eastern traditions. Neurocognitive and psychosomatic phenomena demonstrated during such exercises were instrumentally explored with EEG and other sensors. Neurocognitive modeling in the form of meditative visualization produced persistent temperature effects in the body long after the exercise finished; this raises the question about their psychosomatic or biophysical origin. The work explores this question by comparing experiments with focusing attention inside and outside the body. EEG, temperature, heart and breathing sensors monitor internal body conditions, high resolution differential calorimetric sensors are used to detect thermal effects outside the body. Experiments with 159 attempts (2427 operator-sensor sessions) were carried over five months, control measurements run in the same conditions in parallel to experimental series. Increase of body temperature up to moderate fever zone 38.5 C and intentional control of up and down trend of core temperature by 1.6 C are demonstrated. Persistent temperature variations last >60 min. Experiments also demonstrated induced thermal fluctuations at 10^-3 C level in external calorimetric systems with 15 ml of water for 60-90 min. Repeatability of these attempts is over 90%, statistical Chi-square and Mann-Whitney tests reject the null hypotheses about random character of outcomes. Thus, the obtained data confirm the persistent thermal effects reported in previous publications and indicate their biophysical dimension. To explain these results we refer to a new model in neuroscience that involves spin phenomena in biochemical and physical systems. These experiments demonstrate complex biophysical mechanisms of altered states of consciousness; their function in the body's neurohumoral regulation and non-classical brain functions is discussed. 	
Avalanche: A PyTorch Library for Deep Continual Learning	http://arxiv.org/abs/2302.01766v1	2023-02-02T10:45:20Z	2023-02-02T10:45:20Z	  Continual learning is the problem of learning from a nonstationary stream of data, a fundamental issue for sustainable and efficient training of deep neural networks over time. Unfortunately, deep learning libraries only provide primitives for offline training, assuming that model's architecture and data are fixed. Avalanche is an open source library maintained by the ContinualAI non-profit organization that extends PyTorch by providing first-class support for dynamic architectures, streams of datasets, and incremental training and evaluation methods. Avalanche provides a large set of predefined benchmarks and training algorithms and it is easy to extend and modular while supporting a wide range of continual learning scenarios. Documentation is available at \url{https://avalanche.continualai.org}. 	
"The Challenges and Opportunities in Creating an Early Warning System for
  Global Pandemics"	http://arxiv.org/abs/2302.00863v1	2023-02-02T04:18:47Z	2023-02-02T04:18:47Z	  The COVID-19 pandemic revealed that global health, social systems, and economies can be surprisingly fragile in an increasingly interconnected and interdependent world. Yet, during the last half of 2022, and quite remarkably, we began dismantling essential infectious disease monitoring programs in several countries. Absent such programs, localized biological risks will transform into global shocks linked directly to our lack of foresight regarding emerging health risks. Additionally, recent studies indicate that more than half of all infectious diseases could be made worse by climate change, complicating pandemic containment. Despite this complexity, the factors leading to pandemics are largely predictable but can only be realized through a well-designed global early warning system. Such a system should integrate data from genomics, climate and environment, social dynamics, and healthcare infrastructure. The glue for such a system is community-driven modeling, a modern logistics of data, and democratization of AI tools. Using the example of dengue fever in Brazil, we can demonstrate how thoughtfully designed technology platforms can build global-scale precision disease detection and response systems that significantly reduce exposure to systemic shocks, accelerate science-informed public health policies, and deliver reliable healthcare and economic opportunities as an intrinsic part of the global sustainable development agenda. 	
"Analysis of Biomass Sustainability Indicators from a Machine Learning
  Perspective"	http://arxiv.org/abs/2302.00828v1	2023-02-02T02:31:42Z	2023-02-02T02:31:42Z	  Plant biomass estimation is critical due to the variability of different environmental factors and crop management practices associated with it. The assessment is largely impacted by the accurate prediction of different environmental sustainability indicators. A robust model to predict sustainability indicators is a must for the biomass community. This study proposes a robust model for biomass sustainability prediction by analyzing sustainability indicators using machine learning models. The prospect of ensemble learning was also investigated to analyze the regression problem. All experiments were carried out on a crop residue data from the Ohio state. Ten machine learning models, namely, linear regression, ridge regression, multilayer perceptron, k-nearest neighbors, support vector machine, decision tree, gradient boosting, random forest, stacking and voting, were analyzed to estimate three biomass sustainability indicators, namely soil erosion factor, soil conditioning index, and organic matter factor. The performance of the model was assessed using cross-correlation (R2), root mean squared error and mean absolute error metrics. The results showed that Random Forest was the best performing model to assess sustainability indicators. The analyzed model can now serve as a guide for assessing sustainability indicators in real time. 	
Sustainable pulling motion of an active scatterer	http://arxiv.org/abs/2302.00619v1	2023-02-01T17:34:45Z	2023-02-01T17:34:45Z	  In this paper, we concern the generation of attractive net motion with respect to the location of external wave source for active spherical carriers. Here we recall that the exerted acoustic radiation force in an acoustic field, resulting from an incident wave, a scattered wave, and the radiated wave from the active carrier, can be positive, negative or zero based on the location of the object in the field. Thus in a general case, a sustainable pulling motion is not guaranteed. In this work, by considering the point that the average of the radiation force for an object, active in a single mode, over a complete wavelength is equal to the radiation force applied to a passive object (which is always positive), we put forward a technique to generate the acoustic radiation force with negative average over a complete wavelength to ensure that the net motion is attractive. The idea here is a simultaneous excitation of the object in two modes of breathing and first, with a difference in the phase of excitations. We will also show that by controlling the phase difference, the average of the force exerted on the object can be positive, negative or zero. Moreover, we show that for specific phase differences not only the average of the force is negative but also the force itself never experiences a positive value in a whole wavelength at those phase differences, which this can be a desired state to achieve a perfect negative net motion. 	
Digital Twin Applications in Urban Logistics: An Overview	http://arxiv.org/abs/2302.00484v1	2023-02-01T14:48:01Z	2023-02-01T14:48:01Z	  Urban traffic attributed to commercial and industrial transportation is observed to largely affect living standards in cities due to external effects pertaining to pollution and congestion. In order to counter this, smart cities deploy technological tools to achieve sustainability. Such tools include Digital Twins (DT)s which are virtual replicas of real-life physical systems. Research suggests that DTs can be very beneficial in how they control a physical system by constantly optimizing its performance. The concept has been extensively studied in other technology-driven industries like manufacturing. However, little work has been done with regards to their application in urban logistics. In this paper, we seek to provide a framework by which DTs could be easily adapted to urban logistics networks. To do this, we provide a characterization of key factors in urban logistics for dynamic decision-making. We also survey previous research on DT applications in urban logistics as we found that a holistic overview is lacking. Using this knowledge in combination with the characterization, we produce a conceptual model that describes the ontology, learning capabilities and optimization prowess of an urban logistics digital twin through its quantitative models. We finish off with a discussion on potential research benefits and limitations based on previous research and our practical experience. 	
"The tidal excitation of r modes in a solar type star orbited by a giant
  planet companion and the effect on orbital evolution I: The aligned case"	http://arxiv.org/abs/2302.00473v1	2023-02-01T14:35:29Z	2023-02-01T14:35:29Z	  It has been suggested that tidal interaction is important for shaping the orbital configurations of close orbiting giant planets. The excitation of propagating waves and normal modes (dynamical tide) will be important for estimating time scales for orbital evolution. We consider the tidal interaction of a Jupiter mass planet orbiting a solar type primary. Tidal and rotational frequencies are assumed comparable making the effect of rotation important. Although centrifugal distortion is neglected, Coriolis forces are fully taken into account. We focus in detail on the potentially resonant excitation of $r$ modes associated with spherical harmonics of degrees three and five. These are mostly sited in the radiative core but with a significant response in the convective envelope where dissipation occurs. Away from resonance significant orbital evolution over the system lifetime is unlikely. However, tidal interaction is enhanced near resonances and the orbital evolution accelerated as they are passed through. This speed up may be sustained if near resonance can be maintained. For close orbits with primaries rotating sufficiently rapidly, this could arise from angular momentum loss and stellar spin down through a stellar wind bringing about significant orbital evolution over the system lifetime. 	
"For the Underrepresented in Gender Bias Research: Chinese Name Gender
  Prediction with Heterogeneous Graph Attention Network"	http://arxiv.org/abs/2302.00419v1	2023-02-01T13:08:50Z	2023-02-01T13:08:50Z	  Achieving gender equality is an important pillar for humankind's sustainable future. Pioneering data-driven gender bias research is based on large-scale public records such as scientific papers, patents, and company registrations, covering female researchers, inventors and entrepreneurs, and so on. Since gender information is often missing in relevant datasets, studies rely on tools to infer genders from names. However, available open-sourced Chinese gender-guessing tools are not yet suitable for scientific purposes, which may be partially responsible for female Chinese being underrepresented in mainstream gender bias research and affect their universality. Specifically, these tools focus on character-level information while overlooking the fact that the combinations of Chinese characters in multi-character names, as well as the components and pronunciations of characters, convey important messages. As a first effort, we design a Chinese Heterogeneous Graph Attention (CHGAT) model to capture the heterogeneity in component relationships and incorporate the pronunciations of characters. Our model largely surpasses current tools and also outperforms the state-of-the-art algorithm. Last but not least, the most popular Chinese name-gender dataset is single-character based with far less female coverage from an unreliable source, naturally hindering relevant studies. We open-source a more balanced multi-character dataset from an official source together with our code, hoping to help future research promoting gender equality. 	
"A fuzzy adaptive metaheuristic algorithm for identifying sustainable,
  economical, lightweight, and earthquake-resistant reinforced concrete
  cantilever retaining walls"	http://arxiv.org/abs/2302.00198v1	2023-02-01T03:00:52Z	2023-02-01T03:00:52Z	  In earthquake-prone zones, the seismic performance of reinforced concrete cantilever (RCC) retaining walls is significant. In this study, the seismic performance was investigated using horizontal and vertical pseudo-static coefficients. To tackle RCC weights and forces resulting from these earth pressures, 26 constraints for structural strengths and geotechnical stability along with 12 geometric variables are associated with each design. These constraints and design variables form a constraint optimization problem with a twelve-dimensional solution space. To conduct effective search and produce sustainable, economical, lightweight RCC designs robust against earthquake hazards, a novel adaptive fuzzy-based metaheuristic algorithm is applied. The proposed method divides the search space to sub-regions and establishes exploration, information sharing, and exploitation search capabilities based on its novel search components. Further, fuzzy inference systems were employed to address parameterization and computational cost evaluation issues. It was found that the proposed algorithm can achieve low-cost, low-weight, and low CO2 emission RCC designs under nine seismic conditions in comparison with several classical and best-performing design optimizers. 	
"Diffusive shock acceleration at EeV and associated multimessenger flux
  from ultra-fast outflows driven by Active Galactic Nuclei"	http://arxiv.org/abs/2301.13689v1	2023-01-31T15:05:28Z	2023-01-31T15:05:28Z	  Active galactic nuclei (AGNi) can launch and sustain powerful winds featuring mildly relativistic velocity and wide opening angle. Such winds, known as ultra-fast outflows (UFOs), can develop a bubble structure characterized by a forward shock expanding in the host galaxy and a wind termination shock separating the fast cool wind from the hot shocked wind. In this work we explore whether diffusive shock acceleration can take place efficiently at the wind termination shock of UFOs. We calculate the spectrum of accelerated particles and find that protons can be energized up to the EeV range promoting UFOs to promising candidates for accelerating ultra-high energy cosmic rays (UHECRs). We also compute the associated gamma-ray and neutrino fluxes and compare them with available data in the literature. We observe that high-energy (HE) neutrinos are efficiently produced up to hundreds of PeV while the associated gamma rays are efficiently absorbed beyond a few tens of GeV. By assuming a typical source density of non-jetted AGNi we expect that UFO could play a dominant role as diffuse sources of UHECRs and HE neutrinos. We finally apply our model to the recently observed NGC1068 and we find out that an obscured UFO could provide a sizeable contribution to the observed gamma-ray flux while only contributing up to $\sim 10\%$ to the associated neutrino flux. 	
"Global Instabilities and Mode Transitions in a Low Viscosity Jet
  Emerging Into a High Viscosity Medium"	http://arxiv.org/abs/2301.13593v1	2023-01-31T12:45:38Z	2023-01-31T12:45:38Z	  The effect of viscosity contrast between a jet and its surroundings is experimentally investigated, using density-matched fluids. A gravity-driven flow is established, with a jet of saltwater emerging into an ambient medium composed of high-viscosity propylene glycol. Jet Reynolds numbers Re ranging from 1600 to 3400 were studied, for an ambient-to-jet viscosity ratio M between 1 and 50. Visualization suggests that at low values of the viscosity ratio, the jet breakdown mode is axisymmetric, while helical modes develop at high values of viscosity ratio. The transition between these two modes is attempted to be delineated using a variety of diagnostic tools. Hot film anemometry measurements indicate that the onset of the helical mode was accompanied by the observation of a discrete peak in the frequency spectrum of velocity fluctuations, which exhibited little spatial variation for the first several diameters in the downstream direction. Dye injection accompanied by Laser-Induced Fluorescence was used to identify the jet boundary against the background. An analysis of high-speed images acquired using the LIF technique enables identification of the spatial growth rate of waves on the jet boundary, as well as the frequency of oscillation of the weakly diffusive interface. Temporal fluctuations in of fluorescence intensity are found to be spatially invariant in the jet near-field, further attesting to behavior consistent with that of a self-sustained oscillation whose frequency depends on the viscosity ratio. Singular Value Decomposition was used to analyze the images and identify the various spatial modes, and suggests the existence of a single dominant mode. Together, thee observations provide strong circumstantial evidence for the ecidence of a glonal mode that arises solely due to viscosity variation in a jet flow, without any additional effects due to density variations. 	
Stratified inclined duct: two-layer hydraulics and instabilities	http://arxiv.org/abs/2301.13035v1	2023-01-30T16:23:27Z	2023-01-30T16:23:27Z	  The stratified inclined duct (SID) sustains an exchange flow in a long, gently sloping duct as a model for continuously-forced density-stratified flows such as those found in estuaries. Experiments have shown that the emergence of interfacial waves and their transition to turbulence as the tilt angle is increased appears linked to a threshold in the exchange flow rate given by inviscid two-layer hydraulics. We uncover these hydraulic mechanisms with (i) recent direct numerical simulations (DNS) providing full flow data in the key flow regimes (Zhu & Atoufi et al., arXiv:2301.09773, 2023), (ii) averaging these DNS into two layers, (iii) an inviscid two-layer shallow water and instability theory to diagnose interfacial wave behaviour and provide physical insight. The laminar flow is subcritical and stable throughout the duct and hydraulically controlled at the ends of the duct. As the tilt is increased, the flow becomes everywhere supercritical and unstable to long waves. An internal undular jump featuring stationary waves first appears near the centre of the duct, then leads to larger-amplitude travelling waves, and to stronger jumps, wave breaking and intermittent turbulence at the largest tilt angle. Long waves described by the (nonlinear) shallow water equation are locally interpreted as linear waves on a two-layer parallel base flow described by the Taylor-Goldstein equation. This link helps us interpret long-wave instability and contrast it to short-wave (e.g. Kelvin-Helmholtz) instability. Our results suggest a transition to turbulence in SID through long-wave instability relying on vertical confinement by the top and bottom walls. 	
"Structure of Heterogeneous Two-Phase Rotating Detonation Wave with
  Ethanol-Hydrogen-Air Mixture"	http://arxiv.org/abs/2301.12857v1	2023-01-30T13:09:06Z	2023-01-30T13:09:06Z	  In this study, the structure of a hydrogen-assisted rotating detonation wave (RDW) fueled by liquid ethanol is revealed and expounded. The simulation is carried out under an Eulerian-Lagrangian framework in which the main characteristics of the two-phase RDW are analyzed in detail. Results suggest a self-sustained rotating detonation fueled by liquid ethanol can be achieved where the majority of droplets are heated and consumed by the detonation wave. A laminated structure of the RDW due to the effect of droplet evaporation is captured and clarified, which is found to play a major role in the stable propagation of the two-phase RDW. 	
Vibrationally Induced Magnetism in Supramolecular Aggregates	http://arxiv.org/abs/2301.12777v1	2023-01-30T10:44:26Z	2023-01-30T10:44:26Z	  Magnetic phenomena are in chemistry and condensed matter physics considered to be associated with low temperatures. That a magnetic state, or order, is stable below a critical temperature as well as becoming stronger the lower the temperature is a nearly unquestioned paradigm. It is, therefore, surprising that recent experimental observation made on supramolecular aggregates suggest that, for instance, the magnetic coercivity may increase with increasing temperature, as well as the chiral induced spin selectivity effect may be enhanced. Here, a mechanism for vibrationally stabilized magnetism is proposed and a theoretical model is introduced with which the qualitative aspects of the recent experimental findings can be explained. It is argued that anharmonic vibrations, which become increasingly occupied with increasing temperature, enables nuclear vibrations to both stabilize and sustain magnetic states. The theoretical proposal, hence, pertains to structures without inversion and/or reflection symmetries, for instance, chiral molecules and crystals. 	
Vorticity dynamics in transcritical liquid jet breakup	http://arxiv.org/abs/2301.12602v1	2023-01-30T01:29:29Z	2023-01-30T01:29:29Z	  Contrary to common assumptions, a transcritical domain exists during the early times of liquid hydrocarbon fuel injection at supercritical pressure. A sharp two-phase interface is sustained before substantial heating of the liquid. Thus, two-phase dynamics has been shown to drive the early three-dimensional deformation and atomisation. A recent study of a transcritical liquid jet shows distinct deformation features caused by interface thermodynamics, low surface tension, and intraphase diffusive mixing. In the present work, the vortex identification method ${\lambda}_{\rho}$, which considers the fluid compressibility, is used to study the vortex dynamics in a cool liquid n-decane transcritical jet surrounded by a hotter oxygen gaseous stream at supercritical pressures. The relationship between vortical structures and the liquid surface evolution is detailed, along with the vorticity generation mechanisms, including variable-density effects. The roles of hairpin and roller vortices in the early deformation of lobes, the layering and tearing of liquid sheets, and the formation of fuel-rich gaseous blobs are analysed. At these high pressures, enhanced intraphase mixing and ambient gas dissolution affect the local liquid structures (i.e., lobes). Thus, liquid breakup differs from classical sub-critical atomisation. Near the interface, liquid density and viscosity drop by up to 10% and 70%, respectively, and the liquid is more easily affected by the vortical motion (e.g., liquid sheets wrap around vortices). Despite the variable density, compressible vorticity generation terms are smaller than the vortex stretching and tilting. Layering traps and aligns the vortices along the streamwise direction while mitigating the generation of new rollers. 	
Sustainable Diversity of Phage-Bacteria Systems	http://arxiv.org/abs/2301.12491v1	2023-01-29T16:56:21Z	2023-01-29T16:56:21Z	  Bacteriophages are central to microbial ecosystems for balancing bacterial populations and promoting evolution by applying strong selection pressure. Here we review the aspects that modulate phage-bacteria interaction in a way that naturally promotes their coexistence. We focus on the modulations that arise from structural, physical, or physiological constraints. We argue that they should apply in a broad range of phage-bacteria systems promoting sustainable diversity. 	
"Machine Learning Accelerators in 2.5D Chiplet Platforms with Silicon
  Photonics"	http://arxiv.org/abs/2301.12252v1	2023-01-28T17:06:53Z	2023-01-28T17:06:53Z	  Domain-specific machine learning (ML) accelerators such as Google's TPU and Apple's Neural Engine now dominate CPUs and GPUs for energy-efficient ML processing. However, the evolution of electronic accelerators is facing fundamental limits due to the limited computation density of monolithic processing chips and the reliance on slow metallic interconnects. In this paper, we present a vision of how optical computation and communication can be integrated into 2.5D chiplet platforms to drive an entirely new class of sustainable and scalable ML hardware accelerators. We describe how cross-layer design and fabrication of optical devices, circuits, and architectures, and hardware/software codesign can help design efficient photonics-based 2.5D chiplet platforms to accelerate emerging ML workloads. 	
"Extended Load Flexibility of Utility-Scale P2H Plants: Optimal
  Production Scheduling Considering Dynamic Thermal and HTO Impurity Effects"	http://arxiv.org/abs/2301.12242v1	2023-01-28T16:15:36Z	2023-01-28T16:15:36Z	  In the conversion toward a clear and sustainable energy system, the flexibility of power-to-hydrogen (P2H) production enables the admittance of volatile renewable energies on a utility scale and provides the connected electrical power system with ancillary services. To extend the load flexibility and thus improve the profitability of green hydrogen production, this paper presents an optimal production scheduling approach for utility-scale P2H plants composed of multiple alkaline electrolyzers. Unlike existing works, this work discards the conservative constant steady-state constraints and first leverages the dynamic thermal and hydrogen-to-oxygen (HTO) impurity crossover processes of electrolyzers. Doing this optimizes their effects on the loading range and energy conversion efficiency, therefore improving the load flexibility of P2H production. The proposed multiphysics-aware scheduling model is formulated as mixed-integer linear programming (MILP). It coordinates the electrolyzers' operation state transitions and load allocation subject to comprehensive thermodynamic and mass transfer constraints. A decomposition-based solution method, SDM-GS-ALM, is followingly adopted to address the scalability issue for scheduling large-scale P2H plants composed of tens of electrolyzers. With an experiment-verified dynamic electrolyzer model, case studies up to 22 electrolyzers show that the proposed method remarkably improves the hydrogen output and profit of P2H production powered by either solar or wind energy compared to the existing scheduling approach. 	
Source of pure proton beams	http://arxiv.org/abs/2301.12216v1	2023-01-28T14:44:14Z	2023-01-28T14:44:14Z	  In the quasi-gasdynamic high-current ion source described in this work, the plasma is sustained by high-power millimeter-wave radiation under the electron cyclotron resonance (ECR) condition. In such facilities, it is possible to achieve high volumetric energy input of up to $250$ $W/cm^3$ and obtain pure proton beams with a minimum amount of impurities and molecular ions. Experiments conducted on the GISMO facility demonstrated the possibility of a proton beam formation with a current of $50$ mA and an extremely high ($99.9$\%) content of atomic ions. 	
"Decentralized Energy Market Integrating Carbon Allowance Trade and
  Uncertainty Balance in Energy Communities"	http://arxiv.org/abs/2301.12129v1	2023-01-28T08:47:50Z	2023-01-28T08:47:50Z	  With the sustained attention on carbon neutrality, the personal carbon trading (PCT) scheme has been embraced as an auspicious paradigm for scaling down carbon emissions. To facilitate the simultaneous clearance of energy and carbon allowance inside the energy community while hedging against uncertainty, a joint trading framework is proposed in this article. The energy trading is implemented in a peer-to-peer (P2P) manner without the intervention of a central operator, and the uncertainty trading is materialized through procuring reserve of conventional generators and flexibility of users. Under the PCT scheme, carbon allowance is transacted via a sharing mechanism. Possible excessive carbon emissions due to uncertainty balance are tackled by obliging renewable agents to procure sufficient carbon allowances, following the consumption responsibility principle. A two-stage iterative method consisting of tightening McCormick envelope and alternating direction method of multipliers (ADMM) is devised to transform the model into a mixed-integer second-order cone program (MISOCP) and to allow for a fully decentralized market-clearing procedure. Numerical results have validated the effectiveness of the proposed market model. 	
Self-driven Hybrid Atom Spin Oscillator	http://arxiv.org/abs/2301.12121v1	2023-01-28T08:17:36Z	2023-01-28T08:17:36Z	  A self-driven hybrid atom spin oscillator is demonstrated in theory and experiment with a vapor Rb-Xe dual-spin system. The raw signal of Rb spin oscillation is amplified, phase-shifted and sent back to drive the Xe spins coherently. By fine tuning the driving field strength and phase, a self-sustaining spin oscillation signal with zero frequency shift is obtained. The effective coherence time is infinitely prolonged beyond the intrinsic coherence time of Xe spins, forming a hybrid atom spin oscillator. Spectral analysis indicates that a frequency resolution of 13.1 nHz is achieved, enhancing the detection sensitivity for magnetic field. Allan deviation analysis shows that the spin oscillator can operate in continuous wave mode like a spin maser. The prototype spin oscillator can be easily implanted into other hybrid spin systems and enhance the detection sensitivity of alkali metal-noble gas comagnetometers. 	
"First-Principles Theory of the Relativistic Magnetic Reconnection Rate
  in Astrophysical Pair Plasmas"	http://arxiv.org/abs/2301.12111v1	2023-01-28T06:58:53Z	2023-01-28T06:58:53Z	  We develop a first-principles model for the relativistic magnetic reconnection rate in strongly magnetized pair plasmas. By considering the energy budget and required current density near the x-line, we analytically show that in the magnetically-dominated relativistic regime, the x-line thermal pressure is significantly lower than the upstream magnetic pressure due to the extreme energy needed to sustain the current density, consistent with kinetic simulations. This causes the upstream magnetic field lines to collapse in, producing the open outflow geometry which enables fast reconnection. The result is important for understanding a wide range of extreme astrophysical environments, where fast reconnection has been evoked to explain observations such as transient flares and nonthermal particle signatures. 	
"Turbulence control in plane Couette flow using low-dimensional neural
  ODE-based models and deep reinforcement learning"	http://arxiv.org/abs/2301.12098v1	2023-01-28T05:47:10Z	2023-01-28T05:47:10Z	"  The high dimensionality and complex dynamics of turbulent flows remain an obstacle to the discovery and implementation of control strategies. Deep reinforcement learning (RL) is a promising avenue for overcoming these obstacles, but requires a training phase in which the RL agent iteratively interacts with the flow environment to learn a control policy, which can be prohibitively expensive when the environment involves slow experiments or large-scale simulations. We overcome this challenge using a framework we call ""DManD-RL"" (data-driven manifold dynamics-RL), which generates a data-driven low-dimensional model of our system that we use for RL training. With this approach, we seek to minimize drag in a direct numerical simulation (DNS) of a turbulent minimal flow unit of plane Couette flow at Re=400 using two slot jets on one wall. We obtain, from DNS data with $\mathcal{O}(10^5)$ degrees of freedom, a 25-dimensional DManD model of the dynamics by combining an autoencoder and neural ordinary differential equation. Using this model as the environment, we train an RL control agent, yielding a 440-fold speedup over training on the DNS, with equivalent control performance. The agent learns a policy that laminarizes 84% of unseen DNS test trajectories within 900 time units, significantly outperforming classical opposition control (58%), despite the actuation authority being much more restricted. The agent often achieves laminarization through a counterintuitive strategy that drives the formation of two low-speed streaks, with a spanwise wavelength that is too small to be self-sustaining. The agent demonstrates the same performance when we limit observations to wall shear rate. "	
Beyond Classroom: Making a Difference in Diversity in Tech	http://arxiv.org/abs/2301.12000v1	2023-01-27T21:45:02Z	2023-01-27T21:45:02Z	  With all the opportunities and risks that technology holds in connection to our safe and sustainable future, it is becoming increasingly important to involve a larger portion of our society in becoming active co-creators of our digitalized future -- moving from the passenger seat to the driver seat. Yet, despite extensive efforts around the world, little progress has been made in growing the representation of certain communities and groups in software engineering. This chapter shares one successful project, called Czechitas, triggering a major social change in Czechia, involving 1 000+ volunteers to support 50 000+ women on their way towards software engineering education and career. 	
"Self-powered weigh-in-motion system combining vibration energy
  harvesting and self-sensing composite pavements"	http://arxiv.org/abs/2302.06388v2	2023-02-14T08:25:02Z	2023-01-27T21:05:38Z	  Overloaded vehicles are the primary cause of accelerated degradation of road infrastructures. In this context, although weigh-in-motion (WIM) systems are most efficient to enforce weight regulations, current technologies require costly investments limiting their extensive implementation. Recent advances in multifunctional composites enabled cost-efficient alternatives in the form of smart pavements. Nevertheless, the need for a stable power supply still represents a major practical limitation. This work presents a novel proof-of-concept self-sustainable WIM technology combining smart pavements and vibration-based energy harvesting (EH). The feasibility of piezoelectric bimorph cantilevered beams to harvest traffic-induced vibrations is firstly investigated, followed by the demonstration of the proposed technology under laboratory conditions. The main original contributions of this work comprise (i) the development of a new self-powered data acquisition system, (ii) a novel approach for the fabrication and electromechanical testing of the piezoresistive composite pavement, and (iii) laboratory feasibility analysis of the developed EH unit to conduct traffic load identification through electrical resistivity measurements of the smart pavement. While the presented results conclude the need for dense EH networks or combinations of different EH technologies to attain complete self-sustainability, this work represents an initial feasibility evidence paving the way towards the development of self-powered low-cost WIM systems. 	
"Is TinyML Sustainable? Assessing the Environmental Impacts of Machine
  Learning on Microcontrollers"	http://arxiv.org/abs/2301.11899v1	2023-01-27T18:23:10Z	2023-01-27T18:23:10Z	  The sustained growth of carbon emissions and global waste elicits significant sustainability concerns for our environment's future. The growing Internet of Things (IoT) has the potential to exacerbate this issue. However, an emerging area known as Tiny Machine Learning (TinyML) has the opportunity to help address these environmental challenges through sustainable computing practices. TinyML, the deployment of machine learning (ML) algorithms onto low-cost, low-power microcontroller systems, enables on-device sensor analytics that unlocks numerous always-on ML applications. This article discusses the potential of these TinyML applications to address critical sustainability challenges. Moreover, the footprint of this emerging technology is assessed through a complete life cycle analysis of TinyML systems. From this analysis, TinyML presents opportunities to offset its carbon emissions by enabling applications that reduce the emissions of other sectors. Nevertheless, when globally scaled, the carbon footprint of TinyML systems is not negligible, necessitating that designers factor in environmental impact when formulating new devices. Finally, research directions for enabling further opportunities for TinyML to contribute to a sustainable future are outlined. 	
A Green(er) World for A.I	http://arxiv.org/abs/2301.11581v1	2023-01-27T08:01:38Z	2023-01-27T08:01:38Z	  As research and practice in artificial intelligence (A.I.) grow in leaps and bounds, the resources necessary to sustain and support their operations also grow at an increasing pace. While innovations and applications from A.I. have brought significant advances, from applications to vision and natural language to improvements to fields like medical imaging and materials engineering, their costs should not be neglected. As we embrace a world with ever-increasing amounts of data as well as research and development of A.I. applications, we are sure to face an ever-mounting energy footprint to sustain these computational budgets, data storage needs, and more. But, is this sustainable and, more importantly, what kind of setting is best positioned to nurture such sustainable A.I. in both research and practice? In this paper, we outline our outlook for Green A.I. -- a more sustainable, energy-efficient and energy-aware ecosystem for developing A.I. across the research, computing, and practitioner communities alike -- and the steps required to arrive there. We present a bird's eye view of various areas for potential changes and improvements from the ground floor of AI's operational and hardware optimizations for datacenters/HPCs to the current incentive structures in the world of A.I. research and practice, and more. We hope these points will spur further discussion, and action, on some of these issues and their potential solutions. 	
"A sustainable infrastructure concept for improved accessibility,
  reusability, and archival of research software"	http://arxiv.org/abs/2301.12830v1	2023-01-27T00:16:23Z	2023-01-27T00:16:23Z	  Research software is an integral part of most research today and it is widely accepted that research software artifacts should be accessible and reproducible. However, the sustainable archival of research software artifacts is an ongoing effort. We identify research software artifacts as snapshots of the current state of research and an integral part of a sustainable cycle of software development, research, and publication. We develop requirements and recommendations to improve the archival, access, and reuse of research software artifacts based on installable, configurable, extensible research software, and sustainable public open-access infrastructure. The described goal is to enable the reuse and exploration of research software beyond published research results, in parallel with reproducibility efforts, and in line with the FAIR principles for data and software. Research software artifacts can be reused in varying scenarios. To this end, we design a multi-modal representation concept supporting multiple reuse scenarios. We identify types of research software artifacts that can be viewed as different modes of the same software-based research result, for example, installation-free configurable browser-based apps to containerized environments, descriptions in journal publications and software documentation, or source code with installation instructions. We discuss how the sustainability and reuse of research software are enhanced or enabled by a suitable archive infrastructure. Finally, at the example of a pilot project at the University of Stuttgart, Germany -- a collaborative effort between research software developers and infrastructure providers -- we outline practical challenges and experiences 	
"Metaverse for Wireless Systems: Architecture, Advances, Standardization,
  and Open Challenges"	http://arxiv.org/abs/2301.11441v1	2023-01-26T22:04:19Z	2023-01-26T22:04:19Z	  The growing landscape of emerging wireless applications is a key driver toward the development of novel wireless system designs. Such a design can be based on the metaverse that uses a virtual model of the physical world systems along with other schemes/technologies (e.g., optimization theory, machine learning, and blockchain). A metaverse using a virtual model performs proactive intelligent analytics prior to a user request for efficient management of the wireless system resources. Additionally, a metaverse will enable self-sustainability to operate wireless systems with the least possible intervention from network operators. Although the metaverse can offer many benefits, it faces some challenges as well. Therefore, in this tutorial, we discuss the role of a metaverse in enabling wireless applications. We present an overview, key enablers, design aspects (i.e., metaverse for wireless and wireless for metaverse), and a novel high-level architecture of metaverse-based wireless systems. We discuss metaverse management, reliability, and security of the metaverse-based system. Furthermore, we discuss recent advances and standardization of metaverse-enabled wireless system. Finally, we outline open challenges and present possible solutions. 	
"Exact quantum ground state of a two-dimensional quasicrystalline
  antiferromagnet"	http://arxiv.org/abs/2301.11331v1	2023-01-26T18:59:52Z	2023-01-26T18:59:52Z	  We present the exact dimer ground state of a quantum antiferromagnet defined on a quasicrystal constructed from the Bronze-mean hexagonal quasicrystal. A coupling isotropy on the first and second-neighbor bonds is sufficient to stabilize a product state of singlets on the third-neighbor bonds. We also provide a systematic approach for constructing additional crystals, quasicrystals, and amorphous structures that can sustain an exact dimer ground state. 	
"Sustainability is Stratified: Toward a Better Theory of Sustainable
  Software Engineering"	http://arxiv.org/abs/2301.11129v1	2023-01-26T14:27:35Z	2023-01-26T14:27:35Z	  Background: Sustainable software engineering (SSE) means creating software in a way that meets present needs without undermining our collective capacity to meet our future needs. It is typically conceptualized as several intersecting dimensions or ``pillars'' -- environmental, social, economic, technical and individual. However; these pillars are theoretically underdeveloped and require refinement. Objectives: The objective of this paper is to generate a better theory of SSE. Method: First, a scoping review was conducted to understand the state of research on SSE and identify existing models thereof. Next, a meta-synthesis of qualitative research on SSE was conducted to critique and improve the existing models identified. Results: 961 potentially relevant articles were extracted from five article databases. These articles were de-duplicated and then screened independently by two screeners, leaving 243 articles to examine. Of these, 109 were non-empirical, the most common empirical method was systematic review, and no randomized controlled experiments were found. Most papers focus on ecological sustainability (158) and the sustainability of software products (148) rather than processes. A meta-synthesis of 36 qualitative studies produced several key propositions, most notably, that sustainability is stratified (has different meanings at different levels of abstraction) and multisystemic (emerges from interactions among multiple social, technical, and sociotechnical systems). Conclusion: The academic literature on SSE is surprisingly non-empirical. More empirical evaluations of specific sustainability interventions are needed. The sustainability of software development products and processes should be conceptualized as multisystemic and stratified, and assessed accordingly. 	
A Systematic Review of Green AI	http://arxiv.org/abs/2301.11047v2	2023-01-31T12:47:06Z	2023-01-26T11:41:46Z	  With the ever-growing adoption of AI-based systems, the carbon footprint of AI is no longer negligible. AI researchers and practitioners are therefore urged to hold themselves accountable for the carbon emissions of the AI models they design and use. This led in recent years to the appearance of researches tackling AI environmental sustainability, a field referred to as Green AI. Despite the rapid growth of interest in the topic, a comprehensive overview of Green AI research is to date still missing. To address this gap, in this paper, we present a systematic review of the Green AI literature. From the analysis of 98 primary studies, different patterns emerge. The topic experienced a considerable growth from 2020 onward. Most studies consider monitoring AI model footprint, tuning hyperparameters to improve model sustainability, or benchmarking models. A mix of position papers, observational studies, and solution papers are present. Most papers focus on the training phase, are algorithm-agnostic or study neural networks, and use image data. Laboratory experiments are the most common research strategy. Reported Green AI energy savings go up to 115%, with savings over 50% being rather common. Industrial parties are involved in Green AI studies, albeit most target academic readers. Green AI tool provisioning is scarce. As a conclusion, the Green AI research field results to have reached a considerable level of maturity. Therefore, from this review emerges that the time is suitable to adopt other Green AI research strategies, and port the numerous promising academic results to industrial practice. 	
Hydrodynamic Collapse of the Leidenfrost Vapor Layer	http://arxiv.org/abs/2301.10650v1	2023-01-25T15:46:49Z	2023-01-25T15:46:49Z	  During the Leidenfrost effect, a stable vapor film can separate a hot solid from an evaporating liquid. Eventually, after formation and upon cooling, the vapor layer cannot be sustained and undergoes a violent collapse evidenced by explosive boiling. Computationally, modeling this instability involves an interplay between hydrodynamics, thermodynamics, rapid evaporation, and length-scales from $\mu$m to cm. Selective assumptions, made to reduce computational costs, have limited most previous studies to steady-state investigations. Here, we combine two-phase laminar flow, heat transfer, and evaporation in a finite-element simulation to examine the failure of Leidenfrost vapor layers during cooling. During periods of quiescence, the geometry of the vapor layer agrees well with steady-state lubrication theory. In the simulations, we report the local temperature of the solid at failure, $T_-$, which provides a lower bound for recent experimental work using the same geometric and material conditions. Surprisingly, we find that inertial forces, which are typically ignored in theoretical treatments of the vapor layer, are responsible for initiating the instability leading to failure. 	
"Using novel data and ensemble models to improve automated labeling of
  Sustainable Development Goals"	http://arxiv.org/abs/2301.11353v2	2023-02-01T12:44:44Z	2023-01-25T07:44:46Z	  A number of labeling systems based on text have been proposed to help monitor work on the United Nations (UN) Sustainable Development Goals (SDGs). Here, we present a systematic comparison of systems using a variety of text sources and show that systems differ considerably in their specificity (i.e., true-positive rate) and sensitivity (i.e., true-negative rate), have systematic biases (e.g., are more sensitive to specific SDGs relative to others), and are susceptible to the type and amount of text analyzed. We then show that an ensemble model that pools labeling systems alleviates some of these limitations, exceeding the labeling performance of all currently available systems. We conclude that researchers and policymakers should care about the choice of labeling system and that ensemble methods should be favored when drawing conclusions about the absolute and relative prevalence of work on the SDGs based on automated methods. 	
"Tuning Optical Properties of Metamaterials by Mie Scattering for
  Efficient Sub-ambient Daytime Radiative Cooling"	http://arxiv.org/abs/2301.10338v1	2023-01-24T22:48:16Z	2023-01-24T22:48:16Z	  The management of the abundant eggshell biowaste produced worldwide has become a problematic issue due to the generated odor and microorganisms after directly disposing eggshell biowaste in landfills. Herein, we propose a novel method to convert the hazardous eggshell biowaste to valuable resources for energy management applications. Eggshell-based films are fabricated by embedding eggshell powders into polymer matrix to achieve highly efficient sub-ambient daytime radiative cooling. Benefiting from the Mie scattering of eggshell particles/air pores in the solar spectrum and strong emission of eggshell in the mid-infrared (mid-IR) range, the eggshell-based films present high reflection of 0.96 in the solar spectrum and high emission of 0.95 in the mid-IR range, resulting in significant average temperature drop of 5{\deg}C and 12{\deg}C below the ambient temperature during daytime and nighttime, respectively. Moreover, the eggshell-based films exhibit excellent flexibility and self-cleaning properties, which are beneficial for practical long-term outdoor applications. Our proposed design provides a novel means for an environmentally friendly and sustainable management of the eggshell biowaste. 	
Spectral signatures of symmetry-breaking dynamical phase transitions	http://arxiv.org/abs/2301.10262v1	2023-01-24T19:00:04Z	2023-01-24T19:00:04Z	  Large deviation theory provides the framework to study the probability of rare fluctuations of time-averaged observables, opening new avenues of research in nonequilibrium physics. One of the most appealing results within this context are dynamical phase transitions (DPTs), which might occur at the level of trajectories in order to maximize the probability of sustaining a rare event. While the Macroscopic Fluctuation Theory has underpinned much recent progress on the understanding of symmetry-breaking DPTs in driven diffusive systems, their microscopic characterization is still challenging. In this work we shed light on the general spectral mechanism giving rise to continuous DPTs not only for driven diffusive systems, but for any jump process in which a discrete $\mathbb{Z}_n$ symmetry is broken. By means of a symmetry-aided spectral analysis of the Doob-transformed dynamics, we provide the conditions whereby symmetry-breaking DPTs might emerge and how the different dynamical phases arise from the specific structure of the degenerate eigenvectors. We show explicitly how all symmetry-breaking features are encoded in the subleading eigenvectors of the degenerate manifold. Moreover, by partitioning configuration space into equivalence classes according to a proper order parameter, we achieve a substantial dimensional reduction which allows for the quantitative characterization of the spectral fingerprints of DPTs. We illustrate our predictions in three paradigmatic many-body systems: (i) the 1D boundary-driven weakly asymmetric exclusion process (WASEP), which exhibits a particle-hole symmetry-breaking DPT for current fluctuations, (ii) the $3$ and $4$-state Potts model, which displays discrete rotational symmetry-breaking DPT for energy fluctuations, and (iii) the closed WASEP which presents a continuous symmetry-breaking DPT to a time-crystal phase characterized by a rotating condensate. 	
"Modulation in the motion of an autonomous molecular-machine assembly
  caused by the hysteresis in response to the directionality of the applied
  light"	http://arxiv.org/abs/2301.09873v3	2023-03-09T08:13:01Z	2023-01-24T09:16:09Z	  Living organisms show self-sustained motion, make behavioural decisions in response to their environment, and replicate themselves in a genetic manner. Recently, nanometre-sized molecular machines have been assembled to realise macroscopic systems that exhibit self-sustaining dynamics. However, it is unclear how such systems can acquire the ability to make decisions in response to their environment. We have previously reported that the behaviour of a light-driven self-oscillating crystal becomes complicated when the driving light is polarised. Here, we reveal by incorporating a theoretical analysis that the apparent complexity is due to the orientation of the crystal relative to the incident light. An additional reason for this complexity is that the components remember the polarity of the preceding light input. Our results provide a new concept, i.e., collaboration between a motor molecule to achieve self-sustaining motion and a responsive machine for storing information to realise self-governed dynamics in a multimolecular architecture. 	
Stratified inclined duct: direct numerical simulations	http://arxiv.org/abs/2301.09773v1	2023-01-24T01:05:38Z	2023-01-24T01:05:38Z	  The stratified inclined duct (SID) experiment consists of a zero-net-volume exchange flow in a long tilted rectangular duct, which allows the study of realistic stratified shear flows with sustained internal forcing.   We present the first three-dimensional direct numerical simulations (DNS) of SID to explore the transitions between increasingly turbulent flow regimes first described by Meyer \& Linden (\textit{J. Fluid Mech.} \textbf{753}, 242-253, 2014). We develop a numerical set-up that faithfully reproduces the experiments and sustains the flow for arbitrarily long times at minimal computational cost.   We recover the four qualitative flow regimes found experimentally in the same regions of parameter space: laminar flow, waves, intermittent turbulence, and fully-developed turbulence. We find good qualitative and quantitative agreement between DNS and experiments and highlight the added value of DNS to complement experimental diagnostics and increase our understanding of the transition to turbulence, both temporally (laminar/turbulent cycles) and parametrically (as the tilt angle of the duct and the Reynolds number are increased).   These results demonstrate that numerical studies of SID -- and deeper integration between simulations and experiments -- have the potential to lead to a better understanding of stratified turbulence in environmental flows. 	
"The turbulent convection in protoplanetary disks and its role in the
  angular momentum transfer"	http://arxiv.org/abs/2301.09676v1	2023-01-23T19:14:41Z	2023-01-23T19:14:41Z	  A model for the transport of anisotropic turbulence in an accretion disk is presented. This model is based on the mean field approximation and is designed to study turbulence of various nature and its role in the redistribution of the angular momentum of the accretion disk. The mean field approach makes it possible to take into account various types of instabilities by adding appropriate sources in the form of moments of fluctuations of hydrodynamic quantities. We used the model to study the role of convective instability in a gaseous and dusty circumstellar disk in the framework of a one-dimensional approximation. To do this, it was combined with the calculation of radiative transfer and with the calculation of the convective flow in the mixing length theory approximation. Within this framework, we confirm the conclusions of other authors that the turbulence generated by convection does not provide the observable disk accretion rates and sufficient heat source for which convection would be self-sustaining. The reasons for this are the strong anisotropy of turbulence in the disk, as well as the fact that convection turns out to be too weak source for turbulence. 	
"Non-perturbative renormalization group analysis of nonlinear spiking
  networks"	http://arxiv.org/abs/2301.09600v1	2023-01-23T18:00:05Z	2023-01-23T18:00:05Z	  The critical brain hypothesis posits that neural circuits may operate close to critical points of a phase transition, which has been argued to have functional benefits for neural computation. Theoretical and computational studies arguing for or against criticality in neural dynamics largely rely on establishing power laws or scaling functions of statistical quantities, while a proper understanding of critical phenomena requires a renormalization group (RG) analysis. However, neural activity is typically non-Gaussian, nonlinear, and non-local, rendering models that capture all of these features difficult to study using standard statistical physics techniques. Here, we overcome these issues by adapting the non-perturbative renormalization group (NPRG) to work on (symmetric) network models of stochastic spiking neurons. By deriving a pair of Ward-Takahashi identities and making a ``local potential approximation,'' we are able to calculate non-universal quantities such as the effective firing rate nonlinearity of the network, allowing improved quantitative estimates of network statistics. We also derive the dimensionless flow equation that admits universal critical points in the renormalization group flow of the model, and identify two important types of critical points: in networks with an absorbing state there is Directed Percolation (DP) fixed point corresponding to a non-equilibrium phase transition between sustained activity and extinction of activity, and in spontaneously active networks there is a \emph{complex valued} critical point, corresponding to a spinodal transition observed, e.g., in the Lee-Yang $\phi^3$ model of Ising magnets with explicitly broken symmetry. Our Ward-Takahashi identities imply trivial dynamical exponents $z_\ast = 2$ in both cases, rendering it unclear whether these critical points fall into the known DP or Ising universality classes. 	
"Hatchery-produced sandfish (Holothuria scabra) show altered genetic
  diversity in New Caledonia"	http://arxiv.org/abs/2301.09472v1	2023-01-23T15:09:30Z	2023-01-23T15:09:30Z	  Facing an alarming continuing decline of wild sea cucumber resources, management strategies were developed over the past three decades to sustainably promote development, maintenance, or regeneration of wild sea cucumber fisheries. In New Caledonia (South Pacific), dedicated management efforts via restocking and sea ranching programs were implemented to cope with the overharvesting of the sandfish Holothuria scabra and the recent loss of known populations. In order to investigate genetic implications of a major H. scabra restocking program, we assessed the genetic diversity and structure of wild stocks and hatchery-produced sandfish and compared the genetic outcomes of consecutive spawning and juvenile production events. For this, 1358 sandfish collected at four sites along the northwestern coasts of New Caledonia, as well as during five different restocking events in the Tiabet Bay, were genotyped using nine polymorphic microsatellite markers. We found that wild H. scabra populations from the northwestern coast of New Caledonia likely belonged to one panmictic population with high level of gene flow observed along the study scale. Further, this panmictic population displayed an effective size of breeders large enough to ensure the feasibility of appropriate breeding programs for restocking. In contrast, hatchery-produced samples did suffer from an important reduction in the effective population size: the effective population size were so small that genetic drift was detectable over one generation, with the presence of inbred individuals, as well as more related dyads than in wild populations. All these results suggest that dedicated efforts in hatcheries are further needed to maintain genetic diversity of hatchery-produced individuals in order to unbalance any negative impact during this artificial selection. 	
Dynamic Graphs Generators Analysis : an Illustrative Case Study	http://arxiv.org/abs/2301.09458v1	2023-01-23T14:32:46Z	2023-01-23T14:32:46Z	  In this work, we investigate the analysis of generators for dynamic graphs, which are defined as graphs whose topology changes over time. We introduce a novel concept, called ''sustainability,'' to qualify the long-term evolution of dynamic graphs. A dynamic graph is considered sustainable if its evolution does not result in a static, empty, or periodic graph. To measure the dynamics of the sets of vertices and edges, we propose a metric, named ''Nervousness,'' which is derived from the Jaccard distance.As an illustration of how the analysis can be conducted, we design a parametrized generator, named D3G3 (Degree-Driven Dynamic Geometric Graphs Generator), which generates dynamic graph instances from an initial geometric graph. The evolution of these instances is driven by two rules that operate on the vertices based on their degree. By varying the parameters of the generator, different properties of the dynamic graphs can be produced.Our results show that in order to ascertain the sustainability of the generated dynamic graphs, it is necessary to study both the evolution of the order and the Nervousness for a given set of parameters. 	
"The Energy Worker Profiler from Technologies to Skills to Realize Energy
  Efficiency in Manufacturing"	http://arxiv.org/abs/2301.09445v1	2023-01-23T14:08:34Z	2023-01-23T14:08:34Z	  In recent years, the manufacturing sector has been responsible for nearly 55 percent of total energy consumption, inducing a major impact on the global ecosystem. Although stricter regulations, restrictions on heavy manufacturing and technological advances are increasing its sustainability, zero-emission and fuel-efficient manufacturing is still considered a utopian target. In parallel,companies that have invested in digital innovation now need to align their internal competencies to maximize their return on investment. Moreover, a primary feature of Industry 4.0 is the digitization of production processes, which offers the opportunity to optimize energy consumption. However, given the speed with which innovation manifests itself, tools capable of measuring the impact that technology is having on digital and green professions and skills are still being designed. In light of the above, in this article we present the Worker Profiler, a software designed to map the skills currently possessed by workers, identifying misalignment with those they should ideally possess to meet the renewed demands that digital innovation and environmental preservation impose. The creation of the Worker Profiler consists of two steps: first, the authors inferred the key technologies and skills for the area of interest, isolating those with markedly increasing patent trends and identifying green and digital enabling skills and occupations. Thus, the software was designed and implemented at the user-interface level. The output of the self-assessment is the definition of the missing digital and green skills and the job roles closest to the starting one in terms of current skills; both the results enable the definition of a customized retraining strategy. The tool has shown evidence of being user-friendly, effective in identifying skills gaps and easily adaptable to other contexts. 	
A review on laser-induced crystallization from solution	http://arxiv.org/abs/2301.09434v1	2023-01-23T13:42:47Z	2023-01-23T13:42:47Z	  Crystallization is abound in nature and industrial practice. A plethora of indispensable products ranging from agrochemicals and pharmaceuticals to battery materials, are produced in crystalline form in industrial practice. Yet, our control over the crystallization process across scales, from molecular to macroscopic, is far from complete. This bottleneck not only hinders our ability to engineer the properties of crystalline products essential for maintaining our quality of life but also hampers progress toward a sustainable circular economy in resource recovery. In recent years, approaches leveraging light fields have emerged as promising alternatives to manipulate crystallization. In this review article, we classify laser-induced crystallization approaches where light-material interactions are utilized to influence crystallization phenomena according to proposed underlying mechanisms and experimental setups. We discuss non-photochemical laser-induced nucleation, high-intensity laser-induced nucleation, laser trapping-induced crystallization, and indirect methods in detail. Throughout the review, we highlight connections amongst these separately evolving sub-fields to encourage interdisciplinary exchange of ideas. 	
"From Agile to DevOps, Holistic Approach for Faster and Efficient
  Software Product Release Management"	http://arxiv.org/abs/2301.09429v1	2023-01-23T13:30:55Z	2023-01-23T13:30:55Z	  Release management is one of the most important software processes and is a set of processes that includes the compilation, configuration, and management of software versions in different environments. In recent years, changes in processes, technologies, and tools and changes in practices and understanding have paved the way for more effective, efficient, sustainable, reusable models and methods in this field. The purpose of this study is to examine the DevOps idea to produce a flow, highlight their benefits, and investigate with a model how these philosophies, which are two of the most important processes and methods in software development today, can reveal an effective release management process. What has been learned from the research is how the agile and DevOps practices, which have become widespread in recent years, can be positioned in a general flow in the release management process, although there are different practices, flows, disciplines, and technology. Sharing a case study on these issues in future studies and an experience sharing research where the flow is applied as a case study will reveal positive feedback on the real-life application and results of the flow and the model. Further, a literature review studies in which deficiencies in the literature are identified will be useful in determining the gaps in the process. 	
"THz ultra-strong light-matter coupling up to 200K with
  continuously-graded parabolic quantum wells"	http://arxiv.org/abs/2301.09410v1	2023-01-23T13:10:01Z	2023-01-23T13:10:01Z	  Continuously graded parabolic quantum wells with excellent optical performances are used to overcome the low-frequency and thermal limitations of square quantum wells at terahertz frequencies. The formation of microcavity intersubband polaritons at frequencies as low as 1.8 THz is demonstrated, with a sustained ultra-strong coupling regime up to a temperature of 200K. It is additionally shown that the ultra-strong coupling regime is preserved when the active region is embedded in sub-wavelength resonators, with an estimated relative strength $\eta = \Omega_R / \omega_0 = 0.12$. This represents an important milestone for future studies of quantum vacuum radiation because such resonators can be optically modulated at ultrafast rates, possibly leading to the generation of non-classical light via the dynamic Casimir effect. Finally, with an effective volume of $2.10^{-6} \lambda_0^3$, it is estimated that fewer than 3000 electrons per resonator are ultra-strongly coupled to the quantized electromagnetic mode, proving it is also a promising approach to explore few-electron polaritonic systems operating at relatively high temperatures. 	
"Proactive and Reactive Engagement of Artificial Intelligence Methods for
  Education: A Review"	http://arxiv.org/abs/2301.10231v1	2023-01-23T02:47:36Z	2023-01-23T02:47:36Z	  Quality education, one of the seventeen sustainable development goals (SDGs) identified by the United Nations General Assembly, stands to benefit enormously from the adoption of artificial intelligence (AI) driven tools and technologies. The concurrent boom of necessary infrastructure, digitized data and general social awareness has propelled massive research and development efforts in the artificial intelligence for education (AIEd) sector. In this review article, we investigate how artificial intelligence, machine learning and deep learning methods are being utilized to support students, educators and administrative staff. We do this through the lens of a novel categorization approach. We consider the involvement of AI-driven methods in the education process in its entirety - from students admissions, course scheduling etc. in the proactive planning phase to knowledge delivery, performance assessment etc. in the reactive execution phase. We outline and analyze the major research directions under proactive and reactive engagement of AI in education using a representative group of 194 original research articles published in the past two decades i.e., 2003 - 2022. We discuss the paradigm shifts in the solution approaches proposed, i.e., in the choice of data and algorithms used over this time. We further dive into how the COVID-19 pandemic challenged and reshaped the education landscape at the fag end of this time period. Finally, we pinpoint existing limitations in adopting artificial intelligence for education and reflect on the path forward. 	
Probing non-linear MHD stability of the EDA H-mode in ASDEX Upgrade	http://arxiv.org/abs/2301.09066v1	2023-01-22T07:26:25Z	2023-01-22T07:26:25Z	  Regimes of operation in tokamaks that are devoid of large ELMs have to be better understood to extrapolate their applicability to reactor-relevant devices. This paper describes non-linear extended MHD simulations that use an experimental equilibrium from an EDA H-mode in ASDEX Upgrade. Linear ideal MHD analysis indicates that the operational point lies slightly inside of the stable region. The non-linear simulations with the visco-resistive extended MHD code, JOREK, sustain non-axisymmetric perturbations that are linearly most unstable with toroidal mode numbers of n = \{6 \dots 9\}, but non-linearly higher and lower n become driven and the low-n become dominant. The poloidal mode velocity during the linear phase is found to correspond to the expected velocity for resistive ballooning modes. The perturbations that exist in the simulations have somewhat smaller poloidal wavenumbers (k_{\theta} \sim 0.1 to 0.5 cm^{-1} ) than the experimental expectations for the quasi-coherent mode in EDA, and cause non-negligible transport in both the heat and particle channels. In the transition from linear to non-linear phase, the mode frequency chirps down from approximately 35 kHz to 13 kHz, which corresponds approximately to the lower end of frequencies that are typically observed in EDA H-modes in ASDEX Upgrade. 	
Are physiological oscillations 'physiological'?	http://arxiv.org/abs/2301.08996v2	2023-01-24T22:43:14Z	2023-01-21T19:31:36Z	  Despite widespread and striking examples of physiological oscillations, their functional role is often unclear. Even glycolysis, the paradigm example of oscillatory biochemistry, has seen questions about its oscillatory function. Here, we take a systems approach to summarize evidence that oscillations play critical physiological roles. Oscillatory behavior enables systems to avoid desensitization, to avoid chronically high and therefore toxic levels of chemicals, and to become more resistant to noise. Oscillation also enables complex physiological systems to reconcile incompatible conditions such as oxidation and reduction, by cycling between them, and to synchronize the oscillations of many small units into one large effect. In pancreatic beta cells, glycolytic oscillations are in synchrony with calcium and mitochondrial oscillations to drive pulsatile insulin release, which is pivotal for the liver to regulate blood glucose dynamics. In addition, oscillation can keep biological time, essential for embryonic development in promoting cell diversity and pattern formation. The functional importance of oscillatory processes requires a rethinking of the traditional doctrine of homeostasis, holding that physiological quantities are maintained at constant equilibrium values, a view that has largely failed us in the clinic. A more dynamic approach will enable us to view health and disease through a new light and initiate a paradigm shift in treating diseases, including depression and cancer. This modern synthesis also takes a deeper look into the mechanisms that create, sustain and abolish oscillatory processes, which requires the language of nonlinear dynamics, well beyond the linearization techniques of equilibrium control theory. 	
"Lead-free, luminescent perovskite nanocrystals obtained through ambient
  condition synthesis"	http://arxiv.org/abs/2301.08936v1	2023-01-21T11:00:13Z	2023-01-21T11:00:13Z	  Heterovalent substitution of toxic lead is an increasingly popular design strategy to obtain environmentally sustainable variants of the exciting material class of halide perovskites. Perovskite nanocrystals (NCs) obtained through solution-based methods exhibit exceedingly high optical quality. Unfortunately, most of these synthesis routes still require reaction under inert gas and at very high temperatures. Herein we present a novel synthesis routine for lead-free double perovskite NCs. We combine hot injection and ligand-assisted reprecipitation (LARP) methods to achieve a low-temperature and ambient atmosphere-based synthesis for manganese-doped Cs_{2}NaBiCl_{6} NCs. Mn incorporation is critical for the otherwise non-emissive material, with a 9:1 Bi:Mn precursor ratio maximizing the bright orange photoluminescence (PL) and quantum yield (QY). Higher temperatures slightly increased the material's performance, yet NCs synthesized at room temperature were still emissive, highlighting the versatility of the synthetic approach. Furthermore, the NCs show excellent long-term stability in ambient conditions, facilitating additional investigations and energy-related applications. 	
Corporate Culture and Organizational Fragility	http://arxiv.org/abs/2301.08907v1	2023-01-21T06:31:08Z	2023-01-21T06:31:08Z	  Complex organizations accomplish tasks through many steps of collaboration among workers. Corporate culture supports collaborations by establishing norms and reducing misunderstandings. Because a strong corporate culture relies on costly, voluntary investments by many workers, we model it as an organizational public good, subject to standard free-riding problems, which become severe in large organizations. Our main finding is that voluntary contributions to culture can nevertheless be sustained, because an organization's equilibrium productivity is endogenously highly sensitive to individual contributions. However, the completion of complex tasks is then necessarily fragile to small shocks that damage the organization's culture. 	
"Integration of Data Driven Technologies in Smart Grids for Resilient and
  Sustainable Smart Cities: A Comprehensive Review"	http://arxiv.org/abs/2301.08814v1	2023-01-20T22:07:50Z	2023-01-20T22:07:50Z	  A modern-day society demands resilient, reliable, and smart urban infrastructure for effective and in telligent operations and deployment. However, unexpected, high-impact, and low-probability events such as earthquakes, tsunamis, tornadoes, and hurricanes make the design of such robust infrastructure more complex. As a result of such events, a power system infrastructure can be severely affected, leading to unprecedented events, such as blackouts. Nevertheless, the integration of smart grids into the existing framework of smart cities adds to their resilience. Therefore, designing a resilient and reliable power system network is an inevitable requirement of modern smart city infras tructure. With the deployment of the Internet of Things (IoT), smart cities infrastructures have taken a transformational turn towards introducing technologies that do not only provide ease and comfort to the citizens but are also feasible in terms of sustainability and dependability. This paper presents a holistic view of a resilient and sustainable smart city architecture that utilizes IoT, big data analytics, unmanned aerial vehicles, and smart grids through intelligent integration of renew able energy resources. In addition, the impact of disasters on the power system infrastructure is investigated and different types of optimization techniques that can be used to sustain the power flow in the network during disturbances are compared and analyzed. Furthermore, a comparative review analysis of different data-driven machine learning techniques for sustainable smart cities is performed along with the discussion on open research issues and challenges. 	
The Tachyonic Higgs and the Inflationary Universe	http://arxiv.org/abs/2301.08754v1	2023-01-20T19:00:00Z	2023-01-20T19:00:00Z	  The Standard Model Higgs becomes tachyonic at high energy scales according to current measurements. This unstable regime of the Higgs potential can be realized in the early Universe during high scale inflation, potentially with catastrophic consequences. This letter highlights a crucial inherent feature of such configurations that has so far remained ignored: Higgs particle production out of vacuum induced by the rapidly evolving Higgs field, which gets exponentially enhanced due to the tachyonic instability. Such explosive particle production can rapidly drain energy away from the Higgs field, sustaining a significant density of Higgs particles even during inflation, and could initiate a qualitatively different form of preheating in parts of the post-inflationary Universe. Any study of the Higgs field in its tachyonic phase, either during or after inflation, must therefore take this substantial particle energy density into account, which could significantly affect the subsequent evolution of such systems. This could carry important implications for high scale inflation, post-inflationary preheating, observable signals in the cosmic microwave background, gravitational waves, and primordial black holes, as well as deeper concepts ranging from eternal inflation to the metastability of the electroweak vacuum. 	
"Connecting transonic buffet with incompressible low-frequency
  oscillations on aerofoils"	http://arxiv.org/abs/2301.08508v1	2023-01-20T10:53:57Z	2023-01-20T10:53:57Z	"  Self-sustained low-frequency flow unsteadiness over rigid aerofoils in the transonic regime is referred to as transonic buffet. Although the exact physical mechanisms underlying this phenomenon are unclear, it is generally assumed to be unique to the transonic regime. This assumption is shown to be incorrect here by performing large-eddy simulations of flow over a NACA0012 profile for a wide range of flow conditions. At zero incidence and sufficiently high freestream Mach numbers, M, transonic buffet occurs with shock waves present in the flow. However, self-sustained oscillations that occur at similar frequencies are observed at lower M for which shock waves are absent and the entire flow field remains subsonic at all times. At higher incidences, the oscillations are sustained at progressively lower M. Oscillations were observed for M as low as 0.3, where compressibility effects are small. A spectral proper orthogonal decomposition shows that the spatial structure of these oscillations (i.e., mode shapes) are essentially the same for all cases. These results indicate that buffet on aerofoils does not necessarily require the presence of shock waves. Furthermore, the trend seen with increasing incidence angles suggests that transonic buffet on aerofoils and low-frequency oscillations reported in the incompressible regime (Zaman et al., 1989, J. Fluid Mech., vol. 202, pp. 403--442) have similar origins. Thus, models which rely specifically on shock waves to explain transonic buffet are incorrect. These insights could be useful in understanding the origins of ``transonic"" buffet and reformulating mitigation strategies by shifting the focus away from shock waves. "	
Integrated Planning of Multi-energy Grids: Concepts and Challenges	http://arxiv.org/abs/2301.08454v1	2023-01-20T07:36:18Z	2023-01-20T07:36:18Z	  In order to meet ever-stricter climate targets and achieve the eventual decarbonization of the energy supply of German industrial metropolises, the focus is on gradually phasing out nuclear power, then coal and gas combined with the increased use of renewable energy sources and employing hydrogen as a clean energy carrier. While complete electrification of the energy supply of households and the transportation sector may be the ultimate goal, a transitional phase is necessary as such massive as well as rapid expansion of the electrical distribution grid is infeasible. Additionally, German industries have expressed their plans to use hydrogen as their primary strategy in meeting carbon targets. This poses challenges to the existing electrical, gas, and heating distribution grids. It becomes necessary to integrate the planning and developing procedures for these grids to maximize efficiencies and guarantee security of supply during the transition. The aim of this paper is thus to highlight those challenges and present novel concepts for the integrated planning of the three grids as one multi-energy grid. 	
"Direct detonation initiation in hydrogen/air mixture: effects of
  compositional gradient and hotspot condition"	http://arxiv.org/abs/2301.08363v1	2023-01-20T00:00:13Z	2023-01-20T00:00:13Z	  Two-dimensional simulations are conducted to investigate the direct initiation of cylindrical detonation in hydrogen/air mixtures with detailed chemistry. The effects of hotspot condition and mixture composition gradient on detonation initiation are studied. Different hotspot pressure and composition are first considered in the uniform mixture. It is found that detonation initiation fails for low hotspot pressures and supercritical regime dominates with high hotspot pressures. Detonation is directly initiated from the reactive hotspot, whilst it is ignited somewhere beyond the nonreactive hotspots. Two cell diverging patterns (i.e., abrupt and gradual) are identified and the detailed mechanisms are analyzed. Moreover, cell coalescence occurs if many irregular cells are generated initially, which promotes the local cell growing. We also consider nonuniform detonable mixtures. The results show that the initiated detonation experiences self-sustaining propagation, highly unstable propagation, and extinction in mixtures with a linearly decreasing equivalence ratio along the radial direction respectively, i.e., 1 to 0.9, 1 to 0.5 and 1 to 0. Moreover, the hydrodynamic structure analysis shows that, for the self-sustaining detonations, the hydrodynamic thickness increases at the overdriven stage, decreases as the cells are generated, and eventually become almost constant at the cell diverging stage, within which the sonic plane shows a sawtooth pattern. However, in the detonation extinction cases, the hydrodynamic thickness continuously increases, and no sawtooth sonic plane can be observed. 	
"Modeling sustained transmission of Wolbachia among Anopheles mosquitoes:
  Implications for malaria control in Haiti"	http://arxiv.org/abs/2301.08231v1	2023-01-19T18:40:28Z	2023-01-19T18:40:28Z	  Wolbachia infection in Anopheles albimanus mosquitoes can render mosquitoes less capable of spreading malaria. We develop and analyze an ordinary differential equation model to evaluate the effectiveness of Wolbachia-based vector control strategies among wild Anopheles mosquitoes in Haiti. The model tracks the mosquito life stages, including egg, larva, and adult (male and female). It also accounts for critical biological effects, such as the maternal transmission of Wolbachia through infected females and cytoplasmic incompatibility, which effectively sterilizes uninfected females when they mate with infected males. We derived and interpreted dimensionless numbers, including the basic reproductive number and next-generation numbers. The proposed system presents backward bifurcation, which indicates a threshold infection that needs to be exceeded to establish a stable Wolbachia infection. The sensitivity analysis ranks the relative importance of the epidemiological parameters at the baseline. We simulate different intervention scenarios, including pre-release mitigation using larviciding and thermal fogging before the release, multiple releases of infected populations, and different release timing. Our simulations show that the most efficient approach to establishing Wolbachia is to release all the infected mosquitoes immediately after the pre-release mitigation process. Also, the model predicts that it is more efficient to release during the dry season than the wet season. 	
"A Workflow Model for Holistic Data Management and Semantic
  Interoperability in Quantitative Archival Research"	http://arxiv.org/abs/2301.07676v1	2023-01-18T17:53:52Z	2023-01-18T17:53:52Z	  Archival research is a complicated task that involves several diverse activities for the extraction of evidence and knowledge from a set of archival documents. The involved activities are usually unconnected, in terms of data connection and flow, making difficult their recursive revision and execution, as well as the inspection of provenance information at data element level. This paper proposes a workflow model for holistic data management in archival research; from transcribing and documenting a set of archival documents, to curating the transcribed data, integrating it to a rich semantic network (knowledge graph), and then exploring the integrated data quantitatively. The workflow is provenance-aware, highly-recursive and focuses on semantic interoperability, aiming at the production of sustainable data of high value and long-term validity. We provide implementation details for each step of the workflow and present its application in maritime history research. We also discuss relevant quality aspects and lessons learned from its application in a real context. 	
"MHD simulations of formation, sustainment and loss of Quiescent H-mode
  in the all-tungsten ASDEX Upgrade"	http://arxiv.org/abs/2301.07607v1	2023-01-18T15:39:20Z	2023-01-18T15:39:20Z	  Periodic edge localized modes (ELMs) are the non-linear consequences of pressure-gradient-driven ballooning modes and current-driven peeling modes becoming unstable in the pedestal region of high confinement fusion plasmas. In future tokamaks like ITER, large ELMs are foreseen to severely affect the lifetime of wall components as they transiently deposit large amounts of heat onto a narrow region at the divertor targets. Several strategies exist for avoidance, suppression, or mitigation of these instabilities, such as the naturally ELM-free quiescent H-mode (QH-mode). In the present article, an ASDEX Upgrade equilibrium that features a QH-mode is investigated through non-linear extended MHD simulations covering the dynamics over tens of milliseconds. The equilibrium is close to the ideal peeling limit and non-linearly develops saturated modes at the edge of the plasma. A dominant toroidal mode number of $n=1$ is found, for which the characteristic features of the edge harmonic oscillation are recovered. The saturated modes contribute to heat and particle transport preventing pedestal build-up to the ELM triggering threshold. The non-linear dynamics of the mode, in particular its interaction with the evolution of the edge safety factor is studied, which suggest a possible new saturation mechanism for the QH-mode. The simulations show good qualitative and quantitative agreement to experiments in AUG. In particular, the processes leading to the termination of QH-mode above a density threshold is studied, which results in the transition into an ELM regime. In the vicinity of this threshold, limit cycle oscillations are observed. 	
DC electric field generation and distribution in magnetized plasmas	http://arxiv.org/abs/2301.07159v1	2023-01-17T20:07:24Z	2023-01-17T20:07:24Z	  Very large DC and AC electric fields cannot be sustained between conducting electrodes because of volume gas breakdown and/or surface field emission. However, very large potential fields are now routinely generated in plasma structures such as laser generated wake in unmagnetized plasmas. In magnetized plasmas, large DC fields can also be sustained and controlled perpendicular to the magnetic field, but the metallic end plates limiting the plasma, terminating the magnetic field lines and usually providing the voltage drop feed between the field lines, impose severe restrictions on the maximum field. However, it is shown that very large radial DC voltage drops can be sustained by injecting waves of predetermined frequencies and wave vectors, traveling along the azimuthal direction of an axially magnetized plasma cylinder, or by injecting fast neutral particles beams along this azimuthal direction. The large conductivity along the magnetic field lines and the small conductivity between the field lines then distribute this voltage drop. The global power balance and control parameters of wave and beam generated large DC electric fields in magnetized plasmas are identified, described and analyzed. 	
"Density functional modeling of the binding energies between
  aluminosilicate oligomers and different metal cations"	http://arxiv.org/abs/2301.07046v1	2023-01-17T17:59:14Z	2023-01-17T17:59:14Z	  Interactions between negatively charged aluminosilicate species and positively charged metal cations are critical to many important engineering processes and applications, including sustainable cements and aluminosilicate glasses. In an effort to probe these interactions, here we have calculated the pair-wise interaction energies (i.e., binding energies) between aluminosilicate dimer/trimer and 17 different metal cations using a density functional theory (DFT) approach. Analysis of the DFT-optimized structural representations for the clusters (dimer/trimer + cation) shows that their structural attributes (e.g., interatomic distances) are generally consistent with literature observations on aluminosilicate glasses. The DFT-derived binding energies are seen to vary considerably depending on the type of cations (i.e., charge and ionic radii) and aluminosilicate species (i.e., dimer or trimer). A survey of the literature reveals that the difference in the calculated binding energies between different cations can be used to explain many literature observations on the impact of cations on materials properties (e.g., glass corrosion, mineral dissolution, and ionic transport). Analysis of all the DFT-derived binding energies reveals that the correlation between these energy values and the ionic potential and field strength of the cations are well captured by 2nd order polynomial functions (R2 values of 0.99-1.00 are achieved for regressions). Given that the ionic potential and field strength of a given metal cation can be readily estimated using well-tabulated ionic radii available in the literature, these simple polynomial functions would enable rapid estimation of the binding energies of a much wider range of cations with the aluminosilicate dimer/trimer, providing guidance on the design and optimization of sustainable cements and aluminosilicate glasses and their associated applications. 	
"Characterisation and Tribological Testing of Recycled Crushed Glass as
  an Alternative Rail Sand"	http://arxiv.org/abs/2301.07024v1	2023-01-17T17:18:17Z	2023-01-17T17:18:17Z	  In the UK Network Rail Environmental Sustainability Strategy 2020-2050, minimal waste and the sustainable use of materials are highlighted as core priorities. The ambition is to reuse, repurpose or redeploy all resources. In low adhesion conditions, sand particles are used to enhance traction throughout the network. However, sand is in danger of becoming scarce as many applications demand it. In this study, an alternative adhesion-enhancing particle system made of recycled crushed glass is examined in terms of density, size, shape distribution, mineralogy, mechanical properties, and bulk behaviour to better understand their characteristics in comparison with the typical Great British rail sand currently in use and reported in the literature. Their effects on tribological behaviour and surface damage are also investigated using the High-Pressure Torsion test in dry, wet, and leaf-contaminated conditions. Both particle characterisation and tribological testing show promising results. Recycled glass particles provide an acceptable level of traction with a similar level of rail damage as typical rail sand. It is suggested to perform full-scale laboratory and field tests to further confirm this material's suitability. 	
A Quantum-Classical Model of Brain Dynamics	http://arxiv.org/abs/2301.09569v3	2023-02-26T23:06:09Z	2023-01-17T15:16:21Z	  The study of the human psyche has elucidated a bipartite structure of cognition reflecting the quantum-classical nature of any process that generates knowledge and learning governed by brain activity. Acknowledging the importance of such a finding for modelization, we posit an approach to study brain by means of the quantum-classical dynamics of a Mixed Weyl symbol. The Mixed Weyl symbol is used to describe brain processes at the microscopic level and provides a link to the results of measurements made at the mesoscopic scale. Within this approach, quantum variables (such as,for example, nuclear and electron spins, dipole momenta of particles or molecules, tunneling degrees of freedom, etc may be represented by spinors while the electromagnetic fields and phonon modes involved in the processes are treated either classically or semi-classically, by also considering quantum zero-point fluctuations. Zero-point quantum effects can be incorporated into numerical simulations by controlling the temperature of each field mode via coupling to a dedicated Nos\`e-Hoover chain thermostat. The temperature of each thermostat is chosen in order to reproduce quantum statistics in the canonical ensemble. In this first paper, we introduce a quantum-classical model of brain dynamics, clarifying its mathematical strucure and focusing the discussion on its predictive value. Analytical consequences of the model are not reported in this paper, since they are left for future work. Our treatment incorporates compatible features of three well-known quantum approaches to brain dynamics - namely the electromagnetic field theory approach, the orchestrated objective reduction theory, and the dissipative quantum model of the brain - and hints at convincing arguments that sustain the existence of quantum-classical processes in the brain activity. All three models are reviewed. 	
Carbon Neutrality Approaches for IoT-Enabled Applications -- A Review	http://arxiv.org/abs/2301.06945v1	2023-01-17T15:12:51Z	2023-01-17T15:12:51Z	  Unlike others, IoT-enabled technology has expanded its base in various sectors, including finance, healthcare, agriculture, energy, and so forth. Tens of thousands of applications and products have evolved in recent years, leading to a constant threat to global climate sustainability due to the underlying carbon emissions. Researchers have developed standalone methods/approaches that aimed to tackle carbon emission problems. However, an article that expresses a list of carbon-neutral solutions and their associated technological challenges is not available. This article explores the carbon emission problems of IoT-enabled applications; and, it categorizes the carbon neutrality methods. The exploratory analysis of different carbon-neutral approaches, presented in this article, can present novel ideas and answers to questions that hover over any carbon-conscious IoT-enabled application developers. 	
"Computer Science for Future -- Sustainability and Climate Protection in
  the Computer Science Courses of the HAW Hamburg"	http://arxiv.org/abs/2301.06885v1	2023-01-17T13:43:57Z	2023-01-17T13:43:57Z	  Computer Science for Future (CS4F) is an initiative in the Department of Computer Science at HAW Hamburg. The aim of the initiative is a paradigm shift in the discipline of computer science, thus establishing sustainability goals as a primary leitmotif for teaching and research. The focus is on teaching since the most promising multipliers are the students of a university. The change in teaching influences our research, the transfer to business and civil society as well as the change in our own institution. In this article, we present the initiative CS4F and reflect primarily on the role of students as amplifiers in the transformation process of computer science. 	
"Mitigation of noise in Josephson parametric oscillator by injection
  locking"	http://arxiv.org/abs/2301.06791v1	2023-01-17T10:31:26Z	2023-01-17T10:31:26Z	  Injection locking is a well-established technique widely used in optics as well as solid-state devices for efficient suppression of noise. We present the spectroscopic characterization of the effect of the injection-locking signal (ILS) in mitigating the phase noise of a Josephson parametric oscillator (JPO), whose output oscillating phase undergoes indeterministic switching between the bistable states with symmetry $\theta \rightarrow{\theta+\pi}$. With the injection of a weak locking signal, we measure the phase noise power spectral density of the self-sustained oscillator output state for different locking signal strengths. We observed suppression of phase noise by injection locking. As the ILS strength surpasses more than a few photons, the output state stays completely pinned to the locking phase of the ILS, and the random telegraphic noise due to the switching of the states is significantly suppressed. 	
"Sustainability and coordination in a socially responsible supply chain
  using a combined incentive contract and a social marketing strategy"	http://arxiv.org/abs/2301.06618v1	2023-01-16T21:53:40Z	2023-01-16T21:53:40Z	  Due to the growing concerns for sustainable development, supply chains seek to invest in social sustainability issues to seize more market share in today's competitive business environment. This study aims to develop a coordination scheme for a manufacturer-retailer supply chain (SC) contributing to social donation (SD) activity under a cause-related marketing (CRM) campaign. In the presence of consumer social awareness (CSA), the manufacturer notices consumers through some activities (i.e. labelling) that he participates in a CRM campaign by donating a proportion of the retail price to a cause whenever a consumer makes a purchase. In this study, the market demand depends on the retail price, the retailer's stock level and donation size. The proposed problem is designed under three decision-making systems. Firstly, a decentralized decision-making system (traditional structure), where the SC's members aim to optimize their profits regardless of the other member's profitability, is investigated. Then, the problem is designed under a centralized decision-making system to obtain the best values of the retail price and replenishment decisions from the entire SC perspective. Afterwards, an incentive mechanism based on a cost and revenue-sharing (RCS) factor is developed in the coordination system to persuade the SC members to accept the optimal results of the centralized system without suffering any profit loss. Moreover, the surplus profit obtained in the centralized system is divided between the members based on their bargaining power. The numerical investigations and the blocked decision-making on SD activity are presented to evaluate the proposed model. Not only does the proposed coordination model increase the SC members' profit, but it is also desirable in achieving a more socially responsible SC. 	
"A Fully Automated and Scalable Surface Water Mapping with Topographic
  Airborne LiDAR Data"	http://arxiv.org/abs/2301.06567v1	2023-01-16T19:04:23Z	2023-01-16T19:04:23Z	  Reliable and accurate high-resolution maps of surface waters are critical inputs to models that help understand the impacts and relationships between the environment and human activities. Advances in remote sensing technology have opened up the possibility of mapping very small bodies of water that are closely related to people's daily lives and are mostly affected by anthropogenic pressures. However, a robust and scalable method that works well for all types of water bodies located in diverse landscapes at high-resolution has yet to be developed. This paper presents a method that can accurately extract surface water bodies up to a very fine scale in a wide variety of landscapes. Unlike optical image-based methods, the proposed method exploits the robust assumption that surface water is flat as gravity always pulls liquid molecules down. Based on this natural law, the proposed method extracts accurate, high-resolution water bodies including their elevations in a fully automated manner using only airborne LiDAR data. Extensive experiments with large ($\approx$ 2,500$km^{2}$) and diverse landscapes (urban, coastal, and mountainous areas) confirmed that our method can generate accurate results without site-specific parameter tunings for varied types of surface water. The proposed method enables an automated, scalable high-resolution mapping of a full 3D topography that includes both water and terrain, using only point clouds for the first time. We will release the code to the public in the hope that our work would lead to more effective solutions to help build a sustainable and resilient environment. 	
"The Swansong of the Galactic Center Source X7: An Extreme Example of
  Tidal Evolution near the Supermassive Black Hole"	http://arxiv.org/abs/2301.06562v1	2023-01-16T19:00:01Z	2023-01-16T19:00:01Z	  We present two decades of new high-angular-resolution near-infrared data from the W. M. Keck Observatory that reveal extreme evolution in X7, an elongated dust and gas feature, presently located half an arcsecond from the Galactic Center supermassive black hole. With both spectro-imaging observations of Br-{\gamma} line-emission and Lp (3.8 {\mu}m) imaging data, we provide the first estimate of its orbital parameters and quantitative characterization of the evolution of its morphology and mass. We find that the leading edge of X7 appears to be on a mildly eccentric (e~0.3), relatively short-period (170 years) orbit and is headed towards periapse passage, estimated to occur in ~2036. Furthermore, our kinematic measurements rule out the earlier suggestion that X7 is associated with the stellar source S0-73 or with any other point source that has overlapped with X7 during our monitoring period. Over the course of our observations, X7 has (1) become more elongated, with a current length-to-width ratio of 9, (2) maintained a very consistent long-axis orientation (position angle of 50 deg), (3) inverted its radial velocity differential from tip to tail from -50 to +80 km/sec, and (4) sustained its total brightness (12.8 Lp magnitudes at the leading edge) and color temperature (425 K), which suggest a constant mass of ~50 MEarth. We present a simple model showing that these results are compatible with the expected effect of tidal forces exerted on it by the central black hole and we propose that X7 is the gas and dust recently ejected from a grazing collision in a binary system. 	
"Do I Belong? Modeling Sense of Virtual Community Among Linux Kernel
  Contributors"	http://arxiv.org/abs/2301.06437v3	2023-02-23T01:18:02Z	2023-01-16T13:56:28Z	  The sense of belonging to a community is a basic human need that impacts an individuals behavior, long-term engagement, and job satisfaction, as revealed by research in disciplines such as psychology, healthcare, and education. Despite much research on how to retain developers in Open Source Software projects and other virtual, peer-production communities, there is a paucity of research investigating what might contribute to a sense of belonging in these communities. To that end, we develop a theoretical model that seeks to understand the link between OSS developer motives and a Sense of Virtual Community. We test the model with a dataset collected in the Linux Kernel developer community, using structural equation modeling techniques. Our results for this case study show that intrinsic motivations - social or hedonic motives - are positively associated with a sense of virtual community, but living in an authoritative country and being paid to contribute can reduce the sense of virtual community. Based on these results, we offer suggestions for open source projects to foster a sense of virtual community, with a view to retaining contributors and improving projects sustainability. 	
The fate of water in hydrogen-based iron oxide reduction	http://arxiv.org/abs/2301.06391v1	2023-01-16T12:23:45Z	2023-01-16T12:23:45Z	  Gas-solid reactions are cornerstones of many catalytic and redox processes that will underpin the energy and sustainability transition. The specific case of hydrogen-based iron oxide reduction is the foundation to render the global steel industry fossil-free, an essential target as iron production is the largest single industrial emitter of carbon dioxide. Our perception of gas-solid reactions has not only been limited by the availability of state-of-the-art techniques which can delve into the reacted solids in great structural and chemical detail, but we continue to miss an important reaction partner that defines the thermodynamics and kinetics of gas phase reactions: the gas molecules. In this investigation, we use the latest development in cryogenic atom probe tomography to study the quasi in-situ evolution of gas phase heavy water at iron-iron oxide interfaces resulting from the direct reduction of iron oxide by deuterium gas at 700{\deg}C. The findings provide new insights into the formation kinetics and location of water formed during hydrogen-based reduction of FeO, an its interaction with the ongoing redox reaction. 	
"Mathematical modelling and numerical simulation of reverse-osmosis
  desalination"	http://arxiv.org/abs/2301.13160v1	2023-01-16T09:56:12Z	2023-01-16T09:56:12Z	  The reverse osmosis membrane module is an integral element of a desalination system as it determines the overall performance of the desalination plant. The fraction of clean water that can be recovered via this process is often limited by salt precipitation which plays a critical role in its sustainability. In this work, we present a model to study the complex interplay between flow, transport and precipitation processes in reverse osmosis membranes, which together influence recovery and in turn process sustainability. A reactive porous interface model describes the membrane with a dynamic evolving porosity and permeability to capture the scaling and clogging of the membrane. An open-source finite-volume numerical solver is implemented within the OpenFOAM library and numerical tests are presented here showing the effect of the various parameters of the model and the robustness of the model to describe a wide range of operating conditions. 	
TextileNet: A Material Taxonomy-based Fashion Textile Dataset	http://arxiv.org/abs/2301.06160v1	2023-01-15T19:02:18Z	2023-01-15T19:02:18Z	  The rise of Machine Learning (ML) is gradually digitalizing and reshaping the fashion industry. Recent years have witnessed a number of fashion AI applications, for example, virtual try-ons. Textile material identification and categorization play a crucial role in the fashion textile sector, including fashion design, retails, and recycling. At the same time, Net Zero is a global goal and the fashion industry is undergoing a significant change so that textile materials can be reused, repaired and recycled in a sustainable manner. There is still a challenge in identifying textile materials automatically for garments, as we lack a low-cost and effective technique for identifying them. In light of this, we build the first fashion textile dataset, TextileNet, based on textile material taxonomies - a fibre taxonomy and a fabric taxonomy generated in collaboration with material scientists. TextileNet can be used to train and evaluate the state-of-the-art Deep Learning models for textile materials. We hope to standardize textile related datasets through the use of taxonomies. TextileNet contains 33 fibres labels and 27 fabrics labels, and has in total 760,949 images. We use standard Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) to establish baselines for this dataset. Future applications for this dataset range from textile classification to optimization of the textile supply chain and interactive design for consumers. We envision that this can contribute to the development of a new AI-based fashion platform. 	
Iontronic neuromorphic signalling with conical microfluidic memristors	http://arxiv.org/abs/2301.06158v1	2023-01-15T18:46:16Z	2023-01-15T18:46:16Z	  Experiments have shown that the conductance of conical channels, filled with an aqueous electrolyte, can strongly depend on the history of the applied voltage. These channels hence have a memory and are promising elements in brain-inspired (iontronic) circuits. We show here that the memory of such channels stems from transient concentration polarization over the ionic diffusion time. We derive an analytic approximation for these dynamics which shows good agreement with full finite-element calculations. Using our analytic approximation, we propose an experimentally realisable Hodgkin-Huxley iontronic circuit where micrometer cones take on the role of sodium and potassium channels. Our proposed circuit exhibits key features of neuronal communication such as all-or-none action potentials upon a pulse stimulus and a spike train upon a sustained stimulus. 	
"A Review on the effectiveness of Dimensional Reduction with
  Computational Forensics: An Application on Malware Analysis"	http://arxiv.org/abs/2301.06031v1	2023-01-15T07:34:31Z	2023-01-15T07:34:31Z	  The Android operating system is pervasively adopted as the operating system platform of choice for smart devices. However, the strong adoption has also resulted in exponential growth in the number of Android based malicious software or malware. To deal with such cyber threats as part of cyber investigation and digital forensics, computational techniques in the form of machine learning algorithms are applied for such malware identification, detection and forensics analysis. However, such Computational Forensics modelling techniques are constrained the volume, velocity, variety and veracity of the malware landscape. This in turn would affect its identification and detection effectiveness. Such consequence would inherently induce the question of sustainability with such solution approach. One approach to optimise effectiveness is to apply dimensional reduction techniques like Principal Component Analysis with the intent to enhance algorithmic performance. In this paper, we evaluate the effectiveness of the application of Principle Component Analysis on Computational Forensics task of detecting Android based malware. We applied our research hypothesis to three different datasets with different machine learning algorithms. Our research result showed that the dimensionally reduced dataset would result in a measure of degradation in accuracy performance. 	
"Reinforcement Learning for Protocol Synthesis in Resource-Constrained
  Wireless Sensor and IoT Networks"	http://arxiv.org/abs/2302.05300v1	2023-01-14T03:28:26Z	2023-01-14T03:28:26Z	  This article explores the concepts of online protocol synthesis using Reinforcement Learning (RL). The study is performed in the context of sensor and IoT networks with ultra low complexity wireless transceivers. The paper introduces the use of RL and Multi Armed Bandit (MAB), a specific type of RL, for Medium Access Control (MAC) under different network and traffic conditions. It then introduces a novel learning based protocol synthesis framework that addresses specific difficulties and limitations in medium access for both random access and time slotted networks. The mechanism does not rely on carrier sensing, network time-synchronization, collision detection, and other low level complex operations, thus making it ideal for ultra simple transceiver hardware used in resource constrained sensor and IoT networks. Additionally, the ability of independent protocol learning by the nodes makes the system robust and adaptive to the changes in network and traffic conditions. It is shown that the nodes can be trained to learn to avoid collisions, and to achieve network throughputs that are comparable to ALOHA based access protocols in sensor and IoT networks with simplest transceiver hardware. It is also shown that using RL, it is feasible to synthesize access protocols that can sustain network throughput at high traffic loads, which is not feasible in the ALOHA-based systems. The ability of the system to provide throughput fairness under network and traffic heterogeneities are also experimentally demonstrated. 	
Implementation strategies in phonopy and phono3py	http://arxiv.org/abs/2301.05784v1	2023-01-13T23:06:41Z	2023-01-13T23:06:41Z	  Scientific simulation codes are public property sustained by the community. Modern technology allows anyone to join scientific software projects, from anywhere, remotely via the internet.   The phonopy and phono3py codes are widely used open source phonon calculation codes. This review describes a collection of computational methods and techniques as implemented in these codes and shows their implementation strategies as a whole, aiming to be useful for the community. Some of the techniques presented here are not limited to phonon calculations and may therefore be useful in other area of condensed matter physics. 	
"Evaluating the sustainability of a de facto harvest strategy for British
  Columbia's Spot Prawn (Pandalus platyceros) fishery in the presence of
  environmental drivers of recruitment and hyperstable catch rates"	http://arxiv.org/abs/2301.05782v1	2023-01-13T22:56:21Z	2023-01-13T22:56:21Z	  The Spot Prawn trap fishery off the west coast of British Columbia (BC) is managed using a fixed escapement strategy that aims to prevent recruitment overfishing while maximizing expected long-term yield by closing the fishery when the catch rate of spawners, projected to the following spring, drops below 1.7 spawners per trap (the de jure rule). We develop a management strategy evaluation framework for BC's Spot Prawn fishery that examines the expected performance of the management procedure implemented in practice (the de facto rule), which was significantly more conservative than the de jure rule, usually closing the fishery when spawner catch rates were at least twice as high as specified by the de jure rule. Simulations indicate that the de facto spawner index rule using average empirical March 31st targets from 2000 to 2019 maintains most stocks near or above 0.8 BMSY with or without accounting for environmental effects and/or increasing future SST on recruitment. Abundance indices were found to be strongly hyperstable, with fishing efficiency 1.5 to 3.0 times higher under low biomass than high biomass. 	
"Emergence of Urban Heat Traps from the Intersection of Human Mobility
  and Heat Hazard Exposure in Cities"	http://arxiv.org/abs/2301.05641v2	2023-01-16T02:42:14Z	2023-01-13T16:30:08Z	  Understanding the relationship between spatial structures of cities and environmental hazard exposures (such as urban heat) is essential for urban health and sustainability planning. However, a critical knowledge gap exists in terms of the extent to which socio-spatial networks shaped by human mobility exacerbate or alleviate urban heat exposures of populations in cities. In this study, we utilize location-based data to construct human mobility networks in twenty metropolitan areas in the U.S. The human mobility networks are analyzed in conjunction with the urban heat characteristics of spatial areas. We identify areas with high and low urban heat exposure and evaluate visitation patterns of populations residing in high and low urban heat areas to other spatial areas with similar and dissimilar urban heat exposure. The results reveal the presence of urban heat traps in the majority of the studied metropolitan areas in which populations residing in high heat exposure areas primarily visit areas with high heat exposure. The results also show a small percentage of human mobility to produce urban heat escalate (visitations from low heat areas to high heat areas) and heat escapes (movements from high heat areas to low heat areas). The findings from this study provide a better understanding of urban heat exposure in cities based on patterns of human mobility. These finding contribute to a broader understanding of the intersection of human network dynamics and environmental hazard exposures in cities to inform more integrated urban design and planning to promote health and sustainability. 	
"Second sound resonators and tweezers as vorticity or velocity probes :
  fabrication, model and method"	http://arxiv.org/abs/2301.05519v1	2023-01-13T12:42:00Z	2023-01-13T12:42:00Z	  An analytical model of second-sound resonators with open-cavity is presented and validated against simulations and experiments in superfluid helium using a new design of resonators reaching unprecedented resolution. The model accounts for diffraction, geometrical misalignments and flow through the cavity. It is validated against simulations and experiments using cavities of aspect ratio of the order of unity operated up to their 20$^{th}$ resonance in superfluid helium. An important result is that resonators can be optimized to selectively sense the quantum vortex density carried by the throughflow -- as customarily done in the literature -- or alternatively to sense the mean velocity of this throughflow. Two velocity probing methods are proposed, one taking advantage of geometrical misalignements between the tweezers plates, and another one by driving the resonator non-linearly, beyond a threshold entailing the self-sustainment of a vortex tangle within the cavity.After reviewing several methods, a new mathematical treatment of the resonant signal is proposed, to properly separate the quantum vorticity from the parasitic signals arising for instance from temperature and pressure drift. This so-called \emph{elliptic method} consists in a geometrical projection of the resonance in the inverse complex plane. Its strength is illustrated over a broad range of operating conditions.The resonator model and the elliptic method are applied to characterize a new design of second-sound resonator of high resolution thanks to miniaturization and design optimization. When immersed in a superfluid flow, these so-called \emph{ second-sound tweezers} provide time-space resolved information like classical local probes in turbulence, here down to sub-millimeter and sub-millisecond scales. The principle, design and micro-fabrication of second sound tweezers are detailed, as well as their potential for the exploration of quantum turbulence 	
"Doping control of magnetism and emergent electromagnetic induction in
  high-temperature helimagnets"	http://arxiv.org/abs/2301.05449v1	2023-01-13T09:14:13Z	2023-01-13T09:14:13Z	  Ac current-driven motions of spiral spin textures can give rise to emergent electric fields acting on conduction electrons. This in turn leads to the emergent electromagnetic induction effect which may realize quantum inductor elements of micrometer size. ${\rm YMn}_{6}{\rm Sn}_{6}$ is a helimagnet with a short helical period (2-3 nm) that shows this type of emergent inductance beyond room temperature. To identify the optimized materials conditions for ${\rm YMn}_{6}{\rm Sn}_{6}$-type room-temperature emergent inductors, we have investigated emergent electromagnetic inductance (EEMI) as the magnetism is modified through systematic partial substitution of Y by Tb. By small angle neutron scattering and inductance measurements, we have revealed that the pinning effect on the spin-helix translational mode by Tb doping selectively and largely suppresses the negative component of EEMI, while sustaining the positive inductance arising from the spin tilting mode. We also find that in addition to the spin helix, even the spin-collinear antiferromagnetic structure can host the positive EEMI due to thermally enhanced spin fluctuations. The present study highlights the facile control of both the magnitude and sign of EEMI beyond room temperature, and thus suggests a route to expand the range of emergent inductor candidate materials. 	
"Running vacuum in QFT in FLRW spacetime: The dynamics of $_{\rm
  vac}(H)$ from the quantized matter fields"	http://arxiv.org/abs/2301.05205v2	2023-02-09T09:13:09Z	2023-01-12T18:42:01Z	"  Phenomenological work in the last few years has provided significant support to the idea that the vacuum energy density (VED) is a running quantity with the cosmological evolution and that this running helps to alleviate the cosmological tensions afflicting the $\Lambda$CDM. On the theoretical side, recent devoted studies have shown that the properly renormalized $\rho_{\rm vac}$ in QFT in FLRW spacetime adopts the ""running vacuum model"" (RVM) form. While in three previous studies by two of us (CMP and JSP) such computations focused solely on scalar fields non-minimally coupled to gravity, in the present work we compute the spin-$1/2$ fermionic contributions and combine them both. The calculation is performed using a new version of the adiabatic renormalization procedure based on subtracting the UV divergences at an off-shell renormalization point $M$. The quantum scaling of $\rho_{\rm vac}$ with $M$ turns into cosmic evolution with the Hubble rate, $H$. As a result the ""cosmological constant"" $\Lambda$ appears in our framework as the nearly sustained value of $8\pi G(H)\rho_{\rm vac}(H)$ around (any) given epoch $H$, where $G(H)$ is the gravitational coupling, which is also running, although very mildly (logarithmically). We find that the VED evolution at present reads $\delta \rho_{\rm vac}(H)\sim \nu_{\rm eff}\, m_{\rm Pl}^2 \left(H^2-H_0^2 \right)\ (|\nu_{\rm eff}|\ll 1)$. The coefficient $\nu_{\rm eff}$ receives contributions from all the quantized fields, bosons and fermions. Remarkably, there also exist higher powers ${\cal O}(H^{6})$ which can trigger inflation in the early universe. Finally, the equation of state (EoS) of the vacuum receives also quantum corrections from bosons and fermion fields, shifting its value from -1. The striking consequence is that the EoS of the quantum vacuum may nowadays effectively appears as quintessence. "	
"Observability of silicates in volatile atmospheres of super-Earths and
  sub-Neptunes"	http://arxiv.org/abs/2301.05190v3	2023-01-30T10:59:31Z	2023-01-12T18:18:11Z	  Many of the confirmed short period super-Earths and smaller sub-Neptunes are sufficiently irradiated for the surface silicates to be sustained in a long-lasting molten state. While there is no direct evidence of magma ocean influence on exoplanets, theory suggests that due to outgassing and diverse evolution paths, a wide range of resulting atmospheric compositions should be possible. Atmospheric contamination caused by the outgassing of the underlying magma ocean is potentially detectable using low resolution spectroscopy. The James Webb Space Telescope provides the necessary spectral coverage and sensitivity to characterise smaller planets, including lava worlds. In this light, we assess observability of outgassed silicates submerged in volatile atmospheres on the edge of the evaporation valley. By placing a hypothetical 2 R${_\oplus}$ planet around a Sun-like star, we self-consistently model, in 1-D, a wide range of potential atmospheric compositions, including thermal structure and outgassing. We focus on atmospheres rich in H, C and N. We assess diverse chemistry of silicates and volatiles, and what features of outgassed species could be detected via emission spectroscopy using MIRI LRS. Results indicate that even for substantial volatile envelopes, strong in infrared opacity, the presence of silicates causes deep thermal inversions, affecting emission. Similar to pure lava worlds, SiO remains the only outgassed species with major infrared, 5 and 9 \textmu m, bands. However, even a small amount of volatiles, especially of H2O and H-, may hinder its observability. We also find that the C/O ratio plays a large role in determining the abundance of SiO. Detecting SiO on a strongly irradiated planet could indicate an atmosphere with high metallicity and a low C/O ratio, which may be a result of efficient interaction between the atmosphere and the underlying melt. 	
"Incorporating time-dependent demand patterns in the optimal location of
  capacitated charging stations"	http://arxiv.org/abs/2301.05077v1	2023-01-12T15:21:43Z	2023-01-12T15:21:43Z	  A massive use of electric vehicles is nowadays considered to be a key element of a sustainable transportation policy and the availability of charging stations is a crucial issue for their extensive use. Charging stations in an urban area have to be deployed in such a way that they can satisfy a demand that may dramatically vary in space and time. In this paper we present an optimization model for the location of charging stations that takes into account the main specific features of the problem, in particular the different charging technologies, and their associated service time, and the fact that the demand depends on space and time. To measure the importance of incorporating the time dependence in an optimization model, we also present a simpler model that extends a classical location model and does not include the temporal dimension. A worst-case analysis and extensive computational experiments show that ignoring the temporal dimension of the problem may lead to a substantial amount of unsatisfied demand. 	
Gradient TRIX	http://arxiv.org/abs/2301.05073v1	2023-01-12T15:17:46Z	2023-01-12T15:17:46Z	  Gradient clock synchronization (GCS) algorithms minimize the worst-case clock offset between the nodes in a distributed network of diameter $D$ and size $n$. They achieve optimal offsets of $\Theta(\log D)$ locally, i.e. between adjacent nodes as shown by Lenzen et al., and $\Theta(D)$ globally as shown by Biaz and Welch. As demonstrated in the work of Bund et al., this is a highly promising approach for improved clocking schemes for large-scale synchronous Systems-on-Chip (SoC). Unfortunately, in large systems, faults hinder their practical use. State of the art fault-tolerant, as presented by Bund et al., has a drawback that is fatal in this setting: It relies on node and edge replication. For $f=1$, this translates to at least $16$-fold edge replication and high degree nodes, far from the optimum of $2f+1=3$ for tolerating up to $f$ faulty neighbors.   In this work, we present a self-stabilizing GCS algorithm for a grid-like directed graph with optimal node in- and out-degrees of $3$ that tolerates $1$ faulty in-neighbor. If nodes fail with independent probability $p\in o(n^{-1/2})$, it achieves asymptotically optimal local skew of $\Theta(\log D)$ with probability $1-o(1)$; this holds under general worst-case assumptions on link delay and clock speed variations, provided they change slowly relative to the speed of the system. The failure probability is the largest possible ensuring that with probabity $1-o(1)$ for each node at most one in-neighbor fails. As modern hardware is clocked at gigahertz speeds and the algorithm can simultaneously sustain a constant number of arbitrary changes due to faults in each clock cycle, this results in sufficient robustness to dramatically increase the size of reliable synchronously clocked SoCs. 	
Desynchronizing two oscillators while stimulating and observing only one	http://arxiv.org/abs/2301.04973v1	2023-01-12T12:29:15Z	2023-01-12T12:29:15Z	  Synchronization of two or more self-sustained oscillators is a well-known and studied phenomenon, appearing both in natural and designed systems. In some cases, the synchronized state is undesired, and the aim is to destroy synchrony by external intervention. In this paper, we focus on desynchronizing two self-sustained oscillators by short pulses delivered to the system in a phase-specific manner. We analyze a non-trivial case when we cannot access both oscillators but stimulate only one. The following restriction is that we can monitor only one unit, be it a stimulated or non-stimulated one. First, we use a system of two coupled Rayleigh oscillators to demonstrate how a loss of synchrony can be induced by stimulating a unit once per period at a specific phase and detected by observing consecutive inter-pulse durations. Next, we exploit the phase approximation to develop a rigorous theory formulating the problem in terms of a map. We derive exact expressions for the phase -- isostable coordinates of this coupled system and show a relation between the phase and isostable response curves to the phase response curve of the uncoupled oscillator. Finally, we demonstrate how to obtain phase response information from the system using time series and discuss the differences between observing the stimulated and unstimulated oscillator. 	
"A review of Smart Contract Blockchain Based on Multi-Criteria Analysis:
  Challenges and Motivations"	http://arxiv.org/abs/2302.08496v1	2023-01-12T10:48:32Z	2023-01-12T10:48:32Z	  A smart contract is a digital program of transaction protocol (rules of contract) based on the consensus architecture of blockchain. Smart contracts with Blockchain are modern technologies that have gained enormous attention in scientific and practical applications. A smart contract is the central aspect of a blockchain that facilitates blockchain as a platform outside the cryptocurrency spectrum. The development of blockchain technology, with a focus on smart contracts, has advanced significantly in recent years. However research on the smart contract idea has weaknesses in the implementation sectors based on a decentralized network that shares an identical state. This paper extensively reviews smart contracts based on multi criteria analysis challenges and motivations. Therefore, implementing blockchain in multi-criteria research is required to increase the efficiency of interaction between users via supporting information exchange with high trust. Implementing blockchain in the multi-criteria analysis is necessary to increase the efficiency of interaction between users via supporting information exchange and with high confidence, detecting malfunctioning, helping users with performance issues, reaching a consensus, deploying distributed solutions and allocating plans, tasks and joint missions. The smart contract with decision-making performance, planning and execution improves the implementation based on efficiency, sustainability and management.   Furthermore the uncertainty and supply chain performance lead to improved users confidence in offering new solutions in exchange for problems in smart contacts. Evaluation includes code analysis and performance while development performance can be under development. 	
"Exit options sustain altruistic punishment and decrease the second-order
  free-riders, but it is not a panacea"	http://arxiv.org/abs/2301.04849v1	2023-01-12T07:24:05Z	2023-01-12T07:24:05Z	  The emergence and maintenance of altruistic punishment remains an open question and this conundrum is shared across diverse fields. In this study, we evaluated the evolution of altruistic punishment in a two-stage prisoner's dilemma game in which cooperators and defectors interact with another two actors called altruistic punishers and exiters. Traditionally cooperators and defectors, in the first stage, choose to cooperate and defect with their opponent, respectively, but they do not punish in the second stage; the altruistic punishers cooperate in the first stage and punish defectors in the second stage, and the exiters who simply exit the game in favor of a small payoff. We found that exiters did not provide any substantial assistance to altruistic punishment in well-mixed populations, they destabilize defection and finally replace them. In the finite population, although the exit option enables the coexistence of altruistic punishers, defectors, and exiters through cyclic dominance. Altruistic punishers never dominate the finite population and the exit option provides another alternative cyclic dominance route for the emergence of non-punishing cooperators. In networked populations, however, adding the exit option allows for the establishment of altruistic punishment, and enables the coexistence of altruistic punishers, defectors, and exiters through cyclic dominance. However, this type of cyclic dominance is not always stable, with adjustments to the exit payoff, this type of cyclic dominance is replaced by the cyclic dominance of non-punishing cooperators, defectors, and exiters or a bi-stable state between these two types of cyclic dominance. Our results indicate that although the exit option can help explain altruistic punishment, it is certainly not a panacea. 	
"A Deployment-First Methodology to Mechanism Design and Refinement in
  Distributed Systems"	http://arxiv.org/abs/2301.04508v1	2023-01-11T15:13:42Z	2023-01-11T15:13:42Z	  Catalyzed by the popularity of blockchain technology, there has recently been a renewed interest in the design, implementation and evaluation of decentralized systems. Most of these systems are intended to be deployed at scale and in heterogeneous environments with real users and unpredictable workloads. Nevertheless, most research in this field evaluates such systems in controlled environments that poorly reflect the complex conditions of real-world environments. In this work, we argue that deployment is crucial to understanding decentralized mechanisms in a real-world environment and an enabler to building more robust and sustainable systems. We highlight the merits of deployment by comparing this approach with other experimental setups and show how our lab applied a deployment-first methodology. We then outline how we use Tribler, our peer-to-peer file-sharing application, to deploy and monitor decentralized mechanisms at scale. We illustrate the application of our methodology by describing a deployment trial in experimental tokenomics. Finally, we summarize four lessons learned from multiple deployment trials where we applied our methodology. 	
"The SeaLiT Ontology -- An Extension of CIDOC-CRM for the Modeling and
  Integration of Maritime History Information"	http://arxiv.org/abs/2301.04493v1	2023-01-11T14:37:32Z	2023-01-11T14:37:32Z	  We describe the construction and use of the SeaLiT Ontology, an extension of the ISO standard CIDOC-CRM for the modelling and integration of maritime history information. The ontology has been developed gradually, following a bottom-up approach that required the analysis of large amounts of real primary data (archival material) as well as knowledge and validation by domain experts (maritime historians). We present the specification of the ontology, RDFS and OWL implementations, as well as knowledge graphs that make use of this data model for integrating information originating from a large and diverse set of archival documents, such as crew lists, sailors registers, naval ship registers and payrolls. We also describe an application that operates over these knowledge graphs and which supports historians in exploring and quantitatively analysing the integrated data through a user-friendly interface. Finally, we discuss aspects related to the use, evolution and sustainability of the ontology. 	
"An Efficient Approach to the Online Multi-Agent Path Finding Problem by
  Using Sustainable Information"	http://arxiv.org/abs/2301.04446v1	2023-01-11T13:04:35Z	2023-01-11T13:04:35Z	  Multi-agent path finding (MAPF) is the problem of moving agents to the goal vertex without collision. In the online MAPF problem, new agents may be added to the environment at any time, and the current agents have no information about future agents. The inability of existing online methods to reuse previous planning contexts results in redundant computation and reduces algorithm efficiency. Hence, we propose a three-level approach to solve online MAPF utilizing sustainable information, which can decrease its redundant calculations. The high-level solver, the Sustainable Replan algorithm (SR), manages the planning context and simulates the environment. The middle-level solver, the Sustainable Conflict-Based Search algorithm (SCBS), builds a conflict tree and maintains the planning context. The low-level solver, the Sustainable Reverse Safe Interval Path Planning algorithm (SRSIPP), is an efficient single-agent solver that uses previous planning context to reduce duplicate calculations. Experiments show that our proposed method has significant improvement in terms of computational efficiency. In one of the test scenarios, our algorithm can be 1.48 times faster than SOTA on average under different agent number settings. 	
"Ultrafast two-colour X-ray emission spectroscopy reveals excited state
  landscape in a base metal dyad"	http://arxiv.org/abs/2301.04425v1	2023-01-11T12:04:16Z	2023-01-11T12:04:16Z	  Effective photoinduced charge transfer makes molecular bimetallic assemblies attractive for applications as active light induced proton reduction systems. For a more sustainable future, development of competitive base metal dyads is mandatory. However, the electron transfer mechanisms from the photosensitizer to the proton reduction catalyst in base metal dyads remain so far unexplored. We study a Fe-Co dyad that exhibits photocatalytic H2 production activity using femtosecond X-ray emission spectroscopy, complemented by ultrafast optical spectroscopy and theoretical time-dependent DFT calculations, to understand the electronic and structural dynamics after photoexcitation and during the subsequent charge transfer process from the FeII photosensitizer to the cobaloxime catalyst. Using this novel approach, the simultaneous measurement of the transient Kalpha X-ray emission at the iron and cobalt K-edges in a two-colour experiment is enabled making it possible to correlate the excited state dynamics to the electron transfer processes. The methodology, therefore, provides a clear and direct spectroscopic evidence of the Fe->Co electron transfer responsible for the proton reduction activity. 	
"Dependence of simulated radiation damage on crystal structure and atomic
  misfit in metals"	http://arxiv.org/abs/2301.04303v1	2023-01-11T04:36:05Z	2023-01-11T04:36:05Z	  This study investigates radiation damage in three metals in the low temperature and high radiant flux regime using molecular dynamics and a Frenkel pair accumulation method to simulate up to $2.0$ displacements per atom. The metals considered include Fe, equiatomic CrCoNi, and a fictitious metal with identical bulk properties to the CrCoNi composed of a single atom type referred to as an A-atom. CrCoNi is found to sustain higher concentrations of dislocations than either the Fe or A-atom systems and more stacking faults than the A-atom system. The results suggest that the concentration of vacancies and interstitials are substantially higher for the CrCoNi than the A-atom system, perhaps reflecting that the recombination radius is smaller in CrCoNi due to the roughened potential energy landscape. A model that partitions the major contributions from defects to the stored energy is described, and serves to highlight a general need for higher fidelity approaches to point defect identification. 	
"Near-optimal Online Algorithms for Joint Pricing and Scheduling in EV
  Charging Networks"	http://arxiv.org/abs/2301.06087v1	2023-01-11T03:40:44Z	2023-01-11T03:40:44Z	  With the rapid acceleration of transportation electrification, public charging stations are becoming vital infrastructure in a smart sustainable city to provide on-demand electric vehicle (EV) charging services. As more consumers seek to utilize public charging services, the pricing and scheduling of such services will become vital, complementary tools to mediate competition for charging resources. However, determining the right prices to charge is difficult due to the online nature of EV arrivals. This paper studies a joint pricing and scheduling problem for the operator of EV charging networks with limited charging capacity and time-varying energy cost. Upon receiving a charging request, the operator offers a price, and the EV decides whether to admit the offer based on its own value and the posted price. The operator then schedules the real-time charging process to satisfy the charging request if the EV admits the offer. We propose an online pricing algorithm that can determine the posted price and EV charging schedule to maximize social welfare, i.e., the total value of EVs minus the energy cost of charging stations. Theoretically, we prove the devised algorithm can achieve the order-optimal competitive ratio under the competitive analysis framework. Practically, we show the empirical performance of our algorithm outperforms other benchmark algorithms in experiments using real EV charging data. 	
Data Distillation: A Survey	http://arxiv.org/abs/2301.04272v1	2023-01-11T02:25:10Z	2023-01-11T02:25:10Z	  The popularity of deep learning has led to the curation of a vast number of massive and multifarious datasets. Despite having close-to-human performance on individual tasks, training parameter-hungry models on large datasets poses multi-faceted problems such as (a) high model-training time; (b) slow research iteration; and (c) poor eco-sustainability. As an alternative, data distillation approaches aim to synthesize terse data summaries, which can serve as effective drop-in replacements of the original dataset for scenarios like model training, inference, architecture search, etc. In this survey, we present a formal framework for data distillation, along with providing a detailed taxonomy of existing approaches. Additionally, we cover data distillation approaches for different data modalities, namely images, graphs, and user-item interactions (recommender systems), while also identifying current challenges and future research directions. 	
TERRA: Beam Management for Outdoor mm-Wave Networks	http://arxiv.org/abs/2301.04229v1	2023-01-10T22:30:46Z	2023-01-10T22:30:46Z	  mm-Wave communication systems use narrow directional beams due to the spectrum's characteristic nature: high path and penetration losses. The mobile and the base station primarily employ beams in line of sight (LoS) direction and when needed in non-line of sight direction. Beam management protocol adapts the base station and mobile side beam direction during user mobility and to sustain the link during blockages. To avoid outage in transient pedestrian blockage of the LoS path, the mobile uses reflected or NLoS path available in indoor environments. Reflected paths can sustain time synchronization and maintain connectivity during temporary blockages. In outdoor environments, such reflections may not be available and prior work relied on dense base station deployment or co-ordinated multi-point access to address outage problem.   Instead of dense and hence cost-intensive network deployments, we found experimentally that the mobile can capitalize on ground reflection. We developed TERRA protocol to effectively handle mobile side beam direction during transient blockage events. TERRA avoids outage during pedestrian blockages 84.5 $\%$ of the time in outdoor environments on concrete and gravel surfaces. TERRA also enables the mobile to perform a soft handover to a reserve neighbor base station in the event of a permanent blockage, without requiring any side information, unlike the existing works. Evaluations show that TERRA maintains received signal strength close to the optimal solution while keeping track of the neighbor base station. 	
"Integrated Analysis of Human-compatible Control for Traffic Flow
  Stability"	http://arxiv.org/abs/2301.04043v1	2023-01-10T15:48:01Z	2023-01-10T15:48:01Z	  Autonomous vehicles (AVs) enable more efficient and sustainable transportation systems. Ample studies have shown that controlling a small fraction of AVs can smooth traffic flow and mitigate traffic congestion. However, deploying AVs to real-world systems is challenging due to safety and cost concerns. An alternative approach deployable in the imminent future is $\textit{human-compatible control}$, where human drivers are guided by real-time instructions to stabilize the traffic. To respect drivers' cognitive load, a class of $\textit{piecewise-constant policies}$ is considered, where periodic instructions are given every $\Delta$ seconds to human drivers, who hold the instructed action constant until the next instruction. While previous works separately consider stability analysis for continuous AV control or the extent to which human drivers can follow guidance, this article is the first to consider an integrated theoretical analysis, directly relating the guidance provided to the human drivers to the traffic flow stability outcome. Casting the problem into the Lyapunov stability framework, sufficient conditions are derived for piecewise-constant controls with hold length $\Delta$ to stabilize the system. Numerical simulations reveal that the theoretical analysis closely matches simulated results, and, importantly, classical stability concepts are insufficient for explaining hold lengths. Additionally, the theoretical and empirical analyses can be leveraged to derive improved controllers with greater maximum hold length. 	
"Fountain-driven gas accretion feeding star formation over the disc of
  NGC 2403"	http://arxiv.org/abs/2301.03614v1	2023-01-09T19:00:02Z	2023-01-09T19:00:02Z	  We use a dynamical model of galactic fountain to study the neutral extraplanar gas (EPG) in the nearby spiral galaxy NGC 2403. We have modelled the EPG as a combination of material ejected from the disc by stellar feedback (i.e. galactic fountain) and gas accreting from the inner circumgalactic medium (CGM). This accretion is expected to occur because of cooling/condensation of the hot CGM (corona) triggered by the fountain. Our dynamical model reproduces the distribution and kinematics of the EPG H$\mathrm{\scriptsize{I}}$ emission in NGC 2403 remarkably well and suggests a total EPG mass of $4.7^{+1.2}_{-0.9}\times10^8\mathrm{M}_\odot$, with a typical scale height of around 1 kpc and a vertical gradient of the rotation velocity of $-10.0\pm2.7\,\mathrm{km\,s^{-1}\,kpc^{-1}}$. The best-fitting model requires a characteristic outflow velocity of $50\pm10\,\mathrm{km\,s^{-1}}$. The outflowing gas starts out mostly ionised and only becomes neutral later in the trajectory. The accretion rate from the condensation of the inner hot CGM inferred by the model is 0.8$\,\mathrm{M}_\odot\,\mathrm{yr}^{-1}$, approximately equal to the star formation rate in this galaxy (0.6$\,\mathrm{M}_\odot\,\mathrm{yr}^{-1}$). We show that the accretion profile, which peaks at a radius of about 4.5$\,$kpc, predicts a disc growth rate compatible with the observed value. Our results indicate that fountain-driven corona condensation is a likely mechanism to sustain star formation as well as the disc inside-out growth in local disc galaxies. 	
"Redox state and interior structure control on the long-term habitability
  of stagnant-lid planets"	http://arxiv.org/abs/2301.03466v1	2023-01-09T16:01:55Z	2023-01-09T16:01:55Z	"  A major goal in the search for extraterrestrial life is the detection of liquid water on the surface of exoplanets. On terrestrial planets, volcanic outgassing is a significant source of atmospheric and surface water and a major contributor to the long-term evolution of the atmosphere. The rate of volcanism depends on the interior evolution and on numerous feedback processes between atmosphere and interior, which continuously shape atmospheric composition, pressure, and temperature. We present the results of a comprehensive 1D model of the coupled evolution of the interior and atmosphere of rocky exoplanets that combines central feedback processes between these two reservoirs. We carried out more than 280,000 simulations over a wide range of mantle redox states and volatile content, planetary masses, interior structures and orbital distances in order to robustly assess the emergence, accumulation and preservation of surface water on rocky planets. To establish a conservative baseline of which types of planets can outgas and sustain water on their surface, we focus here on stagnant-lid planets. We find that only a narrow range of the mantle redox state around the iron-w\""ustite buffer allows forming atmospheres that lead to long-term habitable conditions. At oxidizing conditions similar to those of the Earth's mantle, most stagnant-lid planets transition into a runaway greenhouse regime akin to Venus due to strong CO$_2$ outgassing. At more reducing conditions, the amount of outgassed greenhouse gases is often too low to keep surface water from freezing. In addition, Mercury-like planets with large metallic cores are able to sustain habitable conditions at an extended range of orbital distances as a result of lower volcanic activity. "	
"VIPER: A Plasma Wave Detection Instrument onboard Indian Venus Orbiter
  Spacecraft"	http://arxiv.org/abs/2301.03163v1	2023-01-09T04:21:09Z	2023-01-09T04:21:09Z	  Plasma waves are observed in almost all the solar system objects. The planetary ionospheres are capable of sustaining plasma waves which are observed there and play an important role in the ionospheric dynamics. Venus does not possess a global magnetic field unlike Earth. The solar EUV radiation ionizes the neutrals and generates a plasma environment around Venus which can sustain plasma waves. Very few attempts are made to observe all plasma waves that can exist around Venus and that too with instruments having a limited dynamic range such as with Pioneer Venus Orbiter and Venus Express. However, there are some other plasma waves which can exist around Venus but are yet to be observed. 	
AI Maintenance: A Robustness Perspective	http://arxiv.org/abs/2301.03052v1	2023-01-08T15:02:38Z	2023-01-08T15:02:38Z	  With the advancements in machine learning (ML) methods and compute resources, artificial intelligence (AI) empowered systems are becoming a prevailing technology. However, current AI technology such as deep learning is not flawless. The significantly increased model complexity and data scale incur intensified challenges when lacking trustworthiness and transparency, which could create new risks and negative impacts. In this paper, we carve out AI maintenance from the robustness perspective. We start by introducing some highlighted robustness challenges in the AI lifecycle and motivating AI maintenance by making analogies to car maintenance. We then propose an AI model inspection framework to detect and mitigate robustness risks. We also draw inspiration from vehicle autonomy to define the levels of AI robustness automation. Our proposal for AI maintenance facilitates robustness assessment, status tracking, risk scanning, model hardening, and regulation throughout the AI lifecycle, which is an essential milestone toward building sustainable and trustworthy AI ecosystems. 	
"Exploring the formation of ""harmony with diversity"" state within a
  attraction-repulsion model framework"	http://arxiv.org/abs/2301.03042v3	2023-01-12T06:57:31Z	2023-01-08T13:34:31Z	"  As one widely-existed state, the formation of ""harmony with diversity"", where individuals freely express various viewpoints to a certain extent to sustain integration of diversity and at the same time shared values ensure social coherence to avoid ideological split, still remains unclear, as well as its unique dynamic features. Since a general model framework to generate the desired state is still lacked. To address this issue, we develop an attraction-repulsion model based on the general simple assumption that individuals tend to either reach an agreement with shared opinions or to amplify difference from others with distant opinions, which allows us to take account into the three core parameters: interaction strength, individuals' susceptibility and tolerance to others' opinions. We are concerned with the effect of not only time-varying topology but also fixed interactions imposed by static social network, where the tasks of heterogeneous individuals' attributes are also performed. Remarkably, the simple model rules successfully generate state of ``harmony with diversity"" in addition to global neutral consensus and polariztion, along with three different transitions and the triple points, regardless of whether the interactions are time-varying or fixed. We find that sufficient susceptibility, intermediate interaction strength and high tolerance can benefit a balance between repulsive and attractive forces, further leading to the emergence of ""harmony with diversity"". However, fixed interactions can introduce cluster-level self-reinforced mechanism which can unexpectedly promote polarization. Heterogeneous susceptibility or tolerance turns out to be a inhibiting factor, which should be avoided. A method to identify the phase boundaries through computing the maximum susceptibility of opinion entropy, allows us to build phase diagrams and to locate where the triple points are. "	
"MangngalApp -- An integrated package of technology for COVID-19 response
  and rural development: Acceptability and usability using TAM"	http://arxiv.org/abs/2301.02893v1	2023-01-07T16:58:42Z	2023-01-07T16:58:42Z	  The COVID19 pandemic has challenged universities and organizations to devise mechanisms to uplift the well-being and welfare of people and communities. In response, the design and development of an integrated package of technologies, MangngalApp -- A web-based portal and mobile responsive application for rural development served as an opportunity. It showcases different packets of technologies that were outputs of R&D in the field of fisheries and aqua-culture, innovations that were IP-protected, and technologies that harness locally available resources for post-harvest development and aiding in sustaining growth and development in the communities. This paper focused on the usability and acceptability of the MangngalApp implementing a descriptive research design using the Technology Acceptance Model or TAM and ISO 25010 software quality standards. Constrained by government health restrictions due to COVID-19, a Google form-based questionnaire was forwarded to consented participants via an email with the attached consent and evaluation form. Results revealed that the MangngalApp was found to be very acceptable and usable, and compliant to ISO 25010 software quality characteristics to the higher extent. From the results, it is concluded that the developed MangngalApp will be a usable and responsive technology that aids to rural development especially among target users: fishers, gatherers, processors, traders, and farmers. Considering compatibility and usefulness, the MangngalApp is expected to provide greater social development in the community. 	
Perceptual-Neural-Physical Sound Matching	http://arxiv.org/abs/2301.02886v2	2023-03-13T17:16:37Z	2023-01-07T16:17:48Z	"  Sound matching algorithms seek to approximate a target waveform by parametric audio synthesis. Deep neural networks have achieved promising results in matching sustained harmonic tones. However, the task is more challenging when targets are nonstationary and inharmonic, e.g., percussion. We attribute this problem to the inadequacy of loss function. On one hand, mean square error in the parametric domain, known as ""P-loss"", is simple and fast but fails to accommodate the differing perceptual significance of each parameter. On the other hand, mean square error in the spectrotemporal domain, known as ""spectral loss"", is perceptually motivated and serves in differentiable digital signal processing (DDSP). Yet, spectral loss is a poor predictor of pitch intervals and its gradient may be computationally expensive; hence a slow convergence. Against this conundrum, we present Perceptual-Neural-Physical loss (PNP). PNP is the optimal quadratic approximation of spectral loss while being as fast as P-loss during training. We instantiate PNP with physical modeling synthesis as decoder and joint time-frequency scattering transform (JTFS) as spectral representation. We demonstrate its potential on matching synthetic drum sounds in comparison with other loss functions. "	
"Cognitive Endurance, Talent Selection, and the Labor Market Returns to
  Human Capital"	http://arxiv.org/abs/2301.02575v1	2023-01-06T16:08:35Z	2023-01-06T16:08:35Z	  Cognitive endurance -- the ability to sustain performance on a cognitively-demanding task over time -- is thought to be a crucial productivity determinant. However, a lack of data on this variable has limited researchers' ability to understand its role for success in college and the labor market. This paper uses college-admission-exam records from 15 million Brazilian high school students to measure cognitive endurance based on changes in performance throughout the exam. By exploiting exogenous variation in the order of exam questions, I show that students are 7.1 percentage points more likely to correctly answer a given question when it appears at the beginning of the day versus the end (relative to a sample mean of 34.3%). I develop a method to decompose test scores into fatigue-adjusted ability and cognitive endurance. I then merge these measures into a higher-education census and the earnings records of the universe of Brazilian formal-sector workers to quantify the association between endurance and long-run outcomes. I find that cognitive endurance has a statistically and economically significant wage return. Controlling for fatigue-adjusted ability and other student characteristics, a one-standard-deviation higher endurance predicts a 5.4% wage increase. This wage return to endurance is sizable, equivalent to a third of the wage return to ability. I also document positive associations between endurance and college attendance, college quality, college graduation, firm quality, and other outcomes. Finally, I show how systematic differences in endurance across students interact with the exam design to determine the sorting of students to colleges. I discuss the implications of these findings for the use of cognitive assessments for talent selection and investments in interventions that build cognitive endurance. 	
"Microphysically modified magnetosonic modes in collisionless,
  high-$$ plasmas"	http://arxiv.org/abs/2301.02273v1	2023-01-05T19:19:39Z	2023-01-05T19:19:39Z	  With the support of hybrid-kinetic simulations and analytic theory, we describe the nonlinear behaviour of long-wavelength non-propagating (NP) modes and fast magnetosonic waves in high-$\beta$ collisionless plasmas, with particular attention to their excitation of, and reaction to, kinetic micro-instabilities. The perpendicularly pressure balanced polarization of NP modes produces an excess of perpendicular pressure over parallel pressure in regions where the plasma $\beta$ is increased. For mode amplitudes $\delta B/B_0 \gtrsim 0.3$, this excess excites the mirror instability. Particle scattering off these micro-scale mirrors frustrates the nonlinear saturation of transit-time damping, ensuring that large-amplitude NP modes continue their decay to small amplitudes. At asymptotically large wavelengths, we predict that the mirror-induced scattering will be large enough to interrupt transit-time damping entirely, isotropizing the pressure perturbations and morphing the collisionless NP mode into the magnetohydrodynamic (MHD) entropy mode. In fast waves, a fluctuating pressure anisotropy drives both mirror and firehose instabilities when the wave amplitude satisfies $\delta B/B_0 \gtrsim 2\beta^{-1}$. The induced particle scattering leads to delayed shock formation and MHD-like wave dynamics. Taken alongside prior work on self-interrupting Alfv\'en waves and self-sustaining ion-acoustic waves, our results establish a foundation for new theories of electromagnetic turbulence in low-collisionality, high-$\beta$ plasmas such as the intracluster medium, radiatively inefficient accretion flows, and the near-Earth solar wind. 	
A Gaian Habitable Zone	http://arxiv.org/abs/2301.02150v1	2023-01-05T16:52:18Z	2023-01-05T16:52:18Z	  When searching for inhabited exoplanets, understanding the boundaries of the habitable zone around the parent star is key. If life can strongly influence its global environment, then we would expect the boundaries of the habitable zone to be influenced by the presence of life. Here using a simple abstract model of `tangled-ecology' where life can influence a global parameter, labelled as temperature, we investigate the boundaries of the habitable zone of our model system. As with other models of life-climate interactions, the species act to regulate the temperature. However, the system can also experience `punctuations', where the system's state jumps between different equilibria. Despite this, an ensemble of systems still tends to sustain or even improve conditions for life on average, a feature we call Entropic Gaia. The mechanism behind this is sequential selection with memory which is discussed in detail. With this modelling framework we investigate questions about how Gaia can affect and ultimately extend the habitable zone to what we call the Gaian habitable zone. This generates concrete predictions for the size of the habitable zone around stars, suggests directions for future work on the simulation of exoplanets and provides insight into the Gaian bottleneck hypothesis and the habitability/inhabitance paradox. 	
"Improved in-situ characterization of electrochemical interfaces using
  metasurface-driven surface-enhanced infrared absorption spectroscopy"	http://arxiv.org/abs/2301.01993v1	2023-01-05T10:20:53Z	2023-01-05T10:20:53Z	  Electrocatalysis plays a crucial role in realizing the transition towards green energy, driving research directions from hydrogen generation to carbon dioxide reduction. Understanding electrochemical reactions is crucial to improve their efficiency and to bridge the gap toward a sustainable zero-carbon future. Surface-enhanced infrared absorption spectroscopy (SEIRAS) is a suitable method for investigating these processes because it can monitor with chemical specificity the mechanisms of the reactions. However, it remains difficult to detect many relevant aspects of electrochemical reactions such as short-lived intermediates. Here, we develop and experimentally realize an integrated nanophotonic-electrochemical SEIRAS platform for the in situ investigation of molecular signal traces emerging during electrochemical experiments. Specifically, we implement a platinum nano-slot metasurface featuring strongly enhanced electromagnetic near fields and spectrally target it at the weak vibrational bending mode of adsorbed CO at ~2033 cm-1. Crucially, our platinum nano-slot metasurface provides high molecular sensitivity. The resonances can be tuned over a broad range in the mid-infrared spectrum. Compared to conventional unstructured platinum layers, our nanophotonic-electrochemical platform delivers a substantial improvement of the experimentally detected characteristic absorption signals by a factor of 27, enabling the detection of new species with weak signals, fast conversions, or low surface concentrations. By providing a deeper understanding of catalytic reactions, we anticipate our nanophotonic-electrochemical platform to open exciting perspectives for electrochemical SEIRAS, surface-enhanced Raman spectroscopy, and the study of reactions in other fields of chemistry such as photoelectrocatalysis. 	
"Automatic Classification of Single Tree Decay Stages from Combined ALS
  Data and Aerial Imagery using Machine Learning"	http://arxiv.org/abs/2301.01841v1	2023-01-04T22:20:16Z	2023-01-04T22:20:16Z	  Understanding forest health is of great importance for the conservation of the integrity of forest ecosystems. The monitoring of forest health is, therefore, indispensable for the long-term conservation of forests and their sustainable management. In this regard, evaluating the amount and quality of dead wood is of utmost interest as they are favorable indicators of biodiversity. Apparently, remote sensing-based machine learning techniques have proven to be more efficient and sustainable with unprecedented accuracy in forest inventory. However, the application of these techniques is still in its infancy with respect to dead wood mapping. This study investigates for the first time the automatic classification of individual coniferous trees into five decay stages (live, declining, dead, loose bark, and clean) from combined airborne laser scanning (ALS) point clouds and CIR images using three Machine Learning methods - 3D point cloud-based deep learning (PointNet), Convolutional Neural Network (CNN), and Random Forest (RF). All models achieved promising results, reaching overall accuracy (OA) up to 90.9%, 90.6%, and 80.6% for CNN, RF, and PointNet, respectively. The experimental results reveal that the image-based approach notably outperformed the 3D point cloud-based one, while spectral image texture is of the highest relevance to the success of categorizing tree decay. Our models could therefore be used for automatic determination of single tree decay stages and landscape-wide assessment of dead wood amount and quality using modern airborne remote sensing techniques with machine/deep learning. The proposed method can contribute as an important and rigorous tool for monitoring biodiversity in forest ecosystems. 	
"Using Science Education Gateways to improve undergraduate STEM
  education: The QUBES Platform as a case study"	http://arxiv.org/abs/2301.01760v1	2023-01-04T18:51:15Z	2023-01-04T18:51:15Z	"  The QUBES platform was conceived as a ""science education gateway"" and designed to accelerate innovation in undergraduate STEM education. The technical infrastructure was purpose built to provide more equitable access to professional resources, support learning that reflects authentic science, and promote open education practices. Four platform services (OER Library Access; Professional Learning; Partner Support; and Customizable Workspaces) support overlapping faculty user communities, provide multiple points of entry, and enable manifold use case scenarios. The integrated nature of the platform makes it possible to collect, curate, and disseminate a diverse array of reform resources in a scalable and sustainable manner. We believe that the QUBES platform has the capacity to broaden participation in scholarship around teaching and learning and, furthermore, that it can help to lower faculty barriers to the adoption of reform practices. The role of cyberinfrastructure in undergraduate STEM education is generally underappreciated and warrants further exploration. "	
Building Coverage Estimation with Low-resolution Remote Sensing Imagery	http://arxiv.org/abs/2301.01449v2	2023-01-05T04:39:49Z	2023-01-04T05:19:33Z	  Building coverage statistics provide crucial insights into the urbanization, infrastructure, and poverty level of a region, facilitating efforts towards alleviating poverty, building sustainable cities, and allocating infrastructure investments and public service provision. Global mapping of buildings has been made more efficient with the incorporation of deep learning models into the pipeline. However, these models typically rely on high-resolution satellite imagery which are expensive to collect and infrequently updated. As a result, building coverage data are not updated timely especially in developing regions where the built environment is changing quickly. In this paper, we propose a method for estimating building coverage using only publicly available low-resolution satellite imagery that is more frequently updated. We show that having a multi-node quantile regression layer greatly improves the model's spatial and temporal generalization. Our model achieves a coefficient of determination ($R^2$) as high as 0.968 on predicting building coverage in regions of different levels of development around the world. We demonstrate that the proposed model accurately predicts the building coverage from raw input images and generalizes well to unseen countries and continents, suggesting the possibility of estimating global building coverage using only low-resolution remote sensing data. 	
"Identifying Exoplanets with Deep Learning. V. Improved Light Curve
  Classification for TESS Full Frame Image Observations"	http://arxiv.org/abs/2301.01371v1	2023-01-03T21:58:13Z	2023-01-03T21:58:13Z	  The TESS mission produces a large amount of time series data, only a small fraction of which contain detectable exoplanetary transit signals. Deep learning techniques such as neural networks have proved effective at differentiating promising astrophysical eclipsing candidates from other phenomena such as stellar variability and systematic instrumental effects in an efficient, unbiased and sustainable manner. This paper presents a high quality dataset containing light curves from the Primary Mission and 1st Extended Mission full frame images and periodic signals detected via Box Least Squares (Kov\'acs et al. 2002; Hartman 2012). The dataset was curated using a thorough manual review process then used to train a neural network called Astronet-Triage-v2. On our test set, for transiting/eclipsing events we achieve a 99.6% recall (true positives over all data with positive labels) at a precision of 75.7% (true positives over all predicted positives). Since 90% of our training data is from the Primary Mission, we also test our ability to generalize on held-out 1st Extended Mission data. Here, we find an area under the precision-recall curve of 0.965, a 4% improvement over Astronet-Triage (Yu et al. 2019). On the TESS Object of Interest (TOI) Catalog through April 2022, a shortlist of planets and planet candidates, Astronet-Triage-v2 is able to recover 3577 out of 4140 TOIs, while Astronet-Triage only recovers 3349 targets at an equal level of precision. In other words, upgrading to Astronet-Triage-v2 helps save at least 200 planet candidates from being lost. The new model is currently used for planet candidate triage in the Quick-Look Pipeline (Huang et al. 2020a,b; Kunimoto et al. 2021). 	
"The Competitive Leverage Paradox Effect on Information Systems Life
  Cycle"	http://arxiv.org/abs/2301.10006v1	2023-01-03T19:53:25Z	2023-01-03T19:53:25Z	  The fierce market competition has put pressure on organizations leveraging their value chains. The continuous development in strategic technologies such as Artificial Intelligence (AI) has pushed organizations to continuously acquire new Intelligent Information Systems (IIS) while underutilizing existing ones leading to the competitive leverage paradox. However, research on underutilizing IIS has focused on the social and organizational aspects of the problem, ignoring the flaws in designing and evaluating IIS. One of the overlooked factors is the effective life span of an IIS. This research conducted a systematic literature review to profoundly investigate the determinants of the competitive leverage paradox and its effect on the IIS life cycle. The research studies the IISs from economic and design perspectives. We also explore the design and strategic factors that led to defects in the effective life cycle of IIS. This research calls to consider the economic, and design factors in addressing the underutilization of IIS. The study also presents future research propositions to enhance IIS life cycle and return on investment. 	
On the long-term archiving of research data	http://arxiv.org/abs/2301.01189v1	2023-01-03T16:42:27Z	2023-01-03T16:42:27Z	  Accessing research data at any time is what FAIR (Findable Accessible Interoperable Reusable) data sharing aims to achieve at scale. Yet, we argue that it is not sustainable to keep accumulating and maintaining all datasets for rapid access, considering the monetary and ecological cost of maintaining repositories. Here, we address the issue of cold data storage: when to dispose of data for offline storage, how can this be done while maintaining FAIR principles and who should be responsible for cold archiving and long-term preservation. 	
Energy Efficient Design of Extreme Massive MIMO	http://arxiv.org/abs/2301.01119v2	2023-01-13T03:36:00Z	2023-01-03T14:29:25Z	  Ever since the invention of Bell Laboratories Layer Space-Time (BLAST) in mid 1990s, the focus of MIMO research and development has been largely on pushing the limit of spectral efficiency. While massive MIMO technologies laid the foundation of high throughput in 5G and beyond, energy efficiency of the associated radio system leaves much room for improvement. With the substantial negative implications of climate change looming ever closer, enabling sustainability is of paramount importance for any future technology, and minimizing energy use is a key dimension of achieving sustainability. Thus, every aspect of 6G design, implementation, and operation will be scrutinized to maximize energy efficiency. An analysis of the massive MIMO 5G radio energy consumption at different loads reveals under what specific conditions 6G should outperform 5G, setting qualitative energy efficiency design goals for 6G. Following this, we propose some design principles for the 6G, focusing on novel operational, component technology, and architecture innovations to minimize energy consumption. 	
"Conservation Tools: The Next Generation of Engineering--Biology
  Collaborations"	http://arxiv.org/abs/2301.01103v1	2023-01-03T13:58:31Z	2023-01-03T13:58:31Z	  The recent increase in public and academic interest in preserving biodiversity has led to the growth of the field of conservation technology. This field involves designing and constructing tools that utilize technology to aid in the conservation of wildlife. In this article, we will use case studies to demonstrate the importance of designing conservation tools with human-wildlife interaction in mind and provide a framework for creating successful tools. These case studies include a range of complexities, from simple cat collars to machine learning and game theory methodologies. Our goal is to introduce and inform current and future researchers in the field of conservation technology and provide references for educating the next generation of conservation technologists. Conservation technology not only has the potential to benefit biodiversity but also has broader impacts on fields such as sustainability and environmental protection. By using innovative technologies to address conservation challenges, we can find more effective and efficient solutions to protect and preserve our planet's resources. 	
Modal decomposition of nonlinear interactions in wall turbulence	http://arxiv.org/abs/2301.01078v1	2023-01-03T13:06:35Z	2023-01-03T13:06:35Z	  Coherent structures are found in many different turbulent flows and are known to drive self-sustaining processes in wall turbulence. Identifying the triadic interactions which generate coherent structures can provide insights beyond what is possible in the framework of linearized models. There are infinite possible interactions that may generate a given structure. Thus a method to systematically study those, ranking them in terms of their contribution to the structure of interest, is essential. We here use the resolvent-based extended spectral proper orthogonal decomposition (RESPOD) approach (Karban, U. et al. 2022 Self-similar mechanisms in wall turbulence studied using resolvent analysis. Journal of Fluid Mechanics 969, A36) to rank the triadic interactions which give rise to wall-attached structures in a minimal Couette flow at Reynolds number 400. Our analysis identifies that six triadic interactions dominate the most-energetic wall-attached structure, revealing the capability of the methodology to identify and rank nonlinear interactions responsible for a given coherent structure. The approach can be used to analyse the energy exchange in turbulent flows and may guide the construction of reduced-order models based on the interplay between different flow modes. 	
"Solar Sail Propulsion by 2050: An Enabling Capability for Heliophysics
  Missions"	http://arxiv.org/abs/2301.01297v1	2023-01-03T04:31:55Z	2023-01-03T04:31:55Z	  Solar sails enable missions to observe the solar environment from unique vantage points, such as sustained observations away from the Sun-Earth line; sub-L1 station keeping; high inclination solar orbits; Earth polar-sitting and polar-viewing observatories; fast transit missions to study heliosphere to interstellar medium transition, as well as missions of interest across a broad user community. Recent and planned demonstration missions make this technology ready for use on near-term science missions. 	
Five Common Misconceptions About Privacy-Preserving Internet of Things	http://arxiv.org/abs/2301.00920v1	2023-01-03T01:30:28Z	2023-01-03T01:30:28Z	  Billions of devices in the Internet of Things (IoT) collect sensitive data about people, creating data privacy risks and breach vulnerabilities. Accordingly, data privacy preservation is vital for sustaining the proliferation of IoT services. In particular, privacy-preserving IoT connects devices embedded with sensors and maintains the data privacy of people. However, common misconceptions exist among IoT researchers, service providers, and users about privacy-preserving IoT.   This article refutes five common misconceptions about privacy-preserving IoT concerning data sensing and innovation, regulations, and privacy safeguards. For example, IoT users have a common misconception that no data collection is permitted in data privacy regulations. On the other hand, IoT service providers often think data privacy impedes IoT sensing and innovation. Addressing these misconceptions is essential for making progress in privacy-preserving IoT. This article refutes such common misconceptions using real-world experiments and online survey research. First, the experiments indicate that data privacy should not be perceived as an impediment in IoT but as an opportunity to increase customer retention and trust. Second, privacy-preserving IoT is not exclusively a regulatory problem but also a functional necessity that must be incorporated in the early stages of any IoT design. Third, people do not trust services that lack sufficient privacy measures. Fourth, conventional data security principles do not guarantee data privacy protection, and data privacy can be exposed even if data is securely stored. Fifth, IoT decentralization does not attain absolute privacy preservation. 	
"Sustained heating of the chromosphere and transition region over a
  sunspot light bridge"	http://arxiv.org/abs/2301.00608v1	2023-01-02T11:47:07Z	2023-01-02T11:47:07Z	  Sunspot light bridges (LBs) exhibit a wide range of short-lived phenomena in the chromosphere and transition region. In contrast, we use here data from the Multi-Application Solar Telescope (MAST), the Interface Region Imaging Spectrograph (IRIS), Hinode, the Atmospheric Imaging Assembly (AIA), and the Helioseismic and Magnetic Imager (HMI) to analyze the sustained heating over days in an LB in a regular sunspot. Chromospheric temperatures were retrieved from the the MAST Ca II and IRIS Mg II lines by nonlocal thermodynamic equilibrium inversions. Line widths, Doppler shifts, and intensities were derived from the IRIS lines using Gaussian fits. Coronal temperatures were estimated through the differential emission measure, while the coronal magnetic field was obtained from an extrapolation of the HMI vector field. At the photosphere, the LB exhibits a granular morphology with field strengths of about 400 G and no significant electric currents. The sunspot does not fragment, and the LB remains stable for several days. The chromospheric temperature, IRIS line intensities and widths, and AIA 171 \AA and 211 \AA intensities are all enhanced in the LB with temperatures from 8000 K to 2.5 MK. Photospheric plasma motions remain small, while the chromosphere and transition region indicate predominantly red-shifts of 5-20 km/s with occasional supersonic downflows exceeding 100 km/s. The excess thermal energy over the LB is about 3.2x10^26 erg and matches the radiative losses. It could be supplied by magnetic flux loss of the sunspot (7.5x10^27 erg), kinetic energy from the increase in the LB width (4x10^28 erg), or freefall of mass along the coronal loops (6.3x10^26 ,erg). 	
"Fairness Guaranteed and Auction-based x-haul and Cloud Resource
  Allocation in Multi-tenant O-RANs"	http://arxiv.org/abs/2301.00597v3	2023-03-15T17:00:46Z	2023-01-02T11:03:50Z	  The open-radio access network (O-RAN) embraces cloudification and network function virtualization for base-band function processing by dis-aggregated radio units (RUs), distributed units (DUs), and centralized units (CUs). These enable the cloud-RAN vision in full, where multiple mobile network operators (MNOs) can install their proprietary or open RUs, but lease on-demand computational resources for DU-CU functions from commonly available open-clouds via open x-haul interfaces. In this paper, we propose and compare the performances of min-max fairness and Vickrey-Clarke-Groves (VCG) auction-based x-haul and DU-CU resource allocation mechanisms to create a multi-tenant O-RAN ecosystem that is sustainable for small, medium, and large MNOs. The min-max fair approach minimizes the maximum OPEX of RUs through cost-sharing proportional to their demands, whereas the VCG auction-based approach minimizes the total OPEX for all resources utilized while extracting truthful demands from RUs. We consider time-wavelength division multiplexed (TWDM) passive optical network (PON)-based x-haul interfaces where PON virtualization technique is used to flexibly provide optical connections among RUs and edge-clouds at macro-cell RU locations as well as open-clouds at the central office locations. Moreover, we design efficient heuristics that yield significantly better economic efficiency and network resource utilization than conventional greedy resource allocation algorithms and reinforcement learning-based algorithms. 	
"Simple reactor model of relativistic runaway electron avalanche
  development"	http://arxiv.org/abs/2301.00542v1	2023-01-02T06:51:33Z	2023-01-02T06:51:33Z	  High-energy gamma radiation in the Earth's atmosphere is associated with the bremsstrahlung of Relativistic Runaway Electron Avalanches (RREA) developing in thunderstorm electric fields. In this paper, RREA development is studied in the system of two strong electric-field regions within thunderstorms, which accelerate runaway electrons toward each other. Such a system is called the simple reactor. It is discovered that the propagation of gamma rays and runaway electrons from one region to another leads to positive feedback. This feedback called the reactor feedback can make RREA self-sustaining, thus effectively multiplying high-energy particles inside thunderstorms containing the simple reactor. The spectrum and characteristic time scale of the simple reactor gamma radiation are in agreement with Terrestrial Gamma-ray Flashes (TGFs) data. The applicability of the simple reactor model to TGF is discussed, and the distinguishing observable properties of the simple reactor radiation during TGF and Thunderstorm Ground Enhancement are considered. 	
"Using Neural Networks to Learn the Jet Stream Forced Response from
  Natural Variability"	http://arxiv.org/abs/2301.00496v1	2023-01-02T01:03:58Z	2023-01-02T01:03:58Z	"  Two distinct features of anthropogenic climate change, warming in the tropical upper troposphere and warming at the Arctic surface, have competing effects on the mid-latitude jet stream's latitudinal position, often referred to as a ""tug-of-war"". Studies that investigate the jet's response to these thermal forcings show that it is sensitive to model type, season, initial atmospheric conditions, and the shape and magnitude of the forcing. Much of this past work focuses on studying a simulation's response to external manipulation. In contrast, we explore the potential to train a convolutional neural network (CNN) on internal variability alone and then use it to examine possible nonlinear responses of the jet to tropospheric thermal forcing that more closely resemble anthropogenic climate change. Our approach leverages the idea behind the fluctuation-dissipation theorem, which relates the internal variability of a system to its forced response but so far has been only used to quantify linear responses. We train a CNN on data from a long control run of the CESM dry dynamical core and show that it is able to skillfully predict the nonlinear response of the jet to sustained external forcing. The trained CNN provides a quick method for exploring the jet stream sensitivity to a wide range of tropospheric temperature tendencies and, considering that this method can likely be applied to any model with a long control run, could lend itself useful for early stage experiment design. "	
"Investigating the Dynamics of Social Norm Emergence within Online
  Communities"	http://arxiv.org/abs/2301.00453v1	2023-01-01T18:06:26Z	2023-01-01T18:06:26Z	  Although the effects of the social norm on mitigating misinformation are identified, scant knowledge exists about the patterns of social norm emergence, such as the patterns and variations of social tipping in online communities with diverse characteristics. Accordingly, this study investigates the features of social tipping in online communities and examines the correlations between the tipping features and characteristics of online communities. Taking the side effects of COVID-19 vaccination as the case topic, we first track the patterns of tipping features in 100 online communities, which are detected using Louvain Algorithm from the aggregated communication network on Twitter between May 2020 and April 2021. Then, we use multi-variant linear regression to explore the correlations between tipping features and community characteristics. We find that social tipping in online communities can sustain for two to four months and lead to a 50% increase in populations who accept the normative belief in online communities. The regression indicates that the duration of social tipping is positively related to the community populations and original acceptance of social norms, while the correlation between the tipping duration and the degrees among community members is negative. Additionally, the network modularity and original acceptance of social norms have negative relationships with the extent of social tipping, while the degree and betweenness centrality can have significant positive relationships with the extent of tipping. Our findings shed light on more precise normative interventions on misinformation in digital environments as it offers preliminary evidence about the timing and mechanism of social norm emergence. 	
Deep Learning Technique for Human Parsing: A Survey and Outlook	http://arxiv.org/abs/2301.00394v1	2023-01-01T12:39:57Z	2023-01-01T12:39:57Z	  Human parsing aims to partition humans in image or video into multiple pixel-level semantic parts. In the last decade, it has gained significantly increased interest in the computer vision community and has been utilized in a broad range of practical applications, from security monitoring, to social media, to visual special effects, just to name a few. Although deep learning-based human parsing solutions have made remarkable achievements, many important concepts, existing challenges, and potential research directions are still confusing. In this survey, we comprehensively review three core sub-tasks: single human parsing, multiple human parsing, and video human parsing, by introducing their respective task settings, background concepts, relevant problems and applications, representative literature, and datasets. We also present quantitative performance comparisons of the reviewed methods on benchmark datasets. Additionally, to promote sustainable development of the community, we put forward a transformer-based human parsing framework, providing a high-performance baseline for follow-up research through universal, concise, and extensible solutions. Finally, we point out a set of under-investigated open issues in this field and suggest new directions for future study. We also provide a regularly updated project page, to continuously track recent developments in this fast-advancing field: https://github.com/soeaver/awesome-human-parsing. 	
"Mapping smallholder cashew plantations to inform sustainable tree crop
  expansion in Benin"	http://arxiv.org/abs/2301.00363v2	2023-01-15T18:04:42Z	2023-01-01T07:18:47Z	  Cashews are grown by over 3 million smallholders in more than 40 countries worldwide as a principal source of income. As the third largest cashew producer in Africa, Benin has nearly 200,000 smallholder cashew growers contributing 15% of the country's national export earnings. However, a lack of information on where and how cashew trees grow across the country hinders decision-making that could support increased cashew production and poverty alleviation. By leveraging 2.4-m Planet Basemaps and 0.5-m aerial imagery, newly developed deep learning algorithms, and large-scale ground truth datasets, we successfully produced the first national map of cashew in Benin and characterized the expansion of cashew plantations between 2015 and 2021. In particular, we developed a SpatioTemporal Classification with Attention (STCA) model to map the distribution of cashew plantations, which can fully capture texture information from discriminative time steps during a growing season. We further developed a Clustering Augmented Self-supervised Temporal Classification (CASTC) model to distinguish high-density versus low-density cashew plantations by automatic feature extraction and optimized clustering. Results show that the STCA model has an overall accuracy over 85% and the CASTC model achieved an overall accuracy of 76%. We found that the cashew area in Benin almost doubled from 2015 to 2021 with 60% of new plantation development coming from cropland or fallow land, while encroachment of cashew plantations into protected areas has increased by 55%. Only half of cashew plantations were high-density in 2021, suggesting high potential for intensification. Our study illustrates the power of combining high-resolution remote sensing imagery and state-of-the-art deep learning algorithms to better understand tree crops in the heterogeneous smallholder landscape. 	
"Hot entanglement? -- Parametrically coupled quantum oscillators in two
  heat baths: instability, squeezing and driving"	http://arxiv.org/abs/2301.00256v1	2022-12-31T17:24:28Z	2022-12-31T17:24:28Z	  Entanglement being a foundational cornerstone of quantum sciences and the primary resource in quantum information processing, understanding its dynamical evolution in realistic conditions is essential. Unfortunately, numerous model studies show that degradation of entanglement from a quantum system's environment, especially thermal noise, is almost unavoidable. Thus the appellation `hot entanglement' appears like a contradiction, until Galve et al [Phys. Rev. Lett. \textbf{105} 180501 (2010)] announced that entanglement can be kept at high temperatures if one considers a quantum system with time-dependent coupling between the two parties, each interacting with its individual bath. With the goal of understanding the sustenance of entanglement at high temperatures, working with the same model and set up as Galve et al, namely, parametrically-driven coupled harmonic oscillators interacting with their own Markovian baths, this work probes into the feasibility of `hot entanglement' from three aspects listed in the subtitle. Our findings show that 1) hot entanglement functions only in the unstable regimes, 2) instability is a necessary but not sufficient condition, and 3) the power intake required by the drive operating in the unstable regime to sustain entanglement increases exponentially. The last factor indicates that hot entanglement under this modeling is theoretically untenable and its actual implementation likely unattainable. 	
"Ameliorating transport system focusing on sustainability and
  inclusiveness through a mixed-method research (A case study in Tehran, Iran)"	http://arxiv.org/abs/2301.07504v1	2022-12-31T03:33:22Z	2022-12-31T03:33:22Z	  Numerous studies have examined issues such as sustainable transport and urban inclusion; yet there is a gap about disadvantaged people and the hindrances they encounter in terms of public transportation. This study assesses sustainability of transport system in the context of district 8 of Tehran, Iran, focusing on needs of disadvantaged groups, and giving suggestions to ameliorate the condition of transport planning using a mixed method research consist of face-to-face focus groups with elderlies, children, women and disabled people, questionnaire, map analysis (network analysis using ArcGIS) and key informant interview. The results reveal that there are various burdens for disadvantaged people including lack of enthusiasm toward active modes of transport because of safety problems, cost-ineffectiveness and inefficacy of public transportation for some disabled individuals. The recommendations for the area regarding the problems are dividing the district into smaller sub-districts, designing a complete street and location allocation of a park and ride system. 	
"A Mapping of Assurance Techniques for Learning Enabled Autonomous
  Systems to the Systems Engineering Lifecycle"	http://arxiv.org/abs/2301.00057v1	2022-12-30T21:44:23Z	2022-12-30T21:44:23Z	  Learning enabled autonomous systems provide increased capabilities compared to traditional systems. However, the complexity of and probabilistic nature in the underlying methods enabling such capabilities present challenges for current systems engineering processes for assurance, and test, evaluation, verification, and validation (TEVV). This paper provides a preliminary attempt to map recently developed technical approaches in the assurance and TEVV of learning enabled autonomous systems (LEAS) literature to a traditional systems engineering v-model. This mapping categorizes such techniques into three main approaches: development, acquisition, and sustainment. We review the latest techniques to develop safe, reliable, and resilient learning enabled autonomous systems, without recommending radical and impractical changes to existing systems engineering processes. By performing this mapping, we seek to assist acquisition professionals by (i) informing comprehensive test and evaluation planning, and (ii) objectively communicating risk to leaders. 	
"Detection of Malfunctioning Modules in Photovoltaic Power Plants using
  Unsupervised Feature Clustering Segmentation Algorithm"	http://arxiv.org/abs/2212.14653v1	2022-12-30T12:30:38Z	2022-12-30T12:30:38Z	  The energy transition towards photovoltaic solar energy has evolved to be a viable and sustainable source for the generation of electricity. It has effectively emerged as an alternative to the conventional mode of electricity generation for developing countries to meet their energy requirement. Thus, many solar power plants have been set up across the globe. However, in these large-scale or remote solar power plants, monitoring and maintenance persist as challenging tasks, mainly identifying faulty or malfunctioning cells in photovoltaic (PV) panels. In this paper, we use an unsupervised deep-learning image segmentation model for the detection of internal faults such as hot spots and snail trails in PV panels. Generally, training or ground truth labels are not available for large solar power plants, thus the proposed model is highly recommended as it does not require any prior learning or training. It extracts the features from the input image and segments out the faults in the image. Here we use infrared thermal images of the PV panel as input, passed to a convolutional neural network which assigns cluster labels to the pixels. Further, optimize the pixel labels, features and model parameters using backpropagation based on iterative stochastic gradient descent. Then, we compute similarity loss and spatial continuity loss to assign the same label to the pixel with similar features and spatial continuity to reduce noises in the image segmentation process. The effectiveness of the proposed approach was examined on an online available dataset for the recognition of snail trails and hot spot failures in monocrystalline solar panels. 	
"The emergence and growth of the flux transport dynamo model of the
  sunspot cycle"	http://arxiv.org/abs/2212.14617v1	2022-12-30T10:11:27Z	2022-12-30T10:11:27Z	  The sunspot cycle is the magnetic cycle of the Sun produced by the dynamo process. A central idea of the solar dynamo is that the toroidal and the poloidal magnetic fields of the Sun sustain each other. We discuss the relevant observational data both for sunspots (which are manifestations of the toroidal field) and for the poloidal field of the Sun. We point out how the differential rotation of the Sun stretches out the poloidal field to produce the toroidal field primarily at the bottom of the convection zone, from where parts of this toroidal field may rise due to magnetic buoyancy to produce sunspots. In the flux transport dynamo model, the decay of tilted bipolar sunspot pairs gives rise to the poloidal field by the Babcock--Leighton mechanism. In this type of model, the meridional circulation of the Sun, which is poleward at the solar surface and equatorward at the bottom of the convection zone, plays a crucial role in the transport of magnetic fluxes. We finally point out that various stochastic fluctuations associated with the dynamo process may play a key role in producing the irregularities of the sunspot cycle. 	
"Accurate reduced models for the pH oscillations in the urea-urease
  reaction confined to giant lipid vesicles"	http://arxiv.org/abs/2212.14503v1	2022-12-30T00:56:02Z	2022-12-30T00:56:02Z	  This theoretical study concerns a pH oscillator based on the urea-urease reaction confined to giant lipid vesicles. Under suitable conditions, differential transport of urea and hydrogen ion across the unilamellar vesicle membrane periodically resets the pH clock that switches the system from acid to basic, resulting in self-sustained oscillations. We analyse the structure of the phase flow and of the limit cycle, which controls the dynamics for giant vesicles and dominates the pronouncedly stochastic oscillations in small vesicles of submicrometer size. To this end, we derive reduced models, which are amenable to analytic treatments that are complemented by numerical solutions, and obtain the period and amplitude of the oscillations as well as the parameter domain, where oscillatory behavior persists. We show that the accuracy of these predictions is highly sensitive to the employed reduction scheme. In particular, we suggest an accurate two-variable model and show its equivalence to a three-variable model that admits an interpretation in terms of a chemical reaction network. The faithful modeling of a single pH oscillator appears crucial for rationalizing experiments and understanding communication of vesicles and synchronization of rhythms. 	
Localization in musical steelpans	http://arxiv.org/abs/2212.14465v1	2022-12-29T21:59:30Z	2022-12-29T21:59:30Z	  The steelpan is a pitched percussion instrument that takes the form of a concave bowl with several localized dimpled regions of varying curvature. Each of these localized zones, called notes, can vibrate independently when struck, and produces a sustained tone of a well-defined pitch. While the association of the localized zones with individual notes has long been known and exploited, the relationship between the shell geometry and the strength of the mode confinement remains unclear. Here, we explore the spectral properties of the steelpan modeled as a vibrating elastic shell. To characterize the resulting eigenvalue problem, we generalize a recently developed theory of localization landscapes for scalar elliptic operators to the vector-valued case, and predict the location of confined eigenmodes by solving a Poisson problem. A finite element discretization of the shell shows that the localization strength is determined by the difference in curvature between the note and the surrounding bowl. In addition to providing an explanation for how a steelpan operates as a two-dimensional xylophone, our study provides a geometric principle for designing localized modes in elastic shells. 	
"Multi-Agent Deep Reinforcement Learning Based Resource Management in
  SWIPT Enabled Cellular Networks with H2H/M2M Co-Existence"	http://arxiv.org/abs/2212.14234v1	2022-12-29T09:08:33Z	2022-12-29T09:08:33Z	  Machine-to-Machine (M2M) communication is crucial in developing Internet of Things (IoT). As it is well known that cellular networks have been considered as the primary infrastructure for M2M communications, there are several key issues to be addressed in order to deploy M2M communications over cellular networks. Notably, the rapid growth of M2M traffic dramatically increases energy consumption, as well as degrades the performance of existing Human-to-Human (H2H) traffic. Sustainable operation technology and resource management are efficacious ways for solving these issues. In this paper, we investigate a resource management problem in cellular networks with H2H/M2M coexistence. First, considering the energy-constrained nature of machine type communication devices (MTCDs), we propose a novel network model enabled by simultaneous wireless information and power transfer (SWIPT), which empowers MTCDs with the ability to simultaneously perform energy harvesting (EH) and information decoding. Given the diverse characteristics of IoT devices, we subdivide MTCDs into critical and tolerable types, further formulating the resource management problem as an energy efficiency (EE) maximization problem under divers Quality-of-Service (QoS) constraints. Then, we develop a multi-agent deep reinforcement learning (DRL) based scheme to solve this problem. It provides optimal spectrum, transmit power and power splitting (PS) ratio allocation policies, along with efficient model training under designed behaviour-tracking based state space and common reward function. Finally, we verify that with a reasonable training mechanism, multiple M2M agents successfully work cooperatively in a distributed way, resulting in network performance that outperforms other intelligence approaches in terms of convergence speed and meeting the EE and QoS requirements. 	
"High Resolution Modeling and Analysis of Cryptocurrency Mining's Impact
  on Power Grids: Carbon Footprint, Reliability, and Electricity Price"	http://arxiv.org/abs/2212.14189v1	2022-12-29T06:30:22Z	2022-12-29T06:30:22Z	  Blockchain technologies are considered one of the most disruptive innovations of the last decade, enabling secure decentralized trust-building. However, in recent years, with the rapid increase in the energy consumption of blockchain-based computations for cryptocurrency mining, there have been growing concerns about their sustainable operation in electric grids. This paper investigates the tri-factor impact of such large loads on carbon footprint, grid reliability, and electricity market price in the Texas grid. We release open-source high-resolution data to enable high-resolution modeling of influencing factors such as location and flexibility. We reveal that the per-megawatt-hour carbon footprint of cryptocurrency mining loads across locations can vary by as much as 50% of the crude system average estimate. We show that the flexibility of mining loads can significantly mitigate power shortages and market disruptions that can result from the deployment of mining loads. These findings suggest policymakers to facilitate the participation of large mining facilities in wholesale markets and require them to provide mandatory demand response. 	
"Decentralized Voltage Control with Peer-to-peer Energy Trading in a
  Distribution Network"	http://arxiv.org/abs/2212.14156v1	2022-12-29T02:32:20Z	2022-12-29T02:32:20Z	  Utilizing distributed renewable and energy storage resources via peer-to-peer (P2P) energy trading has long been touted as a solution to improve energy system's resilience and sustainability. Consumers and prosumers (those who have energy generation resources), however, do not have expertise to engage in repeated P2P trading, and the zero-marginal costs of renewables present challenges in determining fair market prices. To address these issues, we propose a multi-agent reinforcement learning (MARL) framework to help automate consumers' bidding and management of their solar PV and energy storage resources, under a specific P2P clearing mechanism that utilizes the so-called supply-demand ratio. In addition, we show how the MARL framework can integrate physical network constraints to realize decentralized voltage control, hence ensuring physical feasibility of the P2P energy trading and paving ways for real-world implementations. 	
"Improving a sequence-to-sequence nlp model using a reinforcement
  learning policy algorithm"	http://arxiv.org/abs/2212.14117v1	2022-12-28T22:46:57Z	2022-12-28T22:46:57Z	  Nowadays, the current neural network models of dialogue generation(chatbots) show great promise for generating answers for chatty agents. But they are short-sighted in that they predict utterances one at a time while disregarding their impact on future outcomes. Modelling a dialogue's future direction is critical for generating coherent, interesting dialogues, a need that has led traditional NLP dialogue models that rely on reinforcement learning. In this article, we explain how to combine these objectives by using deep reinforcement learning to predict future rewards in chatbot dialogue. The model simulates conversations between two virtual agents, with policy gradient methods used to reward sequences that exhibit three useful conversational characteristics: the flow of informality, coherence, and simplicity of response (related to forward-looking function). We assess our model based on its diversity, length, and complexity with regard to humans. In dialogue simulation, evaluations demonstrated that the proposed model generates more interactive responses and encourages a more sustained successful conversation. This work commemorates a preliminary step toward developing a neural conversational model based on the long-term success of dialogues. 	
"Large cities are less efficient for sustainable transport: The ABC of
  mobility"	http://arxiv.org/abs/2212.13956v1	2022-12-28T16:59:58Z	2022-12-28T16:59:58Z	  The distance travelled by car in a city has many negative impacts on its population, including pollution, noise and the use of space. Yet, quantifying the motorisation of urban mobility is a serious challenge, particularly across cities of different regions. Here we model the number of kilometres travelled by different modes of transport in a city by aggregating active mobility (A), public transport (B) and cars (C), thus expressing the modal share of a city by its ABC triplet. Data for over 800 cities across over 60 countries is used to model kilometres travelled by car and its relationship with city size. Our findings suggest that although public transport is more prominent in large cities, it is insufficient to reduce the distance travelled by car users within the city and, ultimately, their emissions. For cities outside the US, results show that although the proportion of journeys by car decreases in larger cities, distances become more prolonged, thus experiencing more distance travelled by car. When a city doubles its size, it has 87\% more car journeys, but they are 41% longer, thus experiencing 2.6 times more vehicle kilometres travelled. Further, by matching cities of similar size inside and outside the US, we estimate that cities in the US have 2.3 times more vehicle kilometres travelled than cities elsewhere. 	
"Architecture Decisions in AI-based Systems Development: An Empirical
  Study"	http://arxiv.org/abs/2212.13866v1	2022-12-28T15:33:28Z	2022-12-28T15:33:28Z	  Artificial Intelligence (AI) technologies have been developed rapidly, and AI-based systems have been widely used in various application domains with opportunities and challenges. However, little is known about the architecture decisions made in AI-based systems development, which has a substantial impact on the success and sustainability of these systems. To this end, we conducted an empirical study by collecting and analyzing the data from Stack Overflow (SO) and GitHub. More specifically, we searched on SO with six sets of keywords and explored 32 AI-based projects on GitHub, and finally we collected 174 posts and 128 GitHub issues related to architecture decisions. The results show that in AI-based systems development (1) architecture decisions are expressed in six linguistic patterns, among which Solution Proposal and Information Giving are most frequently used, (2) Technology Decision, Component Decision, and Data Decision are the main types of architecture decisions made, (3) Game is the most common application domain among the eighteen application domains identified, (4) the dominant quality attribute considered in architecture decision-making is Performance, and (5) the main limitations and challenges encountered by practitioners in making architecture decisions are Design Issues and Data Issues. Our results suggest that the limitations and challenges when making architecture decisions in AI-based systems development are highly specific to the characteristics of AI-based systems and are mainly of technical nature, which need to be properly confronted. 	
Hidden costs of La Mancha's production model and drivers of change	http://arxiv.org/abs/2212.13611v1	2022-12-27T20:53:48Z	2022-12-27T20:53:48Z	"  The territory of La Mancha, its rural areas, and its landscapes suffer a kind of atherosclerosis (""the silent killer"") because of the increase in artificial surfaces, the fragmentation of the countryside by various infrastructures, the abandonment of small and medium-sized farms and the loss of agricultural, material, and intangible heritage. At the same time, agricultural industrialization hides, behind a supposed productive efficiency, the deterioration of the quantitative and qualitative ecological status of surface and groundwater bodies, and causes air pollution, greenhouse gas emissions, loss of soil fertility, drainage and plowing of wetlands, forgetfulness of the ancestral environmental heritage, of the emergence of uses and customs of collective self-government and reduction of the adaptive capacity of traditional agroecosystems. This work aims, firstly, to shed light on the true costs of the main causes of environmental degradation in the territory of La Mancha, while deteriorating relations between rural and urban areas and determining the loss of territorial identity of La Mancha. the population. In addition, drivers of change toward a more sustainable social, economic, hydrological, environmental, and cultural production model are identified. "	
"Stochastic control of spiking activity bump expansion: monotonic and
  resonant phenomena"	http://arxiv.org/abs/2212.13602v1	2022-12-27T20:29:19Z	2022-12-27T20:29:19Z	  We consider spatially localized spiking activity patterns, so-called bumps, in ensembles of bistable spiking oscillators. The bistability consists in the coexistence of self-sustained spiking dynamics and quiescent steady-state regime. We show numerically that the processes of growth or contraction of such patterns can be controlled by varying the intensity of multiplicative noise. In particular, the effect of the noise is monotonic in an ensemble of the coupled Hindmarsh-Rose oscillators. On the other hand, in another model proposed by V. Semenov et al. in 2016 (see Ref. [V. Semenov et al., Phys. Rev. E 93, 052210 (2016)]), a resonant noise effect is observed. In that model, stabilization of the activity bump expansion is achieved at an appropriate noise level, and the noise effect reverses with a further increase in noise intensity. Moreover, we show the constructive role of nonlocal coupling which allows to save domains and fronts being totally destroyed due to the action of noise in the case of local coupling. 	
"S2S-WTV: Seismic Data Noise Attenuation Using Weighted Total Variation
  Regularized Self-Supervised Learning"	http://arxiv.org/abs/2212.13523v1	2022-12-27T15:36:09Z	2022-12-27T15:36:09Z	  Seismic data often undergoes severe noise due to environmental factors, which seriously affects subsequent applications. Traditional hand-crafted denoisers such as filters and regularizations utilize interpretable domain knowledge to design generalizable denoising techniques, while their representation capacities may be inferior to deep learning denoisers, which can learn complex and representative denoising mappings from abundant training pairs. However, due to the scarcity of high-quality training pairs, deep learning denoisers may sustain some generalization issues over various scenarios. In this work, we propose a self-supervised method that combines the capacities of deep denoiser and the generalization abilities of hand-crafted regularization for seismic data random noise attenuation. Specifically, we leverage the Self2Self (S2S) learning framework with a trace-wise masking strategy for seismic data denoising by solely using the observed noisy data. Parallelly, we suggest the weighted total variation (WTV) to further capture the horizontal local smooth structure of seismic data. Our method, dubbed as S2S-WTV, enjoys both high representation abilities brought from the self-supervised deep network and good generalization abilities of the hand-crafted WTV regularizer and the self-supervised nature. Therefore, our method can more effectively and stably remove the random noise and preserve the details and edges of the clean signal. To tackle the S2S-WTV optimization model, we introduce an alternating direction multiplier method (ADMM)-based algorithm. Extensive experiments on synthetic and field noisy seismic data demonstrate the effectiveness of our method as compared with state-of-the-art traditional and deep learning-based seismic data denoising methods. 	
What is so special about analogue simulations?	http://arxiv.org/abs/2212.13501v1	2022-12-27T14:33:05Z	2022-12-27T14:33:05Z	"  Contra Dardashti, Th\'ebault, and Winsberg (2017), this paper defends an analysis of arguments from analogue simulations as instances of a familiar kind of inductive inference in science: arguments from material analogy (Hesse, Models and Analogies in Science, Univ Notre Dame Press, 1963). When understood in this way, the capacity of analogue simulations to confirm hypotheses about black holes can be deduced from a general account - fully consistent with a Bayesian standpoint - of how ordinary arguments from material analogy confirm. The proposed analysis makes recommendations about what analogue experiments are worth pursuing that are more credible than Dardashti, Hartmann, Th\'ebault, and Winsberg's (2019). It also offers a more solid basis for addressing the concerns by Crowther, Linneman, and W\""utrich (2019), according to which analogue simulations are incapable of sustaining hypotheses concerning black hole radiation. "	
Off-centre supermassive black holes in bright central galaxies	http://arxiv.org/abs/2212.13277v1	2022-12-26T19:08:05Z	2022-12-26T19:08:05Z	  Supermassive black holes (SMBHs) are believed to reside at the centre of massive galaxies such as brightest cluster galaxies (BCGs). However, as BCGs experienced numerous galaxy mergers throughout their history, the central BH can be significantly kicked from the central region by these dynamical encounters. By combining the Illustris-TNG300 simulations and orbital integrations, we demonstrate that mergers with satellite galaxies on radial orbits are a main driver for such BH displacements in BCGs. BHs can get ejected to distances varying between a few parsecs to hundreds of kiloparsecs. Our results clearly establish that SMBH offsets are common in BCGs and more precisely a third of our BHs are off-centred at $z=0$. This orbital offset can be sustained for up to at least 6 Gyr between $z=2$ and $z=0$ in half of our BCGs. Since the dense gas reservoirs are located in the central region of galaxies, we argue that the consequences of off-center SMBHs in BCGs are to quench any BH growth and BH feedback. 	
"The Effects of Hofstede's Cultural Dimensions on Pro-Environmental
  Behaviour: How Culture Influences Environmentally Conscious Behaviour"	http://arxiv.org/abs/2301.04609v1	2022-12-26T09:53:29Z	2022-12-26T09:53:29Z	  The need for a more sustainable lifestyle is a key focus for several countries. Using a questionnaire survey conducted in Hungary, this paper examines how culture influences environmentally conscious behaviour. Having investigated the direct impact of Hofstedes cultural dimensions on pro-environmental behaviour, we found that the culture of a country hardly affects actual environmentally conscious behaviour. The findings indicate that only individualism and power distance have a significant but weak negative impact on pro-environmental behaviour. Based on the findings, we can state that a positive change in culture is a necessary but not sufficient condition for making a country greener. 	
"Students Perceptions of Sustainable Universities in Hungary. An
  Importance-Performance Analysis"	http://arxiv.org/abs/2301.01278v1	2022-12-26T09:14:01Z	2022-12-26T09:14:01Z	  In order to succeed, universities are forced to respond to the new challenges in the rapidly changing world. The recently emerging fourth-generation universities should meet sustainability objectives to better serve their students and their communities. It is essential for universities to measure their sustainability performance to capitalise on their core strengths and to overcome their weaknesses. In line with the stakeholder theory, the objective of this study was to investigate students perceptions of university sustainability including their expectations about and satisfaction with the efforts that universities make towards sustainability. This paper proposes a new approach that combines the sustainable university scale, developed by the authors, with the importance-performance analysis to identify key areas of university sustainability. To collect data, an online survey was conducted in Hungary in 2019. The sustainable university scale was found to be a reliable construct to measure different aspects of university sustainability. Results of the importance-performance analysis suggest that students consider Hungarian universities unsustainable. Research findings indicate that Hungarian universities perform poorly in sustainable purchasing and renewable energy use, but their location and their efforts towards separate waste collection are their major competitive advantages. The main domains of university sustainability were also discussed. This study provides university decision-makers and researchers with insightful results supporting the transformation of traditional universities into sustainable, fourth-generation higher education institutions. 	
Optical mirages from spinless beams	http://arxiv.org/abs/2212.12972v1	2022-12-25T23:33:13Z	2022-12-25T23:33:13Z	  Spin-orbit interactions of light are ubiquitous in multiple branches of nanophotonics, including optical wave localization. In that framework, it is widely accepted that circularly polarized beams lead to spin-dependent apparent shifts of dipolar targets commonly referred to as optical mirages. In contrast, these optical mirages vanish when the illumination comes from a spinless beam such as a linearly polarized wave. Here we show that optical localization errors emerge for particles sustaining electric and magnetic dipolar response under the illumination of spinless beams. As an example, we calculate the optical mirage for the scattering by a high refractive index nanosphere under the illumination of a linearly polarized plane wave carrying null spin, orbital, and total angular momentum. Our results point to an overlooked interference between the electric and magnetic dipoles rather than the spin-orbit interactions of light as the origin for the tilted position of the nanosphere. 	
RFID-Cloud Integration for Smart Management of Public Car Parking Spaces	http://arxiv.org/abs/2212.14684v1	2022-12-25T00:39:42Z	2022-12-25T00:39:42Z	  Effective management of public shared spaces such as car parking space, is one challenging transformational aspect for many cities, especially in the developing World. By leveraging sensing technologies, cloud computing, and Artificial Intelligence, Cities are increasingly being managed smartly. Smart Cities not only bring convenience to City dwellers, but also improve their quality of life as advocated for by United Nations in the 2030 Sustainable Development Goal on Sustainable Cities and Communities. Through integration of Internet of Things and Cloud Computing, this paper presents a successful proof-of-concept implementation of a framework for managing public car parking spaces. Reservation of parking slots is done through a cloud-hosted application, while access to and out of the parking slot is enabled through Radio Frequency Identification (RFID) technology which in real-time, accordingly triggers update of the parking slot availability in the cloud-hosted database. This framework could bring considerable convenience to City dwellers since motorists only have to drive to a parking space when sure of a vacant parking slot, an important stride towards realization of sustainable smart cities and communities. 	
"Reconstructing Kernel-based Machine Learning Force Fields with
  Super-linear Convergence"	http://arxiv.org/abs/2212.12737v1	2022-12-24T13:45:50Z	2022-12-24T13:45:50Z	"  Kernel machines have sustained continuous progress in the field of quantum chemistry. In particular, they have proven to be successful in the low-data regime of force field reconstruction. This is because many physical invariances and symmetries can be incorporated into the kernel function to compensate for much larger datasets. So far, the scalability of this approach has however been hindered by its cubical runtime in the number of training points. While it is known, that iterative Krylov subspace solvers can overcome these burdens, they crucially rely on effective preconditioners, which are elusive in practice. Practical preconditioners need to be computationally efficient and numerically robust at the same time. Here, we consider the broad class of Nystr\""om-type methods to construct preconditioners based on successively more sophisticated low-rank approximations of the original kernel matrix, each of which provides a different set of computational trade-offs. All considered methods estimate the relevant subspace spanned by the kernel matrix columns using different strategies to identify a representative set of inducing points. Our comprehensive study covers the full spectrum of approaches, starting from naive random sampling to leverage score estimates and incomplete Cholesky factorizations, up to exact SVD decompositions. "	
"Dynamics and proliferation of turbulent stripes in channel and Couette
  flow"	http://arxiv.org/abs/2212.12406v1	2022-12-23T15:43:17Z	2022-12-23T15:43:17Z	  The first long-lived turbulent structures observable in Couette and channel flow take the form of localized stripes, inclined with respect to the mean flow direction. The dynamics of these stripes are central to transition, and recent studies proposed an analogy to directed percolation where the stripes' proliferation is ultimately responsible for turbulence to become sustained. In the present study we focus on the internal stripe dynamics as well as on the eventual stripe expansion, and we compare the underlying mechanisms in pressure and shear driven planar flows, respectively plane-Poiseuille and plane-Couette flow. Despite the similarities of the overall laminar-turbulence patterns, the stripe proliferation processes in the two cases are fundamentally different. Starting from the growth and sustenance of individual stripes, we find that in Couette flow new streaks are created stochastically throughout the stripe whereas in channel flow streak creation is deterministic and occurs locally at the downstream tip. Because of the up/downstream symmetry, Couette stripes, in contrast to channel stripes, have two weak and two strong laminar turbulent interfaces. These differences in symmetry as well as in internal growth give rise to two fundamentally different stripe splitting mechanisms. In channel flow splitting is connected to the elongational growth of the original stripe, and it results from a break-off / shedding of the stripe's tail. In Couette flow splitting follows from a broadening of the original stripe and a division along the stripe into two slimmer stripes. 	
"Analyze the SATCON Algorithm's Capability to Predict Tropical Storm
  Intensity across the West Pacific Basin"	http://arxiv.org/abs/2212.12161v1	2022-12-23T05:55:34Z	2022-12-23T05:55:34Z	"  A group of algorithms for estimating the current intensity (CI) of tropical cyclones (TCs), which use infrared and microwave sensor-based images as the input of the algorithm because it is more skilled than each algorithm separately, are used to create a technique to estimate the TC intensity which is known as SATCON . In the current study, an effort was undertaken to assess how well the SATCON approach performed for estimating TC intensity throughout the west pacific basin from year 2017 to 2021. To do this, 26 TCs over the west pacific basin were analysed using the SATCON-based technique, and the estimates were compared to the best track predictions provided by the Regional Specialized Meteorological Centre (RSMC), Tokyo. The maximum sustained surface winds (Vmax) and estimated central pressures (ECP) for various ``T"" numbers and types of storm throughout the entire year as well as during the pre-monsoon (March-July) and post-monsoon (July-February) seasons have been compared. When compared to weaker and very strong TCs, the ability of the SATCON algorithm to estimate intensity is determined to be rather excellent for mid-range TCs. We demonstrate that SATCON is more effective in the post-monsoon across the west pacific basin than in the pre-monsoon by comparing the algorithm results. "	
Bengali Handwritten Digit Recognition using CNN with Explainable AI	http://arxiv.org/abs/2212.12146v1	2022-12-23T04:40:20Z	2022-12-23T04:40:20Z	  Handwritten character recognition is a hot topic for research nowadays. If we can convert a handwritten piece of paper into a text-searchable document using the Optical Character Recognition (OCR) technique, we can easily understand the content and do not need to read the handwritten document. OCR in the English language is very common, but in the Bengali language, it is very hard to find a good quality OCR application. If we can merge machine learning and deep learning with OCR, it could be a huge contribution to this field. Various researchers have proposed a number of strategies for recognizing Bengali handwritten characters. A lot of ML algorithms and deep neural networks were used in their work, but the explanations of their models are not available. In our work, we have used various machine learning algorithms and CNN to recognize handwritten Bengali digits. We have got acceptable accuracy from some ML models, and CNN has given us great testing accuracy. Grad-CAM was used as an XAI method on our CNN model, which gave us insights into the model and helped us detect the origin of interest for recognizing a digit from an image. 	
"Spin wave dispersion of ultra-low damping hematite
  ($\text{-Fe}_2\text{O}_3$) at GHz frequencies"	http://arxiv.org/abs/2212.11887v2	2022-12-23T06:47:01Z	2022-12-22T17:20:19Z	  Low magnetic damping and high group velocity of spin waves (SWs) or magnons are two crucial parameters for functional magnonic devices. Magnonics research on signal processing and wave-based computation at GHz frequencies focussed on the artificial ferrimagnetic garnet Y$_3$Fe$_5$O$_{12}$ (YIG) so far. We report on spin-wave spectroscopy studies performed on the natural mineral hematite ($\alpha\text{-Fe}_2\text{O}_3$) which is a canted antiferromagnet. By means of broadband GHz spectroscopy and inelastic light scattering, we determine a damping coefficient of $1.1\times10^{-5}$ and magnon group velocities of a few 10 km/s, respectively, at room temperature. Covering a large regime of wave vectors up to $k\approx 24~{\rm rad}/\mu$m, we find the exchange stiffness length to be relatively short and only about 1 \r{A}. In a small magnetic field of 30 mT, the decay length of SWs is estimated to be 1.1 cm similar to the best YIG. Still, inelastic light scattering provides surprisingly broad and partly asymmetric resonance peaks. Their characteristic shape is induced by the large group velocities, low damping and distribution of incident angles inside the laser beam. Our results promote hematite as an alternative and sustainable basis for magnonic devices with fast speeds and low losses based on a stable natural mineral. 	
"Recurrent flow patterns as a basis for turbulence: predicting statistics
  from structures"	http://arxiv.org/abs/2212.11886v1	2022-12-22T17:20:05Z	2022-12-22T17:20:05Z	  A dynamical systems approach to turbulence envisions the flow as a trajectory through a high-dimensional state space transiently visiting the neighbourhoods of unstable simple invariant solutions. The grand hope has always been to turn this appealing picture into a predictive framework where the statistics of the flow follows from one appropriately-weighted sum of the statistics of each simple invariant solution. Two outstanding obstacles have prevented this goal from being achieved: (1) paucity of known solutions and (2) as yet no rational theory to predict the required weights. Here we describe a method to substantially solve the former and a data-driven approach to overcome the latter. In doing so, we provide the first compelling evidence that the statistics of a fully developed turbulent flow can be reconstructed with a set of unstable periodic orbits (UPOs). The new method for finding solutions is based on automatic differentiation in which high-quality guesses are constructed by minimising a trajectory-dependent loss function with gradient descent and then these are fully converged using a Newton solve. Unlike past work, the approach does not require observation of a `near recurrence' on a turbulent orbit and can be used to target solutions with specific physical properties via the addition of appropriate terms to the loss. Scores of new solutions are found with short periods in turbulent, two-dimensional Kolmogorov flow. These can be used to reproduce a variety of statistical quantities after `learning' weights for each periodic orbit by fitting to one statistic only. To our knowledge, this is the first time the statistics of a spatio-temporally-chaotic system have been successfully reproduced with a set of simple invariant states, and provides a fascinating connection between self-sustaining dynamical processes and the more well-known statistical properties of turbulence. 	
"Towards Sustainable Artificial Intelligence: An Overview of
  Environmental Protection Uses and Issues"	http://arxiv.org/abs/2212.11738v1	2022-12-22T14:31:48Z	2022-12-22T14:31:48Z	  Artificial Intelligence (AI) is used to create more sustainable production methods and model climate change, making it a valuable tool in the fight against environmental degradation. This paper describes the paradox of an energy-consuming technology serving the ecological challenges of tomorrow. The study provides an overview of the sectors that use AI-based solutions for environmental protection. It draws on numerous examples from AI for Green players to present use cases and concrete examples. In the second part of the study, the negative impacts of AI on the environment and the emerging technological solutions to support Green AI are examined. It is also shown that the research on less energy-consuming AI is motivated more by cost and energy autonomy constraints than by environmental considerations. This leads to a rebound effect that favors an increase in the complexity of models. Finally, the need to integrate environmental indicators into algorithms is discussed. The environmental dimension is part of the broader ethical problem of AI, and addressing it is crucial for ensuring the sustainability of AI in the long term. 	
"In situ stimulation of self-assembly tunes the elastic properties of
  interpenetrated glycolipid-biopolymer biobased hydrogels"	http://arxiv.org/abs/2212.11721v1	2022-12-22T14:13:38Z	2022-12-22T14:13:38Z	  Hydrogels are widespread soft materials, which can serve a wide range of applications. The control over the viscoelastic properties of the gel is of paramount importance. Ongoing environmental issues have raised the consumer's concern towards the use of more sustainable materials, including hydrogels. However, are greener materials compatible with high functionality? In a safe-by-design approach, this work demonstrates that functional hydrogels with in situ responsivity of their elastic properties by external stimuli can be developed from entirely ``sustainable'' components, a biobased amphiphile and biopolymers (gelatin, chitosan and alginate). The bioamphiphile is a stimuli-responsive glycolipid obtained by microbial fermentation, which can self-assemble into fibers, but also micelles or vesicles, in water under high dilution and by a rapid variation of the stimuli. The elastic properties of the bioamphiphile/biopolymer interpenetrated hydrogels can be modulated by selectively triggering the phase transition of the glycolipid and/or the biopolymer inside the gel by mean of temperature or pH. 	
"Strategic energy flows in input-output relations: a temporal multilayer
  approach"	http://arxiv.org/abs/2212.11585v1	2022-12-22T10:23:02Z	2022-12-22T10:23:02Z	  The energy consumption, the transfer of resources through the international trade, the transition towards renewable energies and the environmental sustainability appear as key drivers in order to evaluate the resilience of the energy systems. Concerning the consumptions, in the literature a great attention has been paid to direct energy, but the production of goods and services also involves indirect energy. Hence, in this work we consider different types of embodied energy sources and the time evolution of the sectors' and countries' interactions. Flows are indeed used to construct a directed and weighted temporal multilayer network based respectively on renewable and non-renewable sources, where sectors are nodes and layers are countries. We provide a methodological approach for analysing the network reliability and resilience and for identifying critical sectors and economies in the system by applying the Multi-Dimensional HITS algorithm. Then, we evaluate central arcs in the network at each time period by proposing a novel topological indicator based on the maximum flow problem. In this way, we provide a full view of economies, sectors and connections that play a relevant role over time in the network and whose removal could heavily affect the stability of the system. We provide a numerical analysis based on the embodied energy flows among countries and sectors in the period from 1990 to 2016. Results prove that the methods are effective in catching the different patterns between renewable and non-renewable energy sources. 	
"The role of grace periods in comparative effectiveness studies of
  different medications"	http://arxiv.org/abs/2212.11398v1	2022-12-21T22:57:49Z	2022-12-21T22:57:49Z	  Researchers are often interested in estimating the effect of sustained use of a pharmacological treatment on a health outcome. However, adherence to strict treatment protocols can be challenging for patients in practice and, when non-adherence is expected, estimates of the effect of sustained use may not be useful for decision making. As an alternative, more relaxed treatment protocols which allow for periods of time off treatment (i.e. grace periods) have been considered in pragmatic randomized trials and observational studies. In this paper we consider the interpretation, identification, and estimation of treatment strategies which include grace periods. We contrast natural grace period strategies which allow individuals the flexibility to take treatment as they would naturally do, with stochastic grace period strategies in which the investigator specifies the distribution of treatment utilization. We estimate the effect of initiation of a thiazide diuretic or an angiotensin-converting enzyme inhibitor (ACEI) in hypertensive patients under various strategies which include grace periods. We find that the risk of adverse cardiovascular and cerebrovascular outcomes is higher under treatment with ACEIs, and that this difference is larger under grace period strategies which impose lower drug utilization. 	
"Towards dynamic stability analysis of sustainable power grids using
  graph neural networks"	http://arxiv.org/abs/2212.11130v1	2022-12-21T15:57:12Z	2022-12-21T15:57:12Z	  To mitigate climate change, the share of renewable needs to be increased. Renewable energies introduce new challenges to power grids due to decentralization, reduced inertia and volatility in production. The operation of sustainable power grids with a high penetration of renewable energies requires new methods to analyze the dynamic stability. We provide new datasets of dynamic stability of synthetic power grids and find that graph neural networks (GNNs) are surprisingly effective at predicting the highly non-linear target from topological information only. To illustrate the potential to scale to real-sized power grids, we demonstrate the successful prediction on a Texan power grid model. 	
"Random spin-orbit gates in the system of a Topological insulator and a
  Quantum dot"	http://arxiv.org/abs/2212.11026v1	2022-12-21T14:06:16Z	2022-12-21T14:06:16Z	  The spin-dependent scattering process in a system of topological insulator and quantum dot is studied. The unitary scattering process is viewed as a gate transformation applied to an initial state of two electrons. Due to the randomness imposed through the impurities and alloying-induced effects of band parameters, the formalism of the random unitary gates is implemented. For quantifying entanglement in the system, we explored concurrence and ensemble-averaged R\'enyi entropy. We found that applied external magnetic field leads to long-range entanglement on the distances much larger than the confinement length. We showed that topological features of itinerant electrons sustain the formation of robust long-distance entanglement, which survives even in the presence of a strong disorder. 	
"Semi-Supervised Bifold Teacher-Student Learning for Indoor Presence
  Detection Under Time-Varying CSI"	http://arxiv.org/abs/2212.10802v1	2022-12-21T06:48:39Z	2022-12-21T06:48:39Z	"  In recent years, there have been abundant researches focused on indoor human presence detection based on laborious supervised learning (SL) and channel state information (CSI). These existing studies adopt spatial information of CSI to improve detection accuracy. However, channel is susceptible to arbitrary environmental changes in practice, such as the object movement, atmospheric factors and machine rebooting, which leads to degraded prediction accuracy. However, the existing SL-based methods require to re-train a new model with time-consuming labeling. Therefore, designing a semi-supervised learning (SSL) based scheme by continuously monitoring model ""life-cycle"" becomes compellingly imperative. In this paper, we propose bifold teacher-student (BTS) learning for presence detection system, which combines SSL by utilizing partial labeled and unlabeled dataset. The proposed primal-dual teacher-student network is capable of intelligently learning spatial and temporal features from labeled and unlabeled CSI. Additionally, the enhanced penalized loss function leveraging entropy and distance measure can distinguish the drifted data, i.e., features of new dataset are affected by time-varying effect and are alternated from the original distribution. The experimental results demonstrate that the proposed BTS system can sustain the asymptotic accuracy after retraining the model with unlabeled data. Moreover, label-free BTS outperforms the existing SSL-based models in terms of the highest detection accuracy, while achieving the similar performance of SL-based methods. "	
"Comparison and Evaluation of Methods for a Predict+Optimize Problem in
  Renewable Energy"	http://arxiv.org/abs/2212.10723v1	2022-12-21T02:34:12Z	2022-12-21T02:34:12Z	"  Algorithms that involve both forecasting and optimization are at the core of solutions to many difficult real-world problems, such as in supply chains (inventory optimization), traffic, and in the transition towards carbon-free energy generation in battery/load/production scheduling in sustainable energy systems. Typically, in these scenarios we want to solve an optimization problem that depends on unknown future values, which therefore need to be forecast. As both forecasting and optimization are difficult problems in their own right, relatively few research has been done in this area. This paper presents the findings of the ``IEEE-CIS Technical Challenge on Predict+Optimize for Renewable Energy Scheduling,"" held in 2021. We present a comparison and evaluation of the seven highest-ranked solutions in the competition, to provide researchers with a benchmark problem and to establish the state of the art for this benchmark, with the aim to foster and facilitate research in this area. The competition used data from the Monash Microgrid, as well as weather data and energy market data. It then focused on two main challenges: forecasting renewable energy production and demand, and obtaining an optimal schedule for the activities (lectures) and on-site batteries that lead to the lowest cost of energy. The most accurate forecasts were obtained by gradient-boosted tree and random forest models, and optimization was mostly performed using mixed integer linear and quadratic programming. The winning method predicted different scenarios and optimized over all scenarios jointly using a sample average approximation method. "	
"Berlin V2X: A Machine Learning Dataset from Multiple Vehicles and Radio
  Access Technologies"	http://arxiv.org/abs/2212.10343v2	2022-12-21T17:03:30Z	2022-12-20T15:26:39Z	  The evolution of wireless communications into 6G and beyond is expected to rely on new machine learning (ML)-based capabilities. These can enable proactive decisions and actions from wireless-network components to sustain quality-of-service (QoS) and user experience. Moreover, new use cases in the area of vehicular and industrial communications will emerge. Specifically in the area of vehicle communication, vehicle-to-everything (V2X) schemes will benefit strongly from such advances. With this in mind, we have conducted a detailed measurement campaign with the purpose of enabling a plethora of diverse ML-based studies. The resulting datasets offer GPS-located wireless measurements across diverse urban environments for both cellular (with two different operators) and sidelink radio access technologies, thus enabling a variety of different studies towards V2X. The datasets are labeled and sampled with a high time resolution. Furthermore, we make the data publicly available with all the necessary information to support the on-boarding of new researchers. We provide an initial analysis of the data showing some of the challenges that ML needs to overcome and the features that ML can leverage, as well as some hints at potential research studies. 	
"A fundamental limit on energy savings in controlled channel flow, and
  how to beat it"	http://arxiv.org/abs/2212.09998v1	2022-12-20T05:07:43Z	2022-12-20T05:07:43Z	  We derive a limit on energy savings in controlled channel flow. For flow in a channel driven by pressure, shear, or any combination of the two, and controlled via wall transpiration or spanwise wall motion, the uncontrolled laminar state requires the least net energy (accounting for the energetic cost of control). Thus, the optimal control solution is to laminarize the flow. Additionally, we raise the possibility of beating this limit. By simultaneously applying wall transpiration and spanwise wall motion, we show that it may be possible to attain sustained sub-laminar energy expenditure in a controlled flow. We provide a necessary design criterion for net energy savings. 	
Sustainable Hydropower Planning in Gabon	http://arxiv.org/abs/2212.09901v1	2022-12-19T22:46:28Z	2022-12-19T22:46:28Z	  Hydropower is a renewable, controllable, and flexible source of electricity. These are instrumental features to support decarbonization efforts, as an enabler of non-controllable and variable sources of renewable electricity. Sometimes hydropower is accompanied by other services provided by multipurpose reservoirs, such as water supply, irrigation, navigation, flood control and recreation. Despite all these benefits, hydropower can be a polarizing issue. A large sample of projects with poor planning and execution provides numerous arguments for its opponents. Large and complex projects frequently suffer overcost and delays. The direct impacts are related to the disruption of river ecosystems and surrounding habitats due to the flooding of large areas, and the fragmentation of rivers caused by the construction of dams and the reduction of sediment transport that impoverishes aquatic life. People displacement and compensation are always a complex issue. Hydropower projects can also cause indirect impacts, such as additional deforestation related to the construction of workers' villages, access roads and transmission lines. Finally, reservoirs may also become a significant source of methane emission, especially in tropical areas. This paper offers an analytical approach for sustainable hydropower planning at the river basin scale called HERA: Hydropower and Environmental Resource Assessment. Built on three main components, namely geoprocessing, engineering, and optimization, HERA screens and compares hydropower development alternatives to guarantee social and environmental objectives while maximizing mentioned economic benefits. It was designed to encourage a transparent and participatory hydropower planning process from the early stages. Experience has shown this approach increases the chances of better and balanced outcomes. A case study is presented in the Ogooue river basin in Gabon. 	
"PullupStructs: Digital Fabrication for Folding Structures via Pull-up
  Nets"	http://arxiv.org/abs/2212.09846v1	2022-12-19T20:42:59Z	2022-12-19T20:42:59Z	  In this paper, we introduce a method to rapidly create 3D geometries by folding 2D sheets via pull-up nets. Given a 3D structure, we unfold its mesh into a planar 2D sheet using heuristic algorithms and populate these with cutlines and throughholes. We develop a web-based simulation tool that translates users' 3D meshes into manufacturable 2D sheets. After laser-cutting the sheet and feeding thread through these throughholes to form a pull-up net, pulling the thread will fold the sheet into the 3D structure using a single degree of freedom. We introduce the fabrication process and build a variety of prototypes demonstrating the method's ability to rapidly create a breadth of geometries suitable for low-fidelity prototyping that are both load-bearing and aesthetic across a range of scales. Future work will expand the breadth of geometries available and evaluate the ability of our prototypes to sustain structural loads. 	
Energy-Aware Packet Schedulers for Battery-Less LoRaWAN Nodes	http://arxiv.org/abs/2212.09453v1	2022-12-19T13:45:48Z	2022-12-19T13:45:48Z	  The Internet of Things (IoT) enables a wide variety of applications where large sensor networks are deployed in remote areas without power grid access. Thus, the sensor nodes often run on batteries, whose replacement and disposal represent important economical and environmental costs. To realize more sustainable IoT solutions, it is therefore desirable to adopt battery-less energy-neutral devices that can harvest energy from renewable sources and store it in super-capacitors, whose environmental impact is much lower than that of batteries. To achieve the energetic self-sustainability of such nodes, however, communication and computational processes must be optimized to make the best use of the scarce and volatile energy available. In this work, we propose different energy-aware packet scheduling algorithms for battery-less LoRaWAN nodes, and compare them in various simulated scenarios, using actual energy-harvesting measurements taken from a testbed. We show that an energy-aware design can significantly increase the number of transmitted packets, also lowering the mean time between packet transmissions, though (as predictable) the gain strongly depends on the harvesting capabilities of the nodes. 	
FTX Collapse: A Ponzi Story	http://arxiv.org/abs/2212.09436v1	2022-12-19T13:23:38Z	2022-12-19T13:23:38Z	  FTX used to be the third-largest centralised exchange (CEX) in crypto markets, managing over \$10B in daily trading volume before its downfall. Such a giant, however, failed to avoid the fate of mania, panic, and crash. In this work, we revisit the FTX's crash by telling it as a Ponzi story. In regards to why FTX could not sustain this Ponzi game, we extract and demonstrate the three facilitators of the FTX collapse, namely, \textit{FTT}, \textit{leverage}, and \textit{diversion}. The unfunctionality in each factor can iteratively magnify the impact of damages when the panic is triggered. Rooted in the unstable ground, FTX eventually suffered insolvency and rapidly crashed in Nov. 2022. The crisis of FTX is not an isolated event; it consequently results in the collapse of a chain of associated companies in the entire crypto market. Recall this painful experience, we discuss possible paths for a way forward for both CeFi and DeFi services. 	
"When elephants nodded and dolls spoke: Bringing together robotics and
  storytelling for environmental literacy"	http://arxiv.org/abs/2212.09313v1	2022-12-19T09:25:27Z	2022-12-19T09:25:27Z	  Inculcating principles of environmental stewardship among the children and youth is needed urgently today for creating a sustainable future. This paper presents a model for promoting environment literacy in India using story telling based workshops while focusing on STEM education including computational thinking, robotics and maker skills. During the workshop, participants build a robotic diorama with digital animations and animatronics to tell their story. Our initial observations from pilot studies conducted in 2019 in six rural and semi-urban schools in India showed us that the children were deeply engaged and enthusiastic throughout the workshop making the entire learning experience a very meaningful and joyful one for all. 	
Exact Entanglement Dynamics of Two Spins in Finite Baths	http://arxiv.org/abs/2212.09151v1	2022-12-18T20:09:44Z	2022-12-18T20:09:44Z	  We consider the buildup and decay of two-spin entanglement through phase interactions in a finite environment of surrounding spins, as realized in quantum computing platforms based on arrays of atoms, molecules, or nitrogen vacancy centers. The non-Markovian dephasing caused by the spin environment through Ising-type phase interactions can be solved exactly and compared to an effective Markovian treatment based on collision models. In a first case study on a dynamic lattice of randomly hopping spins, we find that non-Markovianity boosts the dephasing rate caused by nearest neighbour interactions with the surroundings, degrading the maximum achievable entanglement. However, we also demonstrate that additional three-body interactions can mitigate this degradation, and that randomly timed reset operations performed on the two-spin system can help sustain a finite average amount of steady-state entanglement. In a second case study based on a model nuclear magnetic resonance system, we elucidate the role of bath correlations at finite temperature on non-Markovian dephasing. They speed up the dephasing at low temperatures while slowing it down at high temperatures, compared to an uncorrelated bath, which is related to the number of thermally accessible spin configurations with and without interactions. 	
Universal equation of state for wave turbulence in a quantum gas	http://arxiv.org/abs/2212.08652v1	2022-12-16T18:59:01Z	2022-12-16T18:59:01Z	  Boyle's 1662 observation that the volume of a gas is, at constant temperature, inversely proportional to pressure, offered a prototypical example of how an equation of state (EoS) can succinctly capture key properties of a many-particle system. Such relations are now cornerstones of equilibrium thermodynamics. Extending thermodynamic concepts to far-from-equilibrium systems is of great interest in various contexts including glasses, active matter, and turbulence, but is in general an open problem. Here, using a homogeneous ultracold atomic Bose gas, we experimentally construct an EoS for a turbulent cascade of matter waves. Under continuous forcing at a large length scale and dissipation at a small one, the gas exhibits a non-thermal, but stationary state, which is characterised by a power-law momentum distribution sustained by a scale-invariant momentum-space energy flux. We establish the amplitude of the momentum distribution and the underlying energy flux as equilibrium-like state variables, related by an EoS that does not depend on the details of the energy injection or dissipation, or the history of the system. Moreover, we show that the equations of state for a wide range of interaction strengths and gas densities can be empirically scaled onto each other. This results in a universal dimensionless EoS that sets benchmarks for the theory and should also be relevant for other turbulent systems. 	
"Challenges and Opportunities for Bioenergy in Europe: National
  Deployment, Policy Support, and Possible Future Roles"	http://arxiv.org/abs/2212.08513v1	2022-12-16T14:53:36Z	2022-12-16T14:53:36Z	  Bioenergy is currently a major renewable energy source in Europe but faces an unclear future because of conflicting modelling results and the lack of long-term policy. This paper identifies three challenges and potential opportunities by reviewing bioenergy historical national deployment, current policy support, and possible future roles in Europe. The first challenge is on the supply side. Analysing the supply-consumption dynamics and import dependency of EU bioenergy, we find that the security of bioenergy supply is challenging for liquid biofuels and those countries with the highest per-capita bioenergy consumption in Europe. Second, the definition of sustainable bioenergy in modelling studies is sometimes inconsistent with how EU policies label it. Third, on the demand side, there are unique but competing uses for bioenergy without a clear long-term strategy in Europe. We conclude with three opportunities to tackle these challenges for future research. First, utilising the untapped bioenergy potential with low environmental impacts could improve supply security. A clear and harmonised definition of sustainable bioenergy could better convey modelling results to policymaking. Finally, understanding where best to use limited sustainable bioenergy supply through sector-coupled energy system models can provide direction for a clearer EU bioenergy strategy towards 2050. 	
"Temperature dependence of radiation damage annealing of Silicon
  Photomultipliers"	http://arxiv.org/abs/2212.08474v1	2022-12-16T13:37:26Z	2022-12-16T13:37:26Z	  The last decade has increasingly seen the use of silicon photomultipliers (SiPMs) instead of photomultiplier tubes (PMTs). This is due to various advantages of the former on the latter like its smaller size, lower operating voltage, higher detection efficiency, insensitivity to magnetic fields and mechanical robustness to launch vibrations. All these features make SiPMs ideal for use on space based experiments where the detectors require to be compact, lightweight and capable of surviving launch conditions. A downside with the use of this novel type of detector in space conditions is its susceptibility to radiation damage. In order to understand the lifetime of SiPMs in space, both the damage sustained due to radiation as well as the subsequent recovery, or annealing, from this damage have to be studied. Here we present these studies for three different types of SiPMs from the Hamamatsu S13360 series. Both their behaviour after sustaining radiation equivalent to 2 years in low earth orbit in a typical mission is presented, as well as the recovery of these detectors while stored in different conditions. The storage conditions varied in temperature as well as in operating voltage. The study found that the annealing depends significantly on the temperature of the detectors with those stored at high temperatures recovering significantly faster and at recovering closer to the original performance. Additionally, no significant effect from a reasonable bias voltage on the annealing was observed. Finally the annealing rate as a function of temperature is presented along with various operating strategies for the future SiPM based astrophysical detector POLAR-2 as well as for future SiPM based space borne missions. 	
"Comment on ""Analog Schwarzschild-like geometry in fluids with external
  pressure''"	http://arxiv.org/abs/2212.08431v1	2022-12-16T12:05:42Z	2022-12-16T12:05:42Z	"  In Ref. [1], exact (not only conformally related) analogue models for the Schwarzschild and Reissner-Nordstr\""om spacetimes were found. The background non-relativistic fluid flow was sustained by an external body force which is not affected by the linearised fluctuations. Following a different route, by modelling the external force as the gradient of an external pressure, it was shown in~\cite{bilic} that the speed of sound is significantly modified. This effective speed of sound turns out to be inconsistent with the continuity equation. In this comment we analyse these two contradictory conclusions. We first show that the heuristic justification for the introduction of the external force via a variational principle given in Ref. [2] is conceptually incorrect. Then, by adding the external force appropriately, we show that the conclusions in [1] remain valid. "	
"Strong toroidal magnetic fields sustained by the elastic crust in a
  neutron star"	http://arxiv.org/abs/2212.08309v1	2022-12-16T07:15:49Z	2022-12-16T07:15:49Z	  We investigate new solutions for magnetized neutron stars with a barotropic core in magnetohydrodynamic (MHD) equilibrium and a magneto-elastic crust, which was neglected by previous studies concerning stars in MHD equilibrium. The Lorentz force of the barotropic star is purely irrotational and the structures of magnetic fields are constrained. By contrast, a solenoidal component of the Lorentz force exists in the elastic crust and the structures of the magnetic fields are less restricted. We find that the minor solenoidal component in the elastic crust is important for sustaining the strong magnetic field in the core. Unlike previous studies, the toroidal magnetic field exists in the entire region of the core, and we obtain equilibrium states with large toroidal magnetic fields, where the toroidal magnetic energy is larger than the poloidal magnetic energy. The elastic force of the crust sustains an order of $10^{15}~\mathrm{G}$ toroidal magnetic field in the core, and the maximum strength of the toroidal magnetic field is approximately proportional to the crust thickness. 	
Bra-ket wormholes and Casimir entropy	http://arxiv.org/abs/2212.08246v1	2022-12-16T02:25:35Z	2022-12-16T02:25:35Z	  Bra-ket wormholes are non-trivial saddles in Euclidean gravity. They have to be sustained by negative Casimir energy of matter fields inside the throat. However, Casimir energy is very sensitive to boundary conditions and in presence of gauge symmetries one has to integrate over all possible boundary conditions for the matter fields, as they are a part of bra-ket wormhole moduli. For non- Abelian gauge groups the corresponding measure for the boundary conditions, which we call Casimir entropy, is non-trivial and it competes with the Casimir energy. We find that for large gauge groups this significantly affects the bra-ket wormhole action and modifies the phase diagram. Despite that, we do not find any violations of strong subadditivity in the setup proposed by Chen, Gorbenko and Maldacena. 	
"On the synergy between easier plasma operation and affordable coil-set
  requirements enabled by Negative Triangularity in the prospective ARC fusion
  reactor"	http://arxiv.org/abs/2212.08218v1	2022-12-16T01:11:05Z	2022-12-16T01:11:05Z	  A numerical workflow is developed to explore the viability of running multiple plasma configurations in the ARC fusion pilot plant. Suitable cost functions for various poloidal field coil sets are evaluated based on currents required in the coils, induced stresses, and flexibility in plasma configurations. It is shown, for the first time, that a given set of poloidal field coils can sustain equilibria with both signs of triangularity and that equilibria at Negative Triangularity have comparable coil requirements to those at Positive Triangularity, despite ARC's Positive Triangularity design equilibrium. These results contribute to demonstrate that the Negative Triangularity Tokamak is a promising candidate for the commercialization of fusion power. 	
"QF-MAC: Adaptive, Local Channel Hopping for Interference Avoidance in
  Wireless Meshes"	http://arxiv.org/abs/2212.08161v2	2023-01-22T18:32:55Z	2022-12-15T21:47:53Z	  The throughput efficiency of a wireless mesh network with potentially malicious external or internal interference can be significantly improved by equipping routers with multi-radio access over multiple channels. For reliably mitigating the effect of interference, frequency diversity (e.g., channel hopping) and time diversity (e.g., carrier sense multiple access) are conventionally leveraged to schedule communication channels. However, multi-radio scheduling over a limited set of channels to minimize the effect of interference and maximize network performance in the presence of concurrent network flows remains a challenging problem. The state-of-the-practice in channel scheduling of multi-radios reveals not only gaps in achieving network capacity but also significant communication overhead.   This paper proposes an adaptive channel hopping algorithm for multi-radio communication, QuickFire MAC (QF-MAC), that assigns per-node, per-flow ``local'' channel hopping sequences, using only one-hop neighborhood coordination. QF-MAC achieves a substantial enhancement of throughput and latency with low control overhead. QF-MAC also achieves robustness against network dynamics, i.e., mobility and external interference, and selective jamming attacker where a global channel hopping sequence (e.g., TSCH) fails to sustain the communication performance. Our simulation results quantify the performance gains of QF-MAC in terms of goodput, latency, reliability, communication overhead, and jamming tolerance, both in the presence and absence of mobility, across diverse configurations of network densities, sizes, and concurrent flows. 	
"Minimally driven Kapitza oscillator: A pedagogical perspective from
  Newtonian mechanics and geometry"	http://arxiv.org/abs/2212.09502v1	2022-12-15T20:59:41Z	2022-12-15T20:59:41Z	  The unstable top-equilibrium point of a simple pendulum turns stable when its pivot point is given a fast and strong enough vertical vibration. Known as the Kapitza oscillator, it has four symmetrically spaced points of equilibrium in absence of gravity, out of which two are stable and two are unstable. This article, completely based on a geometric argument and an elementary intuition in Newtonian mechanics, is a visual and pedagogical exposition of (a) why the oscillator has four symmetrically spaced equilibrium points in absence of gravity, (b) which of them are stable or unstable, (c) why they are so and (d) how the stability and position and number of the equilibrium points change when gravity is turned on gradually along the line of vibration of the pivot of the oscillator. A minimal impulsive drive of the pivot is sufficient to illustrate the bare bones of the phenomenon. I propose a construction that can sustain the minimal drive passively in absence of dissipative forces, or actively if all dissipative forces can't be eliminated. In either of the cases, the discussed arguments apply. 	
"Gas accretion onto Jupiter mass planets in discs with laminar accretion
  flows"	http://arxiv.org/abs/2212.08012v1	2022-12-15T18:17:11Z	2022-12-15T18:17:11Z	  (Abridged) Studies have shown that a Jovian mass planet embedded in a viscous protoplanetary disc (PPD) can accrete gas efficiently through the gap and doubles its mass in $\sim 0.1$ Myr. The planet also migrates inwards on a timescale of $\sim 0.1$ Myr. These timescales are short compared to PPD lifetimes, and raise questions about the origins of cold giant exoplanets. However, PPDs are unlikely to be globally turbulent, and instead they may launch magnetised winds such that accretion towards the star occurs in laminar accretion flows located in narrow layers near the surfaces of the disc. The aim of this study is to examine the rate at which gas accretes onto Jovian mass planets that are embedded in layered PPDs. We use 3D hydrodynamical simulations of planets embedded in PPDs, in which a constant radial mass flux towards the star of ${\dot m} = 10^{-8}$ M$_{\odot}$ yr$^{-1}$ is sustained. We consider a classical viscous alpha model, and also models in which an external torque is applied in narrow surface layers to mimic the effects of a magnetised wind. The accreting layers are parameterised by their column densities $\Sigma_{\rm A}$, and we consider values in the range 0.1 to 10 g cm$^{-2}$. The viscous model gives results in agreement with previous studies. We find the accretion rate onto the planet in the layered models crucially depends on the planet's ability to block the wind-induced mass flow. For $\Sigma_{\rm A}=10$ g cm$^{-2}$, the planet torque can block the mass flow through the disc, accretion onto the planet is slow, and a mass doubling time of 10 Myr is obtained. For $\Sigma_{\rm A}=0.1$ g cm$^{-2}$, accretion is fast and the mass doubling time is 0.2 Myr. Although the radial mass flow through the layered disc models is always $10^{-8}$ M$_{\odot}$ yr$^{-1}$, adopting different values of $\Sigma_{\rm A}$ leads to very different gas accretion rates onto gas giant planets. 	
"The First IEEE UV2022 Mathematical Modelling Competition: Backgrounds
  and Problems"	http://arxiv.org/abs/2212.07903v1	2022-12-15T15:37:17Z	2022-12-15T15:37:17Z	  Economic growth, people's health, and urban development face challenges in the post-epidemic era. How to promote high-quality and sustainable urban development, improve citizens' sense of happiness, and solve problems in city management have become a heated and crucial topic. Mathematical modeling is a research method that uses mathematical symbols to express practical problems, establish mathematical models, and then propose solutions. The $1^{s t}$ IEEE UV2022 Mathematical Modelling Competition is a satellite activity of the $6^{t h}$ IEEE International Conference on Universal Village, which expects participants to use mathematical modeling methods for practical problems and provide guidelines for sustainable social progress. This short paper introduces the background of the competition and publishes the problems to be solved. 	
"Comparison between the HUBCAP and DIGITBrain Platforms for Model-Based
  Design and Evaluation of Digital Twins"	http://arxiv.org/abs/2212.07829v1	2022-12-15T13:39:15Z	2022-12-15T13:39:15Z	  Digital twin technology is an essential approach to managing the lifecycle of industrial products. Among the many approaches used to manage digital twins, co-simulation has proven to be a reliable one. There have been multiple attempts to create collaborative and sustainable platforms for management of digital twins. This paper compares two such platforms, namely the HUBCAP and the DIGITbrain. Both these platforms have been and continue to be used among a stable group of researchers and industrial product manufacturers of digital twin technologies. This comparison of the HUBCAP and the DIGITbrain platforms is illustrated with an example use case of industrial factory to be used for manufacturing of agricultural robots. 	
"DOPAMINE: Doppler frequency and Angle of arrival MINimization of
  tracking Error for extended reality"	http://arxiv.org/abs/2212.07764v1	2022-12-15T12:33:47Z	2022-12-15T12:33:47Z	  In this paper, we investigate how Joint Communication And Sensing (JCAS) can be used to improve the Inertial Measurement Unit (IMU)- based tracking accuracy of eXtended Reality (XR) Head-Mounted Displays (HMDs). Such tracking is used when optical and InfraRed (IR) tracking is lost, and its lack of accuracy can lead to disruption of the user experience. In particular, we analyze the impact of using doppler-based speed estimation to aid the accelerometer-based position estimation, and Angle of Arrival (AoA) estimation to aid the gyroscope-based orientation estimation. Although less accurate than IMUs for short times in fact, the JCAS based methods require one fewer integration step, making the tracking more sustainable over time. Based on the proposed model, we conclude that at least in the case of the position estimate, introducing JCAS can make long lasting optical/IR tracking losses more sustainable. 	
"The omnidirectional receiver for UWOC systems based on the diffractive
  deep neural network"	http://arxiv.org/abs/2212.07759v1	2022-12-15T12:23:45Z	2022-12-15T12:23:45Z	  The link alignment requirement in underwater wireless optical communication (UWOC) systems is a knotty problem. The diffractive deep neural network (D2NN) has shown great potential in accomplishing tasks all optically these years. In this paper, an omnidirectional receiver based on 7-layer D2NN is first proposed to alleviate the link alignment difficulties in UWOC systems. In addition, the vectorial diffraction theory is introduced into the training of the D2NN to obtain more accurate diffraction calculations compared with the prevalently adopted scalar diffraction theory. Simulation results verify the validity of the vectorial diffraction theory and demonstrate that the presented method can focus incident light waves with tilt angles from 0 to 89 degrees in a 6.25% area of the detection plane with an average focusing efficiency of 90.96%, proving the feasibility of omnidirectional focusing at the receiver end. Extra simulations further reveal that more layers do not lead to a sustained performance improvement but rather reach a bottleneck, and the D2NN can achieve omnidirectional focusing with a certain range of focusing region size. With more effort, the proposed receiver design, which can be highly integrated with detectors, holds promise to realize both omnidirectional and reliable link establishment in UWOC systems in the future. 	
"Inequality, Crime and Public Health: A Survey of Emerging Trends in
  Urban Data Science"	http://arxiv.org/abs/2212.07676v1	2022-12-15T09:20:51Z	2022-12-15T09:20:51Z	  Urban agglomerations are constantly and rapidly evolving ecosystems, with globalization and increasing urbanization posing new challenges in sustainable urban development well summarized in the United Nations' Sustainable Development Goals (SDGs). The advent of the digital age generated by modern alternative data sources provides new tools to tackle these challenges with spatio-temporal scales that were previously unavailable with census statistics. In this review, we present how new digital data sources are employed to provide data-driven insights to study and track (i) urban crime and public safety; (ii) socioeconomic inequalities and segregation; and (iii) public health, with a particular focus on the city scale. 	
"Surrogate-assisted level-based learning evolutionary search for heat
  extraction optimization of enhanced geothermal system"	http://arxiv.org/abs/2212.07666v3	2022-12-19T01:42:59Z	2022-12-15T08:43:09Z	  An enhanced geothermal system is essential to provide sustainable and long-term geothermal energy supplies and reduce carbon emissions. Optimal well-control scheme for effective heat extraction and improved heat sweep efficiency plays a significant role in geothermal development. However, the optimization performance of most existing optimization algorithms deteriorates as dimension increases. To solve this issue, a novel surrogate-assisted level-based learning evolutionary search algorithm (SLLES) is proposed for heat extraction optimization of enhanced geothermal system. SLLES consists of classifier-assisted level-based learning pre-screen part and local evolutionary search part. The cooperation of the two parts has realized the balance between the exploration and exploitation during the optimization process. After iteratively sampling from the design space, the robustness and effectiveness of the algorithm are proven to be improved significantly. To the best of our knowledge, the proposed algorithm holds state-of-the-art simulation-involved optimization framework. Comparative experiments have been conducted on benchmark functions, a two-dimensional fractured reservoir and a three-dimensional enhanced geothermal system. The proposed algorithm outperforms other five state-of-the-art surrogate-assisted algorithms on all selected benchmark functions. The results on the two heat extraction cases also demonstrate that SLLES can achieve superior optimization performance compared with traditional evolutionary algorithm and other surrogate-assisted algorithms. This work lays a solid basis for efficient geothermal extraction of enhanced geothermal system and sheds light on the model management strategies of data-driven optimization in the areas of energy exploitation. 	
"SMACv2: An Improved Benchmark for Cooperative Multi-Agent Reinforcement
  Learning"	http://arxiv.org/abs/2212.07489v1	2022-12-14T20:15:19Z	2022-12-14T20:15:19Z	  The availability of challenging benchmarks has played a key role in the recent progress of machine learning. In cooperative multi-agent reinforcement learning, the StarCraft Multi-Agent Challenge (SMAC) has become a popular testbed for centralised training with decentralised execution. However, after years of sustained improvement on SMAC, algorithms now achieve near-perfect performance. In this work, we conduct new analysis demonstrating that SMAC is not sufficiently stochastic to require complex closed-loop policies. In particular, we show that an open-loop policy conditioned only on the timestep can achieve non-trivial win rates for many SMAC scenarios. To address this limitation, we introduce SMACv2, a new version of the benchmark where scenarios are procedurally generated and require agents to generalise to previously unseen settings (from the same distribution) during evaluation. We show that these changes ensure the benchmark requires the use of closed-loop policies. We evaluate state-of-the-art algorithms on SMACv2 and show that it presents significant challenges not present in the original benchmark. Our analysis illustrates that SMACv2 addresses the discovered deficiencies of SMAC and can help benchmark the next generation of MARL methods. Videos of training are available at https://sites.google.com/view/smacv2 	
"Entanglement entropy distinguishes PT-symmetry and topological phases in
  a class of non-unitary quantum walks"	http://arxiv.org/abs/2212.07453v1	2022-12-14T19:01:15Z	2022-12-14T19:01:15Z	  We calculate the hybrid entanglement entropy between coin and walker degrees of freedom in a non-unitary quantum walk. The model possesses a joint parity and time-reversal symmetry or PT-symmetry and supports topological phases when this symmetry is unbroken by its eigenstates. An asymptotic analysis at long times reveals that the quantum walk can indefinitely sustain hybrid entanglement in the unbroken symmetry phase even when gain and loss mechanisms are present. However, when the gain-loss strength is too large, the PT-symmetry of the model is spontaneously broken and entanglement vanishes. The entanglement entropy is therefore an effective and robust parameter for constructing PT-symmetry and topological phase diagrams in this non-unitary dynamical system. 	
API-Spector: an API-to-API Specification Recommendation Engine	http://arxiv.org/abs/2212.07253v1	2022-12-14T14:43:51Z	2022-12-14T14:43:51Z	  When designing a new API for a large project, developers need to make smart design choices so that their code base can grow sustainably. To ensure that new API components are well designed, developers can learn from existing API components. However, the lack of standardized method for comparing API designs makes this learning process time-consuming and difficult. To address this gap we developed the API-Spector, to the best of our knowledge one of the first API-to-API specification recommendation engines. API-Spector retrieves relevant specification components written in OpenAPI (a widely adopted language used to describe web APIs). API-Spector presents several significant contributions, including: (1) novel methods of processing and extracting key information from OpenAPI specifications, (2) innovative feature extraction techniques that are optimized for the highly technical API specification domain, and (3) a novel log-linear probabilistic model that combines multiple signals to retrieve relevant and high quality OpenAPI specification components given a query specification. We evaluate API-Spector in both quantitative and qualitative tasks and achieve an overall of 91.7% recall@1 and 56.2% F1, which surpasses baseline performance by 15.4% in recall@1 and 3.2% in F1. Overall, API-Spector will allow developers to retrieve relevant OpenAPI specification components from a public or internal database in the early stages of the API development cycle, so that they can learn from existing established examples and potentially identify redundancies in their work. It provides the guidance developers need to accelerate development process and contribute thoughtfully designed APIs that promote code maintainability and quality. 	
"Tactile Network Resource Allocation enabled by Quantum Annealing based
  on ILP Modeling"	http://arxiv.org/abs/2212.07854v1	2022-12-14T14:12:03Z	2022-12-14T14:12:03Z	  Agile networks with fast adaptation and reconfiguration capabilities are required for sustainable provisioning of high-quality services with high availability. We propose a new methodical framework for short-time network control based on quantum computing (QC) and integer linear program (ILP) models, which has the potential of realizing a real-time network automation. Finally, we study the approach's feasibility with the state-of-the-art quantum annealer D-Wave Advantage 5.2 in case of an example network and provide scaling estimations for larger networks. We embed network problems in quadratic unconstrained binary optimization (QUBO) form for networks of up to 6 nodes. We further find annealing parameters that obtain feasible solutions that are close to a reference solution obtained by classical ILP-solver. We estimate, that a real-sized network with 12 to 16 nodes require a quantum annealing (QA) hardware with at least 50000 qubits or more. 	
"Data-Driven Prediction and Evaluation on Future Impact of Energy
  Transition Policies in Smart Regions"	http://arxiv.org/abs/2212.07019v1	2022-12-14T04:19:34Z	2022-12-14T04:19:34Z	  To meet widely recognised carbon neutrality targets, over the last decade metropolitan regions around the world have implemented policies to promote the generation and use of sustainable energy. Nevertheless, there is an availability gap in formulating and evaluating these policies in a timely manner, since sustainable energy capacity and generation are dynamically determined by various factors along dimensions based on local economic prosperity and societal green ambitions. We develop a novel data-driven platform to predict and evaluate energy transition policies by applying an artificial neural network and a technology diffusion model. Using Singapore, London, and California as case studies of metropolitan regions at distinctive stages of energy transition, we show that in addition to forecasting renewable energy generation and capacity, the platform is particularly powerful in formulating future policy scenarios. We recommend global application of the proposed methodology to future sustainable energy transition in smart regions. 	
"Shock impingement on a transitional hypersonic high-enthalpy boundary
  layer"	http://arxiv.org/abs/2212.06939v1	2022-12-13T23:18:04Z	2022-12-13T23:18:04Z	  The dynamics of a shock wave impinging on a transitional high-enthalpy boundary layer out of thermochemical equilibrium is investigated for the first time by means of a direct numerical simulation. The freestream Mach number is equal to 9 and the oblique shock impinges with a cooled flat-plate boundary layer with an angle of 10{\deg}, generating a reversal flow region. In conjunction with freestream disturbances, the shock impingement triggers a transition to a fully turbulent regime shortly downstream of the interaction region. Accordingly, wall properties emphasize the presence of a laminar region, a recirculation bubble, a transitional zone and fully turbulent region. The breakdown to turbulence is characterized by an anomalous increase of skin friction and wall heat flux, due to the particular shock pattern. At the considered thermodynamic conditions the flow is found to be in a state of thermal non-equilibrium throughout, with non-equilibrium effects enhanced and sustained by the shock-induced laminar/turbulent transition, while chemical activity is almost negligible due to wall cooling. In the interaction region, relaxation towards thermal equilibrium is delayed and the fluctuating values of the rototranslational and the vibrational temperatures strongly differ, despite the strong wall-cooling. The fully turbulent portion exhibits evolutions of streamwise velocity, Reynolds stresses and turbulent Mach number in good accordance with previous results for highly-compressible cooled-wall boundary layers in thermal nonequilibrium, with turbulent motions sustaining thermal nonequilibrium. Nevertheless, the vibrational energy is found to contribute little to the total wall heat flux. 	
Quasars and the Intergalactic Medium at Cosmic Dawn	http://arxiv.org/abs/2212.06907v1	2022-12-13T21:20:23Z	2022-12-13T21:20:23Z	  Quasars at cosmic dawn provide powerful probes of the formation and growth of the earliest supermassive black holes (SMBHs) in the universe, their connections to galaxy and structure formation, and the evolution of the intergalactic medium (IGM) at the epoch of reionization (EoR). Hundreds of quasars have been discovered in the first billion years of cosmic history, with the quasar redshift frontier extended to z~7.6. Observations of quasars at cosmic dawn show that: (1) The number density of luminous quasars declines exponentially at z>5, suggesting that the earliest quasars emerge at z~10; the lack of strong evolution in their average spectral energy distribution indicates a rapid buildup of the AGN environment. (2) Billion-solar-mass BHs already exist at z>7.5; they must form and grow in less than 700 Myr, by a combination of massive early BH seeds with highly efficient and sustained accretion. (3) The rapid quasar growth is accompanied by strong star formation and feedback activity in their host galaxies, which show diverse morphological and kinetic properties, with typical dynamical mass of lower than that implied by the local BH/galaxy scaling relations. (4) HI absorption in quasar spectra probes the tail end of cosmic reionization at z~5.3-6, and indicates the EoR midpoint at 6.9 < z < 7.6 with large spatial fluctuations in IGM ionization. Observations of heavy element absorption lines suggest that the circumgalactic medium also experiences evolution in its ionization structure and metal enrichment during the EoR. 	
Generative methods for Urban design and rapid solution space exploration	http://arxiv.org/abs/2212.06783v1	2022-12-13T17:58:02Z	2022-12-13T17:58:02Z	  Rapid population growth and climate change drive urban renewal and urbanization at massive scales. New computational methods are needed to better support urban designers in developing sustainable, resilient, and livable urban environments. Urban design space exploration and multi-objective optimization of masterplans can be used to expedite planning while achieving better design outcomes by incorporating generative parametric modeling considering different stakeholder requirements and simulation-based performance feedback. However, a lack of generalizable and integrative methods for urban form generation that can be coupled with simulation and various design performance analysis constrain the extensibility of workflows. This research introduces an implementation of a tensor-field-based generative urban modeling toolkit that facilitates rapid design space exploration and multi-objective optimization by integrating with Rhino/Grasshopper ecosystem and its urban analysis and environmental performance simulation tools. Our tensor-field modeling method provides users with a generalized way to encode contextual constraints such as waterfront edges, terrain, view-axis, existing streets, landmarks, and non-geometric design inputs such as network directionality, desired densities of streets, amenities, buildings, and people as forces that modelers can weigh. This allows users to generate many, diverse urban fabric configurations that resemble real-world cities with very few model inputs. We present a case study to demonstrate the proposed framework's flexibility and applicability and show how modelers can identify design and environmental performance synergies that would be hard to find otherwise 	
"The gateway from Centaurs to Jupiter-family Comets: thermal and
  dynamical evolution"	http://arxiv.org/abs/2212.06637v1	2022-12-13T15:15:38Z	2022-12-13T15:15:38Z	"  It was recently proposed that there exists a ""gateway"" in the orbital parameter space through which Centaurs transition to Jupiter-family Comets (JFCs). Further studies have implied that the majority of objects that eventually evolve into JFCs should leave the Centaur population through this gateway. This may be naively interpreted as gateway Centaurs being pristine progenitors of JFCs. This is the point we want to address in this work. We show that the opposite is true: gateway Centaurs are, on average, more thermally processed than the rest of the population of Centaurs crossing Jupiter's orbit. Using a dynamically-validated JFC population, we find that only $\sim 20\%$ of Centaurs pass through the gateway prior to becoming JFCs, in accordance with previous studies. We show that more than half of JFC dynamical clones entering the gateway for the first time have already been JFCs -they simply avoided the gateway on their first pass into the inner solar system. By coupling a thermal evolution model to the orbital evolution of JFC dynamical clones, we find a higher than 50\% chance that the layer currently contributing to the observed activity of gateway objects has been physically and chemically altered, due to previously sustained thermal processing. We further illustrate this effect by examining dynamical clones that match the present-day orbits of 29P/Schwassmann-Wachmann 1, P/2019 LD2 (ATLAS), and P/2008 CL94 (Lemmon). "	
"Automatic ESG Assessment of Companies by Mining and Evaluating Media
  Coverage Data: NLP Approach and Tool"	http://arxiv.org/abs/2212.06540v1	2022-12-13T12:51:14Z	2022-12-13T12:51:14Z	  Context: Sustainable corporate behavior is increasingly valued by society and impacts corporate reputation and customer trust. Hence, companies regularly publish sustainability reports to shed light on their impact on environmental, social, and governance (ESG) factors. Problem: Sustainability reports are written by companies themselves and are therefore considered a company-controlled source. Contrary, studies reveal that non-corporate channels (e.g., media coverage) represent the main driver for ESG transparency. However, analysing media coverage regarding ESG factors is challenging since (1) the amount of published news articles grows daily, (2) media coverage data does not necessarily deal with an ESG-relevant topic, meaning that it must be carefully filtered, and (3) the majority of media coverage data is unstructured. Research Goal: We aim to extract ESG-relevant information from textual media reactions automatically to calculate an ESG score for a given company. Our goal is to reduce the cost of ESG data collection and make ESG information available to the general public. Contribution: Our contributions are three-fold: First, we publish a corpus of 432,411 news headlines annotated as being environmental-, governance-, social-related, or ESG-irrelevant. Second, we present our tool-supported approach called ESG-Miner capable of analyzing and evaluating headlines on corporate ESG-performance automatically. Third, we demonstrate the feasibility of our approach in an experiment and apply the ESG-Miner on 3000 manually labeled headlines. Our approach processes 96.7 % of the headlines correctly and shows a great performance in detecting environmental-related headlines along with their correct sentiment. We encourage fellow researchers and practitioners to use the ESG-Miner at https://www.esg-miner.com. 	
Cosmic rays as a feedback agent in primordial galactic ecosystems	http://arxiv.org/abs/2212.06469v1	2022-12-13T10:39:16Z	2022-12-13T10:39:16Z	  High-redshift primordial galaxies have recently been found with evolved stellar populations and complex star-formation histories reaching back to 250 Myr after the Big Bang. Their intense bursts of star-formation appear to be interspersed with sustained periods of strong quenching, however the processes underlying this evolutionary behaviour remain unclear. Unlike later epochs, galaxies in the early Universe are not located in large associations like clusters. Instead, they co-evolve with their developing circumgalactic halo as relatively isolated ecosystems. Thus, the mechanisms that could bring about the downfall of their star-formation are presumably intrinsic, and feedback processes associated with their intense starburst episodes likely play an important role. Cosmic rays are a viable agent to deliver this feedback, and could account for the star-formation histories inferred for these systems. The cosmic ray impact on galaxies may be investigated using the wealth of multi-wavelength data soon to be obtained with the armada of new and upcoming facilities. Complementary approaches to probe their action across the electromagnetic spectrum can be arranged into a distance ladder of cosmic ray feedback signatures. With a clear understanding of how cosmic ray activity in primordial systems can be traced, it will be possible to extend this ladder to high redshifts and map-out the role played by cosmic rays in shaping galaxy evolution over cosmic time. 	
"Airline service quality ranking based on combined TOPSIS-VIKOR-AISM
  model"	http://arxiv.org/abs/2212.06332v3	2023-01-18T01:55:54Z	2022-12-13T02:30:35Z	  The service quality ranking of airlines is a crucial factor for their sustainability in the intensely competitive airline market. This study intends to offer further insights in this field to produce simpler and explanatory results, however previous studies have been lacking in terms of sample size, efficiency, and reliability. In order to develop an airline service quality evaluation system that incorporates customer utilities, ideal points, and regret values and performs a confrontation hierarchy topology analysis based on the computation of compromise solutions, the TOPSIS-VIKOR-AISM model is proposed in this work. In addition to supporting consumer choice and airline development, this study offers fresh perspectives on how to assess the effectiveness of airlines and other industries. 	
"Mist and Edge Computing Cyber-Physical Human-Centered Systems for
  Industry 5.0: A Cost-Effective IoT Thermal Imaging Safety System"	http://arxiv.org/abs/2212.06294v1	2022-12-13T00:22:38Z	2022-12-13T00:22:38Z	  While many companies worldwide are still striving to adjust to Industry 4.0 principles, the transition to Industry 5.0 is already underway. Under such a paradigm, Cyber-Physical Human-centered Systems (CPHSs) have emerged to leverage operator capabilities in order to meet the goals of complex manufacturing systems towards human-centricity, resilience and sustainability. This article first describes the essential concepts for the development of Industry 5.0 CPHSs and then analyzes the latest CPHSs, identifying their main design requirements and key implementation components. Moreover, the major challenges for the development of such CPHSs are outlined. Next, to illustrate the previously described concepts, a real-world Industry 5.0 CPHS is presented. Such a CPHS enables increased operator safety and operation tracking in manufacturing processes that rely on collaborative robots and heavy machinery. Specifically, the proposed use case consists of a workshop where a smarter use of resources is required, and human proximity detection determines when machinery should be working or not in order to avoid incidents or accidents involving such machinery. The proposed CPHS makes use of a hybrid edge computing architecture with smart mist computing nodes that processes thermal images and reacts to prevent industrial safety issues. The performed experiments show that, in the selected real-world scenario, the developed CPHS algorithms are able to detect human presence with low-power devices (with a Raspberry Pi 3B) in a fast and accurate way (in less than 10 ms with a 97.04% accuracy), thus being an effective solution that can be integrated into many Industry 5.0 applications. Finally, this article provides specific guidelines that will help future developers and managers to overcome the challenges that will arise when deploying the next generation of CPHSs for smart and sustainable manufacturing. 	
"Robust modelling framework for short-term forecasting of global
  horizontal irradiance"	http://arxiv.org/abs/2212.05978v1	2022-12-12T15:36:31Z	2022-12-12T15:36:31Z	  The increasing demand for electricity and the need for clean energy sources have increased solar energy use. Accurate forecasts of solar energy are required for easy management of the grid. This paper compares the accuracy of two Gaussian Process Regression (GPR) models combined with Additive Quantile Regression (AQR) and Bayesian Structural Time Series (BSTS) models in the 2-day ahead forecasting of global horizontal irradiance using data from the University of Pretoria from July 2020 to August 2021. Four methods were adopted for variable selection, Lasso, ElasticNet, Boruta, and GBR (Gradient Boosting Regression). The variables selected using GBR were used because they produced the lowest MAE (Minimum Absolute Errors) value. A comparison of seven models GPR (Gaussian Process Regression), Two-layer DGPR (Two-layer Deep Gaussian Process Regression), bstslong (Bayesian Structural Time Series long), AQRA (Additive Quantile Regression Averaging), QRNN(Quantile Regression Neural Network), PLAQR(Partial Linear additive Quantile Regression), and Opera(Online Prediction by ExpRt Aggregation) was made. The evaluation metrics used to select the best model were the MAE (Mean Absolute Error) and RMSE (Root Mean Square Error). Further evaluations were done using proper scoring rules and Murphy diagrams. The best individual model was found to be the GPR. The best forecast combination was AQRA ((AQR Averaging) based on MAE. However, based on RMSE, GPNN was the best forecast combination method. Companies such as Eskom could use the methods adopted in this study to control and manage the power grid. The results will promote economic development and sustainability of energy resources. 	
"Flexibility Characterization of Sustainable Power Systems in Demand
  Space: A Data-Driven Inverse Optimization Approach"	http://arxiv.org/abs/2212.05963v1	2022-12-12T15:18:44Z	2022-12-12T15:18:44Z	  The deepening of the penetration of renewable energy is challenging how power system operators cope with their associated variability and uncertainty. The inherent flexibility of dispathchable assets present in power systems, which is often ill-characterized, is essential in addressing this challenge. Several proposals for explicit flexibility characterization focus on defining a feasible region that secures operations either in generation or uncertainty spaces. The main drawback of these approaches is the difficulty in visualizing this feasibility region when there are multiple uncertain parameters. Moreover, these approaches focus on system operational constraints and often neglect the impact of inherent couplings (e.g., spatial correlation) of renewable generation and demand variability. To address these challenges, we propose a novel data-driven inverse optimization framework for flexibility characterization of power systems in the demand space along with its geometric intuition. The approach captures the spatial correlation of multi-site renewable generation and load using polyhedral uncertainty sets. Moreover, the framework projects the uncertainty on the feasibility region of power systems in the demand space, which are also called loadability sets. The proposed inverse optimization scheme, recast as a linear optimization problem, is used to infer system flexibility adequacy from loadability sets. 	
"Forecasting Soil Moisture Using Domain Inspired Temporal Graph
  Convolution Neural Networks To Guide Sustainable Crop Management"	http://arxiv.org/abs/2212.06565v1	2022-12-12T14:36:39Z	2022-12-12T14:36:39Z	  Climate change, population growth, and water scarcity present unprecedented challenges for agriculture. This project aims to forecast soil moisture using domain knowledge and machine learning for crop management decisions that enable sustainable farming. Traditional methods for predicting hydrological response features require significant computational time and expertise. Recent work has implemented machine learning models as a tool for forecasting hydrological response features, but these models neglect a crucial component of traditional hydrological modeling that spatially close units can have vastly different hydrological responses. In traditional hydrological modeling, units with similar hydrological properties are grouped together and share model parameters regardless of their spatial proximity. Inspired by this domain knowledge, we have constructed a novel domain-inspired temporal graph convolution neural network. Our approach involves clustering units based on time-varying hydrological properties, constructing graph topologies for each cluster, and forecasting soil moisture using graph convolutions and a gated recurrent neural network. We have trained, validated, and tested our method on field-scale time series data consisting of approximately 99,000 hydrological response units spanning 40 years in a case study in northeastern United States. Comparison with existing models illustrates the effectiveness of using domain-inspired clustering with time series graph neural networks. The framework is being deployed as part of a pro bono social impact program. The trained models are being deployed on small-holding farms in central Texas. 	
A Bit Stream Feature-Based Energy Estimator for HEVC Software Encoding	http://arxiv.org/abs/2212.05609v1	2022-12-11T21:48:55Z	2022-12-11T21:48:55Z	  The total energy consumption of today's video coding systems is globally significant and emphasizes the need for sustainable video coder applications. To develop such sustainable video coders, the knowledge of the energy consumption of state-of-the-art video coders is necessary. For that purpose, we need a dedicated setup that measures the energy of the encoding and decoding system. However, such measurements are costly and laborious. To this end, this paper presents an energy estimator that uses a subset of bit stream features to accurately estimate the energy consumption of the HEVC software encoding process. The proposed model reaches a mean estimation error of 4.88% when averaged over presets of the x265 encoder implementation. The results from this work help to identify properties of encoding energy-saving bit streams and, in turn, are useful for developing new energy-efficient video coding algorithms. 	
"Exact results for sheared polar active suspensions with variable liquid
  crystalline order"	http://arxiv.org/abs/2212.05534v1	2022-12-11T16:10:46Z	2022-12-11T16:10:46Z	  We consider a confined sheared active polar liquid crystal with a uniform orientation and study the effect of variations in the magnitude of polarization. Restricting our analysis to one-dimensional geometries, we demonstrate that with asymmetric boundary conditions, this system is characterized, macroscopically, by a linear shear stress vs. shear strain relationship that does not pass through the origin: At a zero strain rate, the fluid sustains a non-zero stress. Analytic solutions for the polarization, density, and velocity fields are derived for asymptotically large or small systems and are shown by comparison with precise numerical solutions to be good approximations for finite-size systems. 	
"Exploring non-residential technology adoption: an empirical analysis of
  factors associated with the adoption of photovoltaic systems by municipal
  authorities in Germany"	http://arxiv.org/abs/2212.05281v1	2022-12-10T11:49:33Z	2022-12-10T11:49:33Z	  This research article explores potential influencing factors of solar photovoltaic (PV) system adoption by municipal authorities in Germany in the year 2019. We derive seven hypothesized relationships from the empirical literature on residential PV adoption, organizational technology adoption, and sustainability policy adoption by local governments, and apply a twofold empirical approach to examine them. First, we explore the associations of a set of explanatory variables on the installed capacity of adopter municipalities (N=223) in an OLS model. Second, we use a logit model to analyze whether the identified relationships are also apparent between adopter and non-adopter municipalities (N=423). Our findings suggest that fiscal capacity (measured by per capita debt and per capita tax revenue) and peer effects (measured by the pre-existing installed capacity) are positively associated with both the installed capacity and adoption. Furthermore, we find that institutional capacity (measured by the presence of a municipal utility) and environmental concern (measured by the share of green party votes) are positively associated with municipal PV adoption. Economic factors (measured by solar irradiation) show a significant positive but small effect in both regression models. No evidence was found to support the influence of political will. Results for the role of municipal characteristics are mixed, although the population size was consistently positively associated with municipal PV adoption and installed capacity. Our results support previous studies on PV system adoption determinants and offer a starting point for additional research on non-residential decision-making and PV adoption. 	
"Analysis of Explainable Artificial Intelligence Methods on Medical Image
  Classification"	http://arxiv.org/abs/2212.10565v1	2022-12-10T06:17:43Z	2022-12-10T06:17:43Z	  The use of deep learning in computer vision tasks such as image classification has led to a rapid increase in the performance of such systems. Due to this substantial increment in the utility of these systems, the use of artificial intelligence in many critical tasks has exploded. In the medical domain, medical image classification systems are being adopted due to their high accuracy and near parity with human physicians in many tasks. However, these artificial intelligence systems are extremely complex and are considered black boxes by scientists, due to the difficulty in interpreting what exactly led to the predictions made by these models. When these systems are being used to assist high-stakes decision-making, it is extremely important to be able to understand, verify and justify the conclusions reached by the model. The research techniques being used to gain insight into the black-box models are in the field of explainable artificial intelligence (XAI). In this paper, we evaluated three different XAI methods across two convolutional neural network models trained to classify lung cancer from histopathological images. We visualized the outputs and analyzed the performance of these methods, in order to better understand how to apply explainable artificial intelligence in the medical domain. 	
"Walkability Optimization: Formulations, Algorithms, and a Case Study of
  Toronto"	http://arxiv.org/abs/2212.05192v1	2022-12-10T03:52:03Z	2022-12-10T03:52:03Z	"  The concept of walkable urban development has gained increased attention due to its public health, economic, and environmental sustainability benefits. Unfortunately, land zoning and historic under-investment have resulted in spatial inequality in walkability and social inequality among residents. We tackle the problem of Walkability Optimization through the lens of combinatorial optimization. The task is to select locations in which additional amenities (e.g., grocery stores, schools, restaurants) can be allocated to improve resident access via walking while taking into account existing amenities and providing multiple options (e.g., for restaurants). To this end, we derive Mixed-Integer Linear Programming (MILP) and Constraint Programming (CP) models. Moreover, we show that the problem's objective function is submodular in special cases, which motivates an efficient greedy heuristic. We conduct a case study on 31 underserved neighborhoods in the City of Toronto, Canada. MILP finds the best solutions in most scenarios but does not scale well with network size. The greedy algorithm scales well and finds near-optimal solutions. Our empirical evaluation shows that neighbourhoods with low walkability have a great potential for transformation into pedestrian-friendly neighbourhoods by strategically placing new amenities. Allocating 3 additional grocery stores, schools, and restaurants can improve the ""WalkScore"" by more than 50 points (on a scale of 100) for 4 neighbourhoods and reduce the walking distances to amenities for 75% of all residential locations to 10 minutes for all amenity types. Our code and paper appendix are available at https://github.com/khalil-research/walkability. "	
"Activity-Based Recommendations for Demand Response in Smart Sustainable
  Buildings"	http://arxiv.org/abs/2212.05173v1	2022-12-10T01:44:37Z	2022-12-10T01:44:37Z	  The energy consumption of private households amounts to approximately 30% of the total global energy consumption, causing a large share of the CO2 emissions through energy production. An intelligent demand response via load shifting increases the energy efficiency of residential buildings by nudging residents to change their energy consumption behavior. This paper introduces an activity prediction-based framework for the utility-based context-aware multi-agent recommendation system that generates an activity shifting schedule for a 24-hour time horizon to either focus on CO2 emissions or energy cost savings. In particular, we design and implement an Activity Agent that uses hourly energy consumption data. It does not require further sensorial data or activity labels which reduces implementation costs and the need for extensive user input. Moreover, the system enhances the utility option of saving energy costs by saving CO2 emissions and provides the possibility to focus on both dimensions. The empirical results show that while setting the focus on CO2 emissions savings, the system provides an average of 12% of emissions savings and 7% of cost savings. When focusing on energy cost savings, 20% of energy costs and 6% of emissions savings are possible for the studied households in case of accepting all recommendations. Recommending an activity schedule, the system uses the same terms residents describe their domestic life. Therefore, recommendations can be more easily integrated into daily life supporting the acceptance of the system in a long-term perspective. 	
"Constraining galactic baryon cycle using the galaxy stellar-to-halo mass
  relations"	http://arxiv.org/abs/2212.05007v1	2022-12-09T17:46:15Z	2022-12-09T17:46:15Z	  Galaxies display several well-behaved scaling relations between their properties, such as the star formation rate-stellar mass relation (the main sequence) and the stellar mass-halo mass relation (SHMR). In principle, these scaling relations could imply different star formation histories (SFHs) of galaxies and different constraints on galaxy formation physics. In this paper, we derive the SFHs of galaxies by assuming that they always follow the SHMRs at different redshifts and use an empirical model to constrain key processes in their baryon cycle. It is found that, besides cold accretion due to halo growth, outflow of gas produced by stellar feedback has to be recycled to sustain the derived SFHs of galaxies. The recycled fraction is strongly affected by the baryon fraction in accreted low-mass haloes and the mass loading factor which quantifies the ratio between the galactic outflow rate and star formation rate. Our fiducial model predicts that around $20-60\%$ of outflow is recycled in $\sim0.5-4Gyrs$, while simulations predict a slightly higher recycle fraction and a lower recycle time. We argue that strong constraints on the baryon cycle process can be obtained from future observation of the circum-galactic medium (CGM) of galaxies, such as the gas cooling rate of CGM. We also find that the implied SFHs from the SHMRs indicate that galaxies stay on the main sequences only for part of their lifetimes. Our model reproduces the evolution of the mass-metallicity relation as well. 	
"Self-sustaining Ultra-wideband Positioning System for Event-driven
  Indoor Localization"	http://arxiv.org/abs/2212.04896v1	2022-12-09T14:56:38Z	2022-12-09T14:56:38Z	  Smart and unobtrusive mobile sensor nodes that accurately track their own position have the potential to augment data collection with location-based functions. To attain this vision of unobtrusiveness, the sensor nodes must have a compact form factor and operate over long periods without battery recharging or replacement. This paper presents a self-sustaining and accurate ultra-wideband-based indoor location system with conservative infrastructure overhead. An event-driven sensing approach allows for balancing the limited energy harvested in indoor conditions with the power consumption of ultra-wideband transceivers. The presented tag-centralized concept, which combines heterogeneous system design with embedded processing, minimizes idle consumption without sacrificing functionality. Despite modest infrastructure requirements, high localization accuracy is achieved with error-correcting double-sided two-way ranging and embedded optimal multilateration. Experimental results demonstrate the benefits of the proposed system: the node achieves a quiescent current of $47~nA$ and operates at $1.2~\mu A$ while performing energy harvesting and motion detection. The energy consumption for position updates, with an accuracy of $40~cm$ (2D) in realistic non-line-of-sight conditions, is $10.84~mJ$. In an asset tracking case study within a $200~m^2$ multi-room office space, the achieved accuracy level allows for identifying 36 different desk and storage locations with an accuracy of over $95~{\%}$. The system`s long-time self-sustainability has been analyzed over $700~days$ in multiple indoor lighting situations. 	
"High-performance designs for fiber-pigtailed quantum-light sources based
  on quantum dots in electrically-controlled circular Bragg gratings"	http://arxiv.org/abs/2212.04883v1	2022-12-09T14:37:30Z	2022-12-09T14:37:30Z	  We present a numerical investigation of directly fiber-coupled hybrid circular Bragg gratings (CBGs) featuring electrical control for operation in the application relevant wavelength regimes around 930 nm as well as the telecom O- and C-band. We use a surrogate model combined with a Bayesian optimization approach to perform numerical optimization of the device performance which takes into account robustness with respect to fabrication tolerances. The proposed high-performance designs combine hCBGs with a dielectric planarization and a transparent contact material, enabling >86% direct fiber coupling efficiency (up to >93% efficiency into NA 0.8) while exhibiting Purcell Factors >20. Especially the proposed designs for the telecom range prove robust and can sustain expected fiber efficiencies of more than $(82.2\pm4.1)^{+2.2}_{-5.5}$% and expected average Purcell Factors of up to $(23.2\pm2.3)^{+3.2}_{-3.0}$ assuming conservative fabrication accuracies. The wavelength of maximum Purcell enhancement proves to be the most affected performance parameter by the deviations. Finally, we show that electrical field strengths suitable for Stark-tuning of an embedded quantum dot can be reached in the identified designs. 	
"5G on the Farm: Evaluating Wireless Network Capabilities for
  Agricultural Robotics"	http://arxiv.org/abs/2301.01600v1	2022-12-09T14:31:21Z	2022-12-09T14:31:21Z	  Global food security is an issue that is fast becoming a critical matter in the world today. Global warming, climate change and a range of other impacts caused by humans, such as carbon emissions, sociopolitical and economical challenges (e.g. war), traditional workforce/labour decline and population growth are straining global food security. The need for high-speed and reliable wireless communication in agriculture is becoming more of a necessity rather than a technological demonstration or showing superiority in the field. Governments and industries around the world are seeing more urgency in establishing communication infrastructure to scale up agricultural activities and improve sustainability, by employing autonomous agri-robotics and agri-technologies. The work presented here evaluates the physical performance of 5G in an agri-robotics application, and the results are compared against 4G and WiFi6 (a newly emerging wireless communication standard), which are typically used in agricultural environments. In addition, a series of simulation experiments were performed to assess the ``real-time'' operational delay in critical tasks that may require a human-in-the-loop to support decision making. The results lead to the conclusion that 4G cannot be used in the agricultural domain for applications that require high throughput and reliable communication between robot and user. Moreover, a single wireless solution does not exist for the agricultural domain, but instead multiple solutions can be combined to meet the necessary telecommunications requirements. Finally, the results show that 5G greatly outperforms 4G in all performance metrics, and on average only 18.2ms slower than WiFi6 making it very reliable. 	
"Meteorological conditions during Dunkelflauten in Germany:
  Characteristics, the role of weather regimes and impacts on demand"	http://arxiv.org/abs/2212.04870v1	2022-12-09T14:23:04Z	2022-12-09T14:23:04Z	  Renewable generation from wind and solar power is strongly weather-dependent. To plan future sustainable energy systems that are robust to this variability, a better understanding of why and when periods of low wind and solar power output occur is valuable. We call such periods of low wind and solar power output `Dunkelflauten', the German word for dark wind lulls. In this article, we analyse the meteorological conditions during Dunkelflauten in Germany by applying the concept of weather regimes. Weather regimes are quasi-stationary, recurrent, and persistent large-scale circulation patterns which explain multi-day atmospheric variability (5-15 days). We use a regime definition that allows us to distinguish four different types of blocked regimes, characterised by high pressure situations in the North Atlantic-European region. We find that in Germany, Dunkelflauten mainly occur in winter when the solar power output is anyway low and when the wind power output drops for several consecutive days. A high-pressure system over Germany, associated with the European Blocking regime, is responsible for most of the Dunkelflauten. Dunkelflauten during the Greenland Blocking regime are associated with colder temperatures than usual, causing higher electricity demand and presenting a particular challenge as space heating demand electrifies in future. Furthermore, we show that Dunkelflauten occur predominantly when a weather regime is well-established and persists longer than usual. Our study provides novel insight on the occurrence and meteorological characteristics of Dunkelflauten, which is essential for planning resilient energy systems and supporting grid operators to prepare for potential shortages in supply. 	
"Validating quantum-supremacy experiments with exact and fast tensor
  network contraction"	http://arxiv.org/abs/2212.04749v1	2022-12-09T10:01:02Z	2022-12-09T10:01:02Z	"  The quantum circuits that declare quantum supremacy, such as Google Sycamore [Nature \textbf{574}, 505 (2019)], raises a paradox in building reliable result references. While simulation on traditional computers seems the sole way to provide reliable verification, the required run time is doomed with an exponentially-increasing compute complexity. To find a way to validate current ``quantum-supremacy"" circuits with more than $50$ qubits, we propose a simulation method that exploits the ``classical advantage"" (the inherent ``store-and-compute"" operation mode of von Neumann machines) of current supercomputers, and computes uncorrelated amplitudes of a random quantum circuit with an optimal reuse of the intermediate results and a minimal memory overhead throughout the process. Such a reuse strategy reduces the original linear scaling of the total compute cost against the number of amplitudes to a sublinear pattern, with greater reduction for more amplitudes. Based on a well-optimized implementation of this method on a new-generation Sunway supercomputer, we directly verify Sycamore by computing three million exact amplitudes for the experimentally generated bitstrings, obtaining an XEB fidelity of $0.191\%$ which closely matches the estimated value of $0.224\%$. Our computation scales up to $41,932,800$ cores with a sustained single-precision performance of $84.8$ Pflops, which is accomplished within $8.5$ days. Our method has a far-reaching impact in solving quantum many-body problems, statistical problems as well as combinatorial optimization problems where one often needs to contract many tensor networks which share a significant portion of tensors in common. "	
"Automated Integration of Infrastructure Component Status for Real-Time
  Restoration Progress Control: Case Study of Highway System in Hurricane
  Harvey"	http://arxiv.org/abs/2212.04651v1	2022-12-09T03:43:40Z	2022-12-09T03:43:40Z	  Following extreme events, efficient restoration of infrastructure systems is critical to sustaining community lifelines. During the process, effective monitoring and control of the infrastructure restoration progress is critical. This research proposes a systematic approach that automatically integrates component-level restoration status to achieve real-time forecasting of overall infrastructure restoration progress. In this research, the approach is mainly designed for transportation infrastructure restoration following Hurricane Harvey. In detail, the component-level restoration status is linked to the restoration progress forecasting through network modeling and earned value method. Once the new component restoration status is collected, the information is automatically integrated to update the overall restoration progress forecasting. Academically, an approach is proposed to automatically transform the component-level restoration information to overall restoration progress. In practice, the approach expects to ease the communication and coordination efforts between emergency managers, thereby facilitating timely identification and resolution of issues for rapid infrastructure restoration. 	
"CBE Clima Tool: a free and open-source web application for climate
  analysis tailored to sustainable building design"	http://arxiv.org/abs/2212.04609v1	2022-12-09T00:13:20Z	2022-12-09T00:13:20Z	  Buildings that are designed specifically to respond to the local climate can be more comfortable, energy-efficient, and with a lower environmental impact. However, there are many social, cultural, and economic obstacles that might prevent the wide adoption of designing climate-adapted buildings. One of the said obstacles can be removed by enabling practitioners to easily access and analyse local climate data. The CBE Clima Tool (Clima) is a free and open-source web application that offers easy access to publicly available weather files (in EPW format) specifically created for building energy simulation and design. It provides a series of interactive visualization of the variables therein contained and several derived ones. It is aimed at students, educators, and practitioners in the architecture and engineering fields. Since its launch has been consistently recording over 3000 monthly unique users from over 70 countries worldwide, both in professional and educational settings. 	
"Scalable, low-cost, and versatile system design for air pollution and
  traffic density monitoring and analysis"	http://arxiv.org/abs/2212.04313v1	2022-12-08T15:10:04Z	2022-12-08T15:10:04Z	  Vietnam requires a sustainable urbanization, for which city sensing is used in planning and de-cision-making. Large cities need portable, scalable, and inexpensive digital technology for this purpose. End-to-end air quality monitoring companies such as AirVisual and Plume Air have shown their reliability with portable devices outfitted with superior air sensors. They are pricey, yet homeowners use them to get local air data without evaluating the causal effect. Our air quality inspection system is scalable, reasonably priced, and flexible. Minicomputer of the sys-tem remotely monitors PMS7003 and BME280 sensor data through a microcontroller processor. The 5-megapixel camera module enables researchers to infer the causal relationship between traffic intensity and dust concentration. The design enables inexpensive, commercial-grade hardware, with Azure Blob storing air pollution data and surrounding-area imagery and pre-venting the system from physically expanding. In addition, by including an air channel that re-plenishes and distributes temperature, the design improves ventilation and safeguards electrical components. The gadget allows for the analysis of the correlation between traffic and air quali-ty data, which might aid in the establishment of sustainable urban development plans and poli-cies. 	
Tracing Water Masers at their Smallest Scale with VLBI	http://arxiv.org/abs/2212.04174v1	2022-12-08T10:24:26Z	2022-12-08T10:24:26Z	  The high-mass star-forming region NGC6334I-MM1 underwent an energetic accretion event in January 2015. We report the large-scale ($10 - 100$ AU) and small-scale ($\sim 1$ AU) changes in spatial and velocity structures of 22 GHz water masers as observed with VERA before and during the accretion burst. The masers in the northern bow-shock CM2-W2 brightened, and better traced a bow structure during the burst. In the southern regions, there was both activation and disappearance of associations before and during the burst. We measured the amplitudes, central velocities and FWHMs of about 20 features in each epoch. We found that the linear scale of the brightest feature in CM2-W2 grew from 0.6 AU before the burst to 1.4 AU after the burst, possibly indicating that a larger volume of gas was able to sustain masing action as a consequence of the accretion burst. This feature also had a rapid (0.2 yr) brightness increase by a factor of four, which has been previously reported in long-term single-dish monitoring. We propose that the water maser flare could be explained by an increase of the collisional pump rate due to radiative heating of H$_2$ by increased high energy radiation (UV or X-ray) from the inner protostellar core. We also describe the spot and spectral method of maser proper motion calculations. We argue that for high spectral resolution observations the spectral method is more robust for calculating proper motions than the spot method. 	
Acoustic properties of glubam and SPF	http://arxiv.org/abs/2212.04173v1	2022-12-08T10:20:53Z	2022-12-08T10:20:53Z	  Noise pollution has attracted a wide attention due to its negative effect on human health, and many researchers are working on proposing strategies or developing new materials to improve acoustic performance of structures and building materials. Meanwhile, the worldwide emphasis on sustainable development has motivated the development and application of bio-mass materials in every field, including the engineering construction. The purpose of this study is to measure and investigate the performance of a structure-used glued laminated bamboo (Glubam) and spruce-pine-fir (SPF) as soundproof or sound-absorbing materials. The impedance tube method was used to measure the sound reduction index and sound absorption coefficient of glubam and SPF in the lab. After doing some comparison studies, it can be found that glubam and SPF have good performance in sound insulation but behave weakly in sound absorption, and glubam exhibits similar even better acoustic properties than SPF. Moreover, a finite element model was built up using ABAQUS to predict sound insulation properties of materials. According to the numerical results of sound reduction index obtained from the finite element model, developing composite materials and double-layer panels with cavity between should be effective on improving the soundproof performance of SPF and glubam. 	
"Design and Planning of Flexible Mobile Micro-Grids Using Deep
  Reinforcement Learning"	http://arxiv.org/abs/2212.04136v1	2022-12-08T08:30:50Z	2022-12-08T08:30:50Z	  Ongoing risks from climate change have impacted the livelihood of global nomadic communities, and are likely to lead to increased migratory movements in coming years. As a result, mobility considerations are becoming increasingly important in energy systems planning, particularly to achieve energy access in developing countries. Advanced Plug and Play control strategies have been recently developed with such a decentralized framework in mind, more easily allowing for the interconnection of nomadic communities, both to each other and to the main grid. In light of the above, the design and planning strategy of a mobile multi-energy supply system for a nomadic community is investigated in this work. Motivated by the scale and dimensionality of the associated uncertainties, impacting all major design and decision variables over the 30-year planning horizon, Deep Reinforcement Learning (DRL) is implemented for the design and planning problem tackled. DRL based solutions are benchmarked against several rigid baseline design options to compare expected performance under uncertainty. The results on a case study for ger communities in Mongolia suggest that mobile nomadic energy systems can be both technically and economically feasible, particularly when considering flexibility, although the degree of spatial dispersion among households is an important limiting factor. Key economic, sustainability and resilience indicators such as Cost, Equivalent Emissions and Total Unmet Load are measured, suggesting potential improvements compared to available baselines of up to 25%, 67% and 76%, respectively. Finally, the decomposition of values of flexibility and plug and play operation is presented using a variation of real options theory, with important implications for both nomadic communities and policymakers focused on enabling their energy access. 	
ICT4S2022 -- Demonstrations and Posters Track Proceedings	http://arxiv.org/abs/2212.05030v1	2022-12-07T23:56:40Z	2022-12-07T23:56:40Z	  Submissions accepted for The 8th International Conference on ICT for Sustainability (ICT4S 2022), Demonstrations and Posters Track Proceedings, Plovdiv, Bulgaria, Mon 13 - Fri 17 June 2022. Most of the submissions are included in the arXiv proceedings while some demonstrations and posters are out of arXiv publication scope as the ICT4S scope is broad and multidisciplinary. Corresponding posters are available on the ICT4S2022 - Demonstrations and Posters page. 	
"BiPMAP: A Toolbox for Predictions of Perceived Motion Artifacts on
  Modern Displays"	http://arxiv.org/abs/2212.03854v1	2022-12-07T18:51:24Z	2022-12-07T18:51:24Z	  Presenting dynamic scenes without incurring motion artifacts visible to observers requires sustained effort from the display industry. A tool that predicts motion artifacts and simulates artifact elimination through optimizing the display configuration is highly desired to guide the design and manufacture of modern displays. Despite the popular demands, there is no such tool available in the market. In this study, we deliver an interactive toolkit, Binocular Perceived Motion Artifact Predictor (BiPMAP), as an executable file with GPU acceleration. BiPMAP accounts for an extensive collection of user-defined parameters and directly visualizes a variety of motion artifacts by presenting the perceived continuous and sampled moving stimuli side-by-side. For accurate artifact predictions, BiPMAP utilizes a novel model of the human contrast sensitivity function to effectively imitate the frequency modulation of the human visual system. In addition, BiPMAP is capable of deriving various in-plane motion artifacts for 2D displays and depth distortion in 3D stereoscopic displays. 	
"Estimating the proportion of modern contraceptives supplied by the
  public and private sectors using a Bayesian hierarchical penalized spline
  model"	http://arxiv.org/abs/2212.03844v1	2022-12-07T18:39:47Z	2022-12-07T18:39:47Z	  Quantifying the public/private sector supply of contraceptive methods within countries is vital for effective and sustainable family planning (FP) delivery. In many low and middle-income countries (LMIC), measuring the contraceptive supply source often relies on Demographic Health Surveys (DHS). However, many of these countries carry out the DHS approximately every 3-5 years and do not have recent data beyond 2015/16. Our objective in estimating the set of related contraceptive supply-share outcomes (proportion of modern contraceptive methods supplied by the public/private sectors) is to take advantage of latent attributes present in dataset to produce annual, country-specific estimates and projections with uncertainty. We propose a Bayesian, hierarchical, penalized-spline model with multivariate-normal spline coefficients to capture cross-method correlations. Our approach offers an intuitive way to share information across countries and sub-continents, model the changes in the contraceptive supply share over time, account for survey observational errors and produce probabilistic estimates and projections that are informed by past changes in the contraceptive supply share as well as correlations between rates of change across different methods. These results will provide valuable information for evaluating FP program effectiveness. To the best of our knowledge, it is the first model of its kind to estimate these quantities. 	
"Optimal Control Design for Operating a Hybrid PV Plant with Robust Power
  Reserves for Fast Frequency Regulation Services"	http://arxiv.org/abs/2212.03803v1	2022-12-07T17:39:13Z	2022-12-07T17:39:13Z	  This paper presents an optimal control strategy for operating a solar hybrid system consisting of solar photovoltaic (PV) and a high-power, low-storage battery energy storage system (BESS). A state-space model of the hybrid PV plant is first derived, based on which an adaptive model predictive controller is designed. The controller's objective is to control the PV and BESS to follow power setpoints sent to the the hybrid system while maintaining desired power reserves and meeting system operational constraints. Furthermore, an extended Kalman filter (EKF) is implemented for estimating the battery SOC, and an error sensitivity is executed to assess its limitations. To validate the proposed strategy, detailed EMT models of the hybrid system are developed so that losses and control limits can be quantified accurately. Day-long simulations are performed in an OPAL-RT real-time simulator using second-by-second actual PV farm data as inputs. Results verify that the proposed method can follow power setpoints while maintaining power reserves in days of high irradiance intermittency even with a small BESS storage. 	
Structure and evolution of urban heavy truck mobility networks	http://arxiv.org/abs/2212.03672v1	2022-12-07T14:37:57Z	2022-12-07T14:37:57Z	  Revealing the structural properties and understanding the evolutionary mechanisms of the urban heavy truck mobility network (UHTMN) provide insights in assessment of freight policies to manage and regulate the urban freight system, and are of vital importance for improving the livability and sustainability of cities. Although massive urban heavy truck mobility data become available in recent years, in-depth studies on the structure and evolution of UHTMN are still lacking. Here we use massive urban heavy truck GPS data in China to construct the UHTMN and reveal its a wide range of structure properties. We further develop an evolving network model that simultaneously considers weight, space and system element duplication. Our model reproduces the observed structure properties of UHTMN and helps us understand its underlying evolutionary mechanisms. Our model also provides new perspectives for modeling the evolution of many other real-world networks, such as protein interaction networks, citation networks and air transportation networks. 	
"An Optimization Framework for Efficient and Sustainable Logistics
  Operations via Transportation Mode Optimization and Shipment Consolidation: A
  Case Study for GE Gas Power"	http://arxiv.org/abs/2212.03662v1	2022-12-07T14:24:25Z	2022-12-07T14:24:25Z	  General Electric (GE) Gas Power manufactures gas turbines which are then installed in power generation plants across the world. The components for these gas turbines are sourced from suppliers across the world. They are then transported to manufacturing and assembly locations in the United States via different modes of transportation including ocean, air, and ground with varying lead times and costs. It is challenging to identify the minimum cost solution that meets the assembly requirements due to the large volume of shipments and complexity of freight network. We develop a customized, multi-period (dynamic), multi-commodity network flow model with consolidation and storage options at intermediate nodes to solve this problem. This formulation results in an integer program that can be solved using existing commercial solvers for problems of reasonable size. To handle larger sized problems, we develop a novel heuristic algorithm with a rolling time horizon. The overall solution is used for all shipments from China to North America and is expected to scale for all global shipments in 2023. We humbly believe that our work introduces a novel problem to the literature that might be of interest to both industry and academia in operations research, more specifically, to the network optimization and supply chain communities. 	
"Achieving Bright Organic Light Emitting Field Effect Transistors with
  Sustained Efficiency through Hybrid Contact Design"	http://arxiv.org/abs/2212.03409v2	2023-02-08T18:14:48Z	2022-12-07T02:34:48Z	  Organic light emitting field effect transistors (OLEFETs) with bilayer structures have been widely studied due to their potential to integrate high-mobility organic transistors and efficient organic light emitting diodes. However, these devices face a major challenge of imbalance charge transport leading to severe efficiency roll-off at high brightness. Here, we propose a solution to this challenge by introducing a transparent organic/inorganic hybrid contact with specially designed electronic structures. Our design aims to steadily accumulate the electrons injected to the emissive polymer, allowing the light emitting interface to effectively capture more holes even when hole current increases. Our numerical simulations show that the capture efficiency of these steady electrons will dominate charge recombination and lead to a sustained external quantum efficiency of 0.23% over 3 orders of magnitude of brightness (4 to 7700 cd/m2) and current density (1.2 to 2700 mA/cm2) from -4 to -100 V. The same enhancement is retained even after increasing EQE to ~0.51%. The high and tunable brightness with stable efficiency offered by hybrid-contact OLEFETs make them ideal light emitting devices for various applications. These devices have the potential to revolutionize the field of organic electronics by overcoming the fundamental challenge of imbalance charge transport. 	
"Barriers to implementation of blockchain technology in agricultural
  supply chain"	http://arxiv.org/abs/2212.03302v1	2022-12-06T20:06:35Z	2022-12-06T20:06:35Z	  Emerging technologies, such as Blockchain and the Internet of Things (IoT), have had an immense role in propelling the agricultural industry towards the fourth agricultural revolution. Blockchain and IoT can greatly improve the traceability, efficiency, and safety of food along the supply chain. Given these contributions, there are many barriers to widespread adoption of this technology, including a deficit in many workers' ability to understand and effectively use this technology in addition to a lack of infrastructure to educate and support these workers. This paper discusses the barriers to adoption of blockchain and IoT technology in the agricultural supply chain. The authors analyse the impact of Blockchain and IoT in the food supply chain and methods in which governments and corporations can become more adaptable. Through the reduction in imports and protection of demand for local farmers, developing economies can create local sustainable agricultural ecosystems. Furthermore, the use of both public and private Research and Development can greatly contribute to the global knowledge on new technologies and improve many aspects of the food supply chain. In conclusion, both governments and corporations have a big role to play in the increased implementation of progressive technologies and the overall improvement of the food supply chain along with it. 	
"Applications of Machine Learning for the Ratemaking in Agricultural
  Insurances"	http://arxiv.org/abs/2212.03114v3	2022-12-19T08:24:37Z	2022-12-06T16:24:53Z	  This paper evaluates Machine Learning (ML) in establishing ratemaking for new insurance schemes. To make the evaluation feasible, we established expected indemnities as premiums. Then, we use ML to forecast indemnities using a minimum set of variables. The analysis simulates the introduction of an income insurance scheme, the so-called Income Stabilization Tool (IST), in Italy as a case study using farm-level data from the FADN from 2008-2018. We predicted the expected IST indemnities using three ML tools, LASSO, Elastic Net, and Boosting, that perform variable selection, comparing with the Generalized Linear Model (baseline) usually adopted in insurance investigations. Furthermore, Tweedie distribution is implemented to consider the peculiarity shape of the indemnities function, characterized by zero-inflated, no-negative value, and asymmetric fat-tail. The robustness of the results was evaluated by comparing the econometric and economic performance of the models. Specifically, ML has obtained the best goodness-of-fit than baseline, using a small and stable selection of regressors and significantly reducing the gathering cost of information. However, Boosting enabled it to obtain the best economic performance, balancing the most and most minor risky subjects optimally and achieving good economic sustainability. These findings suggest how machine learning can be successfully applied in agricultural insurance.This study represents one of the first to use ML and Tweedie distribution in agricultural insurance, demonstrating its potential to overcome multiple issues. 	
"Estimation of fibre architecture and scar in myocardial tissue using
  electrograms: an in-silico study"	http://arxiv.org/abs/2212.03012v2	2023-02-21T19:05:41Z	2022-12-06T14:37:59Z	  Atrial Fibrillation (AF) is characterized by disorganised electrical activity in the atria and is known to be sustained by the presence of regions of fibrosis (scars) or functional cellular remodeling, both of which may lead to areas of slow conduction. Estimating the effective conductivity of the myocardium and identifying regions of abnormal propagation is therefore crucial for the effective treatment of AF. We hypothesise that the spatial distribution of tissue conductivity can be directly inferred from an array of concurrently acquired contact electrograms (EGMs). We generate a dataset of simulated cardiac AP propagation using randomised scar distributions and a phenomenological cardiac model and calculate contact EGMs at various positions on the field. EGMs are enriched with noise extracted from biological data acquired in the lab. A deep neural network, based on a modified U-net architecture, is trained to estimate the location of the scar and quantify conductivity of the tissue with a Jaccard index of 91%. We adapt a wavelet-based surrogate testing analysis to confirm that the inferred conductivity distribution is an accurate representation of the ground truth input to the model. We find that the root mean square error (RMSE) between the ground truth and our predictions is significantly smaller ($p_{val}<0.01$) than the RMSE between the ground truth and surrogate samples. 	
"An Accessible Method for Simulating Charged-Particle Optics, with
  Examples for Transmission Electron Microscopy"	http://arxiv.org/abs/2212.02966v1	2022-12-06T13:34:19Z	2022-12-06T13:34:19Z	  The transmission electron microscope (TEM) has become an essential tool for innovation in nanoscience, material science, and biology. Despite these instruments being widely used across both industry and academia, academics may hesitate to propose substantial modifications to the optical setup due to the instrument's significant purchase price, fear of voiding the service contract, or downtime being unacceptable in shared user facilities. For instruments found in industry, similarly the risk-reward balance makes substantive modifications untenable. This limits the development of radically new optical geometries, and with the performance of the TEM largely being dictated by the specification of the objective lens pole-piece, exploring novel designs may be valuable.   Alternatively, potential lens designs can be analyzed rapidly and inexpensively using finite element analysis multiphysics simulation packages. Several are available, but here COMSOL Multiphysics was used, which is readily available in many universities. Changes to the geometry or materials of the lens can be investigated without any need to disassemble, reassemble, and realign the TEM column. Here we demonstrate an intuitive and accessible method to simulate charged particle optics using this 'digital twin' approach, with the hope that this encourages new creative and sustainable grassroots innovation in TEM lens design and microscope modification. 	
Classical Mode Dyanmics for Trapped Ion Diagnostics	http://arxiv.org/abs/2212.02722v1	2022-12-06T03:22:25Z	2022-12-06T03:22:25Z	  In this paper we consider two problems in diagnostics of trapped ion crystals in which an analysis of the ions' collective oscillatory motion yield potentially useful results. When one of the ions in a linear crystal undergoes a collision, observation of the subsequent motion allows one to deduce the identity of which ion sustained the collision. When a linear ion crystal is formed with a dark impurity ion, analysis of the ions' motion can identify the mass (and thus give an important clue to the species) of the impurity. 	
"Cosmic Sands: The Origin of Dusty, Star-forming Galaxies in the Epoch of
  Reionization"	http://arxiv.org/abs/2212.02636v1	2022-12-05T22:43:38Z	2022-12-05T22:43:38Z	  We present the Cosmic Sands suite of cosmological zoom-in simulations based on the Simba galaxy formation model in order to study the build up of the first massive and dusty galaxies in the early Universe. Residing in the most massive halos, we find that the compact proto-massive galaxies undergo nearly continuous mergers with smaller subhalos, boosting star formation rates (SFRs) and the build up of stellar mass. The galaxies are already appreciably chemically evolved by z=10, with modeled dust masses comparable to those inferred from observations in the same epoch. We track gas accretion onto the galaxies to understand how extreme SFRs can be sustained by these early systems. We find that smooth gas accretion can maintain SFRs above 250 M$_{\odot}$ / yr but to achieve SFRs that boost galaxies well above the main sequence, a larger perturbation like a gas-rich major merger is necessary to trigger a starburst episode. Post-processing the Cosmic Sands simulations with dust radiative transfer, we find that while the infrared luminosities of the most dust rich galaxies are comparable to local ULIRGs, they are substantially dimmer than classical z=2 sub-millimeter galaxies. We end with a discussion on the possible reasons for this discrepancy at the highest masses and the future work we intend to carry out to study the chemical enrichment of the earliest dusty galaxies. 	
"Topological superconductivity driven by correlations and linear defects
  in multiband superconductors"	http://arxiv.org/abs/2212.02394v1	2022-12-05T16:17:57Z	2022-12-05T16:17:57Z	  There have been several proposals for platforms sustaining topological superconductivity in high temperature superconductors, in order to make use of the larger superconducting gap and the expected robustness of Majorana zero modes towards perturbations. In particular, the iron-based materials offer relatively large $T_c$ and nodeless energy gaps. In addition, atomically flat surfaces enable the engineering of defect structures and the subsequent measurement of spectroscopic properties to reveal topological aspects. From a theory perspective, a materials-specific description is challenging due to the correlated nature of the materials and complications arising from the multiband nature of the electronic structure. Here we include both aspects in realistic interacting models, and find that the correlations themselves can lead to local magnetic order close to linear potential scattering defects at the surface of the superconductor. Using a self-consistent Bogoliubov-de Gennes framework in a real-space setup using a prototype electronic structure, we allow for arbitrary magnetic orders and show how a topological superconducting state emerges. The calculation of the topological invariant and the topological gap allows us to map out the phase diagram for the case of a linear chain of potential scatterers. While intrinsic spin-orbit coupling is not needed to enter the topological state in presence of spin-spiral states, it enlarges the topological phase. We discuss the interplay of a triplet component of the superconducting order parameter and the spin spiral leading effectively to extended spin orbit coupling terms, and connect our results to experimental efforts on the Fe(Se,Te) system. 	
Triglobal resolvent analysis of swept-wing wakes	http://arxiv.org/abs/2212.02009v1	2022-12-05T03:42:35Z	2022-12-05T03:42:35Z	  Through triglobal resolvent analysis, we reveal the effects of wing tip and sweep angle on laminar separated wakes over swept wings. For the present study, we consider wings with semi-aspect ratios from $1$ to $4$, sweep angles from $0^\circ$ to $45^\circ$, and angles of attack of $20^\circ$ and $30^\circ$ at a chord-based Reynolds number of $400$ and a Mach number of $0.1$. Using direct numerical simulations, we observe that unswept wings develop vortex shedding near the wing root with a quasi-steady tip vortex. For swept wings, vortex shedding is seen near the wing tip for low sweep angles, while the wakes are steady for wings with high sweep angles. To gain further insights into the mechanisms of flow unsteadiness, triglobal resolvent analysis is used to identify the optimal spatial input-output mode pairs and the associated gains over a range of frequencies. The three-dimensional forcing and response modes reveal that harmonic fluctuations are directed towards the root for unswept wings and towards the wing tip for swept wings. The overlapping region of the forcing-response mode pairs uncovers triglobal resolvent wavemakers associated with self-sustained unsteady wakes of swept wings. Furthermore, we show that for low aspect ratio wings optimal perturbations develop globally over the entire wingspan. The present study uncovers physical insights on the effects of tip and sweep on the growth of optimal harmonic perturbations and the wake dynamics of separated flows over swept wings. 	
"Estimating Meetings' Air Flight $CO_2$ Equivalent Emissions An
  Illustrative Example with IETF meetings"	http://arxiv.org/abs/2212.03172v1	2022-12-04T23:52:24Z	2022-12-04T23:52:24Z	  These notes describe CO2eq a tool that estimates $CO_2$ equivalent emissions associated with air traffic and applies it to the Internet Engineering Task Force (IETF), an international standard developing organization that meets 3 times a year. CO2eq estimates that the participation to IETF meetings (by a single participant) generates as much $CO_2$ equivalent as the $CO_2$ emissions per capita of European countries generating their energy using coal -- like Germany or Poland for example. This suggests some radical changes should be considered by the IETF.   According to the conclusion of the $26^{th}$ Conference of the Parties (COP26) from the United Nations Secretary-General Ant\'onio Guterres; in 2021, the number of meetings should be limited to a maximum of one meeting per year. In addition, the incorporation of sustainability principles into the IETF's strategy, should include, for example, increasing the effort to enhance the experience of 'remote' participation as well as adhering to programs (such as for example the United Nations Global Compact and the caring for climate initiative) to align its strategy and report progress toward sustainability. 	
"Context-aware multi-head self-attentional neural network model for next
  location prediction"	http://arxiv.org/abs/2212.01953v1	2022-12-04T23:40:14Z	2022-12-04T23:40:14Z	  Accurate activity location prediction is a crucial component of many mobility applications and is particularly required to develop personalized, sustainable transportation systems. Despite the widespread adoption of deep learning models, next location prediction models lack a comprehensive discussion and integration of mobility-related spatio-temporal contexts. Here, we utilize a multi-head self-attentional (MHSA) neural network that learns location transition patterns from historical location visits, their visit time and activity duration, as well as their surrounding land use functions, to infer an individual's next location. Specifically, we adopt point-of-interest data and latent Dirichlet allocation for representing locations' land use contexts at multiple spatial scales, generate embedding vectors of the spatio-temporal features, and learn to predict the next location with an MHSA network. Through experiments on two large-scale GNSS tracking datasets, we demonstrate that the proposed model outperforms other state-of-the-art prediction models, and reveal the contribution of various spatio-temporal contexts to the model's performance. Moreover, we find that the model trained on population data achieves higher prediction performance with fewer parameters than individual-level models due to learning from collective movement patterns. We also reveal mobility conducted in the recent past and one week before has the largest influence on the current prediction, showing that learning from a subset of the historical mobility is sufficient to obtain an accurate location prediction result. We believe that the proposed model is vital for context-aware mobility prediction. The gained insights will help to understand location prediction models and promote their implementation for mobility applications. 	
"Remote estimation of geologic composition using interferometric
  synthetic-aperture radar in California's Central Valley"	http://arxiv.org/abs/2212.04813v1	2022-12-04T23:06:14Z	2022-12-04T23:06:14Z	  California's Central Valley is the national agricultural center, producing 1/4 of the nation's food. However, land in the Central Valley is sinking at a rapid rate (as much as 20 cm per year) due to continued groundwater pumping. Land subsidence has a significant impact on infrastructure resilience and groundwater sustainability. In this study, we aim to identify specific regions with different temporal dynamics of land displacement and find relationships with underlying geological composition. Then, we aim to remotely estimate geologic composition using interferometric synthetic aperture radar (InSAR)-based land deformation temporal changes using machine learning techniques. We identified regions with different temporal characteristics of land displacement in that some areas (e.g., Helm) with coarser grain geologic compositions exhibited potentially reversible land deformation (elastic land compaction). We found a significant correlation between InSAR-based land deformation and geologic composition using random forest and deep neural network regression models. We also achieved significant accuracy with 1/4 sparse sampling to reduce any spatial correlations among data, suggesting that the model has the potential to be generalized to other regions for indirect estimation of geologic composition. Our results indicate that geologic composition can be estimated using InSAR-based land deformation data. In-situ measurements of geologic composition can be expensive and time consuming and may be impractical in some areas. The generalizability of the model sheds light on high spatial resolution geologic composition estimation utilizing existing measurements. 	
Online Shielding for Reinforcement Learning	http://arxiv.org/abs/2212.01861v1	2022-12-04T16:00:29Z	2022-12-04T16:00:29Z	  Besides the recent impressive results on reinforcement learning (RL), safety is still one of the major research challenges in RL. RL is a machine-learning approach to determine near-optimal policies in Markov decision processes (MDPs). In this paper, we consider the setting where the safety-relevant fragment of the MDP together with a temporal logic safety specification is given and many safety violations can be avoided by planning ahead a short time into the future. We propose an approach for online safety shielding of RL agents. During runtime, the shield analyses the safety of each available action. For any action, the shield computes the maximal probability to not violate the safety specification within the next $k$ steps when executing this action. Based on this probability and a given threshold, the shield decides whether to block an action from the agent. Existing offline shielding approaches compute exhaustively the safety of all state-action combinations ahead of time, resulting in huge computation times and large memory consumption. The intuition behind online shielding is to compute at runtime the set of all states that could be reached in the near future. For each of these states, the safety of all available actions is analysed and used for shielding as soon as one of the considered states is reached. Our approach is well suited for high-level planning problems where the time between decisions can be used for safety computations and it is sustainable for the agent to wait until these computations are finished. For our evaluation, we selected a 2-player version of the classical computer game SNAKE. The game represents a high-level planning problem that requires fast decisions and the multiplayer setting induces a large state space, which is computationally expensive to analyse exhaustively. 	
"Quantum Monte Carlo method describing supported metal catalysis:
  Ni(111)/alumina decomposing methane as a route to hydrogen"	http://arxiv.org/abs/2212.01823v1	2022-12-04T14:01:16Z	2022-12-04T14:01:16Z	  Hydrogen production as a clean, sustainable replacement for fossil fuels is gathering pace. Doubling the capacity of Paris-CDG airport has been halted, even with the upcoming Olympic Games, until hydrogen-powered planes can be used. It is thus timely to work on catalytic selective hydrogen production and optimise catalyst structure. Over 90% of all chemical manufacture uses a solid catalyst. This work describes the dissociation of a C-H bond in methane, chemisorbed at Ni(111) that stabilises the ensuing Ni-H linkage. In a subsequent step, gaseous hydrogen is given off. Many chemical reactions involve bond-dissociation. This process is often the key to rate-limiting reaction steps at solid surfaces. Since bond-breaking is poorly described by Hartree-Fock and DFT methods, Quantum Monte Carlo (QMC) methodology is used. Our embedded active site approach demonstrates novel QMC. The rate-limiting reaction step of methane decomposition to hydrogen and carbon is the initial C-H bond stretch. The full dissociation energy is offset by Ni-H bond formation at the surface. Reactive methyl (CH$_3$) radicals also interact with a vicinal Ni. These adsorbed methyl radicals subsequently produce methylene and hydrogen, with one atom dissociated from the methyl radical and the other desorbed from the Ni surface. The QMC activation barrier found is 85.4 +/- 1.1 kJ/mol JCP C (2020). Thus, QMC is shown to be encouraging for investigating similar catalytic systems. 	
"Gibbs-Helmholtz Graph Neural Network: capturing the temperature
  dependency of activity coefficients at infinite dilution"	http://arxiv.org/abs/2212.01199v3	2022-12-16T14:12:08Z	2022-12-02T14:25:58Z	  The accurate prediction of physicochemical properties of chemical compounds in mixtures (such as the activity coefficient at infinite dilution $\gamma_{ij}^\infty$) is essential for developing novel and more sustainable chemical processes. In this work, we analyze the performance of previously-proposed GNN-based models for the prediction of $\gamma_{ij}^\infty$, and compare them with several mechanistic models in a series of 9 isothermal studies. Moreover, we develop the Gibbs-Helmholtz Graph Neural Network (GH-GNN) model for predicting $\ln \gamma_{ij}^\infty$ of molecular systems at different temperatures. Our method combines the simplicity of a Gibbs-Helmholtz-derived expression with a series of graph neural networks that incorporate explicit molecular and intermolecular descriptors for capturing dispersion and hydrogen bonding effects. We have trained this model using experimentally determined $\ln \gamma_{ij}^\infty$ data of 40,219 binary-systems involving 1032 solutes and 866 solvents, overall showing superior performance compared to the popular UNIFAC-Dortmund model. We analyze the performance of GH-GNN for continuous and discrete inter/extrapolation and give indications for the model's applicability domain and expected accuracy. In general, GH-GNN is able to produce accurate predictions for extrapolated binary-systems if at least 25 systems with the same combination of solute-solvent chemical classes are contained in the training set and a similarity indicator above 0.35 is also present. This model and its applicability domain recommendations have been made open-source at https://github.com/edgarsmdn/GH-GNN. 	
"Matching DNN Compression and Cooperative Training with Resources and
  Data Availability"	http://arxiv.org/abs/2212.02304v1	2022-12-02T09:52:18Z	2022-12-02T09:52:18Z	  To make machine learning (ML) sustainable and apt to run on the diverse devices where relevant data is, it is essential to compress ML models as needed, while still meeting the required learning quality and time performance. However, how much and when an ML model should be compressed, and {\em where} its training should be executed, are hard decisions to make, as they depend on the model itself, the resources of the available nodes, and the data such nodes own. Existing studies focus on each of those aspects individually, however, they do not account for how such decisions can be made jointly and adapted to one another. In this work, we model the network system focusing on the training of DNNs, formalize the above multi-dimensional problem, and, given its NP-hardness, formulate an approximate dynamic programming problem that we solve through the PACT algorithmic framework. Importantly, PACT leverages a time-expanded graph representing the learning process, and a data-driven and theoretical approach for the prediction of the loss evolution to be expected as a consequence of training decisions. We prove that PACT's solutions can get as close to the optimum as desired, at the cost of an increased time complexity, and that, in any case, such complexity is polynomial. Numerical results also show that, even under the most disadvantageous settings, PACT outperforms state-of-the-art alternatives and closely matches the optimal energy cost. 	
"Dual Arm Impact-Aware Grasping through Time-Invariant Reference
  Spreading Control"	http://arxiv.org/abs/2212.00877v1	2022-12-01T21:30:04Z	2022-12-01T21:30:04Z	  With the goal of increasing the speed and efficiency in robotic dual-arm manipulation, a novel control approach is presented that utilizes intentional simultaneous impacts to rapidly grasp objects. This approach uses the time-invariant reference spreading framework, in which partly-overlapping ante- and post-impact reference vector fields are used. These vector fields are coupled via the impact dynamics in proximity of the expected impact area, minimizing the otherwise large velocity errors after the impact and the corresponding large control efforts. A purely spatial task is introduced to strongly encourage the synchronization of impact times of the two arms. An interim-impact control phase provides robustness in the execution against the inevitable lack of exact impact simultaneity and the corresponding unreliable velocity error. In this interim phase, a position feedback signal is derived from the ante-impact velocity reference, which is used to enforce sustained contact in all contact points without using velocity error feedback. With an eye towards real-life implementation, the approach is formulated using a QP control framework, and is validated using numerical simulations on a realistic robot model with flexible joints and low-level torque control. 	
"Data analytics on key indicators for the city's urban services and
  dashboards for leadership and decision-making"	http://arxiv.org/abs/2212.03081v3	2023-03-04T21:19:07Z	2022-12-01T19:05:16Z	  Cities are continuously evolving human settlements. Our cities are under strain in an increasingly urbanized world, and planners, decision-makers, and communities must be ready to adapt. Data is an important resource for municipal administration. Some technologies aid in the collection, processing, and visualization of urban data, assisting in the interpretation and comprehension of how urban systems operate. The relationship between data analytics and smart cities has come to light in recent years as interest in both has grown. A sophisticated network of interconnected systems, including planners and inhabitants, is what is known as a smart city. Data analysis has the potential to support data-driven decision-making in the context of smart cities. Both urban managers and residents are becoming more interested in city dashboards. Dashboards may collect, display, analyze, and provide information on regional performance to help smart cities development have sustainability. In order to assist decision-making processes and enhance the performance of cities, we examine how dashboards might be used to acquire accurate and representative information regarding urban challenges. This chapter culminates Data Analytics on key indicators for the city's urban services and dashboards for leadership and decision-making. A single web page with consolidated information, real-time data streams pertinent to planners and decision-makers as well as residents' everyday lives, and site analytics as a method to assess user interactions and preferences are among the proposals for urban dashboards.   Keywords: -Dashboard, data analytics, smart city, sustainability, Smart cities, City dashboards, Urban services, Decision-making, Interconnected systems, Real-time data streams, Key indicators, and Urban challenges. 	
"PHANGS-JWST First Results: Multi-wavelength view of feedback-driven
  bubbles (The Phantom Voids) across NGC 628"	http://arxiv.org/abs/2212.00812v1	2022-12-01T19:00:02Z	2022-12-01T19:00:02Z	  We present a high-resolution view of bubbles within The Phantom Galaxy (NGC 628); a nearby (~10Mpc), star-forming (~2Msun/yr), face-on (i~9deg) grand-design spiral galaxy. With new data obtained as part of the PHANGS-JWST treasury program, we perform a detailed case-study of two regions of interest, one of which contains the largest and most prominent bubble in the galaxy (The Phantom Void; over 1kpc in diameter), and the other being a smaller region that may be the precursor to such a large bubble (The Precursor Phantom Void). When comparing to matched resolution Halpha observations from the Hubble Space Telescope (HST), we see that the ionized gas is brightest in the shells of both bubbles, and is coincident with the youngest (~1Myr) and most massive (~100,000Msun) stellar associations. We also find an older generation (~20Myr) of stellar associations is present within the bubble of The Phantom Void. From our kinematic analysis of the HI, H2 (CO) and HII gas across The Phantom Void, we infer a high expansion speed of around 15 to 50km/s. The large size and high expansion speed of The Phantom Void suggest that the driving mechanism is sustained stellar feedback due to multiple mechanisms, where early feedback first cleared a bubble (as we observe now in The Precursor Phantom Void), and since then SNe have been exploding within the cavity, and have accelerated the shell. Finally, comparison to simulations shows a striking resemblance to our JWST observations, and suggests that such large-scale stellar feedback-driven bubbles should be common within other galaxies. 	
"The Tracking Tapered Gridded Estimator (TTGE) for the power spectrum
  from drift scan observations"	http://arxiv.org/abs/2212.01251v1	2022-12-01T18:21:34Z	2022-12-01T18:21:34Z	  Intensity mapping with the redshifted 21-cm line is an emerging tool in cosmology. Drift scan observations, where the antennas are fixed to the ground and the telescope's pointing center (PC) changes continuously on the sky due to earth's rotation, provide broad sky coverage and sustained instrumental stability needed for 21-cm intensity mapping. Here we present the Tracking Tapered Grided Estimator (TTGE) to quantify the power spectrum of the sky signal estimated directly from the visibilities measured in drift scan radio interferometric observations. The TTGE uses the data from the different PC to estimate the power spectrum of the signal from a small angular region located around a fixed tracking center (TC). The size of this angular region is decided by a suitably chosen tapering window function which serves to reduce the foreground contamination from bright sources located at large angles from the TC. It is possible to cover the angular footprint of the drift scan observations using multiple TC, and combine the estimated power spectra to increase the signal to noise ratio. Here we have validated the TTGE using simulations of $154 \, {\rm MHz}$ MWA drift scan observations. We show that the TTGE can recover the input model angular power spectrum $C_{\ell}$ within $20 \%$ accuracy over the $\ell$ range $40 < \ell < 700$. 	
Evaluating Digital Agriculture Recommendations with Causal Inference	http://arxiv.org/abs/2211.16938v1	2022-11-30T12:20:08Z	2022-11-30T12:20:08Z	  In contrast to the rapid digitalization of several industries, agriculture suffers from low adoption of smart farming tools. While AI-driven digital agriculture tools can offer high-performing predictive functionalities, they lack tangible quantitative evidence on their benefits to the farmers. Field experiments can derive such evidence, but are often costly, time consuming and hence limited in scope and scale of application. To this end, we propose an observational causal inference framework for the empirical evaluation of the impact of digital tools on target farm performance indicators (e.g., yield in this case). This way, we can increase farmers' trust via enhancing the transparency of the digital agriculture market and accelerate the adoption of technologies that aim to secure farmer income resilience and global agricultural sustainability. As a case study, we designed and implemented a recommendation system for the optimal sowing time of cotton based on numerical weather predictions, which was used by a farmers' cooperative during the growing season of 2021. We then leverage agricultural knowledge, collected yield data, and environmental information to develop a causal graph of the farm system. Using the back-door criterion, we identify the impact of sowing recommendations on the yield and subsequently estimate it using linear regression, matching, inverse propensity score weighting and meta-learners. The results reveal that a field sown according to our recommendations exhibited a statistically significant yield increase that ranged from 12% to 17%, depending on the method. The effect estimates were robust, as indicated by the agreement among the estimation methods and four successful refutation tests. We argue that this approach can be implemented for decision support systems of other fields, extending their evaluation beyond a performance assessment of internal functionalities. 	
"Optimal Allocation of Virtual Inertia and Droop Control for Renewable
  Energy in Stochastic Look-Ahead Power Dispatch"	http://arxiv.org/abs/2211.16843v1	2022-11-30T09:33:51Z	2022-11-30T09:33:51Z	  To stabilize the frequency of the renewable energy sources (RESs) dominated power system, frequency supports are required by RESs through virtual inertia emulation or droop control in the newly published grid codes. Since the long-term RES prediction involves significant errors, we need online configure the frequency control parameters of RESs in a rolling manner to improve the operation economics under the premise of stabilizing system frequency. To address this concern, this paper proposes a frequency constrained stochastic look-ahead power dispatch (FCS-LAPD) model to formulate the frequency control parameters of RESs and Energy Storage Systems (ESSs) as scheduling variables, which can optimally allocate the virtual inertia and droop coefficient of RESs and ESSs. In this FCS-LAPD model, the uncertainties of RESs are characterized using Gaussian Mixture Model (GMM). The required reserves are determined by frequency control parameters, and the reserve cost coefficients are adjusted properly to allocate the reserves according to the predicted power generation. Due to the nonlinearity of the frequency nadir constraint, a convex hull approximation method is proposed to linearize it with guaranteed feasibility. The proposed FCS-LAPD is ultimately cast as an instance of quadratic programming and can be efficiently solved. Case studies on modified IEEE 24-bus system and a provincial power system in China are conducted to show the effectiveness of the proposed model. 	
"Toward Robust Diagnosis: A Contour Attention Preserving Adversarial
  Defense for COVID-19 Detection"	http://arxiv.org/abs/2211.16806v1	2022-11-30T08:01:23Z	2022-11-30T08:01:23Z	  As the COVID-19 pandemic puts pressure on healthcare systems worldwide, the computed tomography image based AI diagnostic system has become a sustainable solution for early diagnosis. However, the model-wise vulnerability under adversarial perturbation hinders its deployment in practical situation. The existing adversarial training strategies are difficult to generalized into medical imaging field challenged by complex medical texture features. To overcome this challenge, we propose a Contour Attention Preserving (CAP) method based on lung cavity edge extraction. The contour prior features are injected to attention layer via a parameter regularization and we optimize the robust empirical risk with hybrid distance metric. We then introduce a new cross-nation CT scan dataset to evaluate the generalization capability of the adversarial robustness under distribution shift. Experimental results indicate that the proposed method achieves state-of-the-art performance in multiple adversarial defense and generalization tasks. The code and dataset are available at https://github.com/Quinn777/CAP. 	
An Integrated Ride-Matching Model for Shared Mobility on Demand Services	http://arxiv.org/abs/2211.16656v1	2022-11-30T01:03:34Z	2022-11-30T01:03:34Z	  Shared mobility on demand (MoD) services are receiving increased attention as many high volume ride-hailing companies are offering shared services (e.g. UberPool, LyftLine) at an increasing rate. Also, the advent of autonomous vehicles (AVs) promises further operational opportunities to benefit from these developments as AVs enable a centrally operated and fully connected fleet. There are two fundamental tasks for a shared MoD service: ride-matching and vehicle rebalancing. Traditionally, these two functions are performed sequentially and independently. In this paper, we propose and formulate an integrated ride-matching problem which aims to integrate ride-matching and rebalancing into a single formulation. The integrated problem benefits from interactions between these two tasks. We also propose a methodology to solve the integrated shared ride-matching problem by using supply level information based on a grid representation of the city network. We demonstrate the effectiveness of the proposed methodology through a comparative case study using a benchmark sequential approach and an open source data set. Our results show that the integrated model is able to serve at least the same amount of passengers with significant gains in terms of level of service and sustainability metrics. 	
"Evidence for supernova feedback sustaining gas turbulence in nearby
  star-forming galaxies"	http://arxiv.org/abs/2211.16540v1	2022-11-29T19:04:16Z	2022-11-29T19:04:16Z	  HI and CO observations indicate that the cold gas in galaxies is very turbulent. However, the turbulent energy is expected to be quickly dissipated, implying that some energy source is needed to explain the observations. The nature of such turbulence was long unclear, as even the main candidate, supernova (SN) feedback, seemed insufficient. Other mechanisms have been proposed, but without reaching a general consensus. The key novelty of our work is considering that the gas disc thickness and flaring increase the dissipation timescale of turbulence, thus reducing the energy injection rate required to sustain it. In excellent agreement with the theoretical expectations, we found that the fraction of the SN energy (a.k.a. SN coupling efficiency) needed to maintain the cold gas turbulence is $\sim 1$%, solving a long-standing conundrum. 	
When Quantum Information Technologies Meet Blockchain in Web 3.0	http://arxiv.org/abs/2211.15941v1	2022-11-29T05:38:42Z	2022-11-29T05:38:42Z	  With the drive to create a decentralized digital economy, Web 3.0 has become a cornerstone of digital transformation, developed on the basis of computing-force networking, distributed data storage, and blockchain. With the rapid realization of quantum devices, Web 3.0 is being developed in parallel with the deployment of quantum cloud computing and quantum Internet. In this regard, quantum computing first disrupts the original cryptographic systems that protect data security while reshaping modern cryptography with the advantages of quantum computing and communication. Therefore, in this paper, we introduce a quantum blockchain-driven Web 3.0 framework that provides information-theoretic security for decentralized data transferring and payment transactions. First, we present the framework of quantum blockchain-driven Web 3.0 with future-proof security during the transmission of data and transaction information. Next, we discuss the potential applications and challenges of implementing quantum blockchain in Web 3.0. Finally, we describe a use case for quantum non-fungible tokens (NFTs) and propose a quantum deep learning-based optimal auction for NFT trading to maximize the achievable revenue for sufficient liquidity in Web 3.0. In this way, the proposed framework can achieve proven security and sustainability for the next-generation decentralized digital society. 	
"Continuous gravitational wave emission from neutron stars with pinned
  superfluids in the core"	http://arxiv.org/abs/2211.15507v1	2022-11-28T16:25:56Z	2022-11-28T16:25:56Z	  We investigate the effect of a pinned superfluid component on the gravitational wave emission of a rotating neutron star. Pinning of superfluid vortices to the flux-tubes in the outer core (where the protons are likely to form a type-II superconductor) is a possible mechanism to sustain long-lived and non-axisymmetric neutron currents in the interior, that break the axial symmetry of the unperturbed hydrostatic configuration. We consider pinning-induced perturbations to a stationary corotating configuration, and determine upper limits on the strength of gravitational wave emission due to the pinning of vortices with a strong toroidal magnetic field of the kind predicted by recent magneto-hydrodynamic simulations of neutron star interiors. We estimate the contributions to gravitational wave emission from both the mass and current multipole generated by the pinned vorticity in the outer core, and find that the mass quadrupole can be large enough for gravitational waves to provide the dominant spindown torque in millisecond pulsars. 	
Dynamics of Fecal Coliform Bacteria along Canada's Coast	http://arxiv.org/abs/2211.14965v1	2022-11-27T23:19:47Z	2022-11-27T23:19:47Z	  The vast coastline provides Canada with a flourishing seafood industry including bivalve shellfish production. To sustain a healthy bivalve molluscan shellfish production, the Canadian Shellfish Sanitation Program was established to monitor the health of shellfish harvesting habitats, and fecal coliform bacteria data have been collected at nearly 15,000 marine sample sites across six coastal provinces in Canada since 1979. We applied Functional Principal Component Analysis and subsequent correlation analyses to find annual variation patterns of bacteria levels at sites in each province. The overall magnitude and the seasonality of fecal contamination were modelled by functional principal component one and two, respectively. The amplitude was related to human and warm-blooded animal activities; the seasonality was strongly correlated with river discharge driven by precipitation and snow melt in British Columbia, but such correlation in provinces along the Atlantic coast could not be properly evaluated due to lack of data during winter. 	
"Architecture, Protocols, and Algorithms for Location-Aware Services in
  Beyond 5G Networks"	http://arxiv.org/abs/2211.14781v1	2022-11-27T10:24:33Z	2022-11-27T10:24:33Z	  The automotive and railway industries are rapidly transforming with a strong drive towards automation and digitalization, with the goal of increased convenience, safety, efficiency, and sustainability. Since assisted and fully automated automotive and train transport services increasingly rely on vehicle-to-everything communications, and high-accuracy real-time positioning, it is necessary to continuously maintain high-accuracy localization, even in occlusion scenes such as tunnels, urban canyons, or areas covered by dense foliage. In this paper, we review the 5G positioning framework of the 3rd Generation Partnership Project in terms of methods and architecture and propose enhancements to meet the stringent requirements imposed by the transport industry. In particular, we highlight the benefit of fusing cellular and sensor measurements and discuss required architecture and protocol support for achieving this at the network side. We also propose a positioning framework to fuse cellular network measurements with measurements by onboard sensors. We illustrate the viability of the proposed fusion-based positioning approach using a numerical example. 	
"Multi-Label Continual Learning using Augmented Graph Convolutional
  Network"	http://arxiv.org/abs/2211.14763v1	2022-11-27T08:40:19Z	2022-11-27T08:40:19Z	  Multi-Label Continual Learning (MLCL) builds a class-incremental framework in a sequential multi-label image recognition data stream. The critical challenges of MLCL are the construction of label relationships on past-missing and future-missing partial labels of training data and the catastrophic forgetting on old classes, resulting in poor generalization. To solve the problems, the study proposes an Augmented Graph Convolutional Network (AGCN++) that can construct the cross-task label relationships in MLCL and sustain catastrophic forgetting. First, we build an Augmented Correlation Matrix (ACM) across all seen classes, where the intra-task relationships derive from the hard label statistics. In contrast, the inter-task relationships leverage hard and soft labels from data and a constructed expert network. Then, we propose a novel partial label encoder (PLE) for MLCL, which can extract dynamic class representation for each partial label image as graph nodes and help generate soft labels to create a more convincing ACM and suppress forgetting. Last, to suppress the forgetting of label dependencies across old tasks, we propose a relationship-preserving constrainter to construct label relationships. The inter-class topology can be augmented automatically, which also yields effective class representations. The proposed method is evaluated using two multi-label image benchmarks. The experimental results show that the proposed way is effective for MLCL image recognition and can build convincing correlations across tasks even if the labels of previous tasks are missing. 	
"Smart City Drivers and Challenges in Urban-Mobility, Health-Care, and
  Interdependent Infrastructure Systems"	http://arxiv.org/abs/2212.00730v1	2022-11-26T19:49:18Z	2022-11-26T19:49:18Z	  At the turn of the 21st century, urban development has experienced a paradigm shift so that the quest for smarter cities has become a priority agenda, with the direct participation of industry, policymakers, practitioners, and the scientific community alike. The 2008 financial crisis, the exodus from rural areas, and the densification of urban centers coupled with environmental and sustainability concerns have posed enormous challenges to municipalities all over the globe. The United Nations predicts that the world population will reach 9.8 billion by 2050, a growth of 2.1 billion from the 2018 level. Almost all of this population growth will occur in urban areas and, consequently, stress already overloaded transportation systems. 	
Object Transport by a Confined Active Suspension	http://arxiv.org/abs/2211.14583v1	2022-11-26T15:00:23Z	2022-11-26T15:00:23Z	  Numerical simulations in two space dimensions are used to examine the dynamics, transport, and equilibrium behaviors of a neutrally buoyant circular object immersed in an active suspension within a larger closed circular container. The continuum model of Gao et al. (Phys. Rev. Fluids, 2017) represents the suspension of non-interacting, immotile, extensor-type microscopic agents that have a direction and strength and align in response to strain rate. Such a suspension is well known to be unstable above an activity strength threshold, which depends upon the length scale of the confinement. Introducing the object leads to additional phenomenology. It can confine fluid between it and the container wall, which suppresses local suspension activity. However, its motion also correlates strain rates near its surface with a concomitant correlated active-stress response. Depending on the suspension activity strength, these mechanisms lead to either an attraction toward or repulsion away from the container wall. In addition, a persistent propagating behavior is found for modest activity strength, which provides a mechanism for long-range transport. When activity is so weak that the mobility of the object is essential to support suspension instability and sustain flow, the object essentially parks and all flow terminates when its mobility is diminished as it nears the container wall. Together these mechanisms illustrate potential for performing relatively complex tasks with simple active agents, especially if activity strength is scheduled in time. 	
A dynamic multi-region MFD model for ride-sourcing with ridesplitting	http://arxiv.org/abs/2211.14560v2	2023-01-24T13:24:37Z	2022-11-26T13:12:12Z	  Dynamic network-level models directly addressing ride-sourcing services can support the development of efficient strategies for both congestion alleviation and promotion of more sustainable mobility. Recent developments presented models focusing on ride-hailing (solo rides), but no work addressed ridesplitting (shared rides) in dynamic contexts. Here, we sought to develop a dynamic aggregated traffic network model capable of representing ride-sourcing services and background traffic in a macroscopic multi-region urban network. We combined the Macroscopic Fundamental Diagram (MFD) with detailed state-space and transition descriptions of background traffic and ride-sourcing vehicles in their activities to formulate mass conservation equations. Accumulation-based MFD models might experience additional errors due to the variation profile of trip lengths, e.g., when vehicles cruise for passengers. We integrate the so-called M-model that utilizes the total remaining distance to capture dynamics of regional and inter-regional flows and accumulations for different vehicle (private or ride-sourcing) states. This aggregated model is capable to reproduce the dynamics of complex systems without using resource-expensive simulations. We also show that the model can accurately forecast the vehicles' conditions in near-future predictions. Later, a comparison with benchmark models showed lower errors in the proposed model in all states. Finally, we evaluated the model's robustness to noises in its inputs, and forecast errors remained below 15% even where inputs were 20% off the actual values for ride-sourcing vehicles. The development of such a model prepares the path for developing real-time feedback-based management policies such as priority-based perimeter control or repositioning strategies for idle ride-sourcing vehicles and developing regulations over ride-sourcing in congested areas. 	
"Investigating nonlinearity in wall turbulence: regenerative versus
  parametric mechanisms"	http://arxiv.org/abs/2211.14511v1	2022-11-26T08:29:27Z	2022-11-26T08:29:27Z	  Both linear growth processes associated with non-normality of the mean flow and nonlinear interaction transferring energy among fluctuations contribute to maintaining turbulence. However, a detailed understanding of the mechanism by which they cooperate in sustaining the turbulent state is lacking. In this report, we examine the role of fluctuation-fluctuation nonlinearity by varying the magnitude of the associated term in the dynamics of Couette flow turbulence to determine how this nonlinear component helps maintain and determine the structure of the turbulent state, and particularly whether this mechanism is parametric or regenerative. Having determined that the mechanism supporting the fluctuation field in Navier-Stokes turbulence is parametric, we then study the mechanism by which the fluctuation component of turbulence is maintained by parametric growth in a time-dependent mean flow by examining the parametric growth mechanism in the frequency domain using analysis of the time-dependent resolvent. 	
"Bulk-plasmon-mediated free-electron radiation beyond the conventional
  formation time"	http://arxiv.org/abs/2211.14377v2	2023-03-16T04:19:14Z	2022-11-25T21:27:41Z	"  Free-electron radiation is a fundamental photon emission process that is induced by fast-moving electrons interacting with optical media. Historically, it has been understood that, just like any other photon emission process, free-electron radiation must be constrained within a finite time interval known as the ""formation time"", whose concept is applicable to both Cherenkov radiation and transition radiation, the two basic mechanisms describing radiation from a bulk medium and from an interface, respectively. Here we reveal an alternative mechanism of free-electron radiation far beyond the previously defined formation time. It occurs when a fast electron crosses the interface between vacuum and a plasmonic medium supporting bulk plasmons. While emitted continuously from the crossing point on the interface - thus consistent with the features of transition radiation - the extra radiation beyond the conventional formation time is supported by a long tail of bulk plasmons following the electron's trajectory deep into the plasmonic medium. Such a plasmonic tail mixes surface and bulk effects, and provides a sustained channel for electron-interface interaction. These results also settle the historical debate in Ferrell radiation, regarding whether it is a surface or bulk effect, from transition radiation or plasmonic oscillation. "	
"Extending loophole-free nonlocal correlations to arbitrarily large
  distances"	http://arxiv.org/abs/2211.14231v1	2022-11-25T16:44:44Z	2022-11-25T16:44:44Z	  The detection loophole, particularly the critical detection efficiencies of the spatially separated measurement devices, severely limit the distances over which nonlocal quantum correlations can be sustained in state-of-the-art Bell experiments. Instead of looking for quantum strategies with marginally lower threshold requirements, we exploit the properties of loophole-free nonlocal correlations, which are experimentally attainable today, albeit at short distances, to extend them over arbitrarily large distances. Specifically, we consider Bell experiments wherein the spatially separated parties randomly choose the location of their measurement devices in addition to their measurement settings. We demonstrate that when devices close to the source are perfect and witness extremal loophole-free nonlocal correlations, such correlations can be extended to devices with almost-zero detection efficiency and visibility placed arbitrarily far from the source. We then derive an analytic trade-off specific to the Clauser-Horne-Shimony-Holt Bell inequality: the higher the loophole-free nonlocality close to the source, the lower the threshold requirements away from the source. We utilize this trade-off and optimal quantum strategies to estimate the critical requirements of a measurement device placed away from the source. Finally, we formulate a versatile numerical method utilizing certifiable randomness to measure the nonlocal behaviour of individual measurement devices and estimate their critical parameters in generic network scenarios entailing several spatially separated measurement devices. 	
"The European AI Liability Directives -- Critique of a Half-Hearted
  Approach and Lessons for the Future"	http://arxiv.org/abs/2211.13960v5	2023-01-23T11:57:41Z	2022-11-25T09:08:11Z	  As ChatGPT et al. conquer the world, the optimal liability framework for AI systems remains an unsolved problem across the globe. In a much-anticipated move, the European Commission advanced two proposals outlining the European approach to AI liability in September 2022: a novel AI Liability Directive and a revision of the Product Liability Directive. They constitute the final cornerstone of EU AI regulation. Crucially, the liability proposals and the EU AI Act are inherently intertwined: the latter does not contain any individual rights of affected persons, and the former lack specific, substantive rules on AI development and deployment. Taken together, these acts may well trigger a Brussels Effect in AI regulation, with significant consequences for the US and beyond.   This paper makes three novel contributions. First, it examines in detail the Commission proposals and shows that, while making steps in the right direction, they ultimately represent a half-hearted approach: if enacted as foreseen, AI liability in the EU will primarily rest on disclosure of evidence mechanisms and a set of narrowly defined presumptions concerning fault, defectiveness and causality. Hence, second, the article suggests amendments, which are collected in an Annex at the end of the paper. Third, based on an analysis of the key risks AI poses, the final part of the paper maps out a road for the future of AI liability and regulation, in the EU and beyond. This includes: a comprehensive framework for AI liability; provisions to support innovation; an extension to non-discrimination/algorithmic fairness, as well as explainable AI; and sustainability. I propose to jump-start sustainable AI regulation via sustainability impact assessments in the AI Act and sustainable design defects in the liability regime. In this way, the law may help spur not only fair AI and XAI, but potentially also sustainable AI (SAI). 	
"A renewable power system for an off-grid sustainable telescope fueled by
  solar power, batteries and green hydrogen"	http://arxiv.org/abs/2212.03823v1	2022-11-25T08:35:15Z	2022-11-25T08:35:15Z	  A large portion of astronomy's carbon footprint stems from fossil fuels supplying the power demand of astronomical observatories. Here, we explore various isolated low-carbon power system setups for the newly planned Atacama Large Aperture Submillimeter Telescope, and compare them to a business-as-usual diesel power generated system. Technologies included in the designed systems are photovoltaics, concentrated solar power, diesel generators, batteries, and hydrogen storage. We adapt the electricity system optimization model highRES to this case study and feed it with the telescope's projected energy demand, cost assumptions for the year 2030 and site-specific capacity factors. Our results show that the lowest-cost system with LCOEs of $116/MWh majorly uses photovoltaics paired with batteries and fuel cells running on imported green hydrogen. Some diesel generators run for backup. This solution would reduce the telescope's power-side carbon footprint by 95% compared to the business-as-usual case. 	
"A Machine Learning, Natural Language Processing Analysis of Youth
  Perspectives: Key Trends and Focus Areas for Sustainable Youth Development
  Policies"	http://arxiv.org/abs/2211.14321v1	2022-11-25T02:43:21Z	2022-11-25T02:43:21Z	  Investing in children and youth is a critical step towards inclusive, equitable, and sustainable development for current and future generations. Several international agendas for accomplishing common global goals emphasize the need for active youth participation and engagement for sustainable development. The 2030 Agenda for Sustainable Development emphasizes the need for youth engagement and the inclusion of youth perspectives as an important step toward addressing each of the 17 Sustainable Development Goals. The aim of this study is to analyze youth perspectives, values, and sentiments towards issues addressed by the 17 Sustainable Development Goals through social network analysis using machine learning. Social network data collected during 7 major sustainability conferences aimed at engaging children and youth is analyzed using natural language processing techniques for sentiment analysis. This data categorized using a natural language processing text classifier trained on a sample dataset of social network data during the 7 youth sustainability conferences for deeper understanding of youth perspectives in relation to the SDGs. Machine learning identified demographic and location attributes and features are utilized in order to identify bias and demographic differences between ages, gender, and race among youth. Using natural language processing, the qualitative data collected from over 7 different countries in 3 languages are systematically translated, categorized, and analyzed, revealing key trends and focus areas for sustainable youth development policies. The obtained results reveal the general youth's depth of knowledge on sustainable development and their attitudes towards each of the 17 SDGs. The findings of this study serve as a guide toward better understanding the interests, roles, and perspectives of children and youth in achieving the goals of Agenda 2030. 	
"Learning to Take a Break: Sustainable Optimization of Long-Term User
  Engagement"	http://arxiv.org/abs/2211.13585v1	2022-11-24T13:14:29Z	2022-11-24T13:14:29Z	  Optimizing user engagement is a key goal for modern recommendation systems, but blindly pushing users towards increased consumption risks burn-out, churn, or even addictive habits. To promote digital well-being, most platforms now offer a service that periodically prompts users to take a break. These, however, must be set up manually, and so may be suboptimal for both users and the system. In this paper, we propose a framework for optimizing long-term engagement by learning individualized breaking policies. Using Lotka-Volterra dynamics, we model users as acting based on two balancing latent states: drive, and interest -- which must be conserved. We then give an efficient learning algorithm, provide theoretical guarantees, and empirically evaluate its performance on semi-synthetic data. 	
"Nepal Himalaya Offers Considerable Potential for Pumped Storage
  Hydropower"	http://arxiv.org/abs/2211.13306v3	2023-02-14T14:05:06Z	2022-11-23T21:17:23Z	  There is a pressing need for a transition from fossil fuel to renewable energy to meet the increasing energy demands and reduce greenhouse gas (GHG) emissions. The Himalayas possess substantial renewable energy potential that can be harnessed through hydropower projects due to its peculiar topographic characteristics and abundant water resources. However, the current exploitation rate is low owing to the predominance of run-of-river hydropower systems to support the power system. The utility-scale storage facility is crucial in the load scenario of an integrated power system to manage diurnal variation, peak demand, and penetration of intermittent energy sources. In this study, we first identify the potential of pumped storage hydropower across Nepal (a central Himalayan country) under multiple configurations by pairing lakes, hydropower projects, rivers, and available flat terrains. We then identify technically feasible pairs from those of potential locations. Infrastructural, environmental, operational, and other technical constraints govern the choice of feasible locations. We find the flat land-to-river configuration most promising than other configurations. Our results provide insight into the potential of pumped storage hydropower and are of practical importance in planning sustainable power systems in the Himalayas and beyond. 	
Machine Learning for Screening Large Organic Molecules	http://arxiv.org/abs/2211.15415v1	2022-11-23T17:20:43Z	2022-11-23T17:20:43Z	"  Organic semiconductors are promising materials for cheap, scalable and sustainable electronics, light-emitting diodes and photovoltaics. For organic photovoltaic cells, it is a challenge to find compounds with suitable properties in the vast chemical compound space. For example, the ionization energy should fit to the optical spectrum of sun light, and the energy levels must allow efficient charge transport. Here, a machine-learning model is developed for rapidly and accurately estimating the HOMO and LUMO energies of a given molecular structure. It is build upon the SchNet model (Sch\""utt et al. (2018)) and augmented with a `Set2Set' readout module (Vinyals et al. (2016)). The Set2Set module has more expressive power than sum and average aggregation and is more suitable for the complex quantities under consideration. Most previous models have been trained and evaluated on rather small molecules. Therefore, the second contribution is extending the scope of machine-learning methods by adding also larger molecules from other sources and establishing a consistent train/validation/test split. As a third contribution, we make a multitask ansatz to resolve the problem of different sources coming at different levels of theory. All three contributions in conjunction bring the accuracy of the model close to chemical accuracy. "	
"Drop impact on superheated surfaces: from capillary dominance to
  non-linear advection dominance"	http://arxiv.org/abs/2211.12772v1	2022-11-23T08:42:14Z	2022-11-23T08:42:14Z	  Ambient air cushions the impact of drops on solid substrates, an effect usually revealed by the entrainment of a bubble, trapped as the air squeezed under the drop drains and liquid-solid contact occurs. The presence of air becomes evident for impacts on very smooth surfaces, where the gas film can be sustained, allowing drops to bounce without wetting the substrate. In such a non-wetting situation, Mandre & Brenner (2012) numerically and theoretically evidenced that two physical mechanisms can act to prevent contact: surface tension and non-linear advection. However, the advection dominated regime has remained hidden in experiments as liquid-solid contact prevents to realize rebounds at sufficiently large impact velocities. By performing impacts on superheated surfaces, in the so-called dynamical Leidenfrost regime Tran et al. (2012), we enable drop rebound at higher impact velocities, allowing us to reveal this regime. Using high-speed total internal reflection, we measure the minimal gas film thickness under impacting drops, and provide evidence for the transition from the surface tension to the non-linear inertia dominated regime. We rationalise our measurements through scaling relationships derived by coupling the liquid and gas dynamics, in the presence of evaporation. 	
FAIRification of MLC data	http://arxiv.org/abs/2211.12757v1	2022-11-23T07:53:17Z	2022-11-23T07:53:17Z	  The multi-label classification (MLC) task has increasingly been receiving interest from the machine learning (ML) community, as evidenced by the growing number of papers and methods that appear in the literature. Hence, ensuring proper, correct, robust, and trustworthy benchmarking is of utmost importance for the further development of the field. We believe that this can be achieved by adhering to the recently emerged data management standards, such as the FAIR (Findable, Accessible, Interoperable, and Reusable) and TRUST (Transparency, Responsibility, User focus, Sustainability, and Technology) principles. To FAIRify the MLC datasets, we introduce an ontology-based online catalogue of MLC datasets that follow these principles. The catalogue extensively describes many MLC datasets with comprehensible meta-features, MLC-specific semantic descriptions, and different data provenance information. The MLC data catalogue is extensively described in our recent publication in Nature Scientific Reports, Kostovska & Bogatinovski et al., and available at: http://semantichub.ijs.si/MLCdatasets. In addition, we provide an ontology-based system for easy access and querying of performance/benchmark data obtained from a comprehensive MLC benchmark study. The system is available at: http://semantichub.ijs.si/MLCbenchmark. 	
"The Effects of Gas Angular Momentum on Forming Magnetically Arrested
  Disks and Launching Powerful Jets"	http://arxiv.org/abs/2211.12726v1	2022-11-23T06:32:41Z	2022-11-23T06:32:41Z	  In this Letter, we investigate jet-launching abilities of Bondi-like accretion flows with zero or low specific angular momentum by performing 3D general relativistic magnetohydrodynamic simulations. In order to check if relativistic jets can be launched magnetically, we thread the accretion flow with large-scale poloidal magnetic field, and choose a rapidly spinning black hole. We demonstrate that the magnitude of the initial gas specific angular momentum primarily controls whether the disk can reach and sustain the magnetically arrested disk (MAD) state that launches very powerful jets, at $\gtrsim 100\%$ energy efficiency. We find that MAD forms in the presence of even a very small amount of specific angular momentum, and episodic jets with an average energy efficiency of $\sim 10\%$ can still form even when the gas has zero initial angular momentum. Our results give plausible explanations to why jets can be produced from various astrophysical systems that lack large gas specific angular momenta, such as Sgr A*, wind-fed X-ray binaries, tidal disruption events, and long-duration gamma-ray bursts. 	
"Big Earth Data and Machine Learning for Sustainable and Resilient
  Agriculture"	http://arxiv.org/abs/2211.12584v1	2022-11-22T20:58:54Z	2022-11-22T20:58:54Z	  Big streams of Earth images from satellites or other platforms (e.g., drones and mobile phones) are becoming increasingly available at low or no cost and with enhanced spatial and temporal resolution. This thesis recognizes the unprecedented opportunities offered by the high quality and open access Earth observation data of our times and introduces novel machine learning and big data methods to properly exploit them towards developing applications for sustainable and resilient agriculture. The thesis addresses three distinct thematic areas, i.e., the monitoring of the Common Agricultural Policy (CAP), the monitoring of food security and applications for smart and resilient agriculture. The methodological innovations of the developments related to the three thematic areas address the following issues: i) the processing of big Earth Observation (EO) data, ii) the scarcity of annotated data for machine learning model training and iii) the gap between machine learning outputs and actionable advice.   This thesis demonstrated how big data technologies such as data cubes, distributed learning, linked open data and semantic enrichment can be used to exploit the data deluge and extract knowledge to address real user needs. Furthermore, this thesis argues for the importance of semi-supervised and unsupervised machine learning models that circumvent the ever-present challenge of scarce annotations and thus allow for model generalization in space and time. Specifically, it is shown how merely few ground truth data are needed to generate high quality crop type maps and crop phenology estimations. Finally, this thesis argues there is considerable distance in value between model inferences and decision making in real-world scenarios and thereby showcases the power of causal and interpretable machine learning in bridging this gap. 	
"Two-fluid numerical model of chromospheric heating and plasma outflows
  in a quiet-Sun"	http://arxiv.org/abs/2211.12289v1	2022-11-22T14:05:26Z	2022-11-22T14:05:26Z	  \textbf{Purpose:} This paper addresses long-standing solar physics problems, namely, the heating of the solar chromosphere and the origin of the solar wind. Our aim is to reveal the related mechanisms behind chromospheric heating and plasma outflows in a quiet-Sun. \textbf{Methods:} The approach is based on a two-fluid numerical model that accounts for thermal non-equilibrium (ionization/recombination), non-adiabatic, and non-ideal dynamics of protons+electrons and hydrogen atoms. The model is applied to numerically simulate the propagation and dissipation of granulation-generated waves in the chromosphere and plasma flows inside a quiet region. \textbf{Results:} The obtained results demonstrate that collisions between protons+electrons and hydrogen atoms supplemented by plasma viscosity, magnetic resistivity, and recombination lead to thermal energy release, which compensates radiative and thermal losses in the chromosphere, and sustains the atmosphere with vertical profiles of averaged temperature and periods of generated waves that are consistent with recent observational data. \textbf{Conclusion:} Our model conjectures a most robust and global physical picture of granulation-generated wave motions, plasma flows, and subsequent heating, which form and dynamically couple the various layers of the solar atmosphere. 	
"S-shaped flow curves and local stress oscillations in confined shear
  thickening suspensions"	http://arxiv.org/abs/2211.12272v2	2022-12-14T09:18:17Z	2022-11-22T13:45:00Z	  We experimentally investigated the role of boundary confinements in shear thickening suspensions. Unexpected rheological responses were observed across multiple length scales under highly confined geometries. The flow curves were found to equilibrate at very slow rates, and appeared S-shaped in steady states. By combining shear rheological characterizations with boundary stress microscopy (BSM), we observed sustained local stress oscillations in confined suspensions. The stress heterogeneities were induced by concentrated high-stress clusters that traveled stably along the flow direction. We show that the growth and relaxation of these particle clusters contributed to the non-monotonic flow curves, and mitigated the fluctuations of global shear rate. By comparing the flow properties under different system sizes, we uncovered how boundary confinements effectively determined both the rheological and statistical responses of dense suspensions to shear thickening transition. 	
"Sustainable Wireless Services with UAV Swarms Tailored to Renewable
  Energy Sources"	http://arxiv.org/abs/2211.12224v2	2022-11-23T17:16:56Z	2022-11-22T12:30:39Z	  Unmanned Aerial Vehicle (UAV) swarms are often required in off-grid scenarios, such as disaster-struck, war-torn or rural areas, where the UAVs have no access to the power grid and instead rely on renewable energy. Considering a main battery fed from two renewable sources, wind and solar, we scale such a system based on the financial budget, environmental characteristics, and seasonal variations. Interestingly, the source of energy is correlated with the energy expenditure of the UAVs, since strong winds cause UAV hovering to become increasingly energy-hungry. The aim is to maximize the cost efficiency of coverage at a particular location, which is a combinatorial optimization problem for dimensioning of the multivariate energy generation system under non-convex criteria. We have devised a customized algorithm by lowering the processing complexity and reducing the solution space through sampling. Evaluation is done with condensed real-world data on wind, solar energy, and traffic load per unit area, driven by vendor-provided prices. The implementation was tested in four locations, with varying wind or solar intensity. The best results were achieved in locations with mild wind presence and strong solar irradiation, while locations with strong winds and low solar intensity require higher Capital Expenditure (CAPEX) allocation. 	
"Telling emissions apart in a multiphoton resonance: visualizing a
  conditional evolution"	http://arxiv.org/abs/2211.12144v2	2022-12-22T12:51:32Z	2022-11-22T10:18:30Z	  We find that the phase-space representation of the electromagnetic field inside a driven cavity strongly coupled to a two-level atom can be employed to distinguish photon emissions along a ladder of dressed states sustaining a two-photon resonance. The emissions are told apart by means of the different quantum beats generated by the conditional states they prepare. Sample quantum trajectories explicitly reveal the difference in the transient due to the initial condition, in a background set by the Jaynes-Cummings spectrum and revealed by the strong-coupling limit. Their ensemble-averaged evolution is tracked for a time period similar to that waited for the loss of a next photon as the maximum non-exclusive probability, indicated by the peak of the intensity correlation function. 	
FastFlow: AI for Fast Urban Wind Velocity Prediction	http://arxiv.org/abs/2211.12035v1	2022-11-22T06:13:48Z	2022-11-22T06:13:48Z	  Data-driven approaches, including deep learning, have shown great promise as surrogate models across many domains. These extend to various areas in sustainability. An interesting direction for which data-driven methods have not been applied much yet is in the quick quantitative evaluation of urban layouts for planning and design. In particular, urban designs typically involve complex trade-offs between multiple objectives, including limits on urban build-up and/or consideration of urban heat island effect. Hence, it can be beneficial to urban planners to have a fast surrogate model to predict urban characteristics of a hypothetical layout, e.g. pedestrian-level wind velocity, without having to run computationally expensive and time-consuming high-fidelity numerical simulations. This fast surrogate can then be potentially integrated into other design optimization frameworks, including generative models or other gradient-based methods. Here we present the use of CNNs for urban layout characterization that is typically done via high-fidelity numerical simulation. We further apply this model towards a first demonstration of its utility for data-driven pedestrian-level wind velocity prediction. The data set in this work comprises results from high-fidelity numerical simulations of wind velocities for a diverse set of realistic urban layouts, based on randomized samples from a real-world, highly built-up urban city. We then provide prediction results obtained from the trained CNN, demonstrating test errors of under 0.1 m/s for previously unseen urban layouts. We further illustrate how this can be useful for purposes such as rapid evaluation of pedestrian wind velocity for a potential new layout. It is hoped that this data set will further accelerate research in data-driven urban AI, even as our baseline model facilitates quantitative comparison to future methods. 	
"Explainability of Traditional and Deep Learning Models on Longitudinal
  Healthcare Records"	http://arxiv.org/abs/2211.12002v1	2022-11-22T04:39:17Z	2022-11-22T04:39:17Z	  Recent advances in deep learning have led to interest in training deep learning models on longitudinal healthcare records to predict a range of medical events, with models demonstrating high predictive performance. Predictive performance is necessary but insufficient, however, with explanations and reasoning from models required to convince clinicians for sustained use. Rigorous evaluation of explainability is often missing, as comparisons between models (traditional versus deep) and various explainability methods have not been well-studied. Furthermore, ground truths needed to evaluate explainability can be highly subjective depending on the clinician's perspective. Our work is one of the first to evaluate explainability performance between and within traditional (XGBoost) and deep learning (LSTM with Attention) models on both a global and individual per-prediction level on longitudinal healthcare data. We compared explainability using three popular methods: 1) SHapley Additive exPlanations (SHAP), 2) Layer-Wise Relevance Propagation (LRP), and 3) Attention. These implementations were applied on synthetically generated datasets with designed ground-truths and a real-world medicare claims dataset. We showed that overall, LSTMs with SHAP or LRP provides superior explainability compared to XGBoost on both the global and local level, while LSTM with dot-product attention failed to produce reasonable ones. With the explosion of the volume of healthcare data and deep learning progress, the need to evaluate explainability will be pivotal towards successful adoption of deep learning models in healthcare settings. 	
"Don't Watch Me: A Spatio-Temporal Trojan Attack on
  Deep-Reinforcement-Learning-Augment Autonomous Driving"	http://arxiv.org/abs/2211.14440v1	2022-11-22T02:42:42Z	2022-11-22T02:42:42Z	  Deep reinforcement learning (DRL) is one of the most popular algorithms to realize an autonomous driving (AD) system. The key success factor of DRL is that it embraces the perception capability of deep neural networks which, however, have been proven vulnerable to Trojan attacks. Trojan attacks have been widely explored in supervised learning (SL) tasks (e.g., image classification), but rarely in sequential decision-making tasks solved by DRL. Hence, in this paper, we explore Trojan attacks on DRL for AD tasks. First, we propose a spatio-temporal DRL algorithm based on the recurrent neural network and attention mechanism to prove that capturing spatio-temporal traffic features is the key factor to the effectiveness and safety of a DRL-augment AD system. We then design a spatial-temporal Trojan attack on DRL policies, where the trigger is hidden in a sequence of spatial and temporal traffic features, rather than a single instant state used in existing Trojan on SL and DRL tasks. With our Trojan, the adversary acts as a surrounding normal vehicle and can trigger attacks via specific spatial-temporal driving behaviors, rather than physical or wireless access. Through extensive experiments, we show that while capturing spatio-temporal traffic features can improve the performance of DRL for different AD tasks, they suffer from Trojan attacks since our designed Trojan shows high stealthy (various spatio-temporal trigger patterns), effective (less than 3.1\% performance variance rate and more than 98.5\% attack success rate), and sustainable to existing advanced defenses. 	
"Massive star cluster origin for the galactic cosmic ray population at
  very-high energies"	http://arxiv.org/abs/2211.11625v2	2022-11-30T15:29:41Z	2022-11-21T16:30:19Z	"  We demonstrate that supernova remnant (SNR) shocks embedded within massive star clusters can reproduce both the cosmic-ray proton and all-particle spectra measured in the vicinity of the Earth up to hundreds of peta-electronvolts (PeV). We model two classes of massive star clusters. The first population are ""loose clusters"" which do not power a collective wind termination shock. SNR shocks then expand in a low-density and weakly magnetised medium, and this population mainly contributes up to the ""knee"" of the CR spectrum around 1 PeV. The second population are young compact clusters, which are powerful and compact enough to sustain a collective wind outflow. SNR shocks then expand from the cluster into the strongly magnetised wind and accelerate nuclei up to ultra-high energies. This population, representing only about 15% of all Galactic massive star clusters, nevertheless dominates the spectrum between ~ 1 and 100 PeV. While these two components alone can reproduce the shape of the CR spectrum up to hundreds of PeV, adding a light sub-ankle extragalactic component motivated by composition and anisotropy measurements, allows to reproduce the spectrum up to the highest energies. Fitting parameters are systematically linked to physical variables whose values are in line with theoretical expectations. "	
"Semantic Segmentation for Fully Automated Macrofouling Analysis on
  Coatings after Field Exposure"	http://arxiv.org/abs/2211.11607v1	2022-11-21T16:03:16Z	2022-11-21T16:03:16Z	  Biofouling is a major challenge for sustainable shipping, filter membranes, heat exchangers, and medical devices. The development of fouling-resistant coatings requires the evaluation of their effectiveness. Such an evaluation is usually based on the assessment of fouling progression after different exposure times to the target medium (e.g., salt water). The manual assessment of macrofouling requires expert knowledge about local fouling communities due to high variances in phenotypical appearance, has single-image sampling inaccuracies for certain species, and lacks spatial information. Here we present an approach for automatic image-based macrofouling analysis. We created a dataset with dense labels prepared from field panel images and propose a convolutional network (adapted U-Net) for the semantic segmentation of different macrofouling classes. The establishment of macrofouling localization allows for the generation of a successional model which enables the determination of direct surface attachment and in-depth epibiotic studies. 	
"A Computationally Efficient Robust Model Predictive Control Framework
  for Ecological Adaptive Cruise Control Strategy of Electric Vehicles"	http://arxiv.org/abs/2211.11306v1	2022-11-21T09:45:39Z	2022-11-21T09:45:39Z	  The recent advancement in vehicular networking technology provides novel solutions for designing intelligent and sustainable vehicle motion controllers. This work addresses a car-following task, where the feedback linearisation method is combined with a robust model predictive control (RMPC) scheme to safely, optimally and efficiently control a connected electric vehicle. In particular, the nonlinear dynamics are linearised through a feedback linearisation method to maintain an efficient computational speed and to guarantee global optimality. At the same time, the inevitable model mismatch is dealt with by the RMPC design. The control objective of the RMPC is to optimise the electric energy efficiency of the ego vehicle with consideration of a bounded model mismatch disturbance subject to satisfaction of physical and safety constraints. Numerical results first verify the validity and robustness through a comparison between the proposed RMPC and a nominal MPC. Further investigation into the performance of the proposed method reveals a higher energy efficiency and passenger comfort level as compared to a recently proposed benchmark method using the space-domain modelling approach. 	
"OSDG 2.0: a multilingual tool for classifying text data by UN
  Sustainable Development Goals (SDGs)"	http://arxiv.org/abs/2211.11252v1	2022-11-21T08:41:57Z	2022-11-21T08:41:57Z	  Despite concrete indicators and targets, monitoring the progress of the UN Sustainable Development Goals (SDGs) remains a challenge, given the many different actors, initiatives, and institutions involved. OSDG, an open-source classification tool aims to help navigate the SDG related ambiguities through a simple and easy to use application. The tool allows to map and connect activities to the SDGs by identifying SDG -relevant content in any text. This paper presents OSDG 2.0, a new iteration of the partnership's work, which marks a significant improvement in the tool's methodology, as well as support for content in 15 languages. 	
Graceful Forgetting II. Data as a Process	http://arxiv.org/abs/2211.15441v1	2022-11-20T09:02:51Z	2022-11-20T09:02:51Z	  Data are rapidly growing in size and importance for society, a trend motivated by their enabling power. The accumulation of new data, sustained by progress in technology, leads to a boundless expansion of stored data, in some cases with an exponential increase in the accrual rate itself. Massive data are hard to process, transmit, store, and exploit, and it is particularly hard to keep abreast of the data store as a whole. This paper distinguishes three phases in the life of data: acquisition, curation, and exploitation. Each involves a distinct process, that may be separated from the others in time, with a different set of priorities. The function of the second phase, curation, is to maximize the future value of the data given limited storage. I argue that this requires that (a) the data take the form of summary statistics and (b) these statistics follow an endless process of rescaling. The summary may be more compact than the original data, but its data structure is more complex and it requires an on-going computational process that is much more sophisticated than mere storage. Rescaling results in dimensionality reduction that may be beneficial for learning, but that must be carefully controlled to preserve relevance. Rescaling may be tuned based on feedback from usage, with the proviso that our memory of the past serves the future, the needs of which are not fully known. 	
"TuRaN: True Random Number Generation Using Supply Voltage Underscaling
  in SRAMs"	http://arxiv.org/abs/2211.10894v1	2022-11-20T07:45:07Z	2022-11-20T07:45:07Z	  Prior works propose SRAM-based TRNGs that extract entropy from SRAM arrays. SRAM arrays are widely used in a majority of specialized or general-purpose chips that perform the computation to store data inside the chip. Thus, SRAM-based TRNGs present a low-cost alternative to dedicated hardware TRNGs. However, existing SRAM-based TRNGs suffer from 1) low TRNG throughput, 2) high energy consumption, 3) high TRNG latency, and 4) the inability to generate true random numbers continuously, which limits the application space of SRAM-based TRNGs. Our goal in this paper is to design an SRAM-based TRNG that overcomes these four key limitations and thus, extends the application space of SRAM-based TRNGs. To this end, we propose TuRaN, a new high-throughput, energy-efficient, and low-latency SRAM-based TRNG that can sustain continuous operation. TuRaN leverages the key observation that accessing SRAM cells results in random access failures when the supply voltage is reduced below the manufacturer-recommended supply voltage. TuRaN generates random numbers at high throughput by repeatedly accessing SRAM cells with reduced supply voltage and post-processing the resulting random faults using the SHA-256 hash function. To demonstrate the feasibility of TuRaN, we conduct SPICE simulations on different process nodes and analyze the potential of access failure for use as an entropy source. We verify and support our simulation results by conducting real-world experiments on two commercial off-the-shelf FPGA boards. We evaluate the quality of the random numbers generated by TuRaN using the widely-adopted NIST standard randomness tests and observe that TuRaN passes all tests. TuRaN generates true random numbers with (i) an average (maximum) throughput of 1.6Gbps (1.812Gbps), (ii) 0.11nJ/bit energy consumption, and (iii) 278.46us latency. 	
Sociality and Skill Sharing in the Garden	http://arxiv.org/abs/2211.10766v1	2022-11-19T18:34:11Z	2022-11-19T18:34:11Z	  Gardening is an activity that involves a number of dimensions of increasing interest to HCI and CSCW researchers, including recreation, sustainability, and engagement with nature. This paper considers the garden setting in order to understand the role that collaborative and social computing technologies might play for practitioners engaging in outdoor skilled activities. We conducted participant observations with nine experienced gardeners aged 22-71 years. Through this process, we find that gardeners continuously configure their environments to accommodate their preferences for sociality. They share embodied skills and help others attune to sensory information in person, but also influence learning through the features in their garden that are observed by others. This paper provides an understanding of sociality in the garden, highlights skill sharing as a key domain for design in this space, and contributes design considerations for collaborative technologies in outdoor settings. 	
"Surviving in Ocean Worlds: Experimental Characterization of Fiber Optic
  Tethers across Europa-like Ice Faults and Unraveling the Sliding Behavior of
  Ice"	http://arxiv.org/abs/2211.10337v1	2022-11-18T16:48:04Z	2022-11-18T16:48:04Z	  As an initial step towards in-situ exploration of the interiors of Ocean Worlds to search for life using cryobot architectures, we test how various communication tethers behave under potential Europa-like stress conditions. By freezing two types of pretensioned insulated fiber optic cables inside ice blocks, we simulate tethers being refrozen in a probe's wake as it traverses through an Ocean World's ice shell. Using a cryogenic biaxial apparatus, we simulate shear motion on pre-existing faults at various velocities and temperatures. These shear tests are used to evaluate the mechanical behavior of ice, characterize the behavior of communication tethers, and explore their limitations for deployment by a melt probe. We determine (a) the maximum shear stress tethers can sustain from an ice fault, prior to failure (viable/unviable regimes for deployment) and (b) optical tether performance for communications. We find that these tethers are fairly robust across a range of temperature and velocity conditions expected on Europa (T(K) = 95 to 260; velocity (m/s) = 5 x 10-7 to 3 x 10-4). However, damage to the outer jackets of the tethers and stretching of inner fibers at the coldest temperatures tested both indicate a need for further tether prototype development.   Overall, these studies constrain the behavior of optical tethers for use at Ocean Worlds, improve the ability to probe thermomechanical properties of dynamic ice shells likely to be encountered by landed missions, and guide future technology development for accessing the interiors of (potentially habitable / inhabited) Ocean Worlds. 	
"Sustainable and convenient: bi-modal public transit systems
  outperforming the private car"	http://arxiv.org/abs/2211.10221v2	2022-11-21T10:10:04Z	2022-11-18T13:17:02Z	  Mobility is an indispensable part of modern human societies, but the dominance of motorized individual traffic (MIV, i.e., the private car) leads to a prohibitive waste of energy as well as other resources. Here we show that by combining a line service (e.g., railway) system with a fleet of ride-pooling shuttles connecting line stops to desired pick-up and drop-off points, a bi-modal public transport system may result which provides on-demand door-to-door service at a service level (in terms of transit times) superior to current public transport, and with an overall comfort level comparable to MIV. We identify the conflicting objectives for optimization, i.e., user convenience and energy consumption, and evaluate the system performance in terms of Pareto fronts. By means of simulation and analytical theory, we find that energy consumption can be as low as 20% of MIV, at line service densities typically found in real settings. Surprisingly, we find favorable performance not only in urban, but also in rural settings. 	
"Numerical study of RF power coupling in fusion-relevant single- and
  multi-driver H$^-$ ion sources"	http://arxiv.org/abs/2211.10143v1	2022-11-18T10:36:11Z	2022-11-18T10:36:11Z	  ITER's large and powerful neutral beam injection system is based on an ion source utilizing a modular concept, where eight cylindrical drivers are attached to one common expansion and extraction region. In each driver, a plasma is sustained via inductive coupling with powers of up to 100 kW at a driving radio frequency (RF) of 1 MHz to produce fusion-relevant hydrogen beams. These high powers impose great stress on the electric system. Recent measurements at the single-driver test bed BATMAN Upgrade showed that the RF power transfer efficiency $\eta$, which measures the ratio of power absorbed by plasma to total RF power, is only around 0.5, leaving room for optimization. In multi-driver test beds such as ELISE with four drivers $\eta$ is found to be even further decreased to around 0.4. To explain this difference, a previously validated self-consistent 2D RF power coupling fluid model is applied. For the same absorbed power per driver, the model shows virtually the same spatial distributions of plasma parameters and power absorption in single- and multi-driver sources. However, the coil current is slightly increased in the multi-driver model due to a changed spatial distribution of the magnetic RF field in the region surrounding the drivers. Typically, in multi-driver sources conductive shields are applied to cancel the electromagnetic interference between individual drivers. These shields are found to affect the spatial distribution of the RF fields more severely, the effect being highly dependent on the distance between the RF coil and the shield. In the case of the ELISE ion source a further decrease of $\eta$ is calculated by the model being in good agreement with experimental measurements. 	
"Sequential Self-Propelled Morphology Transitions of Nanoscale
  Condensates Diversify the Jumping-Droplet Condensation"	http://arxiv.org/abs/2211.09546v1	2022-11-17T14:06:27Z	2022-11-17T14:06:27Z	  The jumping-droplet condensation, namely the out-of-plane jumping of condensed droplets upon coalescence, has been a promising technical innovation in the fields of energy harvesting, droplet manipulation, thermal management, etc., yet is limited owing to the challenge of enabling a sustainable and programmable control. Here, we characterized the morphological evolutions and dynamic behaviors of nanoscale condensates on different nanopillar surfaces, and found that there exists an unrevealed domino effect throughout the entire droplet lifecycle and the coalescence is not the only mechanism to access the droplet jumping. The vapor nucleation preferentially occurs in structure intervals, thus the formed liquid embryos incubate and grow in a spatially confined mode, which stores an excess surface energy and simultaneously provides a asymmetric Laplace pressure, stimulating the trapped droplets to undergo a dewetting transition or even a self-jumping, which can be facilitated by the tall and dense nanostructures. Subsequently, the adjacent droplets merge mutually and further trigger more multifarious self-propelled behaviors that are affected by underlying surface nanostructure, including dewetting transition, coalescence-induced jumping and jumping relay. Moreover, an improved energy-based model was developed by considering the nano-physical effects, the theoretical prediction not only extends the coalescence-induced jumping to the nanometer-sized droplets but also correlates the surface nanostructure topology to the jumping velocity. Such a cumulative effect of nucleation-growth-coalescence on the ultimate morphology of droplet may offer a new strategy for designing functional nanostructured surfaces that serve to orientationally manipulate, transport and collect droplets, and motivate surface engineers to achieve the performance ceiling of the jumping-droplet condensation. 	
"Solar Power driven EV Charging Optimization with Deep Reinforcement
  Learning"	http://arxiv.org/abs/2211.09479v1	2022-11-17T11:52:27Z	2022-11-17T11:52:27Z	  Power sector decarbonization plays a vital role in the upcoming energy transition towards a more sustainable future. Decentralized energy resources, such as Electric Vehicles (EV) and solar photovoltaic systems (PV), are continuously integrated in residential power systems, increasing the risk of bottlenecks in power distribution networks. This paper aims to address the challenge of domestic EV charging while prioritizing clean, solar energy consumption. Real Time-of-Use tariffs are treated as a price-based Demand Response (DR) mechanism that can incentivize end-users to optimally shift EV charging load in hours of high solar PV generation with the use of Deep Reinforcement Learning (DRL). Historical measurements from the Pecan Street dataset are analyzed to shape a flexibility potential reward to describe end-user charging preferences. Experimental results show that the proposed DQN EV optimal charging policy is able to reduce electricity bills by an average 11.5\% by achieving an average utilization of solar power 88.4 	
"Lotka-Volterra predator-prey model with periodically varying carrying
  capacity"	http://arxiv.org/abs/2211.09276v2	2023-02-14T10:43:58Z	2022-11-17T00:37:07Z	  We study the stochastic spatial Lotka-Volterra (LV) model for predator-prey interaction subject to a periodically varying carrying capacity. The LV model with on-site lattice occupation restrictions that represent finite food resources for the prey exhibits a continuous active-to-absorbing phase transition. The active phase is sustained by spatio-temporal patterns in the form of pursuit and evasion waves. Monte Carlo simulations on a two-dimensional lattice are utilized to investigate the effect of seasonal variations of the environment on species coexistence. The results of our simulations are also compared to a mean-field analysis. We find that the parameter region of predator and prey coexistence is enlarged relative to the stationary situation when the carrying capacity varies periodically. The stationary regime of our periodically varying LV system shows qualitative agreement between the stochastic model and the mean-field approximation. However, under periodic carrying capacity switching environments, the mean-field rate equations predict period-doubling scenarios that are washed out by internal reaction noise in the stochastic lattice model. Utilizing visual representations of the lattice simulations and dynamical correlation functions, we study how the pursuit and evasion waves are affected by ensuing resonance effects. Correlation function measurements indicate a time delay in the response of the system to sudden changes in the environment. Resonance features are observed in our simulations that cause prolonged persistent spatial correlations. Different effective static environments are explored in the extreme limits of fast- and slow periodic switching. The analysis of the mean-field equations in the fast-switching regime enables a semi-quantitative description of the stationary state. 	
"Secure SWIPT in STAR-RIS Aided Downlink MISO Rate-Splitting Multiple
  Access Networks"	http://arxiv.org/abs/2211.09081v1	2022-11-16T18:02:53Z	2022-11-16T18:02:53Z	  Recently, simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RISs) have emerged as a novel technology that facilitates sustainable communication by providing 360 coverage and new degrees-of-freedom (DoF) for manipulating signal propagation as well as simultaneous wireless information and power transfer (SWIPT). Inspired by these applications, this paper presents a novel STAR-RIS-aided secure SWIPT system for downlink multiple input single output (MISO) Rate-Splitting multiple access (RSMA) networks. The transmitter concurrently communicates with the information receivers (IRs) and sends energy to untrusted energy receivers (UERs). UERs are also able to wiretap the IR streams. The paper assumes that the channel state information (CSI) of the IRs is known at the transmitter. However, only imperfect CSI (ICSI) for the UERs is available at the transmitter. The paper aims to maximize the achievable worst-case sum secrecy rate (WCSSR) of the IRs under a total transmit power constraint, a sum energy constraint for the UERs, and constraints on the transmission and reflection coefficients by jointly optimizing the precoders and the transmission and reflection beamforming at the STAR-RIS. The formulated problem is non-convex with intricately coupled variables, and to tackle this challenge a suboptimal two-step iterative algorithm based on the sequential parametric convex approximation (SPCA) method is proposed. Specifically, the precoders and the transmission and reflection beamforming vectors are optimized alternatingly. Simulations are conducted to show that the proposed RSMA-based algorithm in a STAR-RIS aided network can improve the secrecy of the confidential information and the overall spectral efficiency. 	
"Research Software Science: Expanding the Impact of Research Software
  Engineering"	http://arxiv.org/abs/2211.09034v1	2022-11-16T16:44:23Z	2022-11-16T16:44:23Z	  Software plays a central role in scientific discovery. Improving how we develop and use software for research can have both broad and deep impacts on a spectrum of challenges and opportunities society faces today. The emergence of Research Software Engineer (RSE) as a role correlates with the growing complexity of scientific challenges and diversity of software team skills. In this paper, we describe research software science (RSS), an idea related to RSE, and particularly suited to research software teams. RSS promotes the use of scientific methodologies to explore and establish broadly applicable knowledge. Using RSS, we can pursue sustainable, repeatable, and reproducible software improvements that positively impact research software toward improved scientific discovery. 	
"Challenges related to system-of-systems for greening and climate
  adaptation in smart cities"	http://arxiv.org/abs/2211.08890v1	2022-11-16T12:53:53Z	2022-11-16T12:53:53Z	  This paper presents the results of interviews conducted as part of the DYNASOS project. The objective was to collect challenges related to the design, implementation and management of system-of-systems (SoS) in the context of climate adaptation and greening of smart cities. 23 individuals from cities, academia, and industry were interviewed between March and May 2022 and 57 distinct challenges were collected and analyzed. Our results show that while technical issues (such as interoperability or data acquisition) persist, non-technical issues are the main obstacles. Difficulties in information sharing, effective communication, and synchronization between different actors are the most important challenges. 	
Bi-directional Digital Twin and Edge Computing in the Metaverse	http://arxiv.org/abs/2211.08700v2	2023-02-14T03:24:00Z	2022-11-16T06:25:31Z	  The Metaverse has emerged to extend our lifestyle beyond physical limitations. As essential components in the Metaverse, digital twins (DTs) are the digital replicas of physical items. DTs enable emulation of real-world scenarios and prediction for energy and resource-efficient operation, resulting in sustainable applications. End users access the Metaverse using a variety of devices (e.g., head-mounted devices (HMDs)), mostly lightweight. Multi-access edge computing (MEC) provides responsive services to the end users, leading to an immersive Metaverse experience. With the anticipation to represent physical objects, end users, and edge computing systems as DTs in the Metaverse, the construction of these DTs and the interplay between them have not been investigated. In this paper, we discuss the bidirectional reliance between the DT and the MEC system and investigate the creation of DTs of objects and users on the MEC servers and DT-assisted edge computing (DTEC). We also study the interplay between the DTs and DTECs to allocate the resources fairly and optimally and provide an immersive experience in the Metaverse. Owing to the dynamic network states (e.g., channel states) and mobility of the users, we discuss the interplay between local DTECs (on local MEC servers) and the global DTEC (on cloud server) to cope with the handover among MEC servers and avoid intermittent Metaverse services. 	
"Perona: Robust Infrastructure Fingerprinting for Resource-Efficient Big
  Data Analytics"	http://arxiv.org/abs/2211.08227v2	2023-01-30T10:05:48Z	2022-11-15T15:48:09Z	  Choosing a good resource configuration for big data analytics applications can be challenging, especially in cloud environments. Automated approaches are desirable as poor decisions can reduce performance and raise costs. The majority of existing automated approaches either build performance models from previous workload executions or conduct iterative resource configuration profiling until a near-optimal solution has been found. In doing so, they only obtain an implicit understanding of the underlying infrastructure, which is difficult to transfer to alternative infrastructures and, thus, profiling and modeling insights are not sustained beyond very specific situations.   We present Perona, a novel approach to robust infrastructure fingerprinting for usage in the context of big data analytics. Perona employs common sets and configurations of benchmarking tools for target resources, so that resulting benchmark metrics are directly comparable and ranking is enabled. Insignificant benchmark metrics are discarded by learning a low-dimensional representation of the input metric vector, and previous benchmark executions are taken into consideration for context-awareness as well, allowing to detect resource degradation. We evaluate our approach both on data gathered from our own experiments as well as within related works for resource configuration optimization, demonstrating that Perona captures the characteristics from benchmark runs in a compact manner and produces representations that can be used directly. 	
"Impact of combining human and analytics feedback on students' engagement
  with, and performance in, reflective writing tasks"	http://arxiv.org/abs/2211.08222v1	2022-11-15T15:41:26Z	2022-11-15T15:41:26Z	  Reflective writing is part of many higher education courses across the globe. It is often considered a challenging task for students as it requires self-regulated learning skills to appropriately plan, timely engage and deeply reflect on learning experiences. Despite an advance in writing analytics and the pervasiveness of human feedback aimed to support student reflections, little is known about how to integrate feedback from humans and analytics to improve students' learning engagement and performance in reflective writing tasks. This study proposes a personalised behavioural feedback intervention based on students' writing engagement analytics utilising time-series analysis of digital traces from a ubiquitous online word processing platform. In a semester-long experimental study involving 81 postgraduate students, its impact on learning engagement and performance was studied. The results showed that the intervention cohort engaged statistically significantly more in their reflective writing task after receiving the combined feedback compared to the control cohort which only received human feedback on their reflective writing content. Further analyses revealed that the intervention cohort reflected more regularly at the weekly level, the regularity of weekly reflection led to better performance grades, and the impact on students with low self-regulated learning skills was higher. This study emphasizes the powerful benefits of implementing combined feedback approaches in which the strengths of analytics and human feedback are synthesized to improve student engagement and performance. Further research should explore the long-term sustainability of the observed effects and their validity in other contexts. 	
Faster Verifiable Delay Function For Shorter Delay Parameter	http://arxiv.org/abs/2211.08162v1	2022-11-15T14:15:56Z	2022-11-15T14:15:56Z	  A Verifiable Delay Function (VDF) is a function that takes a specified sequential time $T$ to be evaluated, but can be verified in $O(\log T)$-time. For meaningful security, $T$ can be at most subexponential in the security parameter $\lambda$ but has no lower bound. VDFs are useful in several applications ranging from randomness beacons to sustainable blockchains but are really rare in practice. To the best of our knowledge, the sequential effort required for verification in all the VDFs [7,9,4] known to date, is in $\Omega(\log T)$.   This paper proposes a verifiable delay function that requires only two sequential squaring to verify when the delay parameter is polynomially-bounded i.e., $T\le \mathtt{poly}(\lambda)$. Thus in our VDF, the sequential effort required for verification is fixed and independent of the security parameter. 	
"Aligning Learners' Expectations and Performance by Learning Analytics
  Systemwith a Predictive Model"	http://arxiv.org/abs/2211.07729v1	2022-11-14T20:00:48Z	2022-11-14T20:00:48Z	  Learning analytics (LA) is data collection, analysis, and representation of data about learners in order to improve their learning and performance. Furthermore, LA opens the door to opportunities for self-regulated learning in higher education, a circular process in which learners activate and sustain behaviours that are oriented toward their personal learning goals. The potentials of LA and self-regulated learning are huge; however, they are not yet widely applied in higher education institutions. Slovenian higher education institutions have lagged behind other European countries in LA adoption. Our research aims to fill this gap by using a qualitatively and quantitatively led workflow for building a requirement-oriented LA solution, consisting of empirically gathering the students' expectations of LA and presenting a dashboard solution. Translated Student Expectations of Learning Analytics Questionnaire and focus groups were used to gather expectations from learners. Based on them, a user interface utilizing LA and grade prediction with an AI model was implemented for a selected course. The interface includes early grade prediction, peer comparison, and historical data overview. Grade prediction is based on a machine learning model built on users' interaction in the virtual learning environment, demographic data and lab grades. First, classification is used to determine students at risk of failing - its precision reaches 98% after the first month of the course. Second, the exact grade is predicted with the Decision Tree Regressor, reaching a mean absolute error of 11.2grade points (on a 100 points scale) after the first month. The proposed system's main benefit is the support for self-regulation of the learning process during the semester, possibly motivating students to adjust their learning strategies to prevent failing the course. Initial student evaluation showed positive results. 	
"Giving RSEs a Larger Stage through the Better Scientific Software
  Fellowship"	http://arxiv.org/abs/2211.07436v2	2022-11-15T03:42:52Z	2022-11-14T15:11:47Z	  The Better Scientific Software Fellowship (BSSwF) was launched in 2018 to foster and promote practices, processes, and tools to improve developer productivity and software sustainability of scientific codes. BSSwF's vision is to grow the community with practitioners, leaders, mentors, and consultants to increase the visibility of scientific software production and sustainability. Over the last five years, many fellowship recipients and honorable mentions have identified as research software engineers (RSEs). This paper provides case studies from several of the program's participants to illustrate some of the diverse ways BSSwF has benefited both the RSE and scientific communities. In an environment where the contributions of RSEs are too often undervalued, we believe that programs such as BSSwF can be a valuable means to recognize and encourage community members to step outside of their regular commitments and expand on their work, collaborations and ideas for a larger audience. 	
"Entanglement dynamics of coupled quantum oscillators in independent
  nonMarkovian baths"	http://arxiv.org/abs/2211.07124v1	2022-11-14T05:30:17Z	2022-11-14T05:30:17Z	  This work strives to better understand how the entanglement in an open quantum system, here represented by two coupled Brownian oscillators, is affected by a nonMarkovian environment (with memories), here represented by two independent baths each oscillator separately interacts with. We consider two settings, a `symmetric' configuration wherein the parameters of both oscillators and their baths are identical, and an `asymmetric' configuration wherein they are different, in particular, a `hybrid' configuration, where one of the two coupled oscillators interacts with a nonMarkovian bath and the other with a Markovian bath. We ask two groups of questions: Q1) Which time regime does the bath's nonMarkovianity benefit the system's entanglement most? The answers we get from detailed numerical studies suggest that A1) For an initially entangled pair of oscillators, we see that in the intermediate time range, the duration of entanglement is proportional to the memory time, and it lasts a fraction of the relaxation time, but at late times when the dynamics reaches a steady state, the value of the symplectic eigenvalue of the partially transposed covariance matrix barely benefit from the bath nonMarkovianity. For the second group of questions: Q2)Can the memory of one nonMarkovian bath be passed on to another Markovian bath? And if so, does this memory transfer help to sustain the system's entanglement dynamics? Our results from numerical studies of the asymmetric hybrid configuration indicate that A2) A system with a short memory time can acquire improvement when it is coupled to another system with a long memory time, but, at a cost of the latter. The sustainability of the bipartite entanglement is determined by the party which breaks off entanglement most easily. 	
"Evaluating Distribution System Reliability with Hyperstructures Graph
  Convolutional Nets"	http://arxiv.org/abs/2211.07645v1	2022-11-14T01:29:09Z	2022-11-14T01:29:09Z	  Nowadays, it is broadly recognized in the power system community that to meet the ever expanding energy sector's needs, it is no longer possible to rely solely on physics-based models and that reliable, timely and sustainable operation of energy systems is impossible without systematic integration of artificial intelligence (AI) tools. Nevertheless, the adoption of AI in power systems is still limited, while integration of AI particularly into distribution grid investment planning is still an uncharted territory. We make the first step forward to bridge this gap by showing how graph convolutional networks coupled with the hyperstructures representation learning framework can be employed for accurate, reliable, and computationally efficient distribution grid planning with resilience objectives. We further propose a Hyperstructures Graph Convolutional Neural Networks (Hyper-GCNNs) to capture hidden higher order representations of distribution networks with attention mechanism. Our numerical experiments show that the proposed Hyper-GCNNs approach yields substantial gains in computational efficiency compared to the prevailing methodology in distribution grid planning and also noticeably outperforms seven state-of-the-art models from deep learning (DL) community. 	
"GreenPLM: Cross-lingual pre-trained language models conversion with
  (almost) no cost"	http://arxiv.org/abs/2211.06993v2	2022-11-29T20:45:15Z	2022-11-13T18:59:15Z	  While large pre-trained models have transformed the field of natural language processing (NLP), the high training cost and low cross-lingual availability of such models prevent the new advances from being equally shared by users across all languages, especially the less spoken ones. To promote equal opportunities for all language speakers in NLP research and to reduce energy consumption for sustainability, this study proposes an effective and energy-efficient framework GreenPLM that uses bilingual lexicons to directly translate language models of one language into other languages at (almost) no additional cost. We validate this approach in 18 languages and show that this framework is comparable to, if not better than, other heuristics trained with high cost. In addition, when given a low computational cost (2.5\%), the framework outperforms the original monolingual language models in six out of seven tested languages. We release language models in 50 languages translated from English and the source code here. 	
"A subsurface magma ocean on Io: Exploring the steady state of partially
  molten planetary bodies"	http://arxiv.org/abs/2211.06945v1	2022-11-13T16:39:02Z	2022-11-13T16:39:02Z	  Intense tidal heating within Io produces active volcanism on the surface, and its internal structure has long been a subject of debate. A recent reanalysis of the Galileo magnetometer data suggested the presence of a high melt fraction layer with $>$50~km thickness in the subsurface region of Io. Whether this layer is a ``magmatic sponge'' with interconnected solid or a rheologically liquid ``magma ocean'' would alter the distribution of tidal heating and would also influence the interpretation of various observations. To this end, we explore the steady state of a magmatic sponge and estimate the amount of internal heating necessary to sustain such a layer with a high degree of melting. Our results show that the rate of tidal dissipation within Io is insufficient to sustain a partial melt layer of $\phi>0.2$ for a wide range of parameters, suggesting that such a layer would swiftly separate into two phases. Unless melt and/or solid viscosities are at the higher end of the estimated range, a magmatic sponge would be unstable, and thus a high melt fraction layer suggested in Khurana et al. (2011) is likely to be a subsurface magma ocean. 	
"V5856 Sagittarii/2016: Broad Multi-Epoch Spectral Coverage of a
  Sustained High Luminosity Nova"	http://arxiv.org/abs/2211.06942v1	2022-11-13T16:26:59Z	2022-11-13T16:26:59Z	  Nova V5856 Sagittarii is unique for having remained more than nine magnitudes above its pre-outburst brightness for more than six years. Extensive visible and IR spectra from the time of outburst to the present epoch reveal separate emitting regions with distinct spectral characteristics. Permitted emission lines have both broad and narrow components, whereas the forbidden line profiles are almost entirely broad. The permitted line components frequently display P Cygni profiles indicating high optical depth, whereas the broad components do not show detectable absorption. The densities and velocities deduced from the spectra, including differences in the O I 7773 and 8446 lines, are not consistent with an on-going wind. Instead, the prolonged high luminosity and spectral characteristics are indicative of a post-outburst common envelope that enshrouds the binary, and is likely the primary source of the visible and IR emission. 	
"Predicting Companies' ESG Ratings from News Articles Using Multivariate
  Timeseries Analysis"	http://arxiv.org/abs/2212.11765v1	2022-11-13T11:23:02Z	2022-11-13T11:23:02Z	  Environmental, social and governance (ESG) engagement of companies moved into the focus of public attention over recent years. With the requirements of compulsory reporting being implemented and investors incorporating sustainability in their investment decisions, the demand for transparent and reliable ESG ratings is increasing. However, automatic approaches for forecasting ESG ratings have been quite scarce despite the increasing importance of the topic. In this paper, we build a model to predict ESG ratings from news articles using the combination of multivariate timeseries construction and deep learning techniques. A news dataset for about 3,000 US companies together with their ratings is also created and released for training. Through the experimental evaluation we find out that our approach provides accurate results outperforming the state-of-the-art, and can be used in practice to support a manual determination or analysis of ESG ratings. 	
EdnaML: A Declarative API and Framework for Reproducible Deep Learning	http://arxiv.org/abs/2211.06783v1	2022-11-13T01:27:06Z	2022-11-13T01:27:06Z	  Machine Learning has become the bedrock of recent advances in text, image, video, and audio processing and generation. Most production systems deal with several models during deployment and training, each with a variety of tuned hyperparameters. Furthermore, data collection and processing aspects of ML pipelines are receiving increasing interest due to their importance in creating sustainable high-quality classifiers. We present EdnaML, a framework with a declarative API for reproducible deep learning. EdnaML provides low-level building blocks that can be composed manually, as well as a high-level pipeline orchestration API to automate data collection, data processing, classifier training, classifier deployment, and model monitoring. Our layered API allows users to manage ML pipelines at high-level component abstractions, while providing flexibility to modify any part of it through the building blocks. We present several examples of ML pipelines with EdnaML, including a large-scale fake news labeling and classification system with six sub-pipelines managed by EdnaML. 	
"Ultrafast response of spontaneous photovoltaic effect in 3R-MoS2-based
  heterostructures"	http://arxiv.org/abs/2211.06746v1	2022-11-12T21:07:40Z	2022-11-12T21:07:40Z	  Rhombohedrally stacked MoS2 has been shown to exhibit spontaneous polarization down to the bilayer limit and can sustain a strong depolarization field when sandwiched between graphene. Such a field gives rise to a spontaneous photovoltaic effect without needing any p-n junction. In this work, we show the photovoltaic effect has an external quantum efficiency of 10\% for devices with only two atomic layers of MoS2 at low temperatures, and identify a picosecond-fast photocurrent response, which translates to an intrinsic device bandwidth at ~ 100-GHz level. To this end, we have developed a non-degenerate pump-probe photocurrent spectroscopy technique to deconvolute the thermal and charge-transfer processes, thus successfully revealing the multi-component nature of the photocurrent dynamics. The fast component approaches the limit of the charge-transfer speed at the graphene-MoS2 interface. The remarkable efficiency and ultrafast photoresponse in the graphene-3R-MoS2 devices support the use of ferroelectric van der Waals materials for future high-performance optoelectronic applications. 	
"Learning-based Sustainable Multi-User Computation Offloading for Mobile
  Edge-Quantum Computing"	http://arxiv.org/abs/2211.06681v1	2022-11-12T14:51:30Z	2022-11-12T14:51:30Z	  In this paper, a novel paradigm of mobile edge-quantum computing (MEQC) is proposed, which brings quantum computing capacities to mobile edge networks that are closer to mobile users (i.e., edge devices). First, we propose an MEQC system model where mobile users can offload computational tasks to scalable quantum computers via edge servers with cryogenic components and fault-tolerant schemes. Second, we show that it is NP-hard to obtain a centralized solution to the partial offloading problem in MEQC in terms of the optimal latency and energy cost of classical and quantum computing. Third, we propose a multi-agent hybrid discrete-continuous deep reinforcement learning using proximal policy optimization to learn the long-term sustainable offloading strategy without prior knowledge. Finally, experimental results demonstrate that the proposed algorithm can reduce at least 30% of the cost compared with the existing baseline solutions under different system settings. 	
"Efficient Speech Quality Assessment using Self-supervised Framewise
  Embeddings"	http://arxiv.org/abs/2211.06646v1	2022-11-12T11:57:08Z	2022-11-12T11:57:08Z	  Automatic speech quality assessment is essential for audio researchers, developers, speech and language pathologists, and system quality engineers. The current state-of-the-art systems are based on framewise speech features (hand-engineered or learnable) combined with time dependency modeling. This paper proposes an efficient system with results comparable to the best performing model in the ConferencingSpeech 2022 challenge. Our proposed system is characterized by a smaller number of parameters (40-60x), fewer FLOPS (100x), lower memory consumption (10-15x), and lower latency (30x). Speech quality practitioners can therefore iterate much faster, deploy the system on resource-limited hardware, and, overall, the proposed system contributes to sustainable machine learning. The paper also concludes that framewise embeddings outperform utterance-level embeddings and that multi-task training with acoustic conditions modeling does not degrade speech quality prediction while providing better interpretation. 	
DeepG2P: Fusing Multi-Modal Data to Improve Crop Production	http://arxiv.org/abs/2211.05986v1	2022-11-11T03:32:44Z	2022-11-11T03:32:44Z	  Agriculture is at the heart of the solution to achieve sustainability in feeding the world population, but advancing our understanding on how agricultural output responds to climatic variability is still needed. Precision Agriculture (PA), which is a management strategy that uses technology such as remote sensing, Geographical Information System (GIS), and machine learning for decision making in the field, has emerged as a promising approach to enhance crop production, increase yield, and reduce water and nutrient losses and environmental impacts. In this context, multiple models to predict agricultural phenotypes, such as crop yield, from genomics (G), environment (E), weather and soil, and field management practices (M) have been developed. These models have traditionally been based on mechanistic or statistical approaches. However, AI approaches are intrinsically well-suited to model complex interactions and have more recently been developed, outperforming classical methods. Here, we present a Natural Language Processing (NLP)-based neural network architecture to process the G, E and M inputs and their interactions. We show that by modeling DNA as natural language, our approach performs better than previous approaches when tested for new environments and similarly to other approaches for unseen seed varieties. 	
Quantum Power Flows: From Theory to Practice	http://arxiv.org/abs/2211.05728v1	2022-11-10T17:52:43Z	2022-11-10T17:52:43Z	  Climate change is becoming one of the greatest challenges to the sustainable development of modern society. Renewable energies with low density greatly complicate the online optimization and control processes, where modern advanced computational technologies, specifically quantum computing, have significant potential to help. In this paper, we discuss applications of quantum computing algorithms toward state-of-the-art smart grid problems. We suggest potential, exponential quantum speedup by the use of the Harrow-Hassidim-Lloyd (HHL) algorithms for sparse matrix inversions in power-flow problems. However, practical implementations of the algorithm are limited by the noise of quantum circuits, the hardness of realizations of quantum random access memories (QRAM), and the depth of the required quantum circuits. We benchmark the hardware and software requirements from the state-of-the-art power-flow algorithms, including QRAM requirements from hybrid phonon-transmon systems, and explicit gate counting used in HHL for explicit realizations. We also develop near-term algorithms of power flow by variational quantum circuits and implement real experiments for 6 qubits with a truncated version of power flows. 	
A Note on Optimal Tokamak Control for Fusion Power Simulation	http://arxiv.org/abs/2211.08984v1	2022-11-10T16:57:08Z	2022-11-10T16:57:08Z	  The Tokamak device is the most promising candidate for producing sustainable electric power by nuclear fusion. It is a torus-shaped device that confines plasma by a strong magnetic field. The development, design and control of the design has been an important area of research, and a significant target is to effectively confine the extremely hot plasma inside its hollow torus-shaped body without touching its boundary for a prolonged period of time. In an attempt to control a Tokamak device, this paper investigates an optimal control problem for an incompressible, viscous, electrically conducting MHD fluid confined in a closed toroidal region in the presence of an applied current. The objective functional for the optimal control problem are subject to set of constraint equations, Navier-Stokes and Maxwell equations. We target the transient control of guiding the plasma to a desired flow at a particular short time instant, where it is expected that the flow had been designed offline to be the desired one from the point of view of steady state operation. 	
"Impact of quantum entanglement induced by magnetic fields on primordial
  gravitational waves"	http://arxiv.org/abs/2211.05576v2	2023-01-09T13:19:44Z	2022-11-10T13:52:53Z	  There exist observational evidence to believe the existence of primordial magnetic fields generated during inflation. We study primordial gravitational waves (PGWs) during inflation in the presence of magnetic fields sustained by a gauge kinetic coupling. In the model, not only gravitons as excitations of PGWs, but also photons as excitations of electromagnetic fields are highly squeezed. They become entangled with each other through graviton to photon conversion and vice versa. We derive the reduced density matrix for the gravitons and calculate their entanglement entropy. It turns out that the state of the gravitons is not a squeezed state but a mixed state. 	
RARE: Renewable Energy Aware Resource Management in Datacenters	http://arxiv.org/abs/2211.05346v1	2022-11-10T05:17:14Z	2022-11-10T05:17:14Z	  The exponential growth in demand for digital services drives massive datacenter energy consumption and negative environmental impacts. Promoting sustainable solutions to pressing energy and digital infrastructure challenges is crucial. Several hyperscale cloud providers have announced plans to power their datacenters using renewable energy. However, integrating renewables to power the datacenters is challenging because the power generation is intermittent, necessitating approaches to tackle power supply variability. Hand engineering domain-specific heuristics-based schedulers to meet specific objective functions in such complex dynamic green datacenter environments is time-consuming, expensive, and requires extensive tuning by domain experts. The green datacenters need smart systems and system software to employ multiple renewable energy sources (wind and solar) by intelligently adapting computing to renewable energy generation. We present RARE (Renewable energy Aware REsource management), a Deep Reinforcement Learning (DRL) job scheduler that automatically learns effective job scheduling policies while continually adapting to datacenters' complex dynamic environment. The resulting DRL scheduler performs better than heuristic scheduling policies with different workloads and adapts to the intermittent power supply from renewables. We demonstrate DRL scheduler system design parameters that, when tuned correctly, produce better performance. Finally, we demonstrate that the DRL scheduler can learn from and improve upon existing heuristic policies using Offline Learning. 	
The Friendship Paradox and Social Network Participation	http://arxiv.org/abs/2211.05288v1	2022-11-10T01:51:20Z	2022-11-10T01:51:20Z	"  The friendship paradox implies that a person will, on average, have fewer friends than their friends do. Prior work has shown how the friendship paradox can lead to perception biases regarding behaviors that correlate with the number of friends: for example, people tend to perceive their friends as being more socially engaged than they are. Here, we investigate the consequences of this type of social comparison in the conceptual setting of content creation (""sharing"") in an online social network. Suppose people compare the amount of feedback that their content receives to the amount of feedback that their friends' content receives, and suppose they modify their sharing behavior as a result of that comparison. How does that impact overall sharing on the social network over time? We run simulations over model-generated synthetic networks, assuming initially uniform sharing and feedback rates. Thus, people's initial modifications of their sharing behavior in response to social comparisons are entirely driven by the friendship paradox. These modifications induce inhomogeneities in sharing rates that can further alter perception biases. If people's responses to social comparisons are monotonic (i.e., the larger the disparity, the larger the modification in sharing behavior), our simulations suggest that overall sharing in the network gradually declines. Meanwhile, convex responses can sustain or grow overall sharing in the network. We focus entirely on synthetic graphs in the present work and have not yet extended our simulations to real-world network topologies. Nevertheless, we do discuss practical implications, such as how interventions can be tailored to sustain long-term sharing, even in the presence of adverse social-comparison effects. "	
"MAGAL Constellation -- Using a Small Satellite Altimeter Constellation
  to Monitor Local and Regional Ocean and Inland Water Variations"	http://arxiv.org/abs/2211.05017v1	2022-11-09T16:47:12Z	2022-11-09T16:47:12Z	  MAGAL lays the foundations for a future constellation of small satellites carrying radar altimeters aiming to improve the understanding of ocean circulation variability at local, regional, and global scales. All necessary tools will be developed, including a new small, low-power altimeter payload and a miniaturized satellite platform, grounded on the Space 4.0 industry, to be manufactured inseries, minimizing production, operational and launch costs. To implement a collaborative constellation, and better tackle the gaps of large radar altimeter programmes, MAGAL will use a Data Analysis Centre, based on cloud services, for storage and process of data, based on known and improved algorithms, including overlay of layers from multiple sources (e.g. meteorology and opensource data). As a constellation of six satellites, MAGAL increases the density of sea surface topography measurements, enabling more data for altimetry products, when used in synergy with other missions, in coastal areas and over mesoscale features. This results in scientific and commercial information aggregated into a single platform, displayed in various graphical interfaces, allowing overlaid correlations. MAGAL is aligned with the insights from the EU agenda for sustainable development, adding value, alongside the underlying technology development, bringing together the sea's economy and its sustainable growth. 	
The AEROS ocean observation mission and its CubeSat pathfinder	http://arxiv.org/abs/2211.05008v1	2022-11-09T16:38:49Z	2022-11-09T16:38:49Z	  AEROS aims to develop a nanosatellite as a precursor of a future system of systems, which will include assets and capabilities of both new and existing platforms operating in the Ocean and Space, equipped with state-of-the-art sensors and technologies, all connected through a communication network linked to a data gathering, processing and dissemination system. This constellation leverages scientific and economic synergies emerging from New Space and the opportunities in prospecting, monitoring, and valuing the Ocean in a sustainable manner, addressing the demand for improved spatial, temporal, and spectral coverage in areas such as coastal ecosystems management and climate change assessment and mitigation. Currently, novel sensors and systems, including a miniaturized hyperspectral imager and a flexible software-defined communication system, are being developed and integrated into a new versatile satellite structure, supported by an innovative on-board software. Additional sensors, like the LoRaWAN protocol and a wider field of view RGB camera, are under study. To cope with data needs, a Data Analysis Centre, including a cloud-based data and telemetry dashboard and a back-end layer, to receive and process acquired and ingested data, is being implemented to provide tailored-to-use remote sensing products for a wide range of applications for private and institutional stakeholders. 	
Strategic Plan 2021-2030 for Astronomy in the Netherlands	http://arxiv.org/abs/2211.04991v1	2022-11-09T16:06:58Z	2022-11-09T16:06:58Z	  This document describes the Netherlands' decadal strategic planning process for the current decade. We give the scientific rationale for our prioritization of research areas and the facility choices that follow from our scientific priorities. We also describe actions needed for the sustainability of our community and our work, and the budgets needed to fulfil our stated ambitions. The names listed as authors are in fact the editors of this paper, which results from the work of the entire Netherlands astronomy community. 	
"Electron dynamics in planar radio frequency magnetron plasmas: I. The
  mechanism of Hall heating and the -mode"	http://arxiv.org/abs/2211.04805v1	2022-11-09T10:57:03Z	2022-11-09T10:57:03Z	"  The electron dynamics and the mechanisms of power absorption in radio-frequency (RF) driven, magnetically enhanced capacitively coupled plasmas (MECCPs) at low pressure are investigated. The device in focus is a geometrically asymmetric cylindrical magnetron with a radially nonuniform magnetic field in axial direction and an electric field in radial direction. The dynamics is studied analytically using the cold plasma model and a single-particle formalism, and numerically with the inhouse energy and charge conserving particle-in-cell/Monte Carlo collisions code ECCOPIC1S-M. It is found that the dynamics differs significantly from that of an unmagnetized reference discharge. In the magnetized region in front of the powered electrode, an enhanced electric field arises during sheath expansion and a reversed electric field during sheath collapse. Both fields are needed to ensure discharge sustaining electron transport against the confining effect of the magnetic field. The corresponding azimuthal ExB-drift can accelerate electrons into the inelastic energy range which gives rise to a new mechanism of RF power dissipation. It is related to the Hall current and is different in nature from Ohmic heating, as which it has been classified in previous literature. The new heating is expected to be dominant in many magnetized capacitively coupled discharges. It is proposed to term it the ""{\mu}-mode"" to separate it from other heating modes. "	
"Interpretable Explainability in Facial Emotion Recognition and
  Gamification for Data Collection"	http://arxiv.org/abs/2211.04769v1	2022-11-09T09:53:48Z	2022-11-09T09:53:48Z	  Training facial emotion recognition models requires large sets of data and costly annotation processes. To alleviate this problem, we developed a gamified method of acquiring annotated facial emotion data without an explicit labeling effort by humans. The game, which we named Facegame, challenges the players to imitate a displayed image of a face that portrays a particular basic emotion. Every round played by the player creates new data that consists of a set of facial features and landmarks, already annotated with the emotion label of the target facial expression. Such an approach effectively creates a robust, sustainable, and continuous machine learning training process. We evaluated Facegame with an experiment that revealed several contributions to the field of affective computing. First, the gamified data collection approach allowed us to access a rich variation of facial expressions of each basic emotion due to the natural variations in the players' facial expressions and their expressive abilities. We report improved accuracy when the collected data were used to enrich well-known in-the-wild facial emotion datasets and consecutively used for training facial emotion recognition models. Second, the natural language prescription method used by the Facegame constitutes a novel approach for interpretable explainability that can be applied to any facial emotion recognition model. Finally, we observed significant improvements in the facial emotion perception and expression skills of the players through repeated game play. 	
Self-sustained oscillations in whiskers without vortex shedding	http://arxiv.org/abs/2211.04536v1	2022-11-08T20:09:11Z	2022-11-08T20:09:11Z	  Sensing the flow of water or air disturbance is critical for the survival of many animals: flow information helps them localize food, mates, and prey and to escape predators. Across species, many flow sensors take the form of long, flexible cantilevers. These cantilevers are known to exhibit sustained oscillations when interacting with fluid flow. In the presence of vortex shedding, the oscillations occur through mechanisms such as wake- or vortex-induced vibrations. There is, however, no clear explanation for the mechanisms governing the sustained oscillation of flexible cantilevers without vortex shedding. In recent work, we showed that a flexible cylindrical cantilever could experience sustained oscillations in its first natural vibration mode in water at Reynolds numbers below the critical Reynolds number of vortex shedding. The oscillations were shown to be driven by a frequency match (synchronization) between the flow frequency and the cantilever's first-mode natural frequency. Here, we use a body-fitted fluid-structure solver based on the Navier-Stokes and nonlinear structural equations to simulate the dynamics of a cantilevered whisker in the air at a subcritical value of Reynolds number. Results show that second-mode synchronization governs the whisker's sustained oscillation. Wavy patterns in the shear layer dominate the whisker's wake during the vibrations, indicating that parallel shear layers synchronize with the whisker's motion. As a result of this synchronization, oval-shaped motion trajectories, with matching streamwise and cross-flow vibration frequencies, are observed along the whisker. The outcomes of this study suggest possible directions for designing artificial bio-inspired flow sensors. 	
"Macroeconomic evaluation of the growth of the UK economy over the period
  2000 to 2019"	http://arxiv.org/abs/2212.03947v1	2022-11-08T16:57:31Z	2022-11-08T16:57:31Z	  An information entropy statistical methodology was used to evaluate the growth of the UK economy over the period 2000 to 2019, with an emphasis on the impact of labour productivity on gross domestic product (GDP) per capita and the average growth in real wages, during this time period. The growth of the UK economy over the period 2000 to 2019 can be described in terms of three distinct phases: 1) 2000 to 2007 - strong sustained economic growth 2) 2008 to 2013 - the impact of the international financial crisis, its immediate aftermath, and period of recovery 3) 2014 to 2019 - weak sustained economic growth The key determinant of the UK economic performance over this period would appear to the annual rate of growth in labour productivity. It was closely related to the annual rate of growth in GDP per capita, and it was significantly weaker in the period 2014 to 2019 compared to the period 2000 to 2007. This also corresponded with a weaker rate of growth in annual average real wages over the period 2014 to 2019 compared to the period 2000 to 2007. Throughout the period 2000 to 2019, UK CPI was maintained, on average, at approximately 2.1% per annum. More rapid UK economic growth would be expected to be achieved by sustained investment in measures that enhance labour productivity, with the further expectation that a sustained improvement in labour productivity would increase the annual rate of growth of UK GDP per capita and average real wages. While the results given in this paper are specific to the UK over the time period 2000 to 2019, the expectation is that the methodology and approach adopted can be applied to quantifying the dynamics of any developed economy over any time period. 	
"Bridging Fairness and Environmental Sustainability in Natural Language
  Processing"	http://arxiv.org/abs/2211.04256v1	2022-11-08T14:05:07Z	2022-11-08T14:05:07Z	  Fairness and environmental impact are important research directions for the sustainable development of artificial intelligence. However, while each topic is an active research area in natural language processing (NLP), there is a surprising lack of research on the interplay between the two fields. This lacuna is highly problematic, since there is increasing evidence that an exclusive focus on fairness can actually hinder environmental sustainability, and vice versa. In this work, we shed light on this crucial intersection in NLP by (1) investigating the efficiency of current fairness approaches through surveying example methods for reducing unfair stereotypical bias from the literature, and (2) evaluating a common technique to reduce energy consumption (and thus environmental impact) of English NLP models, knowledge distillation (KD), for its impact on fairness. In this case study, we evaluate the effect of important KD factors, including layer and dimensionality reduction, with respect to: (a) performance on the distillation task (natural language inference and semantic similarity prediction), and (b) multiple measures and dimensions of stereotypical bias (e.g., gender bias measured via the Word Embedding Association Test). Our results lead us to clarify current assumptions regarding the effect of KD on unfair bias: contrary to other findings, we show that KD can actually decrease model fairness. 	
Stability of long-sustained oscillations induced by electron tunneling	http://arxiv.org/abs/2211.04074v1	2022-11-08T08:11:01Z	2022-11-08T08:11:01Z	  Self-oscillations are the result of an efficient mechanism generating periodic motion from a constant power source. In quantum devices, these oscillations may arise due to the interaction between single electron dynamics and mechanical motion. Due to the complexity of this mechanism, these self-oscillations may irrupt, vanish, or exhibit a bistable behavior causing hysteresis cycles. We observe these hysteresis cycles and characterize the stability of different regimes in single and double quantum dot configurations. In particular cases, we find these oscillations stable for over 20 seconds, many orders of magnitude above electronic and mechanical characteristic timescales, revealing the robustness of the mechanism at play. The experimental results are reproduced by our theoretical model that provides a complete understanding of bistability in nanoelectromechanical devices. 	
"Adiabatic monoparametric autonomous motors enabled by self-induced
  nonconservative forces"	http://arxiv.org/abs/2211.03841v1	2022-11-07T19:55:03Z	2022-11-07T19:55:03Z	  Archetypal motors produce work when two slowly varying degrees of freedom (DOF) move around a closed loop of finite area in the parameter space. Here, instead, we propose a simple autonomous {\it monoparametric} optomechanical engine that utilizes nonlinearities to turn a constant energy current into a nonconservative mechanical force. The latter self-sustains the periodic motion of a mechanical DOF whose frequency is orders of magnitude smaller than the photonic DOF. We have identified conditions under which the maximum extracted mechanical power is invariant and show a new type of self-induced robustness of the power production against imperfections and driving noise. 	
Decarbonizing Indian Electricity Grid	http://arxiv.org/abs/2211.05934v1	2022-11-07T16:51:50Z	2022-11-07T16:51:50Z	  India, being one of the fastest growing economies of the world, must take a sustainable path for development. India is responsible for 7 percent of global CO2 emissions. The electricity sector accounts for nearly 35 percent of emissions from the country. The switch from fossil fuels to renewable sources is the key in decarbonizing this sector and is considered as the crucial step for climate mitigation. This research investigates the potential of renewable energy sources; wind, solar and hydro. The optimization model developed in this study analyzes various scenarios for the transition to a sustainable future. The results show that India aims to achieve 450 GW of installed capacity from RES is far from a Net Zero future. Results confirm that India has the potential to meet 100 percent of electricity demand in 2030 from RES including wind, solar and hydro. Introducing Social Cost of Carbon is a viable option to reduce emissions in India. However, due to the low cost of coal, high coal taxes do not lead to reduced emissions. 	
Dynamical Transition of Operator Size Growth in Open Quantum Systems	http://arxiv.org/abs/2211.03535v1	2022-11-07T13:21:50Z	2022-11-07T13:21:50Z	  We study the operator size growth in open quantum systems with all-to-all interactions, in which the operator size is defined by counting the number of non-trivial system operators. We provide a general argument for the existence of a transition of the operator size dynamics when the system-bath coupling $\gamma$ is tuned to its critical value $\gamma_c$. We further demonstrate the transition through the analytical calculation of the operator size distribution in a solvable Brownian SYK model. Our results show that: (i) For $\gamma>\gamma_c$, the system is in a dissipative phase where the system operator size decays with a rate $\sim (\gamma-\gamma_c)$, which indicates the initial information of the system all dives into the bath eventually. (ii) For $\gamma<\gamma_c$, the system sustains a scrambling phase, where the average operator size grows exponentially up to the scrambling time $t_s\sim (\gamma_c-\gamma)^{-1}\log N$ and saturates to a $O(N)$ value in the long-time limit. (iii) At the critical point $\gamma=\gamma_c$, which separates the two phases, the operator size distribution at finite size shows a power-law decay over time. 	
"Electron dynamics in planar radio frequency magnetron plasmas: II.
  Heating and energization mechanisms studied via a 2d3v particle-in-cell/Monte
  Carlo code"	http://arxiv.org/abs/2211.03459v1	2022-11-07T11:17:36Z	2022-11-07T11:17:36Z	  The present work investigates electron transport and heating mechanisms using an (r, z) particle-in-cell (PIC) simulation of a typical rf-driven axisymmetric magnetron discharge with a conducting target. It is shown that for the considered magnetic field topology the electron current flows through different channels in the (r, z) plane: a ``transverse'' one, which involves current flow through the electrons' magnetic confinement region (EMCR) above the racetrack, and two ''longitudinal'' ones. Electrons gain energy from the electric field along these channels following various mechanisms, which are rather distinct from those sustaining dc-powered magnetrons. The longitudinal power absorption involves mirror-effect heating (MEH), nonlinear electron resonance heating (NERH), magnetized bounce heating (MBH), and the heating by the ambipolar field at the sheath-presheath interface. The MEH and MBH represent two new mechanisms missing from the previous literature. The MEH is caused by a reversed electric field needed to overcome the mirror force generated in a nonuniform magnetic field to ensure sufficient flux of electrons to the powered electrode, and the MBH is related to a possibility for an electron to undergo multiple reflections from the expanding sheath in the longitudinal channels connected by the arc-like magnetic field. The electron heating in the transverse channel is caused mostly by the essentially collisionless Hall heating in the EMCR above the racetrack, generating a strong ExB azimuthal drift velocity. The latter mechanism results in an efficient electron energization, i.e., energy transfer from the electric field to electrons in the inelastic range. Since the main electron population energized by this mechanism remains confined within the discharge for a long time, its contribution to the ionization processes is dominant. 	
"Prospects and Challenges for Sustainable Tourism: Evidence from South
  Asian Countries"	http://arxiv.org/abs/2211.03411v1	2022-11-07T10:17:24Z	2022-11-07T10:17:24Z	  Tourism is one of the world's fastest expanding businesses, as well as a significant source of foreign exchange profits and jobs. The research is based on secondary sources. The facts and information were primarily gathered and analyzed from various published papers and articles. The study goals are to illustrate the current scenario of tourism industry in south Asia, classifies the restraints and recommends helpful key developments to achieve sustainable tourism consequently. The study revealed that major challenges of sustainable tourism in south Asian region are lack of infrastructure facilities, modern and sufficient recreation facilities, security and safety, proper training and HR, proper planning from government, marketing and information, product development, tourism awareness, security and safety, and political instability etc. The study also provides some suggestive measures that for the long-term growth of regional tourism, the government should establish and implement policies involving public and private investment and collaboration. 	
Machine-learning approach for discovery of conventional superconductors	http://arxiv.org/abs/2211.03265v1	2022-11-07T02:21:11Z	2022-11-07T02:21:11Z	  First-principles computations are the driving force behind numerous discoveries of hydride-based superconductors, mostly at high pressures, during the last decade. Machine-learning (ML) approaches can further accelerate the future discoveries if their reliability can be improved. The main challenge of current ML approaches, typically aiming at predicting the critical temperature $T_{\rm c}$ of a solid from its chemical composition and target pressure, is that the correlations to be learned are deeply hidden, indirect, and uncertain. In this work, we showed that predicting superconductivity at any pressure from the atomic structure is sustainable and reliable. For a demonstration, we curated a diverse dataset of 584 atomic structures for which $\lambda$ and $\omega_{\log}$, two parameters of the electron-phonon interactions, were computed. We then trained some ML models to predict $\lambda$ and $\omega_{\log}$, from which $T_{\rm c}$ can be computed in a post-processing manner. The models were validated and used to identify two possible superconductors whose $T_{\rm c}\simeq 10-15$K and zero pressure. Going forward, this strategy will be improved to better contribute to the discoveries of new superconductors. 	
"Evaluating Digital Tools for Sustainable Agriculture using Causal
  Inference"	http://arxiv.org/abs/2211.03195v1	2022-11-06T18:22:17Z	2022-11-06T18:22:17Z	  In contrast to the rapid digitalization of several industries, agriculture suffers from low adoption of climate-smart farming tools. Even though AI-driven digital agriculture can offer high-performing predictive functionalities, it lacks tangible quantitative evidence on its benefits to the farmers. Field experiments can derive such evidence, but are often costly and time consuming. To this end, we propose an observational causal inference framework for the empirical evaluation of the impact of digital tools on target farm performance indicators. This way, we can increase farmers' trust by enhancing the transparency of the digital agriculture market, and in turn accelerate the adoption of technologies that aim to increase productivity and secure a sustainable and resilient agriculture against a changing climate. As a case study, we perform an empirical evaluation of a recommendation system for optimal cotton sowing, which was used by a farmers' cooperative during the growing season of 2021. We leverage agricultural knowledge to develop a causal graph of the farm system, we use the back-door criterion to identify the impact of recommendations on the yield and subsequently estimate it using several methods on observational data. The results show that a field sown according to our recommendations enjoyed a significant increase in yield (12% to 17%). 	
Personalizing Sustainable Agriculture with Causal Machine Learning	http://arxiv.org/abs/2211.03179v1	2022-11-06T17:14:14Z	2022-11-06T17:14:14Z	"  To fight climate change and accommodate the increasing population, global crop production has to be strengthened. To achieve the ""sustainable intensification"" of agriculture, transforming it from carbon emitter to carbon sink is a priority, and understanding the environmental impact of agricultural management practices is a fundamental prerequisite to that. At the same time, the global agricultural landscape is deeply heterogeneous, with differences in climate, soil, and land use inducing variations in how agricultural systems respond to farmer actions. The ""personalization"" of sustainable agriculture with the provision of locally adapted management advice is thus a necessary condition for the efficient uplift of green metrics, and an integral development in imminent policies. Here, we formulate personalized sustainable agriculture as a Conditional Average Treatment Effect estimation task and use Causal Machine Learning for tackling it. Leveraging climate data, land use information and employing Double Machine Learning, we estimate the heterogeneous effect of sustainable practices on the field-level Soil Organic Carbon content in Lithuania. We thus provide a data-driven perspective for targeting sustainable practices and effectively expanding the global carbon sink. "	
"Towards Green Metaverse Networking Technologies, Advancements and Future
  Directions"	http://arxiv.org/abs/2211.03057v1	2022-11-06T08:05:26Z	2022-11-06T08:05:26Z	  As the Metaverse is iteratively being defined, its potential to unleash the next wave of digital disruption and create real-life value becomes increasingly clear. With distinctive features of immersive experience, simultaneous interactivity, and user agency, the Metaverse has the capability to transform all walks of life. However, the enabling technologies of the Metaverse, i.e., digital twin, artificial intelligence, blockchain, and extended reality, are known to be energy-hungry, therefore raising concerns about the sustainability of its large-scale deployment and development. This article proposes Green Metaverse Networking for the first time to optimize energy efficiencies of all network components for Metaverse sustainable development. We first analyze energy consumption, efficiency, and sustainability of energy-intensive technologies in the Metaverse. Next, focusing on computation and networking, we present major advancements related to energy efficiency and their integration into the Metaverse. A case study of energy conservation by incorporating semantic communication and stochastic resource allocation in the Metaverse is presented. Finally, we outline the critical challenges of Metaverse sustainable development, thereby indicating potential directions of future research towards the green Metaverse. 	
Toward Human-AI Co-creation to Accelerate Material Discovery	http://arxiv.org/abs/2211.04257v1	2022-11-05T17:48:59Z	2022-11-05T17:48:59Z	  There is an increasing need in our society to achieve faster advances in Science to tackle urgent problems, such as climate changes, environmental hazards, sustainable energy systems, pandemics, among others. In certain domains like chemistry, scientific discovery carries the extra burden of assessing risks of the proposed novel solutions before moving to the experimental stage. Despite several recent advances in Machine Learning and AI to address some of these challenges, there is still a gap in technologies to support end-to-end discovery applications, integrating the myriad of available technologies into a coherent, orchestrated, yet flexible discovery process. Such applications need to handle complex knowledge management at scale, enabling knowledge consumption and production in a timely and efficient way for subject matter experts (SMEs). Furthermore, the discovery of novel functional materials strongly relies on the development of exploration strategies in the chemical space. For instance, generative models have gained attention within the scientific community due to their ability to generate enormous volumes of novel molecules across material domains. These models exhibit extreme creativity that often translates in low viability of the generated candidates. In this work, we propose a workbench framework that aims at enabling the human-AI co-creation to reduce the time until the first discovery and the opportunity costs involved. This framework relies on a knowledge base with domain and process knowledge, and user-interaction components to acquire knowledge and advise the SMEs. Currently,the framework supports four main activities: generative modeling, dataset triage, molecule adjudication, and risk assessment. 	
"Out-of-Plane Biphilic Surface Structuring for Enhanced Capillary-Driven
  Dropwise Condensation"	http://arxiv.org/abs/2211.02876v1	2022-11-05T11:12:30Z	2022-11-05T11:12:30Z	  Rapid and sustained condensate droplet departure from a surface is key towards achieving high heat transfer rates in condensation, a physical process critical to a broad range of industrial and societal applications. Despite progress in enhancing condensation heat transfer through inducing its dropwise mode with hydrophobic materials, sophisticated surface engineering methods that can lead to further enhancement of heat transfer are still highly desirable. Here, by employing a three-dimensional, multiphase computational approach, we present an effective out-of-plane biphilic surface topography, that reveals an unexplored capillarity-driven departure mechanism of condensate droplets. This texture consists of biphilic diverging micro-cavities wherein a matrix of small hydrophilic spots is placed at their bottom, that is, amongst the pyramid-shaped, superhydrophobic micro-textures forming the cavities. We show that an optimal combination of the hydrophilic spots and the angles of the pyramidal structures can achieve high deformational stretching of the droplets, eventually realizing an impressive slingshot-like droplet ejection process from the texture. Such a droplet departure mechanism has the potential to reduce the droplet ejection volume and thus enhance the overall condensation efficiency, compared to coalescence-initiated droplet jumping from other state-of-the-art surfaces. Simulations have shown that optimal pyramid-shaped biphilic micro-structures can provoke droplet self-ejection at low volumes, up to 56% lower compared to superhydrophobic straight pillars, revealing a promising new surface micro-texture design strategy towards enhancing condensation heat transfer efficiency and water harvesting capabilities. 	
A Prompt-based Few-shot Learning Approach to Software Conflict Detection	http://arxiv.org/abs/2211.02709v1	2022-11-04T18:56:44Z	2022-11-04T18:56:44Z	  A software requirement specification (SRS) document is an essential part of the software development life cycle which outlines the requirements that a software program in development must satisfy. This document is often specified by a diverse group of stakeholders and is subject to continual change, making the process of maintaining the document and detecting conflicts between requirements an essential task in software development. Notably, projects that do not address conflicts in the SRS document early on face considerable problems later in the development life cycle. These problems incur substantial costs in terms of time and money, and these costs often become insurmountable barriers that ultimately result in the termination of a software project altogether. As a result, early detection of SRS conflicts is critical to project sustainability. The conflict detection task is approached in numerous ways, many of which require a significant amount of manual intervention from developers, or require access to a large amount of labeled, task-specific training data. In this work, we propose using a prompt-based learning approach to perform few-shot learning for conflict detection. We compare our results to supervised learning approaches that use pretrained language models, such as BERT and its variants. Our results show that prompting with just 32 labeled examples can achieve a similar level of performance in many key metrics to that of supervised learning on training sets that are magnitudes larger in size. In contrast to many other conflict detection approaches, we make no assumptions about the type of underlying requirements, allowing us to analyze pairings of both functional and non-functional requirements. This allows us to omit the potentially expensive task of filtering out non-functional requirements from our dataset. 	
"Polar hairs of mixed-parity nodal superconductors in
  Rarita-Schwinger-Weyl metals"	http://arxiv.org/abs/2211.02649v1	2022-11-04T17:59:23Z	2022-11-04T17:59:23Z	  Linearly dispersing Rarita-Schwinger-Weyl (RSW) fermions featuring two Fermi velocities are the key constituents of itinerant spin-3/2 quantum materials. When doped, RSW metals sustain two Fermi surfaces (FSs), around which one fully gapped $s$-wave and five \emph{mixed-parity} local pairings can take place. Four of them support point nodes at the poles of two FSs. For weak (strong) pairing amplitudes ($\Delta$), gapless north and south poles belonging to the same (different) FS(s) get connected by \emph{polar hairs}, one-dimensional line nodes occupying the region between two FSs. The remaining one, by contrast, supports four nodal rings in between two FSs, symmetrically placed about their equators, but only when $\Delta$ is small. For large $\Delta$, this paired state becomes fully gapped. The transition temperature and pairing amplitudes follow the BCS scaling. We explicitly showcase these outcomes for a rotationally symmetric RSW metal, and contrast our findings when the system possesses an enlarged Lorentz symmetry and with the ones in spin-3/2 Luttinger materials. 	
"The Sustainable Development Goals and Aerospace Engineering: A critical
  note through Artificial Intelligence"	http://arxiv.org/abs/2211.02409v1	2022-11-04T12:37:27Z	2022-11-04T12:37:27Z	  The 2030 Agenda of the United Nations (UN) revolves around the Sustainable Development Goals (SDGs). A critical step towards that objective is identifying whether scientific production aligns with the SDGs' achievement. To assess this, funders and research managers need to manually estimate the impact of their funding agenda on the SDGs, focusing on accuracy, scalability, and objectiveness. With this objective in mind, in this work, we develop ASDG, an easy-to-use artificial-intelligence (AI)-based model for automatically identifying the potential impact of scientific papers on the UN SDGs. As a demonstrator of ASDG, we analyze the alignment of recent aerospace publications with the SDGs. The Aerospace data set analyzed in this paper consists of approximately 820,000 papers published in English from 2011 to 2020 and indexed in the Scopus database. The most-contributed SDGs are 7 (on clean energy), 9 (on industry), 11 (on sustainable cities) and 13 (on climate action). The establishment of the SDGs by the UN in the middle of the 2010 decade did not significantly affect the data. However, we find clear discrepancies among countries, likely indicative of different priorities. Also, different trends can be seen in the most and least cited papers, with clear differences in some SDGs. Finally, the number of abstracts the code cannot identify is decreasing with time, possibly showing the scientific community's awareness of SDG. 	
"Barcelona in the face of globalization, how to think of the city through
  the organization and evaluation of major events?"	http://arxiv.org/abs/2212.13901v1	2022-11-04T10:31:52Z	2022-11-04T10:31:52Z	"  The event questions men whether it is political, cultural or touristic. It has its own meaning as it starts something while showing a will, a new possibility to create, to meet and to surprise. The event is in fact an ""advent that reaches everything"" generally integrating itself into a long process or phase of the evolution of societies in terms of its societal structure. However, if the event exists, it is significant and therefore assessable. How to evaluate an Olympic Games or an international exhibition? Can we evaluate the before (from the statement of position, application file), the during (the course of the tourist, cultural or sporting event) and the after (the closing of the festival and its direct and indirect effects on society)? How then to evaluate all the dimensions of the event generally based on major tourist and urban planning operations? We will take as a field of study a city -- capital -- commercial port which has become a sort of archetype in the context of the organization of mega-events with a tourist vocation, such as the Universal or International Exhibitions and the Olympic Games, namely Barcelona and three very important dates for the Catalan capital: 1888, universal exhibition, 1929 universal and international exhibition, 1992 the modern Olympic Games and 2004 the Universal Forum of Cultures of Unesco, international exhibition. The economic interest of organizing an ephemeral giant event is still relevant and will be confirmed in the future with the role of Asian countries within the IOC and the BIE (Bureau international des expositions). The important thing is to develop a rational argument to communicate on the economic merits of the event. Sustainable development and Corporate Social Responsibility (CSR) are predominant elements for ephemeral events that are intended to be sustainable over time for future generations. "	
A General Purpose Neural Architecture for Geospatial Systems	http://arxiv.org/abs/2211.02348v1	2022-11-04T09:58:57Z	2022-11-04T09:58:57Z	  Geospatial Information Systems are used by researchers and Humanitarian Assistance and Disaster Response (HADR) practitioners to support a wide variety of important applications. However, collaboration between these actors is difficult due to the heterogeneous nature of geospatial data modalities (e.g., multi-spectral images of various resolutions, timeseries, weather data) and diversity of tasks (e.g., regression of human activity indicators or detecting forest fires). In this work, we present a roadmap towards the construction of a general-purpose neural architecture (GPNA) with a geospatial inductive bias, pre-trained on large amounts of unlabelled earth observation data in a self-supervised manner. We envision how such a model may facilitate cooperation between members of the community. We show preliminary results on the first step of the roadmap, where we instantiate an architecture that can process a wide variety of geospatial data modalities and demonstrate that it can achieve competitive performance with domain-specific architectures on tasks relating to the U.N.'s Sustainable Development Goals. 	
"Alternative formulations for gilthead seabream diets: towards a more
  sustainable production"	http://arxiv.org/abs/2211.02430v1	2022-11-03T17:15:08Z	2022-11-03T17:15:08Z	  To support the expected increase in aquaculture production during the next years, a wider range of alternative ingredients to fishmeal is needed, towards contributing to an increase in production sustainability. This study aimed to test diets formulated with non-conventional feed ingredients on gilthead seabream (Sparus aurata) growth performance, feed utilization, apparent digestibility of nutrients and nutrient outputs to the environment. Four isonitrogenous and isoenergetic diets were formulated: a control diet (CTRL) similar to a commercial feed and three experimental diets containing, as main protein sources, plant by-products, glutens and concentrates (PLANT); processed animal proteins (PAP); or micro/macroalgae, insect meals and yeast (EMERG). Diets were tested in triplicate during 80 days. The (EMERG) treatment resulted in lower fish growth performance, higher FCR and lower nutrient and energy retentions than the other treatments. The lowest protein digestibility was found for the EMERG diet, which caused increased nitrogen losses. The PLANT and PAP treatments resulted in better fish growth performance, higher nutrient and energy retentions, and lower FCR than the CTRL treatment. The significant improvement in FCR found for fish fed PLANT and PAP diets and the high protein digestibility of these diets contribute towards minimizing the environmental impacts of seabream production 	
"Driving innovation through project based learning: A pre-university
  STEAM for Social Good initiative"	http://arxiv.org/abs/2211.01998v1	2022-11-03T17:10:25Z	2022-11-03T17:10:25Z	  The Covid pandemic is a clarion call for increased sensitivity to the interconnected nature of social problems facing our world today. A future-oriented education on critical issues, such as those outlined in the United Nations Sustainable Development Goals (UN SDGs) and designing potential solutions for such problems is an imperative skill that must be imparted to children to help them navigate their future in today's unpredictable world. Towards this goal, we have been conducting 3.5 month-long mentoring programs for pre-university students in India to participate in a STEAM for Social Good innovation challenge conducted annually by the Government of India. Using digital and physical computing skills, we helped children explore creative solutions for social problems through a constructionist approach to learning, wherein they ideated and reflected upon the problems in their communities. The children learnt the Engineering Design Thinking process and worked in online groups of two or three, from concept to completion. Despite the constraints posed by the pandemic, they explored creative ways to think about design and innovation. They completed a variety of tasks by making, tinkering, engineering, assembling, and programming to grasp the intricate relationship between software and hardware. Subsequently, the children showcased their creative abilities through video storytelling to a panel of domain experts. In this paper, we present the children's perspective of their experiences through this journey, the evaluation metrics based on IEEE design principles, and our learnings from conducting this initiative as a university-school partnership model for 84 middle and high school students. The aspirational intent of this initiative is to make the children better social problem solvers and help them perceive social problems as opportunities to enhance life for themselves and their communities. 	
A speech corpus for chronic kidney disease	http://arxiv.org/abs/2211.01705v1	2022-11-03T10:57:48Z	2022-11-03T10:57:48Z	  In this study, we present a speech corpus of patients with chronic kidney disease (CKD) that will be used for research on pathological voice analysis, automatic illness identification, and severity prediction. This paper introduces the steps involved in creating this corpus, including the choice of speech-related parameters and speech lists as well as the recording technique. The speakers in this corpus, 289 CKD patients with varying degrees of severity who were categorized based on estimated glomerular filtration rate (eGFR), delivered sustained vowels, sentence, and paragraph stimuli. This study compared and analyzed the voice characteristics of CKD patients with those of the control group; the results revealed differences in voice quality, phoneme-level pronunciation, prosody, glottal source, and aerodynamic parameters. 	
"Characterization of Cs-free negative ion production in the ion source
  SPIDER by Cavity Ring-Down Spectroscopy"	http://arxiv.org/abs/2211.01695v1	2022-11-03T10:39:03Z	2022-11-03T10:39:03Z	  The Neutral beam Injectors of the ITER experiment will be based on negative ion sources for the generation of beams composed by 1 MeV H/D particles. The prototype of these sources is currently under testing in the SPIDER experiment, part of the Neutral Beam Test Facility of Consorzio RFX, Padua. Among the targets of the experimentation in SPIDER, it is of foremost importance to maximize the beam current density extracted from the source acceleration system. The SPIDER operating conditions can be optimized thanks to a Cavity Ring-down Spectroscopy diagnostic, which is able to give line-integrated measurements of negative ion density in proximity of the acceleration system apertures. Regarding the diagnostic technique, this work presents a phenomenon of drift in ring down time measurements, which develops in a time scale of few hours. This issue may significantly affect negative ion density measurements for plasma pulses of 1 h duration, as required by ITER. Causes and solutions are discussed. Regarding the source performance, this paper presents how negative ion density is influenced by the RF power used to sustain the plasma, and by the magnetic filter field present in SPIDER to limit the amount of co-extracted electrons. In this study, SPIDER was operated in hydrogen and deuterium, in Cs-free conditions. 	
"Accelerating the Discovery of g-C$_3$N$_4$-Supported Single Atom
  Catalysts for Hydrogen Evolution Reaction: A Combined DFT and Machine
  Learning Strategy"	http://arxiv.org/abs/2211.01624v1	2022-11-03T07:28:44Z	2022-11-03T07:28:44Z	  Two-dimensional materials supported by single atom catalysis (SACs) are foreseen to replace platinum for large-scale industrial scalability of sustainable hydrogen generation. Here, a series of metal (Al, Sc, Ti, V, Cr, Mn, Fe, Ni, Cu, Zn) and non-metal (B, C, N, O, F, Si, P, S, Cl) single atoms embedded on various active sites of g-C$_3$N$_4$ are screened by DFT calculations and six machine learning (ML) algorithms (support vector regression, gradient boosting regression, random forest regression, AdaBoost regression, multilayer perceptron regression, ridge regression). Our results based on formation energy, Gibbs free energy and bandgap analysis demonstrate that the single atoms of B, Mn and Co anchored on g-C$_3$N$_4$ can serve as highly efficient active sites for hydrogen production. The ML model based on support vector regression (SVR) exhibits the best performance to accurately and rapidly predict the Gibbs free energy of hydrogen adsorption (${\Delta}$GH ) for the test set with a lower mean absolute error (MAE) and a high coefficient of determination (R$^2$) of 0.45 and 0.81, respectively. Feature selection based on the SVR model highlights the top five primary features: formation energy, bond length, boiling point, melting point, and valance electron as key descriptors. Overall, the multistep work-flow employed through DFT calculations combined with ML models for efficient screening of potential hydrogen evolution reaction (HER) from g-C$_3$N$_4$-based single atom catalysis can significantly contribute to the catalyst design and fabrication. 	
"Relaxation dynamics in a long-range system with mixed Hamiltonian and
  non-Hamiltonian interactions"	http://arxiv.org/abs/2211.01018v1	2022-11-02T10:31:30Z	2022-11-02T10:31:30Z	  Sometimes the dynamics of a physical system is described by non-Hamiltonian equations of motion, and additionally, the system is characterized by long-range interactions. A concrete example is that of particles interacting with light as encountered in free-electron laser and cold-atom experiments. In this work, we study the relaxation dynamics to non-Hamiltonian systems, more precisely, to systems with interactions of both Hamiltonian and non-Hamiltonian origin. Our model consists of $N$ globally-coupled particles moving on a circle of unit radius; the model is one-dimensional. We show that in the infinite-size limit, the dynamics, similarly to the Hamiltonian case, is described by the Vlasov equation. In the Hamiltonian case, the system eventually reaches an equilibrium state, even though one has to wait for a long time diverging with $N$ for this to happen. By contrast, in the non-Hamiltonian case, there is no equilibrium state that the system is expected to reach eventually. We characterize this state with its average magnetization. We find that the relaxation dynamics depends strongly on the relative weight of the Hamiltonian and non-Hamiltonian contributions to the interaction. When the non-Hamiltonian part is predominant, the magnetization attains a vanishing value, suggesting that the system does not sustain states with constant magnetization, either stationary or rotating. On the other hand, when the Hamiltonian part is predominant, the magnetization presents long-lived strong oscillations, for which we provide a heuristic explanation. Furthermore, we find that the finite-size corrections are much more pronounced than those in the Hamiltonian case; we justify this by showing that the Lenard-Balescu equation, which gives leading-order corrections to the Vlasov equation, does not vanish, contrary to what occurs in one-dimensional Hamiltonian long-range systems. 	
Superconductivity beyond the Pauli limit in high-pressure CeSb2	http://arxiv.org/abs/2211.00975v1	2022-11-02T09:27:24Z	2022-11-02T09:27:24Z	  We report the discovery of superconductivity at a pressure-induced magnetic quantum critical point in the Kondo-lattice system CeSb2, sustained up to magnetic fields that exceed the conventional Pauli limit eight-fold. Like CeRh2As2, CeSb2 is locally non-centrosymmetric around the Ce-site, but the evolution of critical fields and normal state properties as CeSb2 is tuned through the quantum critical point motivates a fundamentally different explanation for its resilience to applied field. 	
"Effects of syndication network on specialisation and performance of
  venture capital firms"	http://arxiv.org/abs/2211.00873v1	2022-11-02T04:42:56Z	2022-11-02T04:42:56Z	  The Chinese venture capital (VC) market is a young and rapidly expanding financial subsector. Gaining a deeper understanding of the investment behaviours of VC firms is crucial for the development of a more sustainable and healthier market and economy. Contrasting evidence supports that either specialisation or diversification helps to achieve a better investment performance. However, the impact of the syndication network is overlooked. Syndication network has a great influence on the propagation of information and trust. By exploiting an authoritative VC dataset of thirty-five-year investment information in China, we construct a joint-investment network of VC firms and analyse the effects of syndication and diversification on specialisation and investment performance. There is a clear correlation between the syndication network degree and specialisation level of VC firms, which implies that the well-connected VC firms are diversified. More connections generally bring about more information or other resources, and VC firms are more likely to enter a new stage or industry with some new co-investing VC firms when compared to a randomised null model. Moreover, autocorrelation analysis of both specialisation and success rate on the syndication network indicates that clustering of similar VC firms is roughly limited to the secondary neighbourhood. When analysing local clustering patterns, we discover that, contrary to popular beliefs, there is no apparent successful club of investors. In contrast, investors with low success rates are more likely to cluster. Our discoveries enrich the understanding of VC investment behaviours and can assist policymakers in designing better strategies to promote the development of the VC industry. 	
Creation of an isolated turbulent blob fed by vortex rings	http://arxiv.org/abs/2211.00771v3	2022-11-07T16:52:16Z	2022-11-01T22:22:30Z	  Turbulence is hard to control. A plethora of experimental methods have been developed to generate this ephemeral state of matter, leading to fundamental insights into its statistical and structural features as well as its onset at ever higher Reynolds numbers. In all cases however, the central role played by the material boundaries of the apparatus poses a challenge on understanding what the turbulence has been fed, and how it would freely evolve. Here, we build and control a confined state of turbulence using only elemental building blocks: vortex rings. We create a stationary and isolated blob of turbulence ($Re_\lambda$=50-300) in a quiescent environment, initiated and sustained solely by vortex rings. We assemble a full picture of its three-dimensional structure, onset, energy budget and tunability. Crucially, the incoming vortex rings can be endowed with conserved quantities, such as helicity, which can then be controllably transferred to the turbulent state. Our `one eddy at a time' approach paves the way for sculpting turbulent flows much as a state of matter, `printing' it at a targeted position, localizing it, and ultimately harnessing it. Our work paves the way to gaining a complete picture of this ephemeral state of flow. 	
Stochastic thermodynamic bounds on logical circuit operation	http://arxiv.org/abs/2211.00670v1	2022-11-01T18:01:40Z	2022-11-01T18:01:40Z	  Using a thermodynamically consistent, mesoscopic model for modern complementary metal-oxide-semiconductor transistors, we study an array of logical circuits and explore how their function is constrained by recent thermodynamic uncertainty relations when operating near thermal energies. For a single NOT gate, we find operating direction-dependent dynamics, and an optimal trade-off between dissipated heat and operation time certainty. For a memory storage device, we find an exponential relationship between the memory retention time and energy required to sustain that memory state. For a clock, we find that the certainty in the cycle time is maximized at biasing voltages near thermal energy, as is the trade-off between this certainty and the heat dissipated per cycle. We demonstrate that a simple control mechanism for the clock leads to a monotonic increase in cycle time certainty with biasing voltage alleviating its degradation at large biasing voltages. These results provide a framework for assessing thermodynamic costs of realistic computing devices, allowing for circuits to be designed and controlled for thermodynamically optimal operation. 	
"Machine learning can guide experimental approaches for protein
  digestibility estimations"	http://arxiv.org/abs/2211.00625v1	2022-11-01T17:43:58Z	2022-11-01T17:43:58Z	  Food protein digestibility and bioavailability are critical aspects in addressing human nutritional demands, particularly when seeking sustainable alternatives to animal-based proteins. In this study, we propose a machine learning approach to predict the true ileal digestibility coefficient of food items. The model makes use of a unique curated dataset that combines nutritional information from different foods with FASTA sequences of some of their protein families. We extracted the biochemical properties of the proteins and combined these properties with embeddings from a Transformer-based protein Language Model (pLM). In addition, we used SHAP to identify features that contribute most to the model prediction and provide interpretability. This first AI-based model for predicting food protein digestibility has an accuracy of 90% compared to existing experimental techniques. With this accuracy, our model can eliminate the need for lengthy in-vivo or in-vitro experiments, making the process of creating new foods faster, cheaper, and more ethical. 	
"2D Janus Niobium Oxydihalide NbO$XY$: Multifunctional High-Mobility
  Piezoelectric Semiconductor for Electronics, Photonics and Sustainable Energy
  Applications"	http://arxiv.org/abs/2211.00560v2	2022-11-03T15:11:12Z	2022-11-01T16:14:41Z	  Two-dimensional (2D) niobium oxydihalide NbOI$_2$ has been recently demonstrated as an excellent in-plane piezoelectric and nonlinear optical materials. Here we show that Janus niobium oxydihalide, NbO$XY$ (X, Y = Cl, Br, I and X$\neq$Y), is a multifunctional anisotropic semiconductor family with exceptional piezoelectric, electronic, photocatalytic and optical properties. NbO$XY$ are stable and mechancially flexible monolayers with band gap around the visible light regime of $\sim 1.9$ eV. The anisotropic carrier mobility of NbO$XY$ lies in the range of $10^3 \sim 10^4$ cm$^2$V$^{-1}$s$^{-1}$, which represents some of the highest among 2D semiconductors of bandgap $\gtrsim 2$ eV. Inversion symmetry breaking in Janus NbO$XY$ generates sizable out-of-plane $d_{31}$ piezoelectric response while still retaining a strong in-plane piezoelectricity. Remarkably, NbO$XY$ exhibits an additional out-of-plane piezoelectric response, $d_{32}$ as large as 0.55 pm/V. G$_0$W$_0$-BSE calculation further reveals the strong linear optical dichroism of NbO$XY$ in the visible-to-ultraviolet regime. The optical absorption peaks with $14\sim18$ \% in the deep UV regime ($5\sim6$ eV), outperforming the vast majority of other 2D materials. The high carrier mobility, strong optical absorption, sizable built-in electric field and band alignment compatible with overall water splitting further suggest the strengths of NbO$XY$ in energy conversion application. We further propose a directional stress sensing device to demonstrate how the out-of-plane piezoelectricity can be harnessed for functional device applications. Our findings unveil NbO$XY$ as an exceptional multifunctional 2D semiconductor for flexible electronics, optoelectronics, UV photonics, piezoelectric and sustainable energy applications. 	
"Universal Perturbation Attack on Differentiable No-Reference Image- and
  Video-Quality Metrics"	http://arxiv.org/abs/2211.00366v1	2022-11-01T10:28:13Z	2022-11-01T10:28:13Z	  Universal adversarial perturbation attacks are widely used to analyze image classifiers that employ convolutional neural networks. Nowadays, some attacks can deceive image- and video-quality metrics. So sustainability analysis of these metrics is important. Indeed, if an attack can confuse the metric, an attacker can easily increase quality scores. When developers of image- and video-algorithms can boost their scores through detached processing, algorithm comparisons are no longer fair. Inspired by the idea of universal adversarial perturbation for classifiers, we suggest a new method to attack differentiable no-reference quality metrics through universal perturbation. We applied this method to seven no-reference image- and video-quality metrics (PaQ-2-PiQ, Linearity, VSFA, MDTVSFA, KonCept512, Nima and SPAQ). For each one, we trained a universal perturbation that increases the respective scores. We also propose a method for assessing metric stability and identify the metrics that are the most vulnerable and the most resistant to our attack. The existence of successful universal perturbations appears to diminish the metric's ability to provide reliable scores. We therefore recommend our proposed method as an additional verification of metric reliability to complement traditional subjective tests and benchmarks. 	
Urban Mobility	http://arxiv.org/abs/2211.00355v1	2022-11-01T09:58:49Z	2022-11-01T09:58:49Z	  In this chapter, we discuss urban mobility from a complexity science perspective. First, we give an overview of the datasets that enable this approach, such as mobile phone records, location-based social network traces, or GPS trajectories from sensors installed on vehicles. We then review the empirical and theoretical understanding of the properties of human movements, including the distribution of travel distances and times, the entropy of trajectories, and the interplay between exploration and exploitation of locations. Next, we explain generative and predictive models of individual mobility, and their limitations due to intrinsic limits of predictability. Finally, we discuss urban transport from a systemic perspective, including system-wide challenges like ridesharing, multimodality, and sustainable transport. 	
Road Damages Detection and Classification with YOLOv7	http://arxiv.org/abs/2211.00091v1	2022-10-31T18:55:58Z	2022-10-31T18:55:58Z	  Maintaining the roadway infrastructure is one of the essential factors in enabling a safe, economic, and sustainable transportation system. Manual roadway damage data collection is laborious and unsafe for humans to perform. This area is poised to benefit from the rapid advance and diffusion of artificial intelligence technologies. Specifically, deep learning advancements enable the detection of road damages automatically from the collected road images. This work proposes to collect and label road damage data using Google Street View and use YOLOv7 (You Only Look Once version 7) together with coordinate attention and related accuracy fine-tuning techniques such as label smoothing and ensemble method to train deep learning models for automatic road damage detection and classification. The proposed approaches are applied to the Crowdsensing-based Road Damage Detection Challenge (CRDDC2022), IEEE BigData 2022. The results show that the data collection from Google Street View is efficient, and the proposed deep learning approach results in F1 scores of 81.7% on the road damage data collected from the United States using Google Street View and 74.1% on all test images of this dataset. 	
"The merger and assembly histories of Milky Way- and M31-like galaxies
  with TNG50: disk survival through mergers"	http://arxiv.org/abs/2211.00036v1	2022-10-31T18:00:05Z	2022-10-31T18:00:05Z	  We analyze the merger and assembly histories of Milky Way (MW) and Andromeda (M31)-like galaxies to quantify how, and how often, disk galaxies of this mass can survive recent major mergers (stellar mass ratio $\ge$ 1:4). For this, we use the cosmological magneto-hydrodynamical simulation TNG50 and identify 198 analog galaxies, selected based on their $z=0$ stellar mass ($10^{10.5-11.2} {\rm M_{\odot}}$), disky stellar morphology and local environment. Firstly, major mergers are common: 85 per cent (168) of MW/M31-like galaxies in TNG50 have undergone at least one major merger across their lifetime. In fact, 31 galaxies (16 per cent) have undergone a recent major merger, i.e. in the last 5 Gyr. The gas available during the merger suffices to either induce starbursts at pericentric passages or to sustain prolonged star formation after coalescence: in roughly half of the cases, the pre-existing stellar disk is destroyed because of the merger but reforms thanks to star formation. Moreover, higher merger mass ratios are more likely to destroy the stellar disks. In comparison to those with more ancient massive mergers, MW/M31-like galaxies with recent major mergers have, on average, somewhat thicker stellar disks, more massive and somewhat shallower stellar haloes, larger stellar ex-situ mass fractions, but similarly massive kinematically-defined bulges. All this is qualitatively consistent with the different observed properties of the Galaxy and Andromeda and with the constraints on their most recent major mergers, 8-11 and ~2 Gyr ago, respectively. According to contemporary cosmological simulations, a recent quiet merger history is not a pre-requisite for obtaining a relatively-thin stellar disk at $z=0$. 	
IoT System Case Study: Personal Office Energy Monitor (POEM)	http://arxiv.org/abs/2210.17356v1	2022-10-31T14:36:38Z	2022-10-31T14:36:38Z	  This paper describes the design, implementation, and user evaluation of an IoT project focused on monitoring and management of user comfort and energy usage in office buildings. The objective is to depict an instructive use case and to illustrate experiences with all major phases of designing and running a fairly complex IoT system. The design part includes motivation and outline of the problem statement, the resulting definition of data to be collected, system implementation, and subsequent changes resulting from the additional insights that it provided. The user experience part describes quantitative findings as well as key results of the extensive human factors study with over 70 office users participating in two major pilots in France and Japan. The original idea for this project came out from a diverse group of companies exploring challenges of designing and operating smart buildings with net-positive energy balance. Members included companies involved in the design and construction of smart buildings, building-management and automation systems, computer design, energy systems, and office furniture and space design. One of the early insights was that maximum energy efficiency in office buildings cannot be achieved and sustained without the awareness and active participation of building occupants. The resulting project explored and evaluated several ways to engage and empower users in ways that benefit them and makes them the willing and active participants. 	
SIX-Trust for 6G: Towards a Secure and Trustworthy 6G Network	http://arxiv.org/abs/2210.17291v1	2022-10-31T13:13:59Z	2022-10-31T13:13:59Z	  Recent years have witnessed a digital explosion with the deployment of 5G and proliferation of 5G-enabled innovations. Compared with 5G, 6G is envisioned to achieve much higher performance in terms of latency, data rate, connectivity, energy efficiency, coverage and mobility. To fulfil these expectations, 6G will experience a number of paradigm shifts, such as exploiting new spectrum, applying ubiquitous ML/AI technologies and building a space-air-ground-sea integrated network. However, these paradigm shifts may lead to numerous new security and privacy issues, which traditional security measures may not be able to deal with. To tackle these issues and build a trustworthy 6G network, we introduce a novel trust framework named as SIX-Trust, which composes of 3 layers: sustainable trust (S-Trust), infrastructure trust (I-Trust) and xenogenesis trust (X-Trust). Each layer plays a different role, and the importance of each layer varies for different application scenarios of 6G. For each layer, we briefly introduce its related enabling technologies, and demonstrate how these technologies can be applied to enhance trust and security of the 6G network. In general, SIX-Trust provides a holistic framework for defining and modeling trust of 6G, which can facilitate establishing a trustworthy 6G network. 	
ModularFed: Leveraging Modularity in Federated Learning Frameworks	http://arxiv.org/abs/2212.10427v1	2022-10-31T10:21:19Z	2022-10-31T10:21:19Z	  Numerous research recently proposed integrating Federated Learning (FL) to address the privacy concerns of using machine learning in privacy-sensitive firms. However, the standards of the available frameworks can no longer sustain the rapid advancement and hinder the integration of FL solutions, which can be prominent in advancing the field. In this paper, we propose ModularFed, a research-focused framework that addresses the complexity of FL implementations and the lack of adaptability and extendability in the available frameworks. We provide a comprehensive architecture that assists FL approaches through well-defined protocols to cover three dominant FL paradigms: adaptable workflow, datasets distribution, and third-party application support. Within this architecture, protocols are blueprints that strictly define the framework's components' design, contribute to its flexibility, and strengthen its infrastructure. Further, our protocols aim to enable modularity in FL, supporting third-party plug-and-play architecture and dynamic simulators coupled with major built-in data distributors in the field. Additionally, the framework support wrapping multiple approaches in a single environment to enable consistent replication of FL issues such as clients' deficiency, data distribution, and network latency, which entails a fair comparison of techniques outlying FL technologies. In our evaluation, we examine the applicability of our framework addressing three major FL domains, including statistical distribution and modular-based approaches for resource monitoring and client selection. 	
Minimum Processing Near-end Listening Enhancement	http://arxiv.org/abs/2210.17154v1	2022-10-31T09:08:00Z	2022-10-31T09:08:00Z	  The intelligibility and quality of speech from a mobile phone or public announcement system are often affected by background noise in the listening environment. By pre-processing the speech signal it is possible to improve the speech intelligibility and quality -- this is known as near-end listening enhancement (NLE). Although, existing NLE techniques are able to greatly increase intelligibility in harsh noise environments, in favorable noise conditions the intelligibility of speech reaches a ceiling where it cannot be further enhanced. Actually, the focus of existing methods solely on improving the intelligibility causes unnecessary processing of the speech signal and leads to speech distortions and quality degradations. In this paper, we provide a new rationale for NLE, where the target speech is minimally processed in terms of a processing penalty, provided that a certain performance constraint, e.g., intelligibility, is satisfied. We present a closed-form solution for the case where the performance criterion is an intelligibility estimator based on the approximated speech intelligibility index and the processing penalty is the mean-square error between the processed and the clean speech. This produces an NLE method that adapts to changing noise conditions via a simple gain rule by limiting the processing to the minimum necessary to achieve a desired intelligibility, while at the same time focusing on quality in favorable noise situations by minimizing the amount of speech distortions. Through simulation studies, we show the proposed method attains speech quality on par or better than existing methods in both objective measurements and subjective listening tests, whilst still sustaining objective speech intelligibility performance on par with existing methods. 	
"A numerical modeling of rotating substellar objects up to mass-shedding
  limits"	http://arxiv.org/abs/2210.17068v2	2022-11-16T02:17:02Z	2022-10-31T05:13:04Z	  Rotation may affect the occurrence of sustainable hydrogen burning in very low-mass stellar objects by the introduction of centrifugal force to the hydrostatic balance as well as by the appearance of rotational break-up of the objects (mass-shedding limit) for rapidly rotating cases. We numerically construct the models of rotating very low-mass stellar objects that may or may not experience sustained nuclear reaction (hydrogen-burning) as their energy source. The rotation is not limited to being slow so the effect of the rotational deformation of them is not infinitesimally small. Critical curves of sustainable hydrogen burning in the parameter space of mass versus central degeneracy, on which the nuclear energy generation balances the surface luminosity, are obtained for different values of angular momentum. It is shown that if the angular momentum exceeds the threshold $J_0=8.85\times 10^{48}{\rm erg}~{\rm s}$ the critical curve is broken up into two branches with lower and higher degeneracy because of the mass-shedding limit. Based on the results, we model mechano-thermal evolutions of substellar objects, in which cooling, as well as mass/angular momentum reductions, are followed for two simplified cases. The case with such external braking mechanisms as magnetized wind or magnetic braking is mainly controlled by the spin-down timescale. The other case with no external braking leads to the mass-shedding limit after gravitational contraction. Thereafter the object sheds its mass to form a ring or a disc surrounding it and shrinks. 	
Shallow-flow velocity predictions using discontinuous Galerkin solutions	http://arxiv.org/abs/2210.16972v1	2022-10-30T22:42:56Z	2022-10-30T22:42:56Z	  Numerical solvers of the two-dimensional (2D) shallow water equations (2D-SWE) can be an efficient option to predict spatial distribution of velocity fields in quasi-steady flows past or throughout hydraulic engineering structures. A second-order finite volume solver (FV2) spuriously elongates small-scale recirculating eddies within its predictions, unless sustained by an artificial eddy viscosity, while a third-order finite volume (FV3) solver can distort the eddies within its predictions. The extra complexity in a second-order discontinuous Galerkin (DG2) solver leads to significantly reduced error dissipation and improved predictions at a coarser resolution, making it a viable contender to acquire velocity predictions in shallow flows. This paper analyses this predictive capability for a grid-based, open source DG2 solver with reference to FV2 or FV3 solvers for simulating velocity magnitude and direction at the sub-meter scale. The simulated predictions are assessed against measured velocity data for four experimental test cases. The results consistently indicate that the DG2 solver is a competitive choice to efficiently produce more accurate velocity distributions for the simulations dominated by smooth flow regions. 	
"Deep Learning for Verification of Earth-System Parametrisation of Water
  Bodies"	http://arxiv.org/abs/2210.16746v1	2022-10-30T05:10:11Z	2022-10-30T05:10:11Z	  About 2/3 of all densely populated areas (i.e. at least 300 inhabitants per km$^2$) around the globe are situated within a 9 km radius of a permanent waterbody (i.e. inland water or sea/ocean coast), since inland water sustains the vast majority of human activities. Water bodies exchange mass and energy with the atmosphere and need to be accurately simulated in numerical weather prediction and climate modelling as they strongly influence the lower boundary conditions such as skin temperatures, turbulent latent and sensible heat fluxes and moisture availability near the surface. All the non-ocean water (resolved and sub-grid lakes and coastal waters) are represented in the Integrated Forecasting System (IFS) of the European Centre for Medium-Range Weather Forecasts (ECMWF) model, by the Fresh-water Lake (FLake) parametrisation, which treats $\sim$ 1/3 of the land. It is a continuous enterprise to update the surface parametrization schemes and their input fields to better represent small-scale processes. It is, however, difficult to quickly determine both the accuracy of an updated parametrisation, and the added value gained for the purposes of numerical modelling. The aim of our work is to quickly and automatically assess the benefits of an updated lake parametrisation making use of a neural network regression model trained to simulate satellite observed surface skin temperatures. We deploy this tool to determine the accuracy of recent upgrades to the FLake parametrisation, namely the improved permanent lake cover and the capacity to represent seasonally varying water bodies (i.e. ephemeral lakes). We show that for grid-cells where the lake fields have been updated, the prediction accuracy in the land surface temperature improves by 0.45 K on average, whilst for the subset of points where the lakes have been exchanged for bare ground (or vice versa) the improvement is 1.12 K. [abridged] 	
Mass Spectra and Regge Trajectories of $$ Baryons	http://arxiv.org/abs/2210.16573v1	2022-10-29T11:20:05Z	2022-10-29T11:20:05Z	  In contrast to past studies, the current paper is focused on baryons, and all four isospin states have been independently generated using u and d quarks with various constituent masses. The hypercentral Constituent Quark Model (hCQM) serves as the theoretical foundation for computing the resonance masses. The spin-dependent and first order correction terms are added to the confining potential, which is assumed to be in linear form. The resulting results have been contrasted with a wide range of methodologies and experimentally practicable states. Regge trajectories for (n,M^2) and (J,M^2) have also been displayed in addition to mass spectra. 	
"Rod and slit photonic crystal microrings for on-chip cavity quantum
  electrodynamics"	http://arxiv.org/abs/2210.16436v1	2022-10-28T23:34:25Z	2022-10-28T23:34:25Z	  Micro-/nanocavities that combine high quality factor ($Q$) and small mode volume ($V$) have been used to enhance light-matter interactions for cavity quantum electrodynamics (cQED). Whispering gallery mode (WGM) geometries such as microdisks and microrings support high-$Q$ and are design- and fabrication-friendly, but $V$ is often limited to tens of cubic wavelengths to avoid WGM radiation. The stronger modal confinement provided by either one-dimensional or two-dimensional photonic crystal defect geometries can yield sub-cubic-wavelength $V$, yet the requirements on precise design and dimensional control are typically much more stringent to ensure high-$Q$. Given their complementary features, there has been sustained interest in geometries that combine the advantages of WGM and photonic crystal cavities. Recently, a `microgear' photonic crystal ring (MPhCR) has shown promise in enabling additional defect localization ($>$ 10$\times$ reduction of $V$) of a WGM, while maintaining high-$Q$ ($\approx10^6$) and other WGM characteristics in ease of coupling and design. However, the unit cell geometry used is unlike traditional PhC cavities, and etched surfaces may be too close to embedded quantum nodes (quantum dots, atomic defect spins, etc.) for cQED applications. Here, we report two novel PhCR designs with `rod' and `slit' unit cells, whose geometries are more traditional and suitable for solid-state cQED. Both rod and slit PhCRs have high-$Q$ ($>10^6$) with WGM coupling properties preserved. A further $\approx$~10$\times$ reduction of $V$ by defect localization is observed in rod PhCRs. Moreover, both fundamental and 2nd-order PhC modes co-exist in slit PhCRs with high $Q$s and good coupling. Our work showcases that high-$Q/V$ PhCRs are in general straightforward to design and fabricate and are a promising platform to explore for cQED. 	
"Intermodulation of optical frequency combs in a multimode optomechanical
  system"	http://arxiv.org/abs/2210.16370v2	2023-03-03T22:56:01Z	2022-10-28T19:11:31Z	  Phonons offer the possibility to connect the microwave and optical domains while being efficiently transduced with electronic and optical signals. Here, we present a multimodal optomechanical platform, consisting of a mechanical-optical-mechanical resonator configuration. The mechanical modes, with frequencies at 265 MHz and 6.8 GHz, can be simultaneously excited into a phonon lasing regime as supported by a stability analysis of the system. Both the MHz and the GHz modes enter a self-sustained oscillation regime, leading to the intermodulation of two frequency combs in the optical field. We characterize this platform experimentally, demonstrating previously unexplored dynamical regimes. These results suggest the possibility to control multiple mechanical degrees of freedom via a single optical mode, with implications in GHz phononic devices, signal processing, and optical comb sensing applications. 	
"Upgrading the Detection of Electrocatalyst Degradation During the Oxygen
  Evolution Reaction"	http://arxiv.org/abs/2210.16096v1	2022-10-28T12:44:14Z	2022-10-28T12:44:14Z	  Electrocatalysts for the oxygen evolution reaction (OER) are an important component for the transition from fossil to sustainable energy. Commercialization of cost-effective earth-abundant electrocatalysts is in large parts hindered by their degradation. In this short review, I identify common processes leading to a decrease in electrocatalyst activity, followed by an introduction of staple methods to determine degradation electrochemically and by additional physical characterization, which has the potential to remove ambiguities of purely electrochemical studies. I conclude by a summary of the key challenges for an accurate determination of degradation processes and highlight interesting directions to advance the understanding of degradation processes on electrocatalysts. 	
An Online Learning Approach for Vehicle Usage Prediction During COVID-19	http://arxiv.org/abs/2210.16002v1	2022-10-28T09:09:34Z	2022-10-28T09:09:34Z	  Today, there is an ongoing transition to more sustainable transportation, and an essential part of this transition is the switch from combustion engine vehicles to battery electric vehicles (BEVs). BEVs have many advantages from a sustainability perspective, but issues such as limited driving range and long recharge times slow down the transition from combustion engines. One way to mitigate these issues is by performing battery thermal preconditioning, which increases the energy efficiency of the battery. However, to optimally perform battery thermal preconditioning, the vehicle usage pattern needs to be known, i.e., how and when the vehicle will be used. This study attempts to predict the departure time and distance of the first drive each day using different online machine learning models. The online machine learning models are trained and evaluated on historical driving data collected from a fleet of BEVs during the COVID-19 pandemic. Additionally, the prediction models are extended to quantify the uncertainty of their predictions, which can be used as guidance to whether the prediction should be used or dismissed. We show that the best-performing prediction models yield an aggregated mean absolute error of 2.75 hours when predicting departure time and 13.37 km when predicting trip distance. 	
"Sustainable learning, cognitive gains, and improved attitudes in College
  Algebra flipped classrooms"	http://arxiv.org/abs/2210.15979v1	2022-10-28T08:19:25Z	2022-10-28T08:19:25Z	  The objective of this article is to investigate the effect of active-learning pedagogy on learners' academic achievement and their attitude toward mathematics using both quantitative and qualitative methods. We cultivated sustainable learning in mathematics education for college freshmen ($n = 55$) by exposing them to both the conventional teaching method (CTM) and flipped classroom pedagogy (FCP). By splitting them into control and experimental groups alternately ($n_1 = 24$, $n_2 = 31$) and by selecting the four most challenging topics in college algebra, we measured their cognitive gains quantitatively via a sequence of pre- and post-tests. Both groups improved academically over time across all these four topics with statistically very significant outcomes $(p < 0.001)$. Although they were not always statistically significant ($p > 0.05$) in some topics, the post-test results suggest that generally, the FCP trumps the CTM in cognitive gains, except for the first topic on factorization, where the opposite is true with a very statistically significant mean difference $(p < 0.001)$. By examining non-cognitive gains qualitatively, we analyzed the students' feedback on the FCP and their responses to a perception inventory. The finding suggests a favorable response toward the FCP with primary improvements in the attitudes toward mathematics and increased levels of cooperation among students. Since these students are so happy to have control of their own learning, they were more relaxed, motivated, confident, active, and responsible in learning under the FCP. We are confident that although this study is relatively small in scale, it will yield incremental and long-lasting effects not only for the learners themselves but also for other role-takers in education sectors who aspire in nurturing sustainable long-life learning and achieving sustainable development goals successfully. 	
Dynamic modeling of the motions of variable-shape wave energy converters	http://arxiv.org/abs/2210.17297v3	2022-12-12T04:01:56Z	2022-10-28T08:10:18Z	  In the recently introduced Variable-Shape heaving wave energy converters, the buoy changes its shape actively in response to changing incident waves. In this study, a Lagrangian approach for the dynamic modeling of a spherical Variable-Shape Wave Energy Converter is described. The classical bending theory is used to write the stress-strain equations for the flexible body using Love's approximation. The elastic spherical shell is assumed to have an axisymmetric vibrational behavior. The Rayleigh-Ritz discretization method is adopted to find an approximate solution for the vibration model of the spherical shell. A novel equation of motion is presented that serves as a substitute for Cummins equation for flexible buoys. Also, novel hydrodynamic coefficients that account for the buoy mode shapes are proposed. The developed dynamic model is coupled with the open-source boundary element method software NEMOH. Two-way and one-way Fluid-Structure Interaction simulations are performed using MATLAB to study the effect of using a flexible shape buoy in the wave energy converter on its trajectory and power production. Finally, the variable shape buoy was able to harvest more energy for all the tested wave conditions. 	
"Automatic Severity Assessment of Dysarthric speech by using
  Self-supervised Model with Multi-task Learning"	http://arxiv.org/abs/2210.15387v1	2022-10-27T12:48:10Z	2022-10-27T12:48:10Z	  Automatic assessment of dysarthric speech is essential for sustained treatments and rehabilitation. However, obtaining atypical speech is challenging, often leading to data scarcity issues. To tackle the problem, we propose a novel automatic severity assessment method for dysarthric speech, using the self-supervised model in conjunction with multi-task learning. Wav2vec 2.0 XLS-R is jointly trained for two different tasks: severity level classification and an auxilary automatic speech recognition (ASR). For the baseline experiments, we employ hand-crafted features such as eGeMaps and linguistic features, and SVM, MLP, and XGBoost classifiers. Explored on the Korean dysarthric speech QoLT database, our model outperforms the traditional baseline methods, with a relative percentage increase of 4.79% for classification accuracy. In addition, the proposed model surpasses the model trained without ASR head, achieving 10.09% relative percentage improvements. Furthermore, we present how multi-task learning affects the severity classification performance by analyzing the latent representations and regularization effect. 	
A Classification Scheme for Local Energy Trading	http://arxiv.org/abs/2210.15344v1	2022-10-27T11:44:47Z	2022-10-27T11:44:47Z	  The current trend towards more renewable and sustainable energy generation leads to an increased interest in new energy management systems and the concept of a smart grid. One important aspect of this is local energy trading, which is an extension of existing electricity markets by including prosumers, who are consumers also producing electricity. Prosumers having a surplus of energy may directly trade this surplus with other prosumers, which are currently in demand. In this paper, we present an overview of the literature in the area of local energy trading. In order to provide structure to the broad range of publications, we identify key characteristics, define the various settings, and cluster the considered literature along these characteristics. We identify three main research lines, each with a distinct setting and research question. We analyze and compare the settings, the used techniques, and the results and findings within each cluster and derive connections between the clusters. In addition, we identify important aspects, which up to now have to a large extent been neglected in the considered literature and highlight interesting research directions, and open problems for future work. 	
Measuring Transition Risk in Investment Funds	http://arxiv.org/abs/2210.15329v3	2022-12-02T11:23:08Z	2022-10-27T11:12:38Z	  We develop a comprehensive framework to measure the impact of the climate transition on investment portfolios. Our analysis is enriched by including geographical, sectoral, company and ISIN-level data to assess transition risk. We find that investment funds suffer a moderate 5.7% loss upon materialization of a high transition risk scenario. However, the risk distribution is significantly left-skewed, with the worst 1% funds experiencing an average loss of 21.3%. In terms of asset classes, equities are the worst performers (-12.7%), followed by corporate bonds (-5.6%) and government bonds (-4.8%). We discriminate among financial instruments by considering the carbon footprint of specific counterparties and the credit rating, duration, convexity and volatility of individual exposures. We find that sustainable funds are less exposed to transition risk and perform better than the overall fund sector in the low-carbon transition, validating their choice as green investments. 	
"TASA: Deceiving Question Answering Models by Twin Answer Sentences
  Attack"	http://arxiv.org/abs/2210.15221v1	2022-10-27T07:16:30Z	2022-10-27T07:16:30Z	  We present Twin Answer Sentences Attack (TASA), an adversarial attack method for question answering (QA) models that produces fluent and grammatical adversarial contexts while maintaining gold answers. Despite phenomenal progress on general adversarial attacks, few works have investigated the vulnerability and attack specifically for QA models. In this work, we first explore the biases in the existing models and discover that they mainly rely on keyword matching between the question and context, and ignore the relevant contextual relations for answer prediction. Based on two biases above, TASA attacks the target model in two folds: (1) lowering the model's confidence on the gold answer with a perturbed answer sentence; (2) misguiding the model towards a wrong answer with a distracting answer sentence. Equipped with designed beam search and filtering methods, TASA can generate more effective attacks than existing textual attack methods while sustaining the quality of contexts, in extensive experiments on five QA datasets and human evaluations. 	
"Strong Coupling of Self-Trapped Excitons to Acoustic Phonons in Bismuth
  Perovskite $\textrm{Cs}_{3}\textrm{Bi}_{2}\textrm{I}_{9}$"	http://arxiv.org/abs/2210.15165v1	2022-10-27T04:20:01Z	2022-10-27T04:20:01Z	"  To assess the potential optoelectronic applications of metal-halide perovskites, it is critical to have a detailed understanding of the nature, strength, and dynamics of the interactions between carriers and the polar lattices. Here, we report the electronic and structural dynamics of bismuth-based perovskite $\textrm{Cs}_{3}\textrm{Bi}_{2}\textrm{I}_{9}$ revealed by transient reflectivity and ultrafast electron diffraction. A cross-examination of these experimental results combined with theoretical analyses allows the identification of the major carrier-phonon coupling mechanism and the associated time scales. It is found that carriers photoinjected into $\textrm{Cs}_{3}\textrm{Bi}_{2}\textrm{I}_{9}$ form self-trapped excitons on an ultrafast time scale. However, they retain most of their energy and their coupling to Fr\""ohlich-type optical phonons is limited at early times. Instead, the long-lived excitons exert an electronic stress via deformation potential and develop a prominent, sustaining strain field as coherent acoustic phonons in 10 ps. From sub-ps to ns and beyond, a similar extent of the atomic displacements is found throughout the different stages of structural distortions, from limited local modulations to a coherent strain field to the Debye-Waller random atomic motions on longer times. The current results suggest the potential use of bismuth-based perovskites for applications other than photovoltaics to take advantage of carriers' stronger self-trapping and long lifetime. "	
"MEET: Mobility-Enhanced Edge inTelligence for Smart and Green 6G
  Networks"	http://arxiv.org/abs/2210.15111v1	2022-10-27T01:45:16Z	2022-10-27T01:45:16Z	  Edge intelligence is an emerging paradigm for real-time training and inference at the wireless edge, thus enabling mission-critical applications. Accordingly, base stations (BSs) and edge servers (ESs) need to be densely deployed, leading to huge deployment and operation costs, in particular the energy costs. In this article, we propose a new framework called Mobility-Enhanced Edge inTelligence (MEET), which exploits the sensing, communication, computing, and self-powering capabilities of intelligent connected vehicles for the smart and green 6G networks. Specifically, the operators can incorporate infrastructural vehicles as movable BSs or ESs, and schedule them in a more flexible way to align with the communication and computation traffic fluctuations. Meanwhile, the remaining compute resources of opportunistic vehicles are exploited for edge training and inference, where mobility can further enhance edge intelligence by bringing more compute resources, communication opportunities, and diverse data. In this way, the deployment and operation costs are spread over the vastly available vehicles, so that the edge intelligence is realized cost-effectively and sustainably. Furthermore, these vehicles can be either powered by renewable energy to reduce carbon emissions, or charged more flexibly during off-peak hours to cut electricity bills. 	
The Global Care Ecosystems of 3D Printed Assistive Devices	http://arxiv.org/abs/2210.14984v1	2022-10-26T19:02:29Z	2022-10-26T19:02:29Z	  The popularity of 3D printed assistive technology has led to the emergence of new ecosystems of care, where multiple stakeholders (makers, clinicians, and recipients with disabilities) work toward creating new upper limb prosthetic devices. However, despite the increasing growth, we currently know little about the differences between these care ecosystems. Medical regulations and the prevailing culture have greatly impacted how ecosystems are structured and stakeholders work together, including whether clinicians and makers collaborate. To better understand these care ecosystems, we interviewed a range of stakeholders from multiple countries, including Brazil, Chile, Costa Rica, France, India, Mexico, and the U.S. Our broad analysis allowed us to uncover different working examples of how multiple stakeholders collaborate within these care ecosystems and the main challenges they face. Through our study, we were able to uncover that the ecosystems with multi-stakeholder collaborations exist (something prior work had not seen), and these ecosystems showed increased success and impact. We also identified some of the key follow-up practices to reduce device abandonment. Of particular importance are to have ecosystems put in place follow up practices that integrate formal agreements and compensations for participation (which do not need to be just monetary). We identified that these features helped to ensure multi-stakeholder involvement and ecosystem sustainability. We finished the paper with socio-technical recommendations to create vibrant care ecosystems that include multiple stakeholders in the production of 3D printed assistive devices. 	
Evolution of pits at the surface of 67P/Churyumov-Gerasimenko	http://arxiv.org/abs/2210.14634v1	2022-10-26T11:24:02Z	2022-10-26T11:24:02Z	  The observation of pits at the surface of comets offers the opportunity to take a glimpse into the properties and the mechanisms that shape a nucleus through cometary activity. If the origin of these pits is still a matter of debate, multiple studies have recently suggested that known phase transitions alone could not have carved these morphological features on the surface of 67P/C-G. We want to understand how the progressive modification of 67P's surface due to cometary activity might have affected the characteristics of pits. In particular, we aim to understand whether signatures of the formation mechanism of these morphological features can still be identified. To quantify the amount of erosion sustained at the surface of 67P since it arrived on its currently observed orbit, we selected 380 facets of a medium-resolution shape model of the nucleus, sampling 30 pits across the surface. We computed the surface energy balance with a high temporal resolution, including shadowing and self-heating. We then applied a thermal evolution model to assess the amount of erosion sustained after ten orbital revolutions under current illumination conditions. We find that the maximum erosion sustained after ten orbital revolutions is on the order of 80 m, for facets located in the southern hemisphere. We thus confirm that progressive erosion cannot form pits and alcoves, as local erosion is much lower than their observed depth and diameter. We find that plateaus tend to erode more than bottoms, especially for the deepest depressions, and that some differential erosion can affect their morphology. As a general rule, our results suggest that sharp morphological features tend to be erased by progressive erosion. This study supports the assumption that deep circular pits, such as Seth1, are the least processed morphological features at the surface of 67P, or the best preserved since their formation. 	
"RMLStreamer-SISO: an RDF stream generator from streaming heterogeneous
  data"	http://arxiv.org/abs/2210.14599v1	2022-10-26T10:13:42Z	2022-10-26T10:13:42Z	  Stream-reasoning query languages such as CQELS and C-SPARQL enable query answering over RDF streams. Unfortunately, there currently is a lack of efficient RDF stream generators to feed RDF stream reasoners. State-of-the-art RDF stream generators are limited with regard to the velocity and volume of streaming data they can handle. To efficiently generate RDF streams in a scalable way, we extended the RMLStreamer to also generate RDF streams from dynamic heterogeneous data streams. This paper introduces a scalable solution that relies on a dynamic window approach to generate RDF streams with low latency and high throughput from multiple heterogeneous data streams. Our evaluation shows that our solution outperforms the state-of-the-art by achieving millisecond latency (compared to seconds that state-of-the-art solutions need), constant memory usage for all workloads, and sustainable throughput of around 70,000 records/s (compared to 10,000 records/s that state-of-the-art solutions take). This opens up the access to numerous data streams for integration with the semantic web. 	
"Safe and Efficient Switching Mechanism Design for Uncertified Linear
  Controller"	http://arxiv.org/abs/2210.14595v1	2022-10-26T10:10:42Z	2022-10-26T10:10:42Z	"  Sustained research efforts have been devoted to learning optimal controllers for linear stochastic dynamical systems with unknown parameters, but due to the corruption of noise, learned controllers are usually uncertified in the sense that they may destabilize the system. To address this potential instability, we propose a ""plug-and-play"" modification to the uncertified controller which falls back to a known stabilizing controller when the norm of the difference between the uncertified and the fall-back control input exceeds a certain threshold. We show that the switching strategy is both safe and efficient, in the sense that: 1) the linear-quadratic cost of the system is always bounded even if original uncertified controller is destabilizing; 2) in case the uncertified controller is stabilizing, the performance loss caused by switching converges super-exponentially to $0$ for Gaussian noise, while the converging polynomially for general heavy-tailed noise. Finally, we demonstrate the effectiveness of the proposed switching strategy via numerical simulation on the Tennessee Eastman Process. "	
"A Bibliometric Analysis and Review on Reinforcement Learning for
  Transportation Applications"	http://arxiv.org/abs/2210.14524v1	2022-10-26T07:34:51Z	2022-10-26T07:34:51Z	  Transportation is the backbone of the economy and urban development. Improving the efficiency, sustainability, resilience, and intelligence of transportation systems is critical and also challenging. The constantly changing traffic conditions, the uncertain influence of external factors (e.g., weather, accidents), and the interactions among multiple travel modes and multi-type flows result in the dynamic and stochastic natures of transportation systems. The planning, operation, and control of transportation systems require flexible and adaptable strategies in order to deal with uncertainty, non-linearity, variability, and high complexity. In this context, Reinforcement Learning (RL) that enables autonomous decision-makers to interact with the complex environment, learn from the experiences, and select optimal actions has been rapidly emerging as one of the most useful approaches for smart transportation. This paper conducts a bibliometric analysis to identify the development of RL-based methods for transportation applications, typical journals/conferences, and leading topics in the field of intelligent transportation in recent ten years. Then, this paper presents a comprehensive literature review on applications of RL in transportation by categorizing different methods with respect to the specific application domains. The potential future research directions of RL applications and developments are also discussed. 	
"MemoNet:Memorizing Representations of All Cross Features Efficiently via
  Multi-Hash Codebook Network for CTR Prediction"	http://arxiv.org/abs/2211.01334v2	2022-11-03T06:49:56Z	2022-10-25T12:08:14Z	  New findings in natural language processing(NLP) demonstrate that the strong memorization capability contributes a lot to the success of large language models.This inspires us to explicitly bring an independent memory mechanism into CTR ranking model to learn and memorize all cross features'representations. In this paper,we propose multi-Hash Codebook NETwork(HCNet) as the memory mechanism for efficiently learning and memorizing representations of all cross features in CTR tasks.HCNet uses multi-hash codebook as the main memory place and the whole memory procedure consists of three phases: multi-hash addressing,memory restoring and feature shrinking.HCNet can be regarded as a general module and can be incorporated into any current deep CTR model.We also propose a new CTR model named MemoNet which combines HCNet with a DNN backbone.Extensive experimental results on three public datasets show that MemoNet reaches superior performance over state-of-the-art approaches and validate the effectiveness of HCNet as a strong memory module.Besides, MemoNet shows the prominent feature of big models in NLP,which means we can enlarge the size of codebook in HCNet to sustainably obtain performance gains.Our work demonstrates the importance and feasibility of learning and memorizing representations of all cross features ,which sheds light on a new promising research direction. 	
Semantic Image Segmentation with Deep Learning for Vine Leaf Phenotyping	http://arxiv.org/abs/2210.13296v1	2022-10-24T14:37:09Z	2022-10-24T14:37:09Z	  Plant phenotyping refers to a quantitative description of the plants properties, however in image-based phenotyping analysis, our focus is primarily on the plants anatomical, ontogenetical and physiological properties.This technique reinforced by the success of Deep Learning in the field of image based analysis is applicable to a wide range of research areas making high-throughput screens of plants possible, reducing the time and effort needed for phenotypic characterization.In this study, we use Deep Learning methods (supervised and unsupervised learning based approaches) to semantically segment grapevine leaves images in order to develop an automated object detection (through segmentation) system for leaf phenotyping which will yield information regarding their structure and function.In these directions we studied several deep learning approaches with promising results as well as we reported some future challenging tasks in the area of precision agriculture.Our work contributes to plant lifecycle monitoring through which dynamic traits such as growth and development can be captured and quantified, targeted intervention and selective application of agrochemicals and grapevine variety identification which are key prerequisites in sustainable agriculture. 	
"Secure and Trustworthy Artificial Intelligence-Extended Reality (AI-XR)
  for Metaverses"	http://arxiv.org/abs/2210.13289v1	2022-10-24T14:26:59Z	2022-10-24T14:26:59Z	  Metaverse is expected to emerge as a new paradigm for the next-generation Internet, providing fully immersive and personalised experiences to socialize, work, and play in self-sustaining and hyper-spatio-temporal virtual world(s). The advancements in different technologies like augmented reality, virtual reality, extended reality (XR), artificial intelligence (AI), and 5G/6G communication will be the key enablers behind the realization of AI-XR metaverse applications. While AI itself has many potential applications in the aforementioned technologies (e.g., avatar generation, network optimization, etc.), ensuring the security of AI in critical applications like AI-XR metaverse applications is profoundly crucial to avoid undesirable actions that could undermine users' privacy and safety, consequently putting their lives in danger. To this end, we attempt to analyze the security, privacy, and trustworthiness aspects associated with the use of various AI techniques in AI-XR metaverse applications. Specifically, we discuss numerous such challenges and present a taxonomy of potential solutions that could be leveraged to develop secure, private, robust, and trustworthy AI-XR applications. To highlight the real implications of AI-associated adversarial threats, we designed a metaverse-specific case study and analyzed it through the adversarial lens. Finally, we elaborate upon various open issues that require further research interest from the community. 	
Cybersecurity in the Smart Grid: Practitioners' Perspective	http://arxiv.org/abs/2210.13119v1	2022-10-24T11:09:14Z	2022-10-24T11:09:14Z	  The Smart Grid (SG) is a cornerstone of modern society, providing the energy required to sustain billions of lives and thousands of industries. Unfortunately, as one of the most critical infrastructures of our World, the SG is an attractive target for attackers. The problem is aggravated by the increasing adoption of digitalisation, which further increases the SG's exposure to cyberthreats. Successful exploitation of such exposure leads to entire countries being paralysed, which is an unacceptable -- but ultimately inescapable -- risk.   This paper aims to mitigate this risk by elucidating the perspective of real practitioners on the cybersecurity of the SG. We interviewed 18 entities, operating in diverse countries in Europe and covering all domains of the SG -- from energy generation, to its delivery. Our analysis highlights a stark contrast between (a)research and practice, but also between (b) public and private entities. For instance: some threats appear to be much less dangerous than what is claimed in related papers; some technological paradigms have dubious utility for practitioners, but are actively promoted by literature; finally, practitioners may either under- or over-estimate their own cybersecurity capabilities. We derive four takeaways that enable future endeavours to improve the overall cybersecurity in the SG. We conjecture that most of the problems are due to an improper communication between researchers, practitioners and regulatory bodies -- which, despite sharing a common goal, tend to neglect the viewpoint of the other `spheres'. 	
"Social norms of fairness with reputation-based role assignment in the
  dictator game"	http://arxiv.org/abs/2210.12930v1	2022-10-24T03:02:13Z	2022-10-24T03:02:13Z	  A vast body of experiments share the view that social norms are major factors for the emergence of fairness in a population of individuals playing the dictator game (DG). Recently, to explore which social norms are conducive to sustaining cooperation has obtained considerable concern. However, thus far few studies have investigated how social norms influence the evolution of fairness by means of indirect reciprocity. In this study, we propose an indirect reciprocal model of the DG and consider that an individual can be assigned as the dictator due to its good reputation. We investigate the `leading eight' norms and all second-order social norms by a two-timescale theoretical analysis. We show that when role assignment is based on reputation, four of the `leading eight' norms, including stern judging and simple standing, lead to a high level of fairness, which increases with the selection intensity. Our work also reveals that not only the correct treatment of making a fair split with good recipients but also distinguishing unjustified unfair split from justified unfair split matters in elevating the level of fairness. 	
Periodic analogues of the Kerr solutions: a numerical study	http://arxiv.org/abs/2210.12898v1	2022-10-24T00:57:05Z	2022-10-24T00:57:05Z	  In recent years black hole configurations with non standard topology or with non-standard asymptotic have gained considerable attention. In this article we carry out numerical investigations aimed to find periodic coaxial configurations of co-rotating 3+1 vacuum black holes, for which existence and uniqueness has not yet been theoretically proven. The aimed configurations would extend Myers/Korotkin-Nicolai's family of non-rotating (static) coaxial arrays of black holes. We find that numerical solutions with a given value for the area A and for the angular momentum J of the horizons appear to exist only when the separation between consecutive horizons is larger than a certain critical value that depends only on A and |J|. We also establish that the solutions have the same Lewis's cylindrical asymptotic as Stockum's infinite rotating cylinders. Below the mentioned critical value the rotational energy appears to be too big to sustain a global equilibrium and a singularity shows up at a finite distance from the bulk. This phenomenon is a relative of Stockum's asymptotic's collapse, manifesting when the angular momentum (per unit of axial length) reaches a critical value compared to the mass (per unit of axial length), and that results from a transition in the Lewis's class of the cylindrical exterior solution. This remarkable phenomenon seems to be unexplored in the context of coaxial arrays of black holes. Ergospheres and other global properties are also presented in detail. 	
Climate Change Policy Exploration using Reinforcement Learning	http://arxiv.org/abs/2211.17013v1	2022-10-23T18:20:17Z	2022-10-23T18:20:17Z	  Climate Change is an incredibly complicated problem that humanity faces. When many variables interact with each other, it can be difficult for humans to grasp the causes and effects of the very large-scale problem of climate change. The climate is a dynamical system, where small changes can have considerable and unpredictable repercussions in the long term. Understanding how to nudge this system in the right ways could help us find creative solutions to climate change.   In this research, we combine Deep Reinforcement Learning and a World-Earth system model to find, and explain, creative strategies to a sustainable future. This is an extension of the work from Strnad et al. where we extend on the method and analysis, by taking multiple directions. We use four different Reinforcement Learning agents varying in complexity to probe the environment in different ways and to find various strategies. The environment is a low-complexity World Earth system model where the goal is to reach a future where all the energy for the economy is produced by renewables by enacting different policies. We use a reward function based on planetary boundaries that we modify to force the agents to find a wider range of strategies. To favour applicability, we slightly modify the environment, by injecting noise and making it fully observable, to understand the impacts of these factors on the learning of the agents. 	
The Future of Work: Agile in a Hybrid World	http://arxiv.org/abs/2210.12591v1	2022-10-23T01:57:58Z	2022-10-23T01:57:58Z	"  An agile organization adapts what they are building to match their customer's evolving needs. Agile teams also adapt to changes in their organization's work environment. The latest change is the evolving environment of ""hybrid"" work - a mix of in-person and virtual staff. Team members might sometimes work together in the office, work from home, or work in other locations, and they may struggle to sustain a high level of collaboration and innovation. It isn't just pandemic social distancing - many of us want to work from home to eliminate our commute and spend more time with family. Are there learnings and best practices that organizations can use to become and stay effective in a hybrid world? An XP 2022 panel organized by Steven Fraser (Innoxec) discussed these questions in June 2022. The panel was facilitated by Hendrik Esser (Ericsson) and featured Alistair Cockburn (Heart of Agile), Sandy Mamoli (Nomad8), Nils Brede Moe (SINTEF), Jaana Nyfjord (Spotify), and Darja Smite (Blekinge Institute of Technology). "	
"Two-dimensional natural hyperbolic materials: From polaritons modulation
  to applications"	http://arxiv.org/abs/2210.12341v1	2022-10-22T03:56:02Z	2022-10-22T03:56:02Z	  Natural hyperbolic materials (HMs) in two dimensions (2D) have an extraordinarily high anisotropy and a hyperbolic dispersion relation. Some of them can even sustain hyperbolic polaritons with great directional propagation and light compression to deeply sub-wavelength scales due to their inherent anisotropy. Herein, the anisotropic optical features of 2D natural HMs are reviewed. Four hyperbolic polaritons (i.e., phonon polaritons, plasmon polaritons, exciton-polaritons, and shear polaritons) as well as their generation mechanism are discussed in detail. The natural merits of 2D HMs hold promise for practical quantum photonic applications such as valley quantum interference, mid-infrared polarizer, spontaneous emission enhancement, near-field thermal radiation, and a new generation of optoelectronic components, among others. These analyses' conclusion outlines existing issues and potential interesting directions for 2D natural HMs. These findings could spur more interest in anisotropic 2D atomic crystals in the future, as well as the quick generation of natural HMs for new applications. 	
"A machine learning approach to assessing the presence of substructure in
  quasar host galaxies using the Hyper Suprime-Cam Subaru Strategic Program"	http://arxiv.org/abs/2210.12264v2	2022-10-25T06:21:03Z	2022-10-21T21:40:32Z	  The conditions under which galactic nuclear regions become active are largely unknown, although it has been hypothesized that secular processes related to galaxy morphology could play a significant role. We investigate this question using optical i-band images of 3096 SDSS quasars and galaxies at 0.3<z<0.6 from the Hyper Suprime-Cam Subaru Strategic Program, which possess a unique combination of area, depth and resolution, allowing the use of residual images, after removal of the quasar and smooth galaxy model, to investigate internal structural features. We employ a variational auto-encoder which is a generative model that acts as a form of dimensionality reduction. We analyze the lower dimensional latent space in search of features which correlate with nuclear activity. We find that the latent space does separate images based on the presence of nuclear activity which appears to be associated with more pronounced components (i.e., arcs, rings and bars) as compared to a matched control sample of inactive galaxies. These results suggest the importance of secular processes, and possibly mergers (by their remnant features) in activating or sustaining black hole growth. Our study highlights the breadth of information available in ground-based imaging taken under optimal seeing conditions and having accurate characterization of the point spread function (PSF) thus demonstrating future science to come from the Rubin Observatory. 	
EDUKG: a Heterogeneous Sustainable K-12 Educational Knowledge Graph	http://arxiv.org/abs/2210.12228v1	2022-10-21T20:14:41Z	2022-10-21T20:14:41Z	  Web and artificial intelligence technologies, especially semantic web and knowledge graph (KG), have recently raised significant attention in educational scenarios. Nevertheless, subject-specific KGs for K-12 education still lack sufficiency and sustainability from knowledge and data perspectives. To tackle these issues, we propose EDUKG, a heterogeneous sustainable K-12 Educational Knowledge Graph. We first design an interdisciplinary and fine-grained ontology for uniformly modeling knowledge and resource in K-12 education, where we define 635 classes, 445 object properties, and 1314 datatype properties in total. Guided by this ontology, we propose a flexible methodology for interactively extracting factual knowledge from textbooks. Furthermore, we establish a general mechanism based on our proposed generalized entity linking system for EDUKG's sustainable maintenance, which can dynamically index numerous heterogeneous resources and data with knowledge topics in EDUKG. We further evaluate EDUKG to illustrate its sufficiency, richness, and variability. We publish EDUKG with more than 252 million entities and 3.86 billion triplets. Our code and data repository is now available at https://github.com/THU-KEG/EDUKG. 	
"Ethics for Digital Medicine: A Path for Ethical Emerging Medical IoT
  Design"	http://arxiv.org/abs/2210.12007v1	2022-10-21T14:56:42Z	2022-10-21T14:56:42Z	  The dawn of the digital medicine era, ushered in by increasingly powerful embedded systems and Internet of Things (IoT) computing devices, is creating new therapies and biomedical solutions that promise to positively transform our quality of life. However, the digital medicine revolution also creates unforeseen and complex ethical, regulatory, and societal issues. In this article, we reflect on the ethical challenges facing digital medicine. We discuss the perils of ethical oversights in medical devices, and the role of professional codes and regulatory oversight towards the ethical design, deployment, and operation of digital medicine devices that safely and effectively meet the needs of patients. We advocate for an ensemble approach of intensive education, programmable ethical behaviors, and ethical analysis frameworks, to prevent mishaps and sustain ethical innovation, design, and lifecycle management of emerging digital medicine devices. 	
"Core-collapse supernovae simulations with reduced nucleosynthesis
  networks"	http://arxiv.org/abs/2210.11848v1	2022-10-21T10:06:41Z	2022-10-21T10:06:41Z	  We present core-collapse supernovae simulations including nuclear reaction networks which impact explosion dynamics and nucleosynthesis. The different composition treatment can lead to changes in the neutrino heating in the vicinity of the shock, by modifying the amount of nucleons and thus the $\mathrm{\nu}$-opacity of the region. This reduces the ram pressure outside the shock and allows an easier expansion. The energy released by the nuclear reactions during collapse also slows down the accretion, and aids the shock expansion. In addition, nuclear energy generation in the post-shocked matter produces more energetic explosions, up to $20\,\%$. Nucleosynthesis is affected due to the different dynamic evolution of the explosion. Our results indicate that the energy generation from nuclear reactions helps to sustain late outflows from the vicinity of the proto-neutron star (PNS), synthesizing more neutron-rich species. Furthermore, we show that there are systematic discrepancies between the ejecta calculated with in-situ and ex-situ reaction networks. The mass fractions of some Ca, Ti, Cr, and Fe isotopes are consistently under-produced in post-processing calculations, leading to different nucleosynthesis paths. Therefore, large in-situ nuclear reaction networks are needed for a more accurate nucleosynthesis. 	
"Postural balance asymmetry and subsequent noncontact lower extremity
  musculoskeletal injuries among Tunisian soccer players with groin pain: A
  prospective case control study"	http://arxiv.org/abs/2210.11802v1	2022-10-21T08:29:04Z	2022-10-21T08:29:04Z	  Background: Recent studies reported postural balance disorders in patients and soccer players with groin pain (GP) compared to controls. Since postural balance asymmetry identified after an initial injury contributes for subsequent injuries, identification of this asymmetry in soccer players with GP may highlight the risk of sustaining subsequent noncontact lower extremity musculoskeletal injuries in these players. Therefore, the aims of this study were to (i) examine static and dynamic unipedal postural balance asymmetry in soccer players with GP compared to healthy ones, and (ii) quantify the risk of subsequent noncontact lower extremity injuries in these players. Research question: Do soccer players with GP exhibit higher static and dynamic unipedal postural balance asymmetry, and higher risk of sustaining subsequent injuries compared to controls. Methods: In this prospective case control study, 27 soccer players with non-time loss GP (GP group: GPG), and 27 healthy ones (control group: CG) were enrolled. Static and dynamic unipedal postural balance asymmetry were evaluated with a force platform using symmetry index (SI), and Y-balance test (Y-BT), respectively. Additionally, subsequent noncontact lower extremity musculoskeletal injuries were tracked for 10 months. Results: The GPG revealed higher (p < 0.01) SI in eyes closed condition, higher (p < 0.001) side-to-side asymmetry in anterior, posteromedial and posterolateral reach distances and in composite Y-BT score compared to CG. They showed lower (p < 0.001) composite score for injured limb and higher (p < 0.001) side-to-side asymmetry in posteromedial reach distance compared to the cutoff values of 89.6 % and 4 cm, respectively. Moreover, GPG exhibited higher odds (OR= 7.48; 95 % CI = 2.15, 26.00; p < 0.01) of sustaining subsequent injuries compared to CG. Significance: The Y-BT should be instituted into existing pre-participation physical examinations to screen for soccer players with non-time loss GP at an elevated risk of sustaining subsequent injuries. This could help coaches and clinicians make valid return to play decisions. 	
"Design a Sustainable Micro-mobility Future: Trends and Challenges in the
  United States and European Union Using Natural Language Processing Techniques"	http://arxiv.org/abs/2210.11714v2	2022-10-29T21:41:00Z	2022-10-21T03:47:59Z	  Micro-mobility is promising to contribute to sustainable cities in the future with its efficiency and low cost. To better design such a sustainable future, it is necessary to understand the trends and challenges. Thus, we examined people's opinions on micro-mobility in the US and the EU using Tweets. We used topic modeling based on advanced natural language processing techniques and categorized the data into seven topics: promotion and service, mobility, technical features, acceptance, recreation, infrastructure and regulations. Furthermore, using sentiment analysis, we investigated people's positive and negative attitudes towards specific aspects of these topics and compared the patterns of the trends and challenges in the US and the EU. We found that 1) promotion and service included the majority of Twitter discussions in the both regions, 2) the EU had more positive opinions than the US, 3) micro-mobility devices were more widely used for utilitarian mobility and recreational purposes in the EU than in the US, and 4) compared to the EU, people in the US had many more concerns related to infrastructure and regulation issues. These findings help us understand the trends and challenges and prioritize different aspects in micro-mobility to improve their safety and experience across the two areas for designing a more sustainable micro-mobility future. 	
X-Ray Luminous Supernovae: Threats to Terrestrial Biospheres	http://arxiv.org/abs/2210.11622v1	2022-10-20T22:33:56Z	2022-10-20T22:33:56Z	  The spectacular outbursts of energy associated with supernovae (SNe) have long motivated research into their potentially hazardous effects on Earth and analogous environments. Much of this research has focused primarily on the atmospheric damage associated with the prompt arrival of ionizing photons within days or months of the initial outburst, and the high-energy cosmic rays that arrive thousands of years after the explosion. In this study, we turn the focus to persistent X-ray emission, arising in certain SNe that have interactions with a dense circumstellar medium, and observed months and/or years after the initial outburst. The sustained high X-ray luminosity leads to large doses of ionizing radiation out to formidable distances. We provide an assessment of the threat posed by these X-ray luminous SNe by analyzing the collective X-ray observations from Chandra, Swift-XRT, XMM-Newton, NuSTAR, and others. We find that this threat is particularly acute for SNe showing evidence of strong circumstellar interaction, such as Type IIn explosions, which have significantly larger ranges of influence than previously expected, and lethal consequences up to $\sim$ 50 pc away. Furthermore, X-ray bright SNe could pose a substantial and distinct threat to terrestrial biospheres, and tighten the Galactic habitable zone. We urge follow-up X-ray observations of interacting SNe for months and years after the explosion to shed light on the physical nature of the emission and its full time evolution, and to clarify the danger that these events pose for life in our Galaxy and other star-forming regions. 	
"Nonthermal Atmospheric Plasma Reactors for Hydrogen Production from
  Low-Density Polyethylene"	http://arxiv.org/abs/2210.11367v1	2022-10-20T16:08:28Z	2022-10-20T16:08:28Z	  Hydrogen is largely produced via natural gas reforming or electrochemical water-splitting, leaving organic solid feedstocks under-utilized. Plasma technology powered by renewable electricity can lead to the sustainable upcycling of plastic waste and production of green hydrogen. In this work, low-temperature atmospheric pressure plasma reactors based on transferred arc (transarc) and gliding arc (glidarc) discharges are designed, built, and characterized to produce hydrogen from low-density polyethylene (LDPE) as a model plastic waste. Experimental results show that hydrogen production rate and efficiency increase monotonically with increasing voltage level in both reactors, with the maximum hydrogen production of 0.33 and 0.42 mmol/g LDPE for transarc and glidarc reactors, respectively. For the transarc reactor, smaller electrode-feedstock spacing favors greater hydrogen production, whereas, for the glidarc reactor, greater hydrogen production is obtained at intermediate flow rates. The hydrogen production from LDPE is comparable despite the markedly different modes of operation between the two reactors. 	
"Predicting electronic structures at any length scale with machine
  learning"	http://arxiv.org/abs/2210.11343v3	2022-12-08T19:29:51Z	2022-10-20T15:22:30Z	  The properties of electrons in matter are of fundamental importance. They give rise to virtually all molecular and material properties and determine the physics at play in objects ranging from semiconductor devices to the interior of giant gas planets. Modeling and simulation of such diverse applications rely primarily on density functional theory (DFT), which has become the principal method for predicting the electronic structure of matter. While DFT calculations have proven to be very useful to the point of being recognized with a Nobel prize in 1998, their computational scaling limits them to small systems. We have developed a machine learning framework for predicting the electronic structure on any length scale. It shows up to three orders of magnitude speedup on systems where DFT is tractable and, more importantly, enables predictions on scales where DFT calculations are infeasible. Our work demonstrates how machine learning circumvents a long-standing computational bottleneck and advances science to frontiers intractable with any current solutions. This unprecedented modeling capability opens up an inexhaustible range of applications in astrophysics, novel materials discovery, and energy solutions for a sustainable future. 	
"Fine-Grained Session Recommendations in E-commerce using Deep
  Reinforcement Learning"	http://arxiv.org/abs/2210.15451v1	2022-10-20T13:22:13Z	2022-10-20T13:22:13Z	  Sustaining users' interest and keeping them engaged in the platform is very important for the success of an e-commerce business. A session encompasses different activities of a user between logging into the platform and logging out or making a purchase. User activities in a session can be classified into two groups: Known Intent and Unknown intent. Known intent activity pertains to the session where the intent of a user to browse/purchase a specific product can be easily captured. Whereas in unknown intent activity, the intent of the user is not known. For example, consider the scenario where a user enters the session to casually browse the products over the platform, similar to the window shopping experience in the offline setting. While recommending similar products is essential in the former, accurately understanding the intent and recommending interesting products is essential in the latter setting in order to retain a user. In this work, we focus primarily on the unknown intent setting where our objective is to recommend a sequence of products to a user in a session to sustain their interest, keep them engaged and possibly drive them towards purchase. We formulate this problem in the framework of the Markov Decision Process (MDP), a popular mathematical framework for sequential decision making and solve it using Deep Reinforcement Learning (DRL) techniques. However, training the next product recommendation is difficult in the RL paradigm due to large variance in browse/purchase behavior of the users. Therefore, we break the problem down into predicting various product attributes, where a pattern/trend can be identified and exploited to build accurate models. We show that the DRL agent provides better performance compared to a greedy strategy. 	
Lower-than-expected flare temperatures for TRAPPIST-1	http://arxiv.org/abs/2210.11103v1	2022-10-20T08:55:47Z	2022-10-20T08:55:47Z	  Although high energetic radiation from flares is a potential threat to exoplanet atmospheres and may lead to surface sterilization, it might also provide the extra energy for low-mass stars needed to trigger and sustain prebiotic chemistry. We investigate two flares on TRAPPIST-1, an ultra-cool dwarf star that hosts seven exoplanets of which three lie within its habitable zone. The flares are detected in all four passbands of the MuSCAT2 allowing a determination of their temperatures and bolometric energies. We analyzed the light curves of the MuSCAT1 and MuSCAT2 instruments obtained between 2016 and 2021 in $g,r,i,z_\mathrm{s}$-filters. We conducted an automated flare search and visually confirmed possible flare events. We studied the temperature evolution, the global temperature, and the peak temperature of both flares. For the first time we infer effective black body temperatures of flares that occurred on TRAPPIST-1. The black body temperatures for the two TRAPPIST-1 flares derived from the SED are consistent with $T_\mathrm{SED} = 7940_{-390}^{+430}$K and $T_\mathrm{SED} = 6030_{-270}^{+300}$K. The flare black body temperatures at the peak are also calculated from the peak SED yielding $T_\mathrm{SEDp} = 13620_{-1220}^{1520}$K and $T_\mathrm{SEDp} = 8290_{-550}^{+660}$K. We show that for the ultra-cool M-dwarf TRAPPIST-1 the flare black body temperatures associated with the total continuum emission are lower and not consistent with the usually adopted assumption of 9000-10000 K. This could imply different and faster cooling mechanisms. Further multi-color observations are needed to investigate whether or not our observations are a general characteristic of ultra-cool M-dwarfs. This would have significant implications for the habitability of exoplanets around these stars because the UV surface flux is likely to be overestimated by the models with higher flare temperatures. 	
Towards Sustainable Self-supervised Learning	http://arxiv.org/abs/2210.11016v1	2022-10-20T04:49:56Z	2022-10-20T04:49:56Z	"  Although increasingly training-expensive, most self-supervised learning (SSL) models have repeatedly been trained from scratch but not fully utilized, since only a few SOTAs are employed for downstream tasks. In this work, we explore a sustainable SSL framework with two major challenges: i) learning a stronger new SSL model based on the existing pretrained SSL model, also called as ""base"" model, in a cost-friendly manner, ii) allowing the training of the new model to be compatible with various base models. We propose a Target-Enhanced Conditional (TEC) scheme which introduces two components to the existing mask-reconstruction based SSL. Firstly, we propose patch-relation enhanced targets which enhances the target given by base model and encourages the new model to learn semantic-relation knowledge from the base model by using incomplete inputs. This hardening and target-enhancing help the new model surpass the base model, since they enforce additional patch relation modeling to handle incomplete input. Secondly, we introduce a conditional adapter that adaptively adjusts new model prediction to align with the target of different base models. Extensive experimental results show that our TEC scheme can accelerate the learning speed, and also improve SOTA SSL base models, e.g., MAE and iBOT, taking an explorative step towards sustainable SSL. "	
A Referable NFT Scheme	http://arxiv.org/abs/2210.10910v2	2023-03-15T02:00:43Z	2022-10-19T22:19:41Z	  Existing NFTs confront restrictions of \textit{one-time incentive} and \textit{product isolation}. Creators cannot obtain benefits once having sold their NFT products due to the lack of relationships across different NFTs, which results in controversial possible profit sharing. This work proposes a referable NFT scheme to extend the incentive sustainability of NFTs. We construct the referable NFT (rNFT) network to increase exposure and enhance the referring relationship of inclusive items. We introduce the DAG topology to generate directed edges between each pair of NFTs with corresponding weights and labels for advanced usage. We accordingly implement and propose the scheme under Ethereum Improvement Proposal (EIP) standards, indexed in EIP-1155. Further, we provide the mathematical formation to analyze the utility for each rNFT participant. The discussion gives general guidance among multi-dimensional parameters. To our knowledge, this is the first study to build the referable NFT network, explicitly showing the virtual connections among NFTs. 	
"Forming Stars in a Dual AGN Host: Molecular and Ionized Gas in the
  Nearby, Luminous Infrared Merger, Mrk 266"	http://arxiv.org/abs/2210.10853v1	2022-10-19T19:28:51Z	2022-10-19T19:28:51Z	  We present star formation rates based on cold and ionized gas measurements of Mrk 266 (NGC 5256), a system composed of two colliding gas-rich galaxies, each hosting an active galactic nucleus. Using $^{12}$CO (1-0) observations with the Combined Array for Research in Millimeter-Wave Astronomy (CARMA), we find a total H$_2$ mass in the central region of $1.1\pm0.3\times10^{10}$ $M_\odot$ which leads to a possible future star formation rate of $25\pm10 M_\odot$ yr$^{-1}$. With the Fourier Transform Spectrograph (SITELLE) on the Canada-France-Hawaii Telescope, we measure an integrated H$\alpha$ luminosity and estimate a present-day star formation rate of $15\pm2 M_\odot$ yr$^{-1}$ in the core of the system (avoiding the two active nuclei). These results confirm that Mrk 266 is an intermediate stage merger with a relatively high recent star formation rate and enough molecular gas to sustain it for a few hundred million years. Inflowing gas associated with the merger may have triggered both the starburst episode and two AGN but the two galaxy components differ: the region around the SW nucleus appears to be more active than the NE nucleus, which seems relatively quiet. We speculate that this difference may originate in the properties of the interstellar medium in the two systems. 	
The Future of Consumer Edge-AI Computing	http://arxiv.org/abs/2210.10514v1	2022-10-19T12:41:47Z	2022-10-19T12:41:47Z	  Deep Learning has proliferated dramatically across consumer devices in less than a decade, but has been largely powered through the hardware acceleration within isolated devices. Nonetheless, clear signals exist that the next decade of consumer intelligence will require levels of resources, a mixing of modalities and a collaboration of devices that will demand a significant pivot beyond hardware alone. To accomplish this, we believe a new Edge-AI paradigm will be necessary for this transition to be possible in a sustainable manner, without trespassing user-privacy or hurting quality of experience. 	
Holistic Outpost Design for Lunar Lava Tubes	http://arxiv.org/abs/2211.17100v1	2022-10-19T09:30:02Z	2022-10-19T09:30:02Z	"  As the space industry continues its rapid development, humanity is poised to expand beyond Low Earth Orbit (LEO), seeking to establish permanent presence on the Moon and beyond. While space travel has traditionally been the domain of a small number of highly specialized professionals, a new era of human exploration, involving non-space actors and stakeholders, is now becoming a reality. In spite of this development, most space habitats are still designed for a narrow target group. This paper seeks to address this deficit by rethinking the established design approaches, typically limited to tackling engineering and challenges of human space exploration (such as radiation or hypogravity), by instead adopting an interdisciplinary ""big picture"" perspective encompassing social, psychological and cultural aspects of future space habitats. By elaborating and reflecting on our concept, this paper seeks to demonstrate the importance of a trans-disciplinary approach to designing thriving sustainable colonies beyond LEO. We demonstrate the potentially key role of design as mediator in advancing macro-strategies promoting thriving existence and sustainable growth. With this approach we tackle big-picture questions about humanity's future and prospects amongst the stars. "	
Machine Learning for a Sustainable Energy Future	http://arxiv.org/abs/2210.10391v1	2022-10-19T08:59:53Z	2022-10-19T08:59:53Z	  Transitioning from fossil fuels to renewable energy sources is a critical global challenge; it demands advances at the levels of materials, devices, and systems for the efficient harvesting, storage, conversion, and management of renewable energy. Researchers globally have begun incorporating machine learning (ML) techniques with the aim of accelerating these advances. ML technologies leverage statistical trends in data to build models for prediction of material properties, generation of candidate structures, optimization of processes, among other uses; as a result, they can be incorporated into discovery and development pipelines to accelerate progress. Here we review recent advances in ML-driven energy research, outline current and future challenges, and describe what is required moving forward to best lever ML techniques. To start, we give an overview of key ML concepts. We then introduce a set of key performance indicators to help compare the benefits of different ML-accelerated workflows for energy research. We discuss and evaluate the latest advances in applying ML to the development of energy harvesting (photovoltaics), storage (batteries), conversion (electrocatalysis), and management (smart grids). Finally, we offer an outlook of potential research areas in the energy field that stand to further benefit from the application of ML. 	
"Contribution to the initialization of linear non-commensurate
  fractional-order systems for the joint estimation of parameters and
  fractional differentiation orders"	http://arxiv.org/abs/2210.10016v1	2022-10-18T17:34:46Z	2022-10-18T17:34:46Z	"  It has been recognized that using time-varying initialization functions to solve the initial value problem of fractional-order systems (FOS) is both complex and essential in defining the dynamical behavior of the states of FOSs. In this paper, we investigate the use of the initialization functions for the purpose of estimating unknown parameters of linear non-commensurate FOSs. In particular, we propose a novel ""pre-initial"" process that describes the dynamic characteristic of FOSs before the initial state and consists of designing an appropriate time-varying initialization function that ensures accurate convergence of the estimates of the unknown parameters. To do so, we propose an estimation technique that consists of two steps: (i) to design of practical initialization function that is output-dependent and which is employed; (ii) to solve the joint estimation problem of both parameters and fractional differentiation orders (FDOs). A convergence proof has been presented. The performance of the proposed method is illustrated through different numerical examples. Potential applications of the algorithm to joint estimation of parameters and FDOs of the fractional arterial Windkessel and neurovascular models are also presented using both synthetic and real data. The added value of the proposed ""pre-initial"" process to solve the studied estimation problem is shown through different simulation tests that investigate the sensitivity of estimation results using different time-varying initialization functions. "	
"Vision Paper: Causal Inference for Interpretable and Robust Machine
  Learning in Mobility Analysis"	http://arxiv.org/abs/2210.10010v1	2022-10-18T17:28:58Z	2022-10-18T17:28:58Z	  Artificial intelligence (AI) is revolutionizing many areas of our lives, leading a new era of technological advancement. Particularly, the transportation sector would benefit from the progress in AI and advance the development of intelligent transportation systems. Building intelligent transportation systems requires an intricate combination of artificial intelligence and mobility analysis. The past few years have seen rapid development in transportation applications using advanced deep neural networks. However, such deep neural networks are difficult to interpret and lack robustness, which slows the deployment of these AI-powered algorithms in practice. To improve their usability, increasing research efforts have been devoted to developing interpretable and robust machine learning methods, among which the causal inference approach recently gained traction as it provides interpretable and actionable information. Moreover, most of these methods are developed for image or sequential data which do not satisfy specific requirements of mobility data analysis. This vision paper emphasizes research challenges in deep learning-based mobility analysis that require interpretability and robustness, summarizes recent developments in using causal inference for improving the interpretability and robustness of machine learning methods, and highlights opportunities in developing causally-enabled machine learning models tailored for mobility analysis. This research direction will make AI in the transportation sector more interpretable and reliable, thus contributing to safer, more efficient, and more sustainable future transportation systems. 	
Linear instability leading to elastic turbulence in plane Couette flow	http://arxiv.org/abs/2210.09961v1	2022-10-18T16:17:57Z	2022-10-18T16:17:57Z	  Elastic turbulence (ET) is a chaotic flow state observed in dilute polymer solutions in the absence of inertia, which was originally discovered experimentally in curved geometries. It has long been thought that triggering ET in parallel flows requires a finite amplitude perturbation to generate streamline curvature. We demonstrate here that self-sustaining ET can be initiated via a linear instability in inertialess planar Couette flow, a flow configuration which has previously been assumed to be stable to all initial perturbations. The new linear instability is associated with the existence of finite polymer diffusivity and exists for a wide range of realistic parameter settings and different choices of boundary conditions on the polymer conformation tensor. Numerical simulations show that the instability leads to a three-dimensional self-sustaining chaotic state, which we believe is the first reported numerical evidence of ET in a parallel flow. 	
"Simultaneous multitone microwave emission by DC-driven spintronic
  nano-element"	http://arxiv.org/abs/2210.09752v1	2022-10-18T11:05:32Z	2022-10-18T11:05:32Z	  Current-induced self-sustained magnetization oscillations in spin-torque nano-oscillators (STNOs) are promising candidates for ultra-agile microwave sources or detectors. While usually STNOs behave as a monochrome source, we report here clear bimodal simultaneous emission of incommensurate microwave oscillations, where the two tones correspond to two parametrically coupled eigenmodes with tunable splitting. The emission range is crucially sensitive to the change in hybridization of the eigenmodes of free and fixed layers, for instance, through a slight tilt of the applied magnetic field from the normal of the nano-pillar. Our experimental findings are supported both analytically and by micromagnetic simulations, which ascribe the process to four-magnon scattering between a pair of radially symmetric magnon modes and a pair of magnon modes with opposite azimuthal index. Our findings open up new possibilities for cognitive telecommunications and neuromorphic systems that use frequency multiplexing to improve communication performance. 	
"Relationships between patenting trends and research activity for green
  energy technologies"	http://arxiv.org/abs/2210.09611v1	2022-10-18T06:02:28Z	2022-10-18T06:02:28Z	  Green technology is viewed as a means of creating a sustainable society and a catalyst for sustainable development by the global community. It is responsible for both the potential reduction of production waste and the reduction of carbon footprint and CO2 emissions. However, alongside with the growing popularity of green technologies, there is an emerging skepticism about their contribution to solving environmental challenges. This article focuses on three areas of eco-innovation in green technology: renewable energy, hydrogen power, and decarbonization. Our main goal is to analyze the relationship between publication activity and the number of patented research results, thus shedding light on the real-world applicability of scientific outcomes. We used several bibliometric methods for analyzing global publication and patent activity, applied to the Scopus citation database and the European Patent Office's patent database. Our results show that the advancement of research in all three areas of eco-innovation does not automatically lead to the increase in the number of patents. We offer possible reasons for such dependency based on the observations of the worldwide tendencies in green innovation sphere. 	
"How to sustain the terrestrial biosphere in the Anthropocene? A
  thermodynamic Earth system perspective"	http://arxiv.org/abs/2210.09164v1	2022-10-17T15:06:45Z	2022-10-17T15:06:45Z	  Many aspects of anthropogenic global change, such as land cover change, biodiversity loss and the intensification of agricultural production, threaten the natural biosphere. These aspects seem somewhat disjunct and specific so that it is hard to obtain a bigger picture of what these changes imply and to distinguish beneficial from detrimental human impacts. Here I describe a holistic approach that provides such a bigger picture and use it to understand how the terrestrial biosphere can be sustained in the presence of increased human activities. This approach focuses on the free energy generated by photosynthesis, energy needed to sustain either the dissipative metabolic activity of ecosystems or human activities, with the generation rate being set by the physical constraints of the environment. We can then distinguish two kinds of human impacts on the biosphere: detrimental effects caused by enhanced human consumption of this free energy, and empowering effects that allow for more photosynthetic activity and therefore more dissipative activity of the biosphere. I use examples from the terrestrial biosphere to illustrate this view as well as global datasets to show how this can be estimated. I then discuss how certain aspects of human-made technology can act to enhance the free energy generation of the terrestrial biosphere, which can then facilitate sustaining the biosphere in times at which human activity increasingly shapes the functioning of the Earth system. 	
Voluntary participation boosts cooperation in repeated multiplayer games	http://arxiv.org/abs/2210.08969v1	2022-10-17T12:02:10Z	2022-10-17T12:02:10Z	  In repeated social interactions, humans often have the freedom to opt out and be absent due to unpleasant experiences or low benefits. Yet most studies on direct reciprocity neglect this option of opting out and implicitly assume that repeated interactions are compulsory. Here, we introduce a general framework of repeated optional multiplayer games, where individuals can freely opt out of each interaction and resume participation later. We find that optional participation significantly enhances the cooperation rate, promoting both the emergence and maintenance of cooperation. It acts as a catalyst for the emergence of cooperation by helping escape from the social trap of mutual defection and it sustains cooperation by posing more threats to intentional defectors. Furthermore, we analytically identify two novel classes of strategies that readily become equilibria and contribute to such promotive effects. Our work thus highlights that voluntary participation plays a crucial role in the evolution of cooperation in repeated interactions. 	
"Stochastic modeling of physical drag coefficient -- its impact on orbit
  prediction and space traffic management"	http://arxiv.org/abs/2210.08364v2	2022-10-20T13:57:14Z	2022-10-15T19:40:15Z	  Ambitious satellite constellation projects by commercial entities and the ease of access to space in recent times have led to a dramatic proliferation of low-Earth space traffic. It jeopardizes space safety and long-term sustainability, necessitating better space traffic management (STM). Correct modeling of uncertainties in force models and orbital states, among other things, is an essential part of STM. For objects in the low-Earth orbit (LEO) region, the uncertainty in the orbital dynamics mainly emanate from limited knowledge of the atmospheric drag-related parameters and variables. In this paper, which extends the work by Paul et al. [2021], we develop a feed-forward deep neural network model for the prediction of the satellite drag coefficient for the full range of satellite attitude (i.e., satellite pitch $\in$ ($-90^0$, $+90^0$) and satellite yaw $\in$ ($0^0$, $+360^0$)). The model simultaneously predicts the mean and the standard deviation and is well-calibrated. We use numerically simulated physical drag coefficient data for training our neural network. The numerical simulations are carried out using the test particle Monte Carlo method using the diffuse reflection with incomplete accommodation gas-surface interaction model. Modeling is carried out for the well-known CHAllenging Minisatellite Payload (CHAMP) satellite. Finally, we use the Monte Carlo approach to propagate CHAMP over a three-day period under various modeling scenarios to investigate the distribution of radial, in-track, and cross-track orbital errors caused by drag coefficient uncertainty. 	
"Atmospheric water vapor condensation on engineered interfaces: Busting
  the myths"	http://arxiv.org/abs/2210.08301v1	2022-10-15T13:58:42Z	2022-10-15T13:58:42Z	  Condensing atmospheric water vapor on surfaces is a sustainable approach to potentially address the potable water crisis. However, despite extensive research, a key question remains: what is the physical mechanism governing the condensation from humid air and how significantly does it differ from pure steam condensation? The answer may help define an optimal combination of the mode and mechanism of condensation as well as the surface wettability for best possible water harvesting efficacy. Here we show that this lack of clarity is due to the differences in heat transfer characteristics during condensation from pure vapor and humid air environments. Specifically, during condensation from humid air, the thermal resistance across the condensate is non-dominant and the energy transfer is controlled by vapor diffusion and condensate drainage. This leads to filmwise condensation on superhydrophilic surfaces, offering the highest water collection efficiency. To demonstrate this, we measured condensation rate on different sets of superhydrophilic and superhydrophobic surfaces in a wide degree of subcooling (10 - 26 C) and humidity-ratio differences (5 - 45 g/kg of dry air). The resulting condensation rate is enhanced by 57 - 333 % on the superhydrophilic surfaces as compared to the superhydrophobic ones. The findings of this study challenges the nearly century-old scientific ambiguity about the mechanism of vapor condensation from humid air. Our findings will lead to the design of efficient atmospheric water harvesting systems. 	
"High-resolution synthetic residential energy use profiles for the United
  States"	http://arxiv.org/abs/2210.08103v2	2022-12-15T06:55:22Z	2022-10-14T20:55:10Z	  Efficient energy consumption is crucial for achieving sustainable energy goals in the era of climate change and grid modernization. Thus, it is vital to understand how energy is consumed at finer resolutions such as household in order to plan demand-response events or analyze the impacts of weather, electricity prices, electric vehicles, solar, and occupancy schedules on energy consumption. However, availability and access to detailed energy-use data, which would enable detailed studies, has been rare. In this paper, we release a unique, large-scale, synthetic, residential energy-use dataset for the residential sector across the contiguous United States covering millions of households. The data comprise of hourly energy use profiles for synthetic households, disaggregated into Thermostatically Controlled Loads (TCL) and appliance use. The underlying framework is constructed using a bottom-up approach. Diverse open-source surveys and first principles models are used for end-use modeling. Extensive validation of the synthetic dataset has been conducted through comparisons with reported energy-use data. We present a detailed, open, high-resolution, residential energy-use dataset for the United States. 	
AR Training App for Energy Optimal Programming of Cobots	http://arxiv.org/abs/2210.08015v1	2022-10-14T15:10:43Z	2022-10-14T15:10:43Z	  Worldwide most factories aim for low-cost and fast production ignoring resources and energy consumption. But, high revenues have been accompanied by environmental degradation. The United Nations reacted to the ecological problem and proposed the Sustainable Development Goals, and one of them is Sustainable Production (Goal 12). In addition, the participation of lightweight robots, such as collaborative robots, in modern industrial production is increasing. The energy consumption of a single collaborative robot is not significant, however, the consumption of more and more cobots worldwide is representative. Consequently, our research focuses on strategies to reduce the energy consumption of lightweight robots aiming for sustainable production. Firstly, the energy consumption of the lightweight robot UR10e is assessed by a set of experiments. We analyzed the results of the experiments to describe the relationship between the energy consumption and the evaluation parameters, thus paving the way to optimization strategies. Next, we propose four strategies to reduce energy consumption: 1) optimal standby position, 2) optimal robot instruction, 3) optimal motion time, and 4) reduction of dissipative energy. The results show that cobots potentially reduce from 3\% up to 37\% of their energy consumption, depending on the optimization technique. To disseminate the results of our research, we developed an AR game in which the users learn how to energy-efficiently program cobots. 	
"Study of vibrational kinetics of CO2 and CO in CO2-O2 plasmas under
  non-equilibrium conditions"	http://arxiv.org/abs/2210.07778v1	2022-10-14T13:05:20Z	2022-10-14T13:05:20Z	  This work explores the effect of O2 addition on CO2 dissociation and on the vibrational kinetics of CO2 and CO under various non-equilibrium plasma conditions. A self-consistent model, previously validated for pure CO2 discharges, is further extended by adding the vibrational kinetics of CO, including electron impact excitation and de-excitation (e-V), vibration-to-translation relaxation (V-T) and vibration-to-vibration energy exchange (V-V) processes. The vibrational kinetics considered include levels up to v = 10 for CO and up to v1=2 and v2=v3=5, respectively for the symmetric stretch, bending and asymmetric stretch modes of CO2, and accounts for e-V, V-T in collisions between CO, CO2 and O2 molecules and O atoms and V-V processes involving all possible transfers involving CO2 and CO molecules. The kinetic scheme is validated by comparing the model predictions with recent experimental data measured in a DC glow discharge, operating at pressures in the range 0.4 - 5 Torr (53.33 - 666.66 Pa). The experimental results show a lower vibrational temperature of the different modes of CO2 and a decreased dissociation fraction of CO2 when O2 is added to the plasma but an increase of the vibrational temperature of CO. On the one hand, the simulations suggest that the former effect is the result of the stronger V-T energy-transfer collisions with O atoms which leads to an increase of the relaxation of the CO2 vibrational modes; On the other hand, the back reactions with O2 contribute to the lower CO2 dissociation fraction with increased O2 content in the mixture. 	
"The use of industrial molasses waste in the performant synthesis of
  fewlayer graphene (and its Au/Ag nanoparticles nanocomposites):
  Photocatalytic and supercapacitance applications"	http://arxiv.org/abs/2210.07613v1	2022-10-14T08:10:10Z	2022-10-14T08:10:10Z	  In view of clean environment, the industry needs to address multiple demands at different levels of production and processes via the sustainable approach including recycling or smart use of produced waste. On the other hand, a development and success of green energy requires the crucial materials synthesized via efficient, sustainable methodology. Herein, we present the green, simple, easily scalable, fast, and highly efficient synthesis of few-layer graphene (FLG) and its composites with Au and Ag nanoparticles using a waste. The FLG synthesis based on the exfoliation of graphite occurs in water in the presence of industrial co-product, molasses, which next shows also performant reductive properties during Ag and Au NPs formation. The decreased size of NPs deposited on FLG indicates the synergetic effect of molasses and FLG, exhibiting the add role of FLG/molasses as metal stabilizer species. The NPs/FLG composites 2 are efficient photocatalysts in degradation of organic contaminant, bisphenol (BisA), in the presence of peroxy-monosulfate (PMS) activator. The Au/FLG (PVDF) and Ag/FLG (PVDF) based electrodes reveal as well relatively high gravimetric capacitance, 205 Fg-1 and 729 Fg-1. The presented approach is much worthy to be further applied in the synthesis of other layered materials as well as other non-noble supported metallic systems. 	
"Spatiotemporal Classification with limited labels using Constrained
  Clustering for large datasets"	http://arxiv.org/abs/2210.07522v1	2022-10-14T05:05:22Z	2022-10-14T05:05:22Z	  Creating separable representations via representation learning and clustering is critical in analyzing large unstructured datasets with only a few labels. Separable representations can lead to supervised models with better classification capabilities and additionally aid in generating new labeled samples. Most unsupervised and semisupervised methods to analyze large datasets do not leverage the existing small amounts of labels to get better representations. In this paper, we propose a spatiotemporal clustering paradigm that uses spatial and temporal features combined with a constrained loss to produce separable representations. We show the working of this method on the newly published dataset ReaLSAT, a dataset of surface water dynamics for over 680,000 lakes across the world, making it an essential dataset in terms of ecology and sustainability. Using this large unlabelled dataset, we first show how a spatiotemporal representation is better compared to just spatial or temporal representation. We then show how we can learn even better representation using a constrained loss with few labels. We conclude by showing how our method, using few labels, can pick out new labeled samples from the unlabeled data, which can be used to augment supervised methods leading to better classification. 	
K-clique percolation in human structural connectome	http://arxiv.org/abs/2210.07218v1	2022-10-13T17:45:02Z	2022-10-13T17:45:02Z	  In this study, we discuss communities of densely connected structures and k-clique percolation phenomenon as related to the human structural connectome. We observe the existence of k-clique communities of high orders. The comparison of 426 connectomes shows that individual connections form a bulk of large k-clique communities and are critical for k-clique percolation phenomena. We have also shown the existence of a subnetwork of more frequent connections, considered as a core, which plays a key role in the formation of large-order cliques, connectivity within communities of such structures and their sustainability. The Erdos-Renyi model, for which the k-clique percolation phenomenon is well described, was shown to be inconsistent with modeling the formation of k-clique communities in the human structural connectome.for which the k-clique percolation phenomenon is well described, was shown to be inconsistent with modeling the formation of k-clique communities in the human structural connectome. 	
Sustainable Online Reinforcement Learning for Auto-bidding	http://arxiv.org/abs/2210.07006v1	2022-10-13T13:17:20Z	2022-10-13T13:17:20Z	  Recently, auto-bidding technique has become an essential tool to increase the revenue of advertisers. Facing the complex and ever-changing bidding environments in the real-world advertising system (RAS), state-of-the-art auto-bidding policies usually leverage reinforcement learning (RL) algorithms to generate real-time bids on behalf of the advertisers. Due to safety concerns, it was believed that the RL training process can only be carried out in an offline virtual advertising system (VAS) that is built based on the historical data generated in the RAS. In this paper, we argue that there exists significant gaps between the VAS and RAS, making the RL training process suffer from the problem of inconsistency between online and offline (IBOO). Firstly, we formally define the IBOO and systematically analyze its causes and influences. Then, to avoid the IBOO, we propose a sustainable online RL (SORL) framework that trains the auto-bidding policy by directly interacting with the RAS, instead of learning in the VAS. Specifically, based on our proof of the Lipschitz smooth property of the Q function, we design a safe and efficient online exploration (SER) policy for continuously collecting data from the RAS. Meanwhile, we derive the theoretical lower bound on the safety of the SER policy. We also develop a variance-suppressed conservative Q-learning (V-CQL) method to effectively and stably learn the auto-bidding policy with the collected data. Finally, extensive simulated and real-world experiments validate the superiority of our approach over the state-of-the-art auto-bidding algorithm. 	
"SDW-ASL: A Dynamic System to Generate Large Scale Dataset for Continuous
  American Sign Language"	http://arxiv.org/abs/2210.06791v1	2022-10-13T07:08:00Z	2022-10-13T07:08:00Z	  Despite tremendous progress in natural language processing using deep learning techniques in recent years, sign language production and comprehension has advanced very little. One critical barrier is the lack of largescale datasets available to the public due to the unbearable cost of labeled data generation. Efforts to provide public data for American Sign Language (ASL) comprehension have yielded two datasets, comprising more than thousand video clips. These datasets are large enough to enable a meaningful start to deep learning research on sign languages but are far too small to lead to any solution that can be practically deployed. So far, there is still no suitable dataset for ASL production. We proposed a system that can generate large scale ASL datasets for continuous ASL. It is suitable for general ASL processing and is particularly useful for ASL production. The continuous ASL dataset contains English labeled human articulations in condensed body pose data formats. To better serve the research community, we are releasing the first version of our ASL dataset, which contains 30k sentences, 416k words, a vocabulary of 18k words, in a total of 104 hours. This is the largest continuous sign language dataset published to date in terms of video duration. We also describe a system that can evolve and expand the dataset to incorporate better data processing techniques and more contents when available. It is our hope that the release of this ASL dataset and the sustainable dataset generation system to the public will propel better deep-learning research in ASL natural language processing. 	
"Feature Reconstruction Attacks and Countermeasures of DNN training in
  Vertical Federated Learning"	http://arxiv.org/abs/2210.06771v1	2022-10-13T06:23:47Z	2022-10-13T06:23:47Z	  Federated learning (FL) has increasingly been deployed, in its vertical form, among organizations to facilitate secure collaborative training over siloed data. In vertical FL (VFL), participants hold disjoint features of the same set of sample instances. Among them, only one has labels. This participant, known as the active party, initiates the training and interacts with the other participants, known as the passive parties. Despite the increasing adoption of VFL, it remains largely unknown if and how the active party can extract feature data from the passive party, especially when training deep neural network (DNN) models.   This paper makes the first attempt to study the feature security problem of DNN training in VFL. We consider a DNN model partitioned between active and passive parties, where the latter only holds a subset of the input layer and exhibits some categorical features of binary values. Using a reduction from the Exact Cover problem, we prove that reconstructing those binary features is NP-hard. Through analysis, we demonstrate that, unless the feature dimension is exceedingly large, it remains feasible, both theoretically and practically, to launch a reconstruction attack with an efficient search-based algorithm that prevails over current feature protection techniques. To address this problem, we develop a novel feature protection scheme against the reconstruction attack that effectively misleads the search to some pre-specified random values. With an extensive set of experiments, we show that our protection scheme sustains the feature reconstruction attack in various VFL applications at no expense of accuracy loss. 	
"Unveiling the formation of NGC 2915 with MUSE: A counter-rotating
  stellar disk embedded in a disordered gaseous environment"	http://arxiv.org/abs/2210.06485v2	2022-12-22T04:14:32Z	2022-10-12T18:00:00Z	  NGC 2915 is a unique nearby galaxy that is classified as an isolated blue compact dwarf based on its optical appearance but has an extremely extended H i gas disk with prominent Sd-type spiral arms. To unveil the starburst-triggering mystery of NGC 2915, we performed a comprehensive analysis of deep VLT/MUSE integral field spectroscopic observations that cover the star-forming region in the central kiloparsec of the galaxy. We find that episodes of bursty star formation have recurred in different locations throughout the central region, and the most recent one peaked around 50 Myr ago. The bursty star formation has significantly disturbed the kinematics of the ionized gas but not the neutral atomic gas, which implies that the two gas phases are largely spatially decoupled along the line of sight. No evidence for an active galactic nucleus is found based on the classical line-ratio diagnostic diagrams. The ionized gas metallicities have a positive radial gradient, which confirms the previous study based on several individual H ii regions and may be attributed to both the stellar feedback-driven outflows and metal-poor gas inflow. Evidence for metal-poor gas infall or inflow includes discoveries of high-speed collisions between gas clouds of different metallicities, localized gas metallicity drops and unusually small metallicity differences between gas and stars. The central stellar disk appears to be counter-rotating with respect to the extended H i disk, implying that the recent episodes of bursty star formation have been sustained by externally accreted gas. 	
"Trends in Energy Estimates for Computing in AI/Machine Learning
  Accelerators, Supercomputers, and Compute-Intensive Applications"	http://arxiv.org/abs/2210.17331v1	2022-10-12T16:14:33Z	2022-10-12T16:14:33Z	  We examine the computational energy requirements of different systems driven by the geometrical scaling law, and increasing use of Artificial Intelligence or Machine Learning (AI-ML) over the last decade. With more scientific and technology applications based on data-driven discovery, machine learning methods, especially deep neural networks, have become widely used. In order to enable such applications, both hardware accelerators and advanced AI-ML methods have led to the introduction of new architectures, system designs, algorithms, and software. Our analysis of energy trends indicates three important observations: 1) Energy efficiency due to geometrical scaling is slowing down; 2) The energy efficiency at the bit-level does not translate into efficiency at the instruction-level, or at the system-level for a variety of systems, especially for large-scale AI-ML accelerators or supercomputers; 3) At the application level, general-purpose AI-ML methods can be computationally energy intensive, off-setting the gains in energy from geometrical scaling and special purpose accelerators. Further, our analysis provides specific pointers for integrating energy efficiency with performance analysis for enabling high-performance and sustainable computing in the future. 	
Resource-aware Deep Learning for Wireless Fingerprinting Localization	http://arxiv.org/abs/2211.01759v1	2022-10-12T12:39:29Z	2022-10-12T12:39:29Z	  Location based services, already popular with end users, are now inevitably becoming part of new wireless infrastructures and emerging business processes. The increasingly popular Deep Learning (DL) artificial intelligence methods perform very well in wireless fingerprinting localization based on extensive indoor radio measurement data. However, with the increasing complexity these methods become computationally very intensive and energy hungry, both for their training and subsequent operation. Considering only mobile users, estimated to exceed 7.4 billion by the end of 2025, and assuming that the networks serving these users will need to perform only one localization per user per hour on average, the machine learning models used for the calculation would need to perform $65 \times 10^{12}$ predictions per year. Add to this equation tens of billions of other connected devices and applications that rely heavily on more frequent location updates, and it becomes apparent that localization will contribute significantly to carbon emissions unless more energy-efficient models are developed and used. In this Chapter, we discuss the latest results and trends in wireless localization and look at paths towards achieving more sustainable AI. We then elaborate on a methodology for computing DL model complexity, energy consumption and carbon footprint and show on a concrete example how to develop a more resource-aware model for fingerprinting. We finally compare relevant works in terms of complexity and training CO$_2$ footprint. 	
"Predicting the vascular adhesion of deformable drug carriers in narrow
  capillaries traversed by blood cell"	http://arxiv.org/abs/2210.06043v1	2022-10-12T09:29:47Z	2022-10-12T09:29:47Z	  In vascular targeted therapies, blood-borne carriers should realize sustained drug release from the luminal side towards the diseased tissue. In this context, such carriers are required to firmly adhere to the vessel walls for a sufficient period of time while resisting force perturbations induced by the blood flow and circulating cells. Here, a hybrid computational model, combining a Lattice Boltzmann (LBM) and Immersed Boundary Methods (IBM), is proposed for predicting the strength of adhesion of particles in narrow capillaries (7.5 $\mu \mathrm{m})$ traversed by blood cells. While flowing down the capillary, globular and biconcave deformable cells ( $7 \mu \mathrm{m}$ ) encounter $2 \mu \mathrm{m}$ discoidal particles, adhering to the vessel walls. Particles present aspect ratios ranging from $0.25$ to $1.0$ and a mechanical stiffness varying from rigid $(\mathrm{Ca}=0)$ to soft $\left(\mathrm{Ca}=10^{-3}\right)$. Cell-particle interactions are quantitatively predicted over time via three independent parameters: the cell membrane stretching $\delta p$; the cell-to-particle distance $r$, and the number of engaged ligand-receptor bonds $N_{\mathrm{L}}$. 	
"A novel approach to preventing SARS-CoV-2 transmission in classrooms: An
  OpenFOAM based CFD Study"	http://arxiv.org/abs/2211.06295v1	2022-10-12T09:06:38Z	2022-10-12T09:06:38Z	  The education sector has suffered a catastrophic setback due to ongoing COVID-pandemic, with classrooms being closed indefinitely. The current study aims to solve the existing dilemma by examining COVID transmission inside a classroom and providing long-term sustainable solutions. In this work, a standard 5m x 3m x 5m classroom is considered where 24 students are seated, accompanied by a teacher. A computational fluid dynamics simulation based on OpenFOAM is performed using a Eulerian-Lagrangian framework. Based on the stochastic dose response framework, we have evaluated the infection risk in the classroom for two distinct cases: (i) certain students are infected (ii) the teacher is infected. If the teacher is infected, the probability of infection could reach 100% for certain students. When certain students are infected, the maximum infection risk for a susceptible person reaches 30%. The commonly used cloth mask proves to be ineffective in providing protection against infection transmission reducing the maximum infection probability by approximately 26% only. Another commonly used solution in the form of shields installed on desks have also failed to provide adequate protection against infection reducing the infection risk only by 50%. Furthermore, the shields serves as a source of fomite mode of infection. Screens suspended from the ceiling, which entrap droplets, have been proposed as a novel solution that reduces the infection risk by 90% and 95% compared to the no screen scenario besides being completely devoid of fomite infection mode. As a result of the screens, the class-time can be extended by 55 minutes. 	
"Pathology Steered Stratification Network for Subtype Identification in
  Alzheimer's Disease"	http://arxiv.org/abs/2210.05880v1	2022-10-12T02:52:00Z	2022-10-12T02:52:00Z	  Alzheimer's disease (AD) is a heterogeneous, multifactorial neurodegenerative disorder characterized by beta-amyloid, pathologic tau, and neurodegeneration. The massive heterogeneity between neurobiological examinations and clinical assessment is the current biggest challenge in the early diagnosis of Alzheimer's disease, urging for a comprehensive stratification of the aging population that is defined by reliable neurobiological biomarkers and closely associated with clinical outcomes. However, existing statistical inference approaches in neuroimaging studies of AD subtype identification fail to take into account the neuropathological domain knowledge, which could lead to ill-posed results that are sometimes inconsistent with neurological principles. To fill this knowledge gap, we propose a novel pathology steered stratification network (PSSN) that integrates mainstream AD pathology with multimodal longitudinal neuroimaging data to categorize the aging population. By combining theory-based biological modeling and data-driven deep learning, this cross-disciplinary approach can not only generate long-term biomarker prediction consistent with the end-state of individuals but also stratifies subjects into fine-grained subtypes with distinct neurological underpinnings, where ag-ing brains within the same subtype share com-mon biological behaviors that emerge as similar trajectories of cognitive decline. Our stratification outperforms K-means and SuStaIn in both inter-cluster heterogeneity and intra-cluster homogeneity of various clinical scores. Importantly, we identify six subtypes spanning AD spectrum, where each subtype exhibits a distinctive biomarker pattern that is consistent with its clinical outcome. A disease evolutionary graph is further provided by quantifying subtype transition probabilities, which may assist pre-symptomatic diagnosis and guide therapeutic treatments. 	
Optimality and sustainability of delayed impulsive harvesting	http://arxiv.org/abs/2210.05878v1	2022-10-12T02:47:52Z	2022-10-12T02:47:52Z	  We consider a logistic differential equation subject to impulsive delayed harvesting, where the deduction information is a function of the population size at the time of one of the previous impulses. A close connection to the dynamics of high-order difference equations is used to conclude that while the inclusion of a delay in the impulsive condition does not impact the optimality of the yield, sustainability may be highly affected and is generally delay-dependent. Maximal and other types of yields are explored, and sharp stability tests are obtained for the model, as well as explicit sufficient conditions. It is also shown that persistence of the solution is not guaranteed for all positive initial conditions, and extinction in finite time is possible, as is illustrated in the simulations. 	
"Toward Sustainable Continual Learning: Detection and Knowledge
  Repurposing of Similar Tasks"	http://arxiv.org/abs/2210.05751v1	2022-10-11T19:35:30Z	2022-10-11T19:35:30Z	  Most existing works on continual learning (CL) focus on overcoming the catastrophic forgetting (CF) problem, with dynamic models and replay methods performing exceptionally well. However, since current works tend to assume exclusivity or dissimilarity among learning tasks, these methods require constantly accumulating task-specific knowledge in memory for each task. This results in the eventual prohibitive expansion of the knowledge repository if we consider learning from a long sequence of tasks. In this work, we introduce a paradigm where the continual learner gets a sequence of mixed similar and dissimilar tasks. We propose a new continual learning framework that uses a task similarity detection function that does not require additional learning, with which we analyze whether there is a specific task in the past that is similar to the current task. We can then reuse previous task knowledge to slow down parameter expansion, ensuring that the CL system expands the knowledge repository sublinearly to the number of learned tasks. Our experiments show that the proposed framework performs competitively on widely used computer vision benchmarks such as CIFAR10, CIFAR100, and EMNIST. 	
"Correlations and linewidth of the atomic beam continuous superradiant
  laser"	http://arxiv.org/abs/2210.05464v2	2022-11-17T14:31:36Z	2022-10-11T14:06:39Z	  We propose a minimalistic model to account for the main properties of a continuous superradiant laser, in which a beam of atoms crosses the mode of a high-finesse Fabry-Perot cavity, and collectively emits light into the cavity mode. We focus on the case of weak single atom - cavity cooperativity, and highlight the relevant regime where decoherence due to the finite transit time dominates over spontaneous emission. We propose an original approach where the dynamics of atoms entering and leaving the cavity is described by a Hamiltonian process. This allows deriving the main dynamical equations for the superradiant laser, without the need for a stochastic approach. We derive analytical conditions for a sustained emission and show that the ultimate linewidth is set by the fundamental quantum fluctuations of the collective atomic dipole. We calculate steady-state values of the two-body correlators and show that the continuous superradiant regime is tied to the growth of atom-atom correlations, although these correlations only have a small impact on the laser linewidth. 	
"Modeling of Energy Consumption and Streaming Video QoE using a
  Crowdsourcing Dataset"	http://arxiv.org/abs/2210.05444v1	2022-10-11T13:37:11Z	2022-10-11T13:37:11Z	  In the past decade, we have witnessed an enormous growth in the demand for online video services. Recent studies estimate that nowadays, more than 1% of the global greenhouse gas emissions can be attributed to the production and use of devices performing online video tasks. As such, research on the true power consumption of devices and their energy efficiency during video streaming is highly important for a sustainable use of this technology. At the same time, over-the-top providers strive to offer high-quality streaming experiences to satisfy user expectations. Here, energy consumption and QoE partly depend on the same system parameters. Hence, a joint view is needed for their evaluation. In this paper, we perform a first analysis of both end-user power efficiency and Quality of Experience of a video streaming service. We take a crowdsourced dataset comprising 447,000 streaming events from YouTube and estimate both the power consumption and perceived quality. The power consumption is modeled based on previous work which we extended towards predicting the power usage of different devices and codecs. The user-perceived QoE is estimated using a standardized model. Our results indicate that an intelligent choice of streaming parameters can optimize both the QoE and the power efficiency of the end user device. Further, the paper discusses limitations of the approach and identifies directions for future research. 	
"Intranight optical variability of low-mass Active Galactic Nuclei: A
  Pointer to blazar-like activity"	http://arxiv.org/abs/2210.05186v1	2022-10-11T06:46:11Z	2022-10-11T06:46:11Z	  This study aims to characterise, for the first time, intranight optical variability (INOV) of low-mass active galactic nuclei (LMAGN) which host a black hole (BH) of mass $M_{BH} \sim 10^6 M_{\odot}$, i.e., even less massive than the Galactic centre black hole Sgr A* and 2-3 orders of magnitude below the supermassive black holes (SMBH, $M_{BH}$ $\sim$ $10^8 - 10^9 M_{\odot}$) which are believed to power quasars. Thus, LMAGN are a crucial subclass of AGN filling the wide gap between SMBH and stellar-mass BHs of Galactic X-ray binaries. We have carried out a 36-session campaign of intranight optical monitoring of a well-defined, representative sample of 12 LMAGNs already detected in X-ray and radio bands. This set of LMAGN is found to exhibit INOV at a level statistically comparable to that observed for blazars (M$_{BH} \gtrsim$ 10$^{8-9}$ M$_{\odot}$) and for the $\gamma$-ray detected Narrow-line Seyfert1 galaxies (M$_{BH}\sim 10^7$ M$_{\odot}$) which, too, are believed to have relativistic jets. This indicates that the blazar-level activity can even be sustained by central engines with black holes near the upper limit for Intermediate Mass Black Holes ($M_{BH}$ $\sim$ $10^3 - 10^6 M_{\odot}$). 	
"Experimental characterization of photoemission from plasmonic nanogroove
  arrays"	http://arxiv.org/abs/2210.05056v2	2023-03-14T08:48:23Z	2022-10-11T00:02:39Z	  Metal photocathodes are an important source of high-brightness electron beams, ubiquitous in the operation of both large-scale accelerators and table-top microscopes. When the surface of a metal is nano-engineered with patterns on the order of the optical wavelength, it can lead to the excitation and confinement of surface plasmon polariton waves which drive nonlinear photoemission. In this work, we aim to evaluate gold plasmonic nanogrooves as a concept for producing bright electron beams for accelerators via nonlinear photoemission. We do this by first comparing their optical properties to numerical calculations from first principles to confirm our ability to fabricate these nanoscale structures. Their nonlinear photoemission yield is found by measuring emitted photocurrent as the intensity of their driving laser is varied. Finally, the mean transverse energy of this electron source is found using the solenoid scan technique. Our data demonstrate the ability of these cathodes to provide a tenfold enhancement in the efficiency of photoemission over flat metals driven with a linear process. We find that these cathodes are robust and capable of reaching sustained average currents over 100 nA at optical intensities larger than 2 GW/cm$^2$ with no degradation of performance. The emittance of the generated beam is found to be highly asymmetric, a fact we can explain with calculations involving the also asymmetric roughness of the patterned surface. These results demonstrate the use of nano-engineered surfaces as enhanced photocathodes, providing a robust, air-stable source of high average current electron beams with great potential for industrial and scientific applications. 	
"FX Resilience around the World: Fighting Volatile Cross-Border Capital
  Flows"	http://arxiv.org/abs/2210.04648v1	2022-10-10T12:49:21Z	2022-10-10T12:49:21Z	  We show that capital flow (CF) volatility exerts an adverse effect on exchange rate (FX) volatility, regardless of whether capital controls have been put in place. However, this effect can be significantly moderated by certain macroeconomic fundamentals that reflect trade openness, foreign assets holdings, monetary policy easing, fiscal sustainability, and financial development. Passing the threshold levels of these macroeconomic fundamentals, the adverse effect of CF volatility may be negligible. We further construct an intuitive FX resilience measure, which provides an assessment of the strength of a country's exchange rates. 	
Seller-buyer networks in NFT art are driven by preferential ties	http://arxiv.org/abs/2210.04339v2	2022-11-14T20:43:01Z	2022-10-09T20:09:41Z	  Non-Fungible Tokens (NFTs) have recently surged to mainstream attention by allowing the exchange of digital assets via blockchains. NFTs have also been adopted by artists to sell digital art. One of the promises of NFTs is broadening participation to the arts market, a traditionally closed and opaque system, to sustain a wider and more diverse set of artists and collectors. A key sign of this effect would be the disappearance or at least reduction in importance of seller-buyer preferential ties, whereby the success of an artist is strongly dependent on the patronage of a single collector. We investigate NFT art seller-buyer networks considering several galleries and a large set of nearly 40,000 sales for over 230M USD in total volume. We find that NFT art is a highly concentrated market driven by few successful sellers and even fewer systematic buyers. High concentration is present in both the number of sales and, even more strongly, in their priced volume. Furthermore, we show that, while a broader-participation market was present in the early phase of NFT art adoption, preferential ties have dominated during market growth, peak and recent decline. We consistently find that the top buyer accounts on average for over 80% of buys for a given seller. Similar trends apply to buyers and their top seller. We conclude that NFT art constitutes, at the present, a highly concentrated market driven by preferential seller-buyer ties. 	
"How do you go where? Improving next location prediction by learning
  travel mode information using transformers"	http://arxiv.org/abs/2210.04095v2	2022-10-27T20:55:31Z	2022-10-08T19:36:58Z	  Predicting the next visited location of an individual is a key problem in human mobility analysis, as it is required for the personalization and optimization of sustainable transport options. Here, we propose a transformer decoder-based neural network to predict the next location an individual will visit based on historical locations, time, and travel modes, which are behaviour dimensions often overlooked in previous work. In particular, the prediction of the next travel mode is designed as an auxiliary task to help guide the network's learning. For evaluation, we apply this approach to two large-scale and long-term GPS tracking datasets involving more than 600 individuals. Our experiments show that the proposed method significantly outperforms other state-of-the-art next location prediction methods by a large margin (8.05% and 5.60% relative increase in F1-score for the two datasets, respectively). We conduct an extensive ablation study that quantifies the influence of considering temporal features, travel mode information, and the auxiliary task on the prediction results. Moreover, we experimentally determine the performance upper bound when including the next mode prediction in our model. Finally, our analysis indicates that the performance of location prediction varies significantly with the chosen next travel mode by the individual. These results show potential for a more systematic consideration of additional dimensions of travel behaviour in human mobility prediction tasks. The source code of our model and experiments is available at https://github.com/mie-lab/location-mode-prediction. 	
"Good AI for Good: How AI Strategies of the Nordic Countries Address the
  Sustainable Development Goals"	http://arxiv.org/abs/2210.09010v1	2022-10-08T08:17:30Z	2022-10-08T08:17:30Z	  Developed and used responsibly Artificial Intelligence (AI) is a force for global sustainable development. Given this opportunity, we expect that the many of the existing guidelines and recommendations for trustworthy or responsible AI will provide explicit guidance on how AI can contribute to the achievement of United Nations' Sustainable Development Goals (SDGs). This would in particular be the case for the AI strategies of the Nordic countries, at least given their high ranking and overall political focus when it comes to the achievement of the SDGs. In this paper, we present an analysis of existing AI recommendations from 10 different countries or organisations based on topic modelling techniques to identify how much these strategy documents refer to the SDGs. The analysis shows no significant difference on how much these documents refer to SDGs. Moreover, the Nordic countries are not different from the others albeit their long-term commitment to SDGs. More importantly, references to \textit{gender equality} (SDG 5) and \textit{inequality} (SDG 10), as well as references to environmental impact of AI development and use, and in particular the consequences for life on earth, are notably missing from the guidelines. 	
Variability Analysis of Isolated Intersections Through Case Study	http://arxiv.org/abs/2210.03908v1	2022-10-08T04:13:35Z	2022-10-08T04:13:35Z	  Population and economic growth of urban areas have led to intensive use of private vehicles, thereby increasing traffic volume and congestion on roads. The traffic management in the city is a challenge for concerned authorities, and the signalized intersections are the primary interest of traffic management. Interpreting traffic patterns and current traffic signal operations can provide thorough insights to take appropriate actions. In this view, a comprehensive study is conducted at selected intersections from Tumakuru (tier-2 city), Karnataka, India. Data estimates traffic parameters such as saturation flow, composition, volume, and volume-to-capacity ratio. The statistical results currently confirm the stable traffic condition but do not ensure sustainability. The volume-to-capacity ratio is greater than 0.73 along three major arterial roads of study intersections, indicating congestion in the future as the traffic volume is increasing gradually, as per the Directorate of Urban Land Use and Transportation, Government of Karnataka. The statistical results obtained through the current study uphold the report. The empirical results showed 40% of green time wastage at one of the study intersections, which results in additional waiting delays, thereby increasing fuel consumption and emissions. The overall service level of the study intersections is of class C based on computed delay and volume-to-capacity ratio. The study suggests possible treatments for improving the service level at the intersection operations and sustaining the city's stable traffic condition. The study supports city traffic management authorities in identifying suitable treatment and implementing accordingly. 	
Quantum spin Hall phase in GeSn heterostructures on silicon	http://arxiv.org/abs/2210.02981v1	2022-10-06T15:08:25Z	2022-10-06T15:08:25Z	  Quantum phases of solid-state electron systems look poised to sustain exotic phenomena and a very rich spin physics. We propose a practical silicon-based architecture that spontaneously sustains topological properties, while being fully compatible with the high-volume manufacturing capabilities of modern microelectronic foundries. Here we show how Ge1-xSnx alloys, an emerging group IV semiconductor, can be engineered into junctions that demonstrate a broken gap alignment. We predict such basic building block undergo a quantum phase transition that can elegantly accommodate the existence of gate-controlled chiral edge states directly on Si. This will enable tantalizing prospects for designing integrated circuits hosting quantum spin hall insulators and advanced topological functionalities. 	
Comet nuclei composition and evolution	http://arxiv.org/abs/2210.02741v1	2022-10-06T08:11:01Z	2022-10-06T08:11:01Z	  Thanks to Rosetta orbiter's and Philae lander's data our knowledge of cometary nuclei composition has experienced a great advancement. The properties of 67P/CG nucleus are discussed and compared with other comets explored in the past by space missions. Cometary nuclei are made by a collection of ices, minerals, organic matter, and salts resulting in very dark and red-colored surfaces. When far from the Sun, exposed water and carbon dioxide ices are found only in few locations of 67P/CG where the exposure of pristine subsurface layers or the recondensation of volatile species driven by the solar heating and local terrain morphology can sustain their temporary presence on the surface. The nucleus surface appears covered by a dust layer of variable thickness. Dust grains appear mostly dehydrated and are made by an assemblage of minerals, organic matter, and salts. Spectral analysis shows that the mineral phase is dominated by silicates, fine-grained opaques and ammoniated salts. Aliphatic and aromatic groups, with the presence of the strong hydroxyl group, are identified within the organic matter. The surface composition of cometary nuclei evolves with heliocentric distance and seasonal cycling: approaching perihelion the increase of the solar flux boosts the activity through the sublimation of volatiles which in turn causes the erosion of surface layers, the exposure of ices, the activity in cliffs and pits, the collapse of overhangs and walls, and the mobilization and redistribution of dust. The evolution of color, composition, and texture changes occurring across different morphological regions of the nucleus are correlated with these processes. In this chapter we discuss 67P/CG nucleus composition and evolutionary processes as observed by Rosetta mission in the context of other comets previously explored by space missions or observed from Earth. 	
"Green transition as a driver of technical efficiency. An empirical study
  on Italian airports"	http://arxiv.org/abs/2210.02736v1	2022-10-06T08:01:38Z	2022-10-06T08:01:38Z	  The transition to more environmentally sustainable production processes and managerial practices is an increasingly important topic. Many industries need to undergo radical change to meet environmental sustainability requirements; the tourism industry is no exception. In this respect, a particular aspect that needs further attention is the relationship between airport performances and investments in environmental sustainability policies. This work represents a first attempt to provide empirical evidences about this relationship. Through the application of a non-parametrical method, we first assess the efficiency of the Italian airports industry. Secondly, we investigated the relationship between airports performance and management commitment toward the ecological transition using a Tobit regression model. The results show that airports' adherence to formal multi-year ecological transition programs has a positive and consistent impact on their performance. 	
"Dwarf galaxy archaeology from chemical abundances and star formation
  histories"	http://arxiv.org/abs/2210.01816v1	2022-10-04T18:00:04Z	2022-10-04T18:00:04Z	  We model the stellar abundances and ages of two disrupted dwarf galaxies in the Milky Way stellar halo: Gaia-Sausage Enceladus (GSE) and Wukong/LMS-1. Using a statistically robust likelihood function, we fit one-zone models of galactic chemical evolution with exponential infall histories to both systems, deriving e-folding timescales of $\tau_\text{in} = 1.01 \pm 0.13$ Gyr for GSE and $\tau_\text{in} = 3.08^{+3.19}_{-1.16}$ Gyr for Wukong/LMS-1. GSE formed stars for $\tau_\text{tot} = 5.40^{+0.32}_{-0.31}$ Gyr, sustaining star formation for $\sim$$1.5 - 2$ Gyr after its first infall into the Milky Way $\sim$10 Gyr ago. Our fit suggests that star formation lasted for $\tau_\text{tot} = 3.36^{+0.55}_{-0.47}$ Gyr in Wukong/LMS-1, though our sample does not contain any age measurements. The differences in evolutionary parameters between the two are qualitatively consistent with trends with stellar mass $M_\star$ predicted by simulations and semi-analytic models of galaxy formation. Our fitting method is based only on poisson sampling from an evolutionary track and requires no binning of the data. We demonstrate its accuracy by testing against mock data, showing that it accurately recovers the input model across a broad range of sample sizes ($20 \leq N \leq 2000$) and measurement uncertainties ($0.01 \leq \sigma_\text{[$\alpha$/Fe]}, \sigma_\text{[Fe/H]} \leq 0.5$; $0.02 \leq \sigma_{\log_{10}(\text{age})} \leq 1$). Our inferred values of the outflow mass-loading factor reasonably match $\eta \propto M_\star^{-1/3}$ as predicted by galactic wind models. Due to the generic nature of our derivation, this likelihood function should be applicable to one-zone models of any parametrization and easily extensible to other astrophysical models which predict tracks in some observed space. 	
"Energy Consumption of Neural Networks on NVIDIA Edge Boards: an
  Empirical Model"	http://arxiv.org/abs/2210.01625v1	2022-10-04T14:12:59Z	2022-10-04T14:12:59Z	  Recently, there has been a trend of shifting the execution of deep learning inference tasks toward the edge of the network, closer to the user, to reduce latency and preserve data privacy. At the same time, growing interest is being devoted to the energetic sustainability of machine learning. At the intersection of these trends, we hence find the energetic characterization of machine learning at the edge, which is attracting increasing attention. Unfortunately, calculating the energy consumption of a given neural network during inference is complicated by the heterogeneity of the possible underlying hardware implementation. In this work, we hence aim at profiling the energetic consumption of inference tasks for some modern edge nodes and deriving simple but realistic models. To this end, we performed a large number of experiments to collect the energy consumption of convolutional and fully connected layers on two well-known edge boards by NVIDIA, namely Jetson TX2 and Xavier. From the measurements, we have then distilled a simple, practical model that can provide an estimate of the energy consumption of a certain inference task on the considered boards. We believe that this model can be used in many contexts as, for instance, to guide the search for efficient architectures in Neural Architecture Search, as a heuristic in Neural Network pruning, or to find energy-efficient offloading strategies in a Split computing context, or simply to evaluate the energetic performance of Deep Neural Network architectures. 	
"Location-aware green energy availability forecasting for multiple time
  frames in smart buildings: The case of Estonia"	http://arxiv.org/abs/2210.01619v1	2022-10-04T14:02:43Z	2022-10-04T14:02:43Z	  Renewable Energies (RE) have gained more attention in recent years since they offer clean and sustainable energy. One of the major sustainable development goals (SDG-7) set by the United Nations (UN) is to achieve affordable and clean energy for everyone. Among the world's all renewable resources, solar energy is considered as the most abundant and can certainly fulfill the target of SDGs. Solar energy is converted into electrical energy through Photovoltaic (PV) panels with no greenhouse gas emissions. However, power generated by PV panels is highly dependent on solar radiation received at a particular location over a given time period. Therefore, it is challenging to forecast the amount of PV output power. Predicting the output power of PV systems is essential since several public or private institutes generate such green energy, and need to maintain the balance between demand and supply. This research aims to forecast PV system output power based on weather and derived features using different machine learning models. The objective is to obtain the best-fitting model to precisely predict output power by inspecting the data. Moreover, different performance metrics are used to compare and evaluate the accuracy under different machine learning models such as random forest, XGBoost, KNN, etc. 	
"Opacity of relativistically underdense plasmas for extremely intense
  laser pulses"	http://arxiv.org/abs/2210.01606v1	2022-10-04T13:33:26Z	2022-10-04T13:33:26Z	  It is generally believed that relativistically underdense plasma is transparent for intense laser radiation. However, particle-in-cell simulations reveal abnormal laser field absorption above the intensity threshold about~$3 \times 10^{24}~\mathrm{W}\,\mathrm{cm}^{-2}$ for the wavelength of $1~\mu \mathrm{m}$. Above the threshold, the further increase of the laser intensity doesn't lead to the increase of the propagation distance. The simulations take into account emission of hard photons and subsequent pair photoproduction in the laser field. These effects lead to onset of a self-sustained electromagnetic cascade and to formation of dense electron-positron ($e^+e^-$) plasma right inside the laser field. The plasma absorbs the field efficiently, that ensures the plasma opacity. The role of a weak longitudinal electron-ion electric field in the cascade growth is discussed. 	
What is the Price of a Skill? The Value of Complementarity	http://arxiv.org/abs/2210.01535v2	2022-11-30T16:57:17Z	2022-10-04T11:29:29Z	  The global workforce is urged to constantly reskill, as technological change favours particular new skills while making others redundant. But which skills are most marketable and have a sustainable demand? We propose a model for skill evaluation that attaches a market value to a set of 962 digital skills based on near real-time online labour market data. We demonstrate that the value of a specific skill is strongly determined by complementarity - that is with how many other high-value skills a competency can be combined. Most importantly, we show that the value of a skill is relative, as it depends on the capacities it is combined with. For most skills, their value is highest when used in combination with skills of the same type. We illustrate our model with a set of AI skills that are particularly valuable because of their strong complementarities, and also because of the significant increase in their demand in recent years. Finally, we contrast our skill premia with automation probabilities and find that some skills are very susceptible to automation despite their high market value. The model and metrics of our work can inform the policy and practice of digital re-skilling to reduce labour market mismatches. In cooperation with online platforms and education providers, researchers and policy makers should consider using this blueprint to provide learners with personalised skill recommendations that complement their existing capacities and fit their occupational background. 	
CaiRL: A High-Performance Reinforcement Learning Environment Toolkit	http://arxiv.org/abs/2210.01235v1	2022-10-03T21:24:04Z	2022-10-03T21:24:04Z	  This paper addresses the dire need for a platform that efficiently provides a framework for running reinforcement learning (RL) experiments. We propose the CaiRL Environment Toolkit as an efficient, compatible, and more sustainable alternative for training learning agents and propose methods to develop more efficient environment simulations.   There is an increasing focus on developing sustainable artificial intelligence. However, little effort has been made to improve the efficiency of running environment simulations. The most popular development toolkit for reinforcement learning, OpenAI Gym, is built using Python, a powerful but slow programming language. We propose a toolkit written in C++ with the same flexibility level but works orders of magnitude faster to make up for Python's inefficiency. This would drastically cut climate emissions.   CaiRL also presents the first reinforcement learning toolkit with a built-in JVM and Flash support for running legacy flash games for reinforcement learning research. We demonstrate the effectiveness of CaiRL in the classic control benchmark, comparing the execution speed to OpenAI Gym. Furthermore, we illustrate that CaiRL can act as a drop-in replacement for OpenAI Gym to leverage significantly faster training speeds because of the reduced environment computation time. 	
"Sustained FU Orionis-type outbursts from colliding discs in stellar
  flybys"	http://arxiv.org/abs/2210.01143v1	2022-10-03T18:00:07Z	2022-10-03T18:00:07Z	  We perform 3D hydrodynamics simulations of disc-disc stellar flybys with on-the-fly Monte Carlo radiative transfer. We show that pre-existing circumstellar discs around both stars result in fast rising ($\sim$yrs) outbursts lasting 2-5 times longer than for a star-disc flyby. The perturber always goes into outburst ($\dot{M}>10^{-5}~{\rm M_{\odot}~ yr^{-1}}$). Whereas we find that the primary goes into a decades long outburst only when the flyby is retrograde to the circumprimary disc rotation. High accretion rates during the outburst are triggered by angular momentum cancellation in misaligned material generated by the encounter. A large fraction of accreted material is alien. 	
Minimal entropy production in anisotropic temperature fields	http://arxiv.org/abs/2210.01062v1	2022-10-03T16:20:29Z	2022-10-03T16:20:29Z	  Anisotropy of temperature fields, chemical potentials and ion concentration gradients provide the fuel that feeds dynamical processes that sustain life. Dynamical flows in respective environments incur losses manifested as entropy production. In this work we consider a rudimentary model of an overdamped stochastic thermodynamic system in an anisotropic temperature heat bath, and analyze the problem to minimize entropy production while driving the system between thermodynamic states in finite time. It is noted that entropy production in a fully isotropic temperature field, can be expressed as the Wasserstein-2 length of the path traversed by the thermodynamic state of the system. In the presence of an anisotropic temperature field, the mechanism of entropy production is substantially more complicated as, besides dissipation, it entails seepage of energy between the ambient heat sources by way of the system dynamics. We show that, in this case, the entropy production can be expressed as the solution of a suitably constrained and generalized Optimal Mass Transport (OMT) problem. In contrast to the situation in standard OMT, entropy production may not be identically zero, even when the thermodynamic state remains unchanged. Physically, this is due to the fact that maintaining a Non-Equilibrium Steady State (NESS), incurs an intrinsic entropic cost. As already noted, NESSs are the hallmark of life and living systems by necessity operate away from equilibrium. Thus our problem of minimizing entropy production appears of central importance in understanding biological processes, such as molecular motors and motor proteins, and on how such processes may have evolved to optimize for available usage of resources. 	
"Towards sustainability assessment of artificial intelligence in artistic
  practices"	http://arxiv.org/abs/2210.08981v1	2022-10-03T15:02:22Z	2022-10-03T15:02:22Z	  An increasing number of artists use Ai in their creative practices (Creative-Ai) and their works have by now become visible at prominent art venues. The research community has, on the other hand, recognized that there are sustainability concerns of using Ai technologies related to, for instance, energy consumption and the increasing size and complexity of models. These two conflicting trajectories constitute the starting point of our research. Here, we discuss insights from our currently on-going fieldwork research and outline considerations for drawing various limitations in sustainability assessment studies of Ai art. We provide ground for further, more specific sustainability assessments in the domain, as well as knowledge on the state of sustainability assessments in this domain. 	
Green Learning: Introduction, Examples and Outlook	http://arxiv.org/abs/2210.00965v1	2022-10-03T14:30:30Z	2022-10-03T14:30:30Z	  Rapid advances in artificial intelligence (AI) in the last decade have largely been built upon the wide applications of deep learning (DL). However, the high carbon footprint yielded by larger and larger DL networks becomes a concern for sustainability. Furthermore, DL decision mechanism is somewhat obsecure and can only be verified by test data. Green learning (GL) has been proposed as an alternative paradigm to address these concerns. GL is characterized by low carbon footprints, small model sizes, low computational complexity, and logical transparency. It offers energy-effective solutions in cloud centers as well as mobile/edge devices. GL also provides a clear and logical decision-making process to gain people's trust. Several statistical tools have been developed to achieve this goal in recent years. They include subspace approximation, unsupervised and supervised representation learning, supervised discriminant feature selection, and feature space partitioning. We have seen a few successful GL examples with performance comparable with state-of-the-art DL solutions. This paper offers an introduction to GL, its demonstrated applications, and future outlook. 	
"Multi-Wavelength Photonic Neuromorphic Computing for Intra and
  Inter-Channel Distortion Compensations in WDM Optical Communication Systems"	http://arxiv.org/abs/2210.00930v1	2022-10-03T13:45:02Z	2022-10-03T13:45:02Z	  DSP (digital signal processing) has been widely applied in optical communication systems to mitigate signal distortions and has become one of the key technologies that have sustained data traffic growth over the past decade. However, the strict energy budget of application-specific integrated circuit-based DSP chips has prevented the deployment of some powerful but computationally costly DSP algorithms. As a result, fiber nonlinearity-induced signal distortions impede fiber communications systems, especially in wavelength-division multiplexed (WDM) transmission systems. To solve these challenges, photonics hardware (i.e., photonic neural networks) promises to break performance limitations in electronics and gain advantages in bandwidth, latency, and power consumption in solving intellectual tasks that are unreachable by conventional digital electronic platforms. This work proposes a photonic recurrent neural network (RNN) capable of simultaneously resolving dispersion and both intra and inter-channel fiber nonlinearities in multiple WDM channels in the photonic domain, for the first time to our best knowledge. Furthermore, our photonic RNN can directly process optical WDM signals in the photonic domain, avoiding prohibitive energy consumption and speed overhead in analog to digital converters (ADC). We demonstrate in simulation that our photonic RNN can process multiple WDM channels simultaneously and achieve a reduced bit error rate compared to typical DSP algorithms for all WDM channels in a pulse-amplitude modulation 4-level (PAM4) transmission system, thanks to its unique capability to address inter-channel fiber nonlinearities. In addition to signal quality performance, the proposed system also promises to significantly reduce the power consumption and the latency compared to the state-of-the-art DSP chips, according to our power and latency analysis. 	
"A Dynamic Model for Bus Arrival Time Estimation based on Spatial
  Patterns using Machine Learning"	http://arxiv.org/abs/2210.00733v1	2022-10-03T06:35:03Z	2022-10-03T06:35:03Z	  The notion of smart cities is being adapted globally to provide a better quality of living. A smart city's smart mobility component focuses on providing smooth and safe commuting for its residents and promotes eco-friendly and sustainable alternatives such as public transit (bus). Among several smart applications, a system that provides up-to-the-minute information like bus arrival, travel duration, schedule, etc., improves the reliability of public transit services. Still, this application needs live information on traffic flow, accidents, events, and the location of the buses. Most cities lack the infrastructure to provide these data. In this context, a bus arrival prediction model is proposed for forecasting the arrival time using limited data sets. The location data of public transit buses and spatial characteristics are used for the study. One of the routes of Tumakuru city service, Tumakuru, India, is selected and divided into two spatial patterns: sections with intersections and sections without intersections. The machine learning model XGBoost is modeled for both spatial patterns individually. A model to dynamically predict bus arrival time is developed using the preceding trip information and the machine learning model to estimate the arrival time at a downstream bus stop. The performance of models is compared based on the R-squared values of the predictions made, and the proposed model established superior results. It is suggested to predict bus arrival in the study area. The proposed model can also be extended to other similar cities with limited traffic-related infrastructure. 	
Decentralized nation, solving the web identity crisis	http://arxiv.org/abs/2210.08978v1	2022-10-03T01:02:24Z	2022-10-03T01:02:24Z	  The web of today whether you prefer to call it web 2.0, web 3.0, web 5.0 or even the metaverse is at a critical stage of evolution and challenge, largely centered around its crisis of identity. Like teenagers who cannot assess properly their reason for being and do not seem ready to take responsibility for their actions, we are constantly blaming the very system we are trying to get away from. To truly realize the benefits from innovation and technology, this crisis has to be resolved, not just through tactical solutions but through developments that enhance the sustainability of the web and its benefits. Significant strides are being made in the evolution of digital services enabled by technology, regulation, and the sheer pace of societal change. The journey to the decentralized web is mirroring the convergence of the physical and digital worlds across all economies and is increasingly embracing the digital native world. Technology has provided the foundational platform for individuals and entities to create and manage wealth, potentially without the need for big institutions. Ironically, despite all of the advancements, we are still facing an unprecedented and increasing wealth gap. Clearly, the system is broken, not just around the edges but at the very core of the democratic underpinning of our society. In this whitepaper, we propose how artificial intelligence on blockchain can be used to generate a new class of identity through direct human computer interaction. We demonstrate how this, combined with new perspectives for sustaining community and governance embedded within the use of blockchain technology, will underpin a sustainable solution to protect identity, authorship and privacy at the same time while contributing to restore trust amongst members of a future decentralized nation and hence contribute to solving the web most significant identity crisis. 	
Energy-Rate-Quality Tradeoffs of State-of-the-Art Video Codecs	http://arxiv.org/abs/2210.00618v1	2022-10-02T20:39:25Z	2022-10-02T20:39:25Z	  The adoption of video conferencing and video communication services, accelerated by COVID-19, has driven a rapid increase in video data traffic. The demand for higher resolutions and quality, the need for immersive video formats, and the newest, more complex video codecs increase the energy consumption in data centers and display devices. In this paper, we explore and compare the energy consumption across optimized state-of-the-art video codecs, SVT-AV1, VVenC/VVdeC, VP9, and x.265. Furthermore, we align the energy usage with various objective quality metrics and the compression performance for a set of video sequences across different resolutions. The results indicate that from the tested codecs and configurations, SVT-AV1 provides the best tradeoff between energy consumption and quality. The reported results aim to serve as a guide towards sustainable video streaming while not compromising the quality of experience of the end user. 	
"Sustained oscillations in multi-topic belief dynamics over signed
  networks"	http://arxiv.org/abs/2210.00353v1	2022-10-01T20:00:49Z	2022-10-01T20:00:49Z	  We study the dynamics of belief formation on multiple interconnected topics in networks of agents with a shared belief system. We establish sufficient conditions and necessary conditions under which sustained oscillations of beliefs arise on the network in a Hopf bifurcation and characterize the role of the communication graph and the belief system graph in shaping the relative phase and amplitude patterns of the oscillations. 	
"Equity Scores for Public Transit Lines from Open-Data and Accessibility
  Measures"	http://arxiv.org/abs/2210.00128v1	2022-09-30T22:58:11Z	2022-09-30T22:58:11Z	"  Current transit suffers from an evident inequity: the level of service of transit in suburbs is much less satisfying than in city centers. As a consequence, private cars are still the dominant transportation mode for suburban people, which results in congestion and pollution. To achieve sustainability goals and reduce car-dependency, transit should be (re)designed around equity. To this aim, it is necessary to (i) quantify the ""level of equity"" of the transit system and (ii) provide an indicator that scores the transit lines that contribute the most to keep transit equitable. This indicator could suggest on which lines the transit operator must invest to increase the service level (frequency or coverage) in order to reduce inequity in the system.   To the best of our knowledge, this paper is the first to tackle (ii). To this aim, we propose efficient scoring methods that rely solely on open data, which allows us to perform the analysis on multiple cities (7 in this paper). Our method can be used to guide large-scale iterative optimization algorithms to improve accessibility equity. "	
"Digital Twin and Artificial Intelligence Incorporated With Surrogate
  Modeling for Hybrid and Sustainable Energy Systems"	http://arxiv.org/abs/2210.00073v1	2022-09-30T20:14:16Z	2022-09-30T20:14:16Z	  Surrogate modeling has brought about a revolution in computation in the branches of science and engineering. Backed by Artificial Intelligence, a surrogate model can present highly accurate results with a significant reduction in computation time than computer simulation of actual models. Surrogate modeling techniques have found their use in numerous branches of science and engineering, energy system modeling being one of them. Since the idea of hybrid and sustainable energy systems is spreading rapidly in the modern world for the paradigm of the smart energy shift, researchers are exploring the future application of artificial intelligence-based surrogate modeling in analyzing and optimizing hybrid energy systems. One of the promising technologies for assessing applicability for the energy system is the digital twin, which can leverage surrogate modeling. This work presents a comprehensive framework/review on Artificial Intelligence-driven surrogate modeling and its applications with a focus on the digital twin framework and energy systems. The role of machine learning and artificial intelligence in constructing an effective surrogate model is explained. After that, different surrogate models developed for different sustainable energy sources are presented. Finally, digital twin surrogate models and associated uncertainties are described. 	
"FedTrees: A Novel Computation-Communication Efficient Federated Learning
  Framework Investigated in Smart Grids"	http://arxiv.org/abs/2210.00060v1	2022-09-30T19:47:46Z	2022-09-30T19:47:46Z	  Smart energy performance monitoring and optimisation at the supplier and consumer levels is essential to realising smart cities. In order to implement a more sustainable energy management plan, it is crucial to conduct a better energy forecast. The next-generation smart meters can also be used to measure, record, and report energy consumption data, which can be used to train machine learning (ML) models for predicting energy needs. However, sharing fine-grained energy data and performing centralised learning may compromise users' privacy and leave them vulnerable to several attacks. This study addresses this issue by utilising federated learning (FL), an emerging technique that performs ML model training at the user level, where data resides. We introduce FedTrees, a new, lightweight FL framework that benefits from the outstanding features of ensemble learning. Furthermore, we developed a delta-based early stopping algorithm to monitor FL training and stop it when it does not need to continue. The simulation results demonstrate that FedTrees outperforms the most popular federated averaging (FedAvg) framework and the baseline Persistence model for providing accurate energy forecasting patterns while taking only 2% of the computation time and 13% of the communication rounds compared to FedAvg, saving considerable amounts of computation and communication resources. 	
Dynamical consistency conditions for rapid turn inflation	http://arxiv.org/abs/2210.00031v2	2022-10-28T11:44:18Z	2022-09-30T18:18:23Z	  We derive consistency conditions for sustained slow roll and rapid turn inflation in two-field cosmological models with oriented scalar field space, which imply that inflationary models with field-space trajectories of this type are non-generic. In particular, we show that third order adiabatic slow roll, together with large and slowly varying turn rate, requires the scalar potential of the model to satisfy a certain nonlinear second order PDE, whose coefficients depend on the scalar field metric. We also derive consistency conditions for slow roll inflationary solutions in the so called ``rapid turn attractor'' approximation, as well as study the consistency conditions for circular rapid turn trajectories with slow roll in two-field models with rotationally invariant field space metric. Finally, we argue that the rapid turn regime tends to have a natural exit after a limited number of e-folds. 	
"A Learnable Optimization and Regularization Approach to Massive MIMO CSI
  Feedback"	http://arxiv.org/abs/2209.15340v1	2022-09-30T09:49:00Z	2022-09-30T09:49:00Z	  Channel state information (CSI) plays a critical role in achieving the potential benefits of massive multiple input multiple output (MIMO) systems. In frequency division duplex (FDD) massive MIMO systems, the base station (BS) relies on sustained and accurate CSI feedback from the users. However, due to the large number of antennas and users being served in massive MIMO systems, feedback overhead can become a bottleneck. In this paper, we propose a model-driven deep learning method for CSI feedback, called learnable optimization and regularization algorithm (LORA). Instead of using l1-norm as the regularization term, a learnable regularization module is introduced in LORA to automatically adapt to the characteristics of CSI. We unfold the conventional iterative shrinkage-thresholding algorithm (ISTA) to a neural network and learn both the optimization process and regularization term by end-toend training. We show that LORA improves the CSI feedback accuracy and speed. Besides, a novel learnable quantization method and the corresponding training scheme are proposed, and it is shown that LORA can operate successfully at different bit rates, providing flexibility in terms of the CSI feedback overhead. Various realistic scenarios are considered to demonstrate the effectiveness and robustness of LORA through numerical simulations. 	
"Review of Electric Vehicle Charging Technologies, Configurations, and
  Architectures"	http://arxiv.org/abs/2209.15242v1	2022-09-30T05:21:30Z	2022-09-30T05:21:30Z	  Electric Vehicles (EVs) are projected to be one of the major contributors to energy transition in the global transportation due to their rapid expansion. The EVs will play a vital role in achieving a sustainable transportation system by reducing fossil fuel dependency and greenhouse gas (GHG) emissions. However, high level of EVs integration into the distribution grid has introduced many challenges for the power grid operation, safety, and network planning due to the increase in load demand, power quality impacts and power losses. An increasing fleet of electric mobility requires the advanced charging systems to enhance charging efficiency and utility grid support. Innovative EV charging technologies are obtaining much attention in recent research studies aimed at strengthening EV adoption while providing ancillary services. Therefore, analysis of the status of EV charging technologies is significant to accelerate EV adoption with advanced control strategies to discover a remedial solution for negative grid impacts, enhance desired charging efficiency and grid support. This paper presents a comprehensive review of the current deployment of EV charging systems, international standards, charging configurations, EV battery technologies, architecture of EV charging stations, and emerging technical challenges. The charging systems require a dedicated converter topology, a control strategy and international standards for charging and grid interconnection to ensure optimum operation and enhance grid support. An overview of different charging systems in terms of onboard and off-board chargers, AC-DC and DC-DC converter topologies, and AC and DC-based charging station architectures are evaluated. 	
"Size-dependent transient nature of localized turbulence in transitional
  channel flow"	http://arxiv.org/abs/2209.15184v1	2022-09-30T02:18:46Z	2022-09-30T02:18:46Z	  It has been reported that a fully localized turbulent band in channel flow becomes sustained when the Reynolds number is above a threshold. Here we show evidences that turbulent bands are of a transient nature instead. When the band length is controlled to be fixed, lifetimes of turbulent bands appear to be stochastic and exponentially distributed, a sign of a memoryless transient nature. Besides increasing with the Reynolds number, the mean lifetime also strongly increases with the band length. Given that the band length always changes over time in real channel flow, this size dependence may translate into a time dependence, which needs to be taken into account when clarifying the relationship between channel flow transition and the directed percolation universality class. 	
"Circularity of Thermodynamical Material Networks: Indicators, Examples,
  and Algorithms"	http://arxiv.org/abs/2209.15051v2	2022-12-13T19:21:06Z	2022-09-29T18:52:09Z	  The transition towards a circular economy has gained importance over the last years since the traditional linear take-make-dispose paradigm is not sustainable in the long term. Recently, thermodynamical material networks (TMNs) [1] have been proposed as an approach to re-design material flows based on the idea that any supply chain can be seen as a set of thermodynamic compartments that can be added, removed, modified or connected differently. In this paper, we develop several circularity indicators of TMNs using a graph-based formalism and illustrate their calculation through examples. The paper source code is publicly available. 	
"Evolving Reference Architecture Description: Guidelines based on
  ISO/IEC/IEEE 42010"	http://arxiv.org/abs/2209.14714v1	2022-09-29T12:19:03Z	2022-09-29T12:19:03Z	  The architectural design of software systems is not a trivial task, requiring sometimes large experience and knowledge accumulated for years. Reference architectures have been increasingly adopted as a means to support such task, also contributing to the standardization and evolution of these systems. Although considerable time and effort are devoted to design these architectures, an outdated description is still found in several of them and, as a consequence, resulting in their non-continuation. This article presents guidelines to evolve the description of reference architectures, considering different types of stakeholders and required tasks. To complement our statement that the guidelines are correct by construction as they were grounded in widely known international standard ISO/IEC/IEEE 42010 and literature, we also briefly present a qualitative analysis comparing the guidelines with an ad hoc way (commonly occurred in reference architectures). We believe solutions like these guidelines are necessary and could further contribute to the sustainability and longevity of reference architectures. 	
"Evidence of persistence of weak magnetic cycles driven by meridional
  plasma flows during solar grand minima phases"	http://arxiv.org/abs/2209.14651v1	2022-09-29T09:24:07Z	2022-09-29T09:24:07Z	  Long-term sunspot observations and solar activity reconstructions reveal that the Sun occasionally slips into quiescent phases known as solar grand minima, the dynamics during which is not well understood. We use a flux transport dynamo model with stochastic fluctuations in the mean-field and Babcock-Leighton poloidal field source terms to simulate solar cycle variability. Our long-term simulations detect a gradual decay of the polar field during solar grand minima episodes. Although regular active region emergence stops, compromising the Babcock-Leighton mechanism, weak magnetic activity continues during minima phases sustained by a mean-field $\alpha$-effect; surprisingly, periodic polar field amplitude modulation persist during these phases. A spectral analysis of the simulated polar flux time series shows that the 11-year cycle becomes less prominent while high frequency periods and periods around 22 years manifest during grand minima episodes. Analysis of long-term solar open flux observations appears to be consistent with this finding. Through numerical experimentation we demonstrate that the persistence of periodic amplitude modulation in the polar field and the dominant frequencies during grand minima episodes are governed by the speed of the meridional plasma flow -- which appears to act as a clock. 	
"Transmission Model for Resonant Beam SWIPT with Telescope Internal
  Modulator"	http://arxiv.org/abs/2209.14539v1	2022-09-29T04:03:46Z	2022-09-29T04:03:46Z	  To satisfy the long-range and energy self-sustaining communication needs of electronic devices in the Internet of Things (IoT), we introduce a simultaneous wireless information and power transfer (SWIPT) system using the resonant beam that incorporates a telescope modulator inside a cavity for suppressing diffraction losses. We theoretically analyze power transfer in the resonant beam system with telescope internal modulator (TIM-RBS) considering the electromagnetic field propagation, the end-to-end (E2E) power transfer, and power and information reception. The numerical evaluation demonstrates that the TIM can effectively compress the beam spot, which allows the TIM-RBS to transmit energy twice as far as the RBS without TIM at higher power. Additionally, the largest transmission distance and maximum output power are proportional to the input power, and about 34m transmission distance, 4W electric power, and 12bps/Hz spectral efficiency can be achieved in the TIM-RBS with 200W input power. Hence, TIM-RBS can be considered as a promising option for realizing long-range, high-power, and high-rate SWIPT. 	
"The Fungibility of Non-Fungible Tokens: A Quantitative Analysis of
  ERC-721 Metadata"	http://arxiv.org/abs/2209.14517v1	2022-09-29T02:33:31Z	2022-09-29T02:33:31Z	  Non-Fungible Tokens (NFTs), digital certificates of ownership for virtual art, have until recently been traded on a highly lucrative and speculative market. Yet, an emergence of misconceptions, along with a sustained market downtime, are calling the value of NFTs into question. This project (1) describes three properties that any valuable NFT should possess (permanence, immutability and uniqueness), (2) creates a quantitative summary of permanence as an initial criteria, and (3) tests our measures on 6 months of NFTs on the Ethereum blockchain, finding 45% of ERC721 tokens in our corpus do not satisfy this initial criteria. Our work could help buyers and marketplaces identify and warn users against purchasing NFTs that may be overvalued. 	
"Optimal Retail Tariff Design with Prosumers: Pursuing Equity at the
  Expenses of Economic Efficiencies?"	http://arxiv.org/abs/2209.14505v1	2022-09-29T01:42:07Z	2022-09-29T01:42:07Z	  Distributed renewable resources owned by prosumers can be an effective way of fortifying grid resilience and enhancing sustainability. However, prosumers serve their own interests and their objectives are unlikely to align with that of society. This paper develops a bilevel model to study the optimal design of retail electricity tariffs considering the balance between economic efficiency and energy equity. The retail tariff entails a fixed charge and a volumetric charge tied to electricity usage to recover utilities' fixed costs. We analyze solution properties of the bilevel problem and prove an optimal rate design, which is to use fixed charges to recover fixed costs and to balance energy equity among different income groups. This suggests that programs similar to CARE (California Alternative Rate of Energy), which offer lower retail rates to low-income households, are unlikely to be efficient, even if they are politically appealing. 	
AI Governance and Ethics Framework for Sustainable AI and Sustainability	http://arxiv.org/abs/2210.08984v1	2022-09-28T22:23:10Z	2022-09-28T22:23:10Z	  AI is transforming the existing technology landscape at a rapid phase enabling data-informed decision making and autonomous decision making. Unlike any other technology, because of the decision-making ability of AI, ethics and governance became a key concern. There are many emerging AI risks for humanity, such as autonomous weapons, automation-spurred job loss, socio-economic inequality, bias caused by data and algorithms, privacy violations and deepfakes. Social diversity, equity and inclusion are considered key success factors of AI to mitigate risks, create values and drive social justice. Sustainability became a broad and complex topic entangled with AI. Many organizations (government, corporate, not-for-profits, charities and NGOs) have diversified strategies driving AI for business optimization and social-and-environmental justice. Partnerships and collaborations become important more than ever for equity and inclusion of diversified and distributed people, data and capabilities. Therefore, in our journey towards an AI-enabled sustainable future, we need to address AI ethics and governance as a priority. These AI ethics and governance should be underpinned by human ethics. 	
Mathematical Models of Theory of Mind	http://arxiv.org/abs/2209.14450v1	2022-09-28T22:15:14Z	2022-09-28T22:15:14Z	  Socially assistive robots provide physical and mental assistance for humans via cognitive human-machine interactions. These robots should sustain long-term engaging interactions with humans in a similar way humans interact with each other. According to the theory of mind, in their interactions humans develop cognitive models of each other in order to estimate their unobservable state-of-mind, predict their behavior, and act accordingly. Based on the theory of mind, we propose mathematical cognitive models of humans, which enable machines to understand cognitive procedures of humans in general and as distinct individuals. In particular, a network representation that is formulated based on a proposed extended version of fuzzy cognitive maps is introduced. The resulting models are identified and validated using (1) computer-based simulations designed according to a general data set of human's intuitive reasoning and literature and (2) real-life personalised experiments with 15 human participants. The results of the experiments show that the proposed cognitive models can excellently be personalised to different participants and precisely estimate and predict their current and future state-of-mind and expected behaviors. 	
"Enhancing Agile Software Development Sustainability through the
  Integration of User Experience and Gamification"	http://arxiv.org/abs/2209.14263v1	2022-09-28T17:25:26Z	2022-09-28T17:25:26Z	  This article provides a rich discussion on how the sustainability of agile development processes can be enhanced. In particular, we focus on a recently developed framework, named GLUX, that integrates Lean UX into Scrum. GLUX's main goal is to facilitate a seamless integration between agile and user experience (UX) by using gamification to motivate agile teams to adopt a user-centered mindset and carry out UX activities collaboratively throughout the development process. Our role as software researchers is to contribute towards improving software sustainability and provide the software engineering community with the tools and techniques that will improve the human, economic, and environmental sustainability of software development. We found that GLUX addresses human sustainability by empowering self-sufficient, problem-focused teams, building a motivating and engaging environment, and developing team cooperation. Economic sustainability is addressed by minimizing UX debt and using gamification techniques to direct the focus of the behavior and mindset of agile teams towards value creation. Finally, environmental sustainability is promoted by encouraging agile teams to build a minimum viable product (MVP). 	
"Energy Efficient Deployment and Orchestration of Computing Resources at
  the Network Edge: a Survey on Algorithms, Trends and Open Challenges"	http://arxiv.org/abs/2209.14141v1	2022-09-28T14:42:59Z	2022-09-28T14:42:59Z	  Mobile networks are becoming energy hungry, and this trend is expected to continue due to a surge in communication and computation demand. Multi-access Edge Computing (MEC), will entail energy-consuming services and applications, with non-negligible impact in terms of ecological sustainability. In this paper, we provide a comprehensive review of existing approaches to make edge computing networks greener, including but not limited to the exploitation of renewable energy resources, and context-awareness. We hence provide an updated account of recent developments on MEC from an energetic sustainability perspective, addressing the initial deployment of computing resources, their dynamic (re)allocation, as well as distributed and federated learning designs. In doing so, we highlight the energy aspects of these algorithms, advocating the need for energy-sustainable edge computing systems that are aligned with Sustainable Development Goals (SDGs) and the Paris agreement. To the best of our knowledge, this is the first work providing a systematic literature review on the efficient deployment and management of energy harvesting MEC, with special focus on the deployment, provisioning, and scheduling of computing tasks, including federated learning for distributed edge intelligence, toward making edge networks greener and more sustainable. At the end of the paper, open research avenues and challenges are identified for all the surveyed topics. 	
"The Fate of the Upper Polariton: Breakdown of the Quasiparticle Picture
  in the Continuum"	http://arxiv.org/abs/2209.13698v2	2022-10-02T18:45:23Z	2022-09-27T21:23:37Z	  Organic polaritons resulting from the strong hybridisation between photons and matter excitations have arisen as a suitable platform to device light-matter technological interfaces at room temperature. Despite their inherent complexity, organic polaritons are commonly regarded as coherent light-matter excitations that can be described in terms of Landau's quasiparticle approach. Here, we experimentally unveil the role of incoherent matter excitations on the polaritons by exploring the relevant energy-momentum parameter space. We demonstrate the emergence of a well-defined lower polariton branch and an intriguing fading of the upper polariton at its entrance to a continuum of matter excitations. This marks the breakdown of the simplistic quasiparticle picture for this branch and the formation of a more complex quantum state. Our experimental results are sustained by a general theoretical framework that allows understanding the light-matter hybridisation beyond the quasiparticle approach. Our work expands the understanding of organic polaritons in all their complexity and increases their technological significance. 	
CREW HaT: A Magnetic Shielding System for Space Habitats	http://arxiv.org/abs/2209.13624v1	2022-09-27T18:40:25Z	2022-09-27T18:40:25Z	  At the dawn of a new space exploration age, aiming to send humans back to the Moon and for the first time to Mars, it is necessary to devise a solution to mitigate the impact that space radiation has on spacecraft and astronauts. Although technically challenging, active magnetic shielding is generally considered a promising solution. We propose a lightweight deployable system producing an open magnetic field around a space habitat. Our Cosmic Radiation Extended Warding (CREW) system consists of a cylindrical Halbach array coil arrangement, or Halbach Torus (HaT). This configuration generates an enhanced external magnetic field while suppressing it in the habitat volume. The CREW HaT takes advantage of recent innovations in high-temperature superconductors (e.g., ReBCO) that enables the needed high currents. We present a preliminary feasibility design of the magnetic shielding system and its collapsible mechanical structure to sustain the internal magnetic forces while protecting astronauts. We also lay down the next steps towards a more evolved and comprehensive device design. 	
"MTTBA- A Key Contributor for Sustainable Energy Consumption Time and
  Space Utility for Highly Secured Crypto Transactions in Blockchain Technology"	http://arxiv.org/abs/2209.13431v1	2022-09-27T14:38:30Z	2022-09-27T14:38:30Z	  A Merkle tree is an information construction that is used in Blockchain to verify data or transactions in a large content pool in a safe manner. The role of the Merkle tree is crucial in Bitcoin and other cryptocurrencies in a Blockchain network. In this paper, we propose a bright and enhanced verification method, Merkle Trim Tree-based Blockchain Authentication (MTTBA) for the hash node traversal to reach the Merkle Root in a minimum time. MTTBA is a unique mechanism for verifying the Merkle Tree's accumulated transactions specifically for an odd number of transactions. The future impact of cryptocurrency is going to be massive and MTTBA proves its efficacy in transaction speed and eliminating node duplication. Our method enables any block to validate transactions' full availability without duplicating hash nodes. Performance has been evaluated in different parameters and the results show marked improvement in throughput(1680ms), processing time(29700kbps), memory usage(140MB), and security(99.30%). The energy consumption factor is crucial in the scenario, and MTTBA has achieved the lowest of 240 joules. 	
CSRE4SOC (CSR evaluation for software companies)	http://arxiv.org/abs/2209.13372v1	2022-09-27T13:17:45Z	2022-09-27T13:17:45Z	  Software development companies are increasingly concerned about their impact on the environment. This is translated into the incorporation of actions related to software sustainability in their Corporate Social Responsibility (CSR) document. CSR reflects a company's obligations to society and the environment. However, we have found that companies do not always have the necessary knowledge to be able to include actions related to software sustainability. Moreover, there is still a lot of work to be done, as the number of actions they incorporate is often insufficient. Taking all this into account, we consider it essential for software development companies to have a tool that allows them to assess their level of software sustainability, based on the actions of their CSR, and to automatically provide them with a series of improvements to advance their level of software sustainability. Therefore, this paper introduces CSRE4SOC, a tool for the evaluation and monitoring of the software sustainability level of software development companies according to their CSR. 	
Timespot1: A 28nm CMOS Pixel Read-Out ASIC for 4D Tracking at High Rates	http://arxiv.org/abs/2209.13242v3	2022-12-22T12:15:56Z	2022-09-27T08:26:37Z	  We present the first characterization results of Timespot1, an ASIC designed in CMOS 28 nm technology, featuring a $32 \times 32$ pixel matrix with a pitch of $55 ~ \mu m$. Timespot1 is the first small-size prototype, conceived to readout fine-pitch pixels with single-hit time resolution below $50 ~ ps_\text{rms}$ and input rates of several hundreds of kilohertz per pixel. Such experimental conditions will be typical of the next generation of high-luminosity collider experiments, from the LHC run5 and beyond. Each pixel of the ASIC includes a charge amplifier, a discriminator, and a Time-to-Digital Converter with time resolution indicatively of $22.6 ~ ps_\text{rms}$ and maximum readout rates (per pixel) of $3 ~ MHz$. To respect system-level constraints, the timing performance has been obtained keeping the power budget per pixel below $40 ~ \mu W$. The ASIC has been tested and characterised in the laboratory concerning its performance in terms of time resolution, power budget and sustainable rates. The ASIC will be hybridized on a matched $32 \times 32$ pixel sensor matrix and will be tested under laser beam and Minimum Ionizing Particles in the laboratory and at test beams. In this paper we present a description of the ASIC operation and the first results obtained from characterization tests concerning its performance. 	
"Evaluating Effects of Geometry and Material Composition on Production of
  Transversely Shaped Beams from Diamond Field Emission Array Cathodes"	http://arxiv.org/abs/2209.13047v1	2022-09-26T22:00:28Z	2022-09-26T22:00:28Z	  Field emission cathodes (FECs) are attractive for the next generation of injectors due to their ability to provide high current density bright beams with low intrinsic emittance. One application of FECs worthy of special attention is to provide transversely shaped electron beams for emittance exchange that translates a transverse electron beam pattern into a longitudinal pattern. FECs can be fabricated in a desired pattern and produce transversely shaped beams without the need for complex masking or laser schemes. However, reliable and consistent production of transversely shaped beams is affected by material properties of the FEC. This paper reports the results of testing two diamond field emitter array (DFEA) FECs with the same lithography pattern and emitter geometry but different material and tip characteristics. Although both cathodes were able to sustain gradients of 44 MV/m and produce maximum output integral charge of 0.5 nC per radiofrequency (rf) pulse, their emission patterns were quite different. One cathode did not produce a patterned beam while the other one did. Differences in field emission characteristics and patterned beam production were explained by the differences in the tip geometry and the cathode material properties. The main practical takeaway was found to be that the tip sharpness was not a prerequisite for good patterned beam production. Instead, other material characteristics, such as the ballast resistance, determined cathode performance. 	
"FaRO 2: an Open Source, Configurable Smart City Framework for Real-Time
  Distributed Vision and Biometric Systems"	http://arxiv.org/abs/2209.12962v1	2022-09-26T18:52:53Z	2022-09-26T18:52:53Z	  Recent global growth in the interest of smart cities has led to trillions of dollars of investment toward research and development. These connected cities have the potential to create a symbiosis of technology and society and revolutionize the cost of living, safety, ecological sustainability, and quality of life of societies on a world-wide scale. Some key components of the smart city construct are connected smart grids, self-driving cars, federated learning systems, smart utilities, large-scale public transit, and proactive surveillance systems. While exciting in prospect, these technologies and their subsequent integration cannot be attempted without addressing the potential societal impacts of such a high degree of automation and data sharing. Additionally, the feasibility of coordinating so many disparate tasks will require a fast, extensible, unifying framework. To that end, we propose FaRO2, a completely reimagined successor to FaRO1, built from the ground up. FaRO2 affords all of the same functionality as its predecessor, serving as a unified biometric API harness that allows for seamless evaluation, deployment, and simple pipeline creation for heterogeneous biometric software. FaRO2 additionally provides a fully declarative capability for defining and coordinating custom machine learning and sensor pipelines, allowing the distribution of processes across otherwise incompatible hardware and networks. FaRO2 ultimately provides a way to quickly configure, hot-swap, and expand large coordinated or federated systems online without interruptions for maintenance. Because much of the data collected in a smart city contains Personally Identifying Information (PII), FaRO2 also provides built-in tools and layers to ensure secure and encrypted streaming, storage, and access of PII data across distributed systems. 	
Environmental and Social Sustainability of Creative-Ai	http://arxiv.org/abs/2209.12879v2	2022-09-28T10:18:49Z	2022-09-26T17:47:19Z	  The recent developments of artificial intelligence increase its capability for the creation of arts in both largely autonomous and collaborative contexts. In both contexts, Ai aims to imitate, combine, and extend existing artistic styles, and can transform creative practices. In our ongoing research, we investigate such Creative-Ai from sustainability and ethical perspectives. The two main focus areas are understanding the environmental sustainability aspects (material, practices) in the context of artistic processes that involve Creative-Ai, and ethical issues related to who gets to be involved in the creation process (power, authorship, ownership). This paper provides an outline of our ongoing research in these two directions. We will present our interdisciplinary approach, which combines interviews, workshops, online ethnography, and energy measurements, to address our research questions: How is Creative-Ai currently used by artist communities, and which future applications do artists imagine? When Ai is applied to creating art, how might it impact the economy and environment? And, how can answers to these questions guide requirements for intellectual property regimes for Creative-Ai? 	
Evolutionary Dynamics of Sustainable Blockchains	http://arxiv.org/abs/2209.12809v1	2022-09-26T16:00:42Z	2022-09-26T16:00:42Z	  The energy sustainability of blockchains, whose consensus protocol rests on the Proof-of-Work, nourishes a heated debate. The underlying issue lies in a highly energy-consuming process, defined as mining, required to validate crypto-asset transactions. Mining is the process of solving a cryptographic puzzle, incentivised by the possibility of gaining a reward. The higher the number of users performing mining, i.e. miners, the higher the overall electricity consumption of a blockchain. For that reason, mining constitutes a negative environmental externality. Here, we study whether miners' interests can meet the collective need to curb energy consumption. To this end, we introduce the Crypto-Asset Game, namely a model based on the framework of Evolutionary Game Theory devised for studying the dynamics of a population whose agents can play as crypto-asset users or as miners. The energy consumption of mining impacts the payoff of both strategies, representing a direct cost for miners and an environmental factor for crypto-asset users. The proposed model, studied via numerical simulations, shows that, in some conditions, the agent population can reach a strategy profile that optimises global energy consumption, i.e. composed of a low density of miners. To conclude, can a Proof-of-Work-based blockchain become energetically sustainable? Our results suggest that blockchain protocol parameters could have a relevant role in the global energy consumption of this technology. 	
"Material Prediction for Design Automation Using Graph Representation
  Learning"	http://arxiv.org/abs/2209.12793v1	2022-09-26T15:49:35Z	2022-09-26T15:49:35Z	  Successful material selection is critical in designing and manufacturing products for design automation. Designers leverage their knowledge and experience to create high-quality designs by selecting the most appropriate materials through performance, manufacturability, and sustainability evaluation. Intelligent tools can help designers with varying expertise by providing recommendations learned from prior designs. To enable this, we introduce a graph representation learning framework that supports the material prediction of bodies in assemblies. We formulate the material selection task as a node-level prediction task over the assembly graph representation of CAD models and tackle it using Graph Neural Networks (GNNs). Evaluations over three experimental protocols performed on the Fusion 360 Gallery dataset indicate the feasibility of our approach, achieving a 0.75 top-3 micro-f1 score. The proposed framework can scale to large datasets and incorporate designers' knowledge into the learning process. These capabilities allow the framework to serve as a recommendation system for design automation and a baseline for future work, narrowing the gap between human designers and intelligent design agents. 	
"Robust Causality and False Attribution in Data-Driven Earth Science
  Discoveries"	http://arxiv.org/abs/2209.12580v1	2022-09-26T10:45:48Z	2022-09-26T10:45:48Z	  Causal and attribution studies are essential for earth scientific discoveries and critical for informing climate, ecology, and water policies. However, the current generation of methods needs to keep pace with the complexity of scientific and stakeholder challenges and data availability combined with the adequacy of data-driven methods. Unless carefully informed by physics, they run the risk of conflating correlation with causation or getting overwhelmed by estimation inaccuracies. Given that natural experiments, controlled trials, interventions, and counterfactual examinations are often impractical, information-theoretic methods have been developed and are being continually refined in the earth sciences. Here we show that transfer entropy-based causal graphs, which have recently become popular in the earth sciences with high-profile discoveries, can be spurious even when augmented with statistical significance. We develop a subsample-based ensemble approach for robust causality analysis. Simulated data, and observations in climate and ecohydrology, suggest the robustness and consistency of this approach. 	
"From Silicon Shield to Carbon Lock-in ? The Environmental Footprint of
  Electronic Components Manufacturing in Taiwan (2015-2020)"	http://arxiv.org/abs/2209.12523v1	2022-09-26T08:59:45Z	2022-09-26T08:59:45Z	  Taiwan plans to rapidly increase its industrial production capacity of electronic components while concurrently setting policies for its ecological transition. Given that the island is responsible for the manufacturing of a significant part of worldwide electronics components, the sustainability of the Taiwanese electronics industry is therefore of critical interest. In this paper, we survey the environmental footprint of 16 Taiwanese electronic components manufacturers (ECM) using corporate sustainability responsibility reports (CSR). Based on data from 2015 to 2020, this study finds out that our sample of 16 manufacturers increased its greenhouse gases (GHG) emissions by 7.5\% per year, its final energy and electricity consumption by 8.8\% and 8.9\%, and the water usage by 6.1\%. We show that the volume of manufactured electronic components and the environmental footprints compiled in this study are strongly correlated, which suggests that relative efficiency gains are not sufficient to curb the environmental footprint at the national scale. Given the critical nature of electronics industry for Taiwan's geopolitics and economics, the observed increase of energy consumption and the slow renewable energy roll-out, these industrial activities could create a carbon lock-in, blocking the Taiwanese government from achieving its carbon reduction goals and its sustainability policies. Besides, the European Union, the USA or even China aim at developing an industrial ecosystem targeting sub-10nm CMOS technology nodes similar to Taiwan. This study thus provides important insights regarding the environmental implications associated with such a technology roadmap. All data and calculation models used in this study are provided as supplementary material. 	
Study of pnictides for photovoltaic applications	http://arxiv.org/abs/2209.12458v1	2022-09-26T06:58:05Z	2022-09-26T06:58:05Z	"  For the transition into a sustainable mode of energy usage, it is important to develop photovoltaic materials that exhibit better solar-to-electricity conversion efficiencies, a direct optimal band gap, and made of non-toxic, earth abundant elements compared to the state-of-the-art silicon photovoltaics. Here, we explore the non-redox-active pnictide chemical space, including binary A$_3$B$_2$, ternary AA'$_2$B$_2$, and quaternary AA'A""B$_2$ compounds (A, A', A"" = Ca, Sr, or Zn; B = N or P), as candidate beyond-Si photovoltaics using density functional theory calculations. Specifically, we evaluate the ground state configurations, band gaps, and 0 K thermodynamic stability for all 20 pnictide compositions considered, besides computing the formation energy of cation vacancies, anion vacancies, and cation anti-sites in a subset of candidate compounds. Importantly, we identify SrZn$_2$N$_2$, SrZn$_2$P$_2$, and CaZn$_2$P$_2$ to be promising candidates, exhibiting optimal (1.1-1.5 eV) hybrid-functional-calculated band gaps, stability at 0 K, and high resistance to point defects (formation energies $>$1 eV), while other possible candidates include ZnCa$_2$N$_2$ and ZnSr$_2$N$_2$, which may be susceptible to N-vacancy formation. We hope that our study will contribute to the practical development of pnictide semiconductors as beyond-silicon light absorbers. "	
Terra: Blockage Resilience in Outdoor mmWave Networks	http://arxiv.org/abs/2209.12296v1	2022-09-25T18:52:37Z	2022-09-25T18:52:37Z	  We address the problem of pedestrian blockage in outdoor mm-Wave networks, which can disrupt Line of Sight (LoS) communication and result in an outage. This necessitates either reacquisition as a new user that can take up to 1.28 sec in 5G New Radio, disrupting high-performance applications, or handover to a different base station (BS), which however requires very costly dense deployments to ensure multiple base stations are always visible to a mobile outdoors. We have found that there typically exists a strong ground reflection from concrete and gravel surfaces, within 4-6 dB of received signal strength (RSS) of LoS paths. The mobile can switch to such a Non-Line Sight (NLoS) beam to sustain the link for use as a control channel during a blockage event. This allows the mobile to maintain time-synchronization with the base station, allowing it to revert to the LoS path when the temporary blockage disappears. We present a protocol, Terra, to quickly discover, cache, and employ ground reflections. It can be used in most outdoor built environments since pedestrian blockages typically last only a few hundred milliseconds. 	
"Determination of Chain Strength induced by Embedding in D-Wave Quantum
  Annealer"	http://arxiv.org/abs/2209.12166v1	2022-09-25T06:59:10Z	2022-09-25T06:59:10Z	  The D-wave quantum annealer requires embedding with ferromagnetic (FM) chains connected by several qubits, because it cannot capture exact long-range coupling between qubits, and retains the specific architecture that depends on the hardware type. Therefore, determination of the chain strength $J_c$ required to sustain FM order of qubits in the chains is crucial for the accuracy of quantum annealing. In this study, we devise combinatorial optimization problems with ordered and disordered qubits for various embeddings to predict appropriate $J_c$ values. We analyze the energy interval $\Delta_s$ and $\Delta_c$ between ground and first excited states in the combinatorial optimization problems without and with chains respectively, using the exact approach. We also measure the probability $p$ that the exact ground energy per site $E_g$ is observed in many simulated annealing shots. We demonstrate that the determination of $J_c$ is increasingly sensitive with growing disorder of qubits in the combinatorial optimization problems. In addition, the values of appropriate $J_c$, where the values of $p$ are at a maximum, increase with decreasing $\Delta_s$. Finally, the appropriate value of $J_c$ is shown to be observed at approximately $\Delta_c/\Delta_s=0.25$ and $2.1 E_g$ in the ordered and disordered qubits, respectively. 	
"Are Turn-by-Turn Navigation Systems of Regular Vehicles Ready for
  Edge-Assisted Autonomous Vehicles?"	http://arxiv.org/abs/2211.01343v1	2022-09-23T21:54:53Z	2022-09-23T21:54:53Z	  Future private and public transportation will be dominated by Autonomous Vehicles (AV), which are potentially safer than regular vehicles. However, ensuring good performance for the autonomous features requires fast processing of heavy computational tasks. Providing each AV with powerful enough computing resources is certainly a practical solution but may result in increased AV cost and decreased driving range. An alternative solution being explored in research is to install low-power computing hardware on each AV and offload the heavy tasks to powerful nearby edge servers. In this case, the AV's reaction time depends on how quickly the navigation tasks are completed in the edge server. To reduce task completion latency, the edge servers must be equipped with enough network and computing resources to handle the vehicle demands. However, this demand shows large spatio-temporal variations. Thus, deploying the same amount of resources in different locations may lead to unnecessary resource over-provisioning.   Taking these challenges into consideration, in this paper, we discuss the implications of deploying different amounts of resources in different city areas based on real traffic data to sustain peak versus average demand. Because deploying edge resources to handle the average demand leads to lower deployment costs and better system utilization, we then investigate how peak-hour demand affect the safe travel time of AVs and whether current turn-by-turn navigation apps would still provide the fastest travel route. The insights and findings of this paper will inspire new research that can considerably speed up the deployment of edge-assisted AVs in our society. 	
"Software Sustainability: A Design Case for Achieving Sustainable Pension
  Services in Developing Country"	http://arxiv.org/abs/2209.11351v1	2022-09-23T00:23:34Z	2022-09-23T00:23:34Z	  The need for efficient and sustainable software to improve business and achieve goals cannot be over-emphasized. Sustainable digital services and product delivery cannot be achieved without embracing sustainable software design practices. Despite the current research progress on software sustainability, most software development practitioners in developing countries are unclear about what constitutes software sustainability and often lack the proper understanding of how to implement it in their specific industry domain. Research efforts from software engineering focused on promoting software sustainability awareness in developed countries, and fewer efforts have been channeled to studying the same awareness in developing countries. This has affected the level of awareness about sustainable software design practices in most developing countries. This research investigates the awareness of software sustainability in the Nigerian pension industry and its challenges among practitioners. The software development practitioners were engaged and interviewed. We offered ways to mitigate the identified challenges and promote the awareness of software sustainability in the pension industry. Our findings further show that, with the right sustainability knowledge, the software practitioners in the pension industry have the potential to support their organization's sustainable culture and improve the efficiency of product design and service delivery. 	
"Building a National Smart Campus to support sustainable business
  development: An ecosystem approach"	http://arxiv.org/abs/2209.13613v1	2022-09-22T16:24:02Z	2022-09-22T16:24:02Z	  Universities are racing towards making their campuses and cities smart in response to the global digitalization trend. However, the sustainability impact of Smart Campus research, development, and innovation services on other relevant stakeholders such as the small and medium-sized businesses, remain under-investigated. The Finnish National Smart Campus project seeks to bridge this gap by orchestrating a SC ecosystem where eight SC collaborate to bring trailblazing services to businesses and society. To maximize the sustainability impact of the SC ecosystem, this study used a participatory workshop to identify the challenges of SC, provide a step-by-step guide on how to identify other relevant stakeholders, and ascertain the perceived sustainability impact using one of the SC ecosystems RDIs as a case study. The preliminary results revealed that barriers to university-industry ecosystem development include (i), the lack of clarity in the shared goals (i.e., value proposition) between actors and (ii), weak stakeholder involvement in university RDI processes. Finally, this paper proposed a SC ecosystem model which offers a mindset shift for higher educational institutions in promoting the convergence of SC services and sustainability to support the sustainable development of Finnish-based SMEs. 	
One-Shot Messaging at Any Load Through Random Sub-Channeling in OFDM	http://arxiv.org/abs/2209.11056v1	2022-09-22T14:49:12Z	2022-09-22T14:49:12Z	"  Compressive Sensing has well boosted massive random access protocols over the last decade. In this paper we apply an orthogonal FFT basis as it is used in OFDM, but subdivide its image into so-called sub-channels and let each sub-channel take only a fraction of the load. In a random fashion the subdivision is consecutively applied over a suitable number of time-slots. Within the time-slots the users will not change their sub-channel assignment and send in parallel the data. Activity detection is carried out jointly across time-slots in each of the sub-channels. For such system design we derive three rather fundamental results: i) First, we prove that the subdivision can be driven to the extent that the activity in each sub-channel is sparse by design. An effect that we call sparsity capture effect. ii) Second, we prove that effectively the system can sustain any overload situation relative to the FFT dimension, i.e. detection failure of active and non-active users can be kept below any desired threshold regardless of the number of users. The only price to pay is delay, i.e. the number of time-slots over which cross-detection is performed. We achieve this by jointly exploring the effect of measure concentration in time and frequency and careful system parameter scaling. iii) Third, we prove that parallel to activity detection active users can carry one symbol per pilot resource and time-slot so it supports so-called one-shot messaging.   The key to proving these results are new concentration results for sequences of randomly sub-sampled FFTs detecting the sparse vectors ""en bloc"". Eventually, we show by simulations that the system is scalable resulting in a coarsely 30-fold capacity increase compared to standard OFDM. "	
"Implementing and Experimenting with Diffusion Models for Text-to-Image
  Generation"	http://arxiv.org/abs/2209.10948v1	2022-09-22T12:03:33Z	2022-09-22T12:03:33Z	  Taking advantage of the many recent advances in deep learning, text-to-image generative models currently have the merit of attracting the general public attention. Two of these models, DALL-E 2 and Imagen, have demonstrated that highly photorealistic images could be generated from a simple textual description of an image. Based on a novel approach for image generation called diffusion models, text-to-image models enable the production of many different types of high resolution images, where human imagination is the only limit.   However, these models require exceptionally large amounts of computational resources to train, as well as handling huge datasets collected from the internet. In addition, neither the codebase nor the models have been released. It consequently prevents the AI community from experimenting with these cutting-edge models, making the reproduction of their results complicated, if not impossible.   In this thesis, we aim to contribute by firstly reviewing the different approaches and techniques used by these models, and then by proposing our own implementation of a text-to-image model. Highly based on DALL-E 2, we introduce several slight modifications to tackle the high computational cost induced. We thus have the opportunity to experiment in order to understand what these models are capable of, especially in a low resource regime. In particular, we provide additional and analyses deeper than the ones performed by the authors of DALL-E 2, including ablation studies.   Besides, diffusion models use so-called guidance methods to help the generating process. We introduce a new guidance method which can be used in conjunction with other guidance methods to improve image quality. Finally, the images generated by our model are of reasonably good quality, without having to sustain the significant training costs of state-of-the-art text-to-image models. 	
"Symmetry-breaking transition between defect-free and defect-laden
  turbulence in polar active matter"	http://arxiv.org/abs/2209.10916v2	2022-10-10T08:26:39Z	2022-09-22T10:56:58Z	  Coherent flows of self-propelled particles are characterized by vortices and jets that sustain chaotic flows, referred to as active turbulence. Here, we reveal a transition between defect-free active turbulence and active turbulence laden with defects. Interestingly, we show that concurrent to the transition from defect-free active turbulence to defect-laden turbulence is the restoration of the previously broken $U(1)$-symmetry and fast decay of the two-point correlations which suggests a symmetry-breaking transition. By stability analyses of the topological charge density field, we provide an analytical prediction of the activity threshold for the transition to the defect-laden active turbulent state. Moreover, despite the distinct symmetry features between the defect-free and defect-laden active turbulence, we demonstrate universal behaviors for the self-similarity of the flow fluctuations at large scales, and exponential decay of polarity power spectrum, at small length scales compared to the active energy injection length. It is further shown that increasing the self-propulsion of the active particles results in exponential rarefaction of topological defects and a transition from active defect-laden turbulence to a flocking state. These findings reveal new dynamical transitions between distinct spatiotemporal organization patterns in polar active mater. 	
"Measuring web connectivity between research organizations through ROR
  identifiers"	http://arxiv.org/abs/2209.10821v1	2022-09-22T07:07:52Z	2022-09-22T07:07:52Z	  Digital information needs to be accessed and used in a manageable and sustainable manner to facilitate the advancement of science and science management. Many types of Persistent Identifiers (PIDs) are already in use and well-established in support of the scholarly communication industry, mainly digital objects (e.g., DOIs) and person identifiers (e.g., ORCID). PIDs improve the interoperability of digital entities, make them reusable, and, at the same time, foster FAIR principles. The main objective of this exploratory work is to measure the degree and type of use of ROR identifiers by the online scientific and academic ecosystem through link-based indicators. The analysis yielded 149,851 links to ror.org webpages: 147,154 links to ROR-based URLs and 2,698 links to other informative webpages under the ror.org website. The results obtained evidence that the percentage of ROR identifiers linked is limited (51.6% of ROR identifiers have been linked at least once). These links come from a limited number of referring domains (242 unique domain names) and mainly from bibliographic records (51.4% of links) and organization cards (36% of links). While the distribution of ROR identifiers is biased towards Anglo-Saxon countries (mainly United States) and types (companies), the educational research organizations are the institutions most linked through their corresponding ROR-based URLs. The connectivity between DOIs, ORCIDs and RORs can be the spearhead to carry out new webometric and bibliometric studies, of interest to characterize the presence, impact, and interconnection of the global academic Web. 	
"Coevolution of Supermassive Black Holes and their Host Galaxies with
  Galaxy Mergers"	http://arxiv.org/abs/2209.10535v1	2022-09-21T17:56:19Z	2022-09-21T17:56:19Z	  Understanding the formation of the supermassive black holes (SMBHs) present in the centers of galaxies is a key topic in modern astrophysics. Observations have detected the SMBHs with mass $M$ of $10^{9}\, \rm M_\odot$ in the high redshifts galaxies with z$\sim7$. However, how SMBHs grew to such huge masses within the first billion years after the big bang remains elusive. One possible explanation is that SMBHs grew in a short period through the frequent mergers of galaxies, which provides sustainable gas to maintain the rapid growth. In this study, we present the hydrodynamics simulations of the SMBHs' growth with their host galaxies using the GIZMO code. In contrast to previous simulations, we developed a molecular cloud model by separating molecular-gas particles from the atomic-gas particles and then evolving them independently. During major mergers, we showed that the effect of the mass segregation of the atomic and molecular gas particles can enhance the dynamical friction of molecular particles. Consequently, molecular gas is substantially accreted onto the galactic centers that grows SMBHs from $10^{6}\, \rm M_\odot$ to $10^{9}\, \rm M_\odot$ within 300 Myr, explaining the rapid growth of SMBHs, and this accretion also triggers a violent starburst at the galactic center. Furthermore, We examined the impact of minor mergers on the bulge of a Milky-Way-like galaxy and found that the size and mass of the bulge can increase from 0.92 kpc to 1.9 kpc and from $4.7\times 10^{10}\, \rm M_\odot$ to $7\times 10^{10}\, \rm M_\odot$. 	
"Benchmarking energy consumption and latency for neuromorphic computing
  in condensed matter and particle physics"	http://arxiv.org/abs/2209.10481v2	2023-02-21T17:07:40Z	2022-09-21T16:33:44Z	  The massive use of artificial neural networks (ANNs), increasingly popular in many areas of scientific computing, rapidly increases the energy consumption of modern high-performance computing systems. An appealing and possibly more sustainable alternative is provided by novel neuromorphic paradigms, which directly implement ANNs in hardware. However, little is known about the actual benefits of running ANNs on neuromorphic hardware for use cases in scientific computing. Here we present a methodology for measuring the energy cost and compute time for inference tasks with ANNs on conventional hardware. In addition, we have designed an architecture for these tasks and estimate the same metrics based on a state-of-the-art analog in-memory computing (AIMC) platform, one of the key paradigms in neuromorphic computing. Both methodologies are compared for a use case in quantum many-body physics in two dimensional condensed matter systems and for anomaly detection at 40 MHz rates at the Large Hadron Collider in particle physics. We find that AIMC can achieve up to one order of magnitude shorter computation times than conventional hardware, at an energy cost that is up to three orders of magnitude smaller. This suggests great potential for faster and more sustainable scientific computing with neuromorphic hardware. 	
"Bias at a Second Glance: A Deep Dive into Bias for German Educational
  Peer-Review Data Modeling"	http://arxiv.org/abs/2209.10335v2	2022-09-22T13:08:04Z	2022-09-21T13:08:16Z	  Natural Language Processing (NLP) has become increasingly utilized to provide adaptivity in educational applications. However, recent research has highlighted a variety of biases in pre-trained language models. While existing studies investigate bias in different domains, they are limited in addressing fine-grained analysis on educational and multilingual corpora. In this work, we analyze bias across text and through multiple architectures on a corpus of 9,165 German peer-reviews collected from university students over five years. Notably, our corpus includes labels such as helpfulness, quality, and critical aspect ratings from the peer-review recipient as well as demographic attributes. We conduct a Word Embedding Association Test (WEAT) analysis on (1) our collected corpus in connection with the clustered labels, (2) the most common pre-trained German language models (T5, BERT, and GPT-2) and GloVe embeddings, and (3) the language models after fine-tuning on our collected data-set. In contrast to our initial expectations, we found that our collected corpus does not reveal many biases in the co-occurrence analysis or in the GloVe embeddings. However, the pre-trained German language models find substantial conceptual, racial, and gender bias and have significant changes in bias across conceptual and racial axes during fine-tuning on the peer-review data. With our research, we aim to contribute to the fourth UN sustainability goal (quality education) with a novel dataset, an understanding of biases in natural language education data, and the potential harms of not counteracting biases in language models for educational tasks. 	
"Artificial Intelligence and Innovation to Reduce the Impact of Extreme
  Weather Events on Sustainable Production"	http://arxiv.org/abs/2210.08962v1	2022-09-21T06:52:39Z	2022-09-21T06:52:39Z	  Frequent occurrences of extreme weather events substantially impact the lives of the less privileged in our societies, particularly in agriculture-inclined economies. The unpredictability of extreme fires, floods, drought, cyclones, and others endangers sustainable production and life on land (SDG goal 15), which translates into food insecurity and poorer populations. Fortunately, modern technologies such as Artificial Intelligent (AI), the Internet of Things (IoT), blockchain, 3D printing, and virtual and augmented reality (VR and AR) are promising to reduce the risk and impact of extreme weather in our societies. However, research directions on how these technologies could help reduce the impact of extreme weather are unclear. This makes it challenging to emploring digital technologies within the spheres of extreme weather. In this paper, we employed the Delphi Best Worst method and Machine learning approaches to identify and assess the push factors of technology. The BWM evaluation revealed that predictive nature was AI's most important criterion and role, while the mass-market potential was the less important criterion. Based on this outcome, we tested the predictive ability of machine elarning on a publilcly available dataset to affrm the predictive rols of AI. We presented the managerial and methodological implications of the study, which are crucial for research and practice. The methodology utilized in this study could aid decision-makers in devising strategies and interventions to safeguard sustainable production. This will also facilitate allocating scarce resources and investment in improving AI techniques to reduce the adverse impacts of extreme events. Correspondingly, we put forward the limitations of this, which necessitate future research. 	
"Deep learning reconstruction of sunspot vector magnetic fields for
  forecasting solar storms"	http://arxiv.org/abs/2209.09944v1	2022-09-20T18:42:09Z	2022-09-20T18:42:09Z	  Solar magnetic activity produces extreme solar flares and coronal mass ejections, which pose grave threats to electronic infrastructure and can significantly disrupt economic activity. It is therefore important to appreciate the triggers of explosive solar activity and develop reliable space-weather forecasting. Photospheric vector-magnetic-field data capture sunspot magnetic-field complexity and can therefore improve the quality of space-weather prediction. However, state-of-the-art vector-field observations are consistently only available from Solar Dynamics Observatory/Helioseismic and Magnetic Imager (SDO/HMI) since 2010, with most other current and past missions and observational facilities such as Global Oscillations Network Group (GONG) only recording line-of-sight (LOS) fields. Here, using an inception-based convolutional neural network, we reconstruct HMI sunspot vector-field features from LOS magnetograms of HMI as well as GONG with high fidelity (~ 90% correlation) and sustained flare-forecasting accuracy. We rebuild vector-field features during the 2003 Halloween storms, for which only LOS-field observations are available, and the CNN-estimated electric-current-helicity accurately captures the observed rotation of the associated sunspot prior to the extreme flares, showing a striking increase. Our study thus paves the way for reconstructing three solar cycles worth of vector-field data from past LOS measurements, which are of great utility in improving space-weather forecasting models and gaining new insights about solar activity. 	
"Characteristics of a Titanium Manganese redox flow battery based on
  Comsol"	http://arxiv.org/abs/2209.09904v1	2022-09-20T17:38:45Z	2022-09-20T17:38:45Z	  A simulation model and design of Titanium Manganese Redox Flow Battery (TMRFB) is proposed to study the distribution of dissociation rate, overpotential, current density, and electrode potential. TMRFB is one of the most promising new energy storages because of its high capacity and eco-friendly characteristics in the current condition of energy scarcity and environmental pollution. Moreover, Mn-based flow batteries are gaining popularity due to their inexpensive cost and high energy density in lieu of all vanadium redox flow batteries which are expensive. This research shows that the surface dissociation rate of Ti4+/ Ti3+ and Mn3+/Mn2+ ions are higher at the membrane and lower at the inlet where the velocity of the electrolyte flow is higher; Furthermore, our work reveals that when the thickness of the electrode is compressed from 4.5 mm to 3 mm, overpotential reduces whereas current density and electrode potential increases. The COMSOL Multiphysics software is used to solve the model's equations using the finite element approach. From the dissociation rate it is concluded that less potential is required at the membrane for the oxidation reduction reaction and with optimized electrolyte flow rate battery performance can be improved. Thus, electrode compression increases conductivity and battery performance. 	
Storage Management with Multi-Version Partitioned B-Trees	http://arxiv.org/abs/2209.09726v1	2022-09-20T13:59:36Z	2022-09-20T13:59:36Z	  Database Management Systems and K/V-Stores operate on updatable datasets -- massively exceeding the size of available main memory. Tree-based K/V storage management structures became particularly popular in storage engines. B+ Trees allow constant search performance, however write-heavy workloads yield in inefficient write patterns to secondary storage devices and poor performance characteristics. LSM-Trees overcome this issue by horizontal partitioning fractions of data - small enough to fully reside in main memory, but require frequent maintenance to sustain search performance.   Firstly, we propose Multi-Version Partitioned BTrees (MV-PBT) as sole storage and index management structure in key-sorted storage engines like K/V-Stores. Secondly, we compare MV-PBT against LSM-Trees. The logical horizontal partitioning in MV-PBT allows leveraging recent advances in modern B$^+$-Tree techniques in a small transparent and memory resident portion of the structure. Structural properties sustain steady read performance, yielding efficient write patterns and reducing write amplification.   We integrated MV-PBT in the WiredTiger KV storage engine. MV-PBT offers an up to 2x increased steady throughput in comparison to LSM-Trees and several orders of magnitude in comparison to B+ Trees in a YCSB workload. 	
"Quasi-spiral solution to the mixed intracluster medium and the universal
  entropy profile of galaxy clusters"	http://arxiv.org/abs/2209.09259v1	2022-09-19T18:00:02Z	2022-09-19T18:00:02Z	  Well-resolved galaxy clusters often show a large-scale quasi-spiral structure in deprojected density $\rho$ and temperature $T$ fields, delineated by a tangential discontinuity known as a cold front, superimposed on a universal radial entropy profile with a linear $K(r)\propto T\rho^{-2/3}\propto r$ adiabat. We show that a spiral structure provides a natural quasi-stationary solution for the mixed intracluster medium (ICM), introducing a modest pressure spiral that confines the locally buoyant or heavy plasma phases. The solution persists in the presence of uniform or differential rotation, and can accommodate both an inflow and an outflow. Hydrodynamic adiabatic simulations with perturbations that deposit angular momentum and mix the plasma thus asymptote to a self-similar spiral structure. We find similar spirals in Eulerian and Lagrangian simulations of 2D and 3D, merger and offset, clusters. The discontinuity surface is given in spherical coordinates $\{r,\theta,\phi\}$ by $\phi\propto \Phi(r)$, where $\Phi$ is the gravitational potential, combining a trailing spiral in the equatorial ($\theta=\pi/2$) plane and semicircles perpendicular to the plane, in resemblance of a snail shell. A local convective instability can develop between spiral windings, driving a modified global instability in sublinear $K(r)$ regions; evolved spirals thus imprint the observed $K\propto r$ onto the ICM even after they dissipate. The spiral structure brings hot and cold phases to close proximity, suggesting that the observed fast outflows could sustain the structure even in the presence of radiative cooling. 	
Effect of Pore Formation on Redox-Driven Phase Transformation	http://arxiv.org/abs/2209.09069v2	2023-03-06T17:49:06Z	2022-09-19T15:03:07Z	  When solid-state redox-driven phase transformations are associated with mass loss, vacancies are produced that develop into pores. These pores can influence the kinetics of certain redox and phase transformation steps. We investigated the structural and chemical mechanisms in and at pores in a combined experimental-theoretical study, using the reduction of iron oxide by hydrogen as a model system. The redox product (water) accumulates inside the pores and shifts the local equilibrium at the already reduced material back towards re-oxidation into cubic-Fe1-xO (where x refers to Fe deficiency, space group Fm3-m). This effect helps to understand the sluggish reduction of cubic-Fe1-xO by hydrogen, a key process for future sustainable steelmaking. 	
"Mapping STI ecosystems via Open Data: overcoming the limitations of
  conflicting taxonomies. A case study for Climate Change Research in Denmark"	http://arxiv.org/abs/2209.08920v1	2022-09-19T10:59:39Z	2022-09-19T10:59:39Z	  Science, Technology and Innovation (STI) decision-makers often need to have a clear vision of what is researched and by whom to design effective policies. Such a vision is provided by effective and comprehensive mappings of the research activities carried out within their institutional boundaries. A major challenge to be faced in this context is the difficulty in accessing the relevant data and in combining information coming from different sources: indeed, traditionally, STI data has been confined within closed data sources and, when available, it is categorised with different taxonomies. Here, we present a proof-of-concept study of the use of Open Resources to map the research landscape on the Sustainable Development Goal (SDG) 13-Climate Action, for an entire country, Denmark, and we map it on the 25 ERC panels. 	
Operationalizing Machine Learning: An Interview Study	http://arxiv.org/abs/2209.09125v1	2022-09-16T16:59:36Z	2022-09-16T16:59:36Z	  Organizations rely on machine learning engineers (MLEs) to operationalize ML, i.e., deploy and maintain ML pipelines in production. The process of operationalizing ML, or MLOps, consists of a continual loop of (i) data collection and labeling, (ii) experimentation to improve ML performance, (iii) evaluation throughout a multi-staged deployment process, and (iv) monitoring of performance drops in production. When considered together, these responsibilities seem staggering -- how does anyone do MLOps, what are the unaddressed challenges, and what are the implications for tool builders?   We conducted semi-structured ethnographic interviews with 18 MLEs working across many applications, including chatbots, autonomous vehicles, and finance. Our interviews expose three variables that govern success for a production ML deployment: Velocity, Validation, and Versioning. We summarize common practices for successful ML experimentation, deployment, and sustaining production performance. Finally, we discuss interviewees' pain points and anti-patterns, with implications for tool design. 	
Color-Perception-Guided Display Power Reduction for Virtual Reality	http://arxiv.org/abs/2209.07610v2	2022-09-19T22:57:49Z	2022-09-15T21:12:38Z	"  Battery life is an increasingly urgent challenge for today's untethered VR and AR devices. However, the power efficiency of head-mounted displays is naturally at odds with growing computational requirements driven by better resolution, refresh rate, and dynamic ranges, all of which reduce the sustained usage time of untethered AR/VR devices. For instance, the Oculus Quest 2, under a fully-charged battery, can sustain only 2 to 3 hours of operation time. Prior display power reduction techniques mostly target smartphone displays. Directly applying smartphone display power reduction techniques, however, degrades the visual perception in AR/VR with noticeable artifacts. For instance, the ""power-saving mode"" on smartphones uniformly lowers the pixel luminance across the display and, as a result, presents an overall darkened visual perception to users if directly applied to VR content.   Our key insight is that VR display power reduction must be cognizant of the gaze-contingent nature of high field-of-view VR displays. To that end, we present a gaze-contingent system that, without degrading luminance, minimizes the display power consumption while preserving high visual fidelity when users actively view immersive video sequences. This is enabled by constructing a gaze-contingent color discrimination model through psychophysical studies, and a display power model (with respect to pixel color) through real-device measurements. Critically, due to the careful design decisions made in constructing the two models, our algorithm is cast as a constrained optimization problem with a closed-form solution, which can be implemented as a real-time, image-space shader. We evaluate our system using a series of psychophysical studies and large-scale analyses on natural images. Experiment results show that our system reduces the display power by as much as 24% with little to no perceptual fidelity degradation. "	
ESAVE: Estimating Server and Virtual Machine Energy	http://arxiv.org/abs/2209.07394v1	2022-09-15T15:55:09Z	2022-09-15T15:55:09Z	  Sustainable software engineering has received a lot of attention in recent times, as we witness an ever-growing slice of energy use, for example, at data centers, as software systems utilize the underlying infrastructure. Characterizing servers for their energy use accurately without being intrusive, is therefore important to make sustainable software deployment choices. In this paper, we introduce ESAVE which is a machine learning-based approach that leverages a small set of hardware attributes to characterize a server or virtual machine's energy usage across different levels of utilization. This is based upon an extensive exploration of multiple ML approaches, with a focus on a minimal set of required attributes, while showcasing good accuracy. Early validations show that ESAVE has only around 12% average prediction error, despite being non-intrusive. 	
"Complex systems science and urban science: towards applications to
  sustainability trade-offs in territorial systems"	http://arxiv.org/abs/2209.07373v1	2022-09-15T15:37:09Z	2022-09-15T15:37:09Z	  Urban systems are at the core of current sustainability concerns, and their study from a complexity perspective has a long history in several disciplines. We survey this literature and discuss future research directions relevant to sustainable planning, in particular the construction of integrative approaches. We finally illustrate this research program with the coupling of urban simulation models to explore trade-offs between sustainable development goals in systems of cities. 	
"Identifying research supporting the United Nations Sustainable
  Development Goals"	http://arxiv.org/abs/2209.07285v4	2022-10-13T14:12:34Z	2022-09-15T13:26:13Z	  The United Nations (UN) Sustainable Development Goals (SDGs) challenge the global community to build a world where no one is left behind. Recognizing that research plays a fundamental part in supporting these goals, attempts have been made to classify research publications according to their relevance in supporting each of the UN's SDGs. In this paper, we outline the methodology that we followed when mapping research articles to SDGs and which is adopted by Times Higher Education in their Social Impact rankings. We also discuss various aspects in which the methodology can be improved and generalized to other types of content apart from research articles. The results presented in this paper are the outcome of the SDG Research Mapping Initiative that was established as a partnership between the University of Southern Denmark, the Aurora European Universities Alliance (represented by Vrije Universiteit Amsterdam), the University of Auckland, and Elsevier to bring together broad expertise and share best practices on identifying research contributions to UN's Sustainable Development Goals. 	
Diversity beyond density: experienced social mixing of urban streets	http://arxiv.org/abs/2209.07041v1	2022-09-15T04:49:52Z	2022-09-15T04:49:52Z	  Urban density, in the form of residents' and visitors' concentration, is long considered to foster diverse exchanges of interpersonal knowledge and skills, which are intrinsic to sustainable human settlements. However, with current urban studies primarily devoted to city and district-level analysis, we cannot unveil the elemental connection between urban density and diversity. Here we use an anonymized and privacy-enhanced mobile data set of 0.5 million opted-in users from three metropolitan areas in the U.S to show that at the scale of urban streets, density is not the only path to diversity. We represent the diversity of each street with the Experienced Social Mixing (ESM), which describes the chances of people meeting diverse income groups throughout their daily experience. We conduct multiple experiments and show that the concentration of visitors only explains 26% of street-level ESM. However, adjacent amenities, residential diversity, and income level account for 44% of the ESM. Moreover, using longitudinal business data, we show that streets with an increased number of food businesses have seen an increased ESM from 2016 to 2018. Lastly, although streets with more visitors are more likely to have crime, diverse streets tend to have fewer crimes. These findings suggest that cities can leverage many tools beyond density to curate a diverse and safe street experience for people. 	
"Bioeconomic analysis of harvesting within a predator-prey system: A case
  study in the Chesapeake Bay fisheries"	http://arxiv.org/abs/2209.06944v2	2023-01-12T16:46:16Z	2022-09-14T21:29:41Z	  Sustainable use of biological resources is very important as over exploitation on the long run may lead to stock depletion, which in turn may threaten biodiversity. The Chesapeake Bay is an extremely complex ecosystem, and sustainable harvesting of its fisheries is essential both for the ecosystem's biodiversity and economic prosperity of the area. Here, we use ecosystem based mathematical modeling to study the population dynamics with harvesting of two key fishes in the Chesapeake Bay, the Atlantic Menhaden (Brevoortia tyrannus) as a prey and the Striped Bass (Morone saxatilis) as a predator. We start by fitting the generalized Lotka-Volterra model to actual time series abundance data of the two species obtained from fisheries in the Bay. We derive conditions for the existence of the bio-economic equilibrium and investigate the stability and the resilience of the biological system. We study the maximum sustainable yield, maximum economic yield, and resilience maximizing yield policies and their effects on the fisheries long term sustainability, particularly with respect to the menhaden-bass population dynamics. This study may be used by policy-makers to balance the economic and ecological harvesting goals while managing the populations of Atlantic menhaden and striped bass in the Chesapeake Bay fisheries. 	
Time Series Prediction for Food sustainability	http://arxiv.org/abs/2209.06889v1	2022-09-14T19:27:31Z	2022-09-14T19:27:31Z	  With exponential growth in the human population, it is vital to conserve natural resources without compromising on producing enough food to feed everyone. Doing so can improve people's livelihoods, health, and ecosystems for the present and future generations. Sustainable development, a paradigm of the United Nations, is rooted in food, crop, livestock, forest, population, and even the emission of gases. By understanding the overall usage of natural resources in different countries in the past, it is possible to forecast the demand in each country. The proposed solution consists of implementing a machine learning system using a statistical regression model that can predict the top k products that would endure a shortage in each country in a specific period in the future. The prediction performance in terms of absolute error and root mean square error show promising results due to its low errors. This solution could help organizations and manufacturers understand the productivity and sustainability needed to satisfy the global demand. 	
"Dynamic Switching of GOP configurations in High Efficiency Video Coding
  (HEVC) using Relational Databases for Multi-objective Optimization"	http://arxiv.org/abs/2212.14669v1	2022-09-14T18:55:25Z	2022-09-14T18:55:25Z	  Our current technological era is flooded with smart devices that provide significant computational resources that require optimal video communications solutions. Optimal and dynamic management of video bitrate, quality and energy demands needs to take into account their inter-dependencies. With emerging network generations providing higher bandwidth rates, there is also a growing need to communicate video with the best quality subject to the availability of resources such as computational power and available bandwidth. Similarly, for accommodating multiple users, there is a need to minimize bitrate requirements while sustaining video quality for reasonable encoding times.   This thesis focuses on providing an efficient mechanism for deriving optimal solutions for HEVC codec based on switching GOP configurations. The approach provides a basic system for multi-objective optimization with constraints on power, video quality, bitrate. This is accomplished by utilizing a recently introduced framework known as Dynamically Reconfigurable Architectures for Time-varying Image Constraints (DRASTIC) in HEVC/H.265 codec with six different GOP configurations to support optimization modes for minimum bitrate, maximum quality and minimum computational time (minimum energy in constant power configuration) mode of operation. Pareto-Optimal GOP configs are used in implementing these DRASTIC modes. 	
"Beyond Learning from Next Item: Sequential Recommendation via
  Personalized Interest Sustainability"	http://arxiv.org/abs/2209.06644v1	2022-09-14T13:47:58Z	2022-09-14T13:47:58Z	  Sequential recommender systems have shown effective suggestions by capturing users' interest drift. There have been two groups of existing sequential models: user- and item-centric models. The user-centric models capture personalized interest drift based on each user's sequential consumption history, but do not explicitly consider whether users' interest in items sustains beyond the training time, i.e., interest sustainability. On the other hand, the item-centric models consider whether users' general interest sustains after the training time, but it is not personalized. In this work, we propose a recommender system taking advantages of the models in both categories. Our proposed model captures personalized interest sustainability, indicating whether each user's interest in items will sustain beyond the training time or not. We first formulate a task that requires to predict which items each user will consume in the recent period of the training time based on users' consumption history. We then propose simple yet effective schemes to augment users' sparse consumption history. Extensive experiments show that the proposed model outperforms 10 baseline models on 11 real-world datasets. The codes are available at https://github.com/dmhyun/PERIS. 	
"Magnetization switching in polycrystalline Mn3Sn thin film induced by
  self-generated spin-polarized current"	http://arxiv.org/abs/2209.06503v1	2022-09-14T09:00:43Z	2022-09-14T09:00:43Z	  Electrical manipulation of spins is essential to design state-of-the-art spintronic devices and commonly relies on the spin current injected from a second heavy-metal material. The fact that chiral antiferromagnets produce spin current inspires us to explore the magnetization switching of chiral spins using self-generated spin torque. Here, we demonstrate the electric switching of noncollinear antiferromagnetic state in Mn3Sn by observing a crossover from conventional spin-orbit torque to the self-generated spin torque when increasing the MgO thickness in Ta/MgO/Mn3Sn polycrystalline films. The spin current injection from the Ta layer can be controlled and even blocked by varying the MgO thickness, but the switching sustains even at a large MgO thickness. Furthermore, the switching polarity reverses when the MgO thickness exceeds around 3 nm, which cannot be explained by the spin-orbit torque scenario due to spin current injection from the Ta layer. Evident current-induced switching is also observed in MgO/Mn3Sn and Ti/Mn3Sn bilayers, where external injection of spin Hall current to Mn3Sn is negligible. The inter-grain spin-transfer torque induced by spin-polarized current explains the experimental observations. Our findings provide an alternative pathway for electrical manipulation of non-collinear antiferromagnetic state without resorting to the conventional bilayer structure. 	
Using Genetic Algorithms to Simulate Evolution	http://arxiv.org/abs/2209.06822v1	2022-09-14T00:23:06Z	2022-09-14T00:23:06Z	  Evolution is the theory that plants and animals today have come from kinds that have existed in the past. Scientists such as Charles Darwin and Alfred Wallace dedicate their life to observe how species interact with their environment, grow, and change. We are able to predict future changes as well as simulate the process using genetic algorithms. Genetic Algorithms give us the opportunity to present multiple variables and parameters to an environment and change values to simulate different situations. By optimizing genetic algorithms to hold entities in an environment, we are able to assign varying characteristics such as speed, size, and cloning probability, to the entities to simulate real natural selection and evolution in a shorter period of time. Learning about how species grow and evolve allows us to find ways to improve technology, help animals going extinct to survive, and figure* out how diseases spread and possible ways of making an environment uninhabitable for them. Using data from an environment including genetic algorithms and parameters of speed, size, and cloning percentage, the ability to test several changes in the environment and observe how the species interacts within it appears. After testing different environments with a varied amount of food while keeping the number of starting population at 10 entities, it was found that an environment with a scarce amount of food was not sustainable for small and slow entities. All environments displayed an increase in speed, but the environments that were richer in food allowed for the entities to live for the entire duration of 50 generations, as well as allowed the population to grow significantly. 	
SEER: Sustainable E-commerce with Environmental-impact Rating	http://arxiv.org/abs/2209.06156v1	2022-09-13T16:55:27Z	2022-09-13T16:55:27Z	"  With online shopping gaining massive popularity over the past few years, e-commerce platforms can play a significant role in tackling climate change and other environmental problems. In this study, we report that the ""attitude-behavior"" gap identified by prior sustainable consumption literature also exists in an online setting. We propose SEER, a concept design for online shopping websites to help consumers make more sustainable choices. We introduce explainable environmental impact ratings to increase knowledge, trust, and convenience for consumers willing to purchase eco-friendly products. In our quasi-randomized case-control experiment with 98 subjects across the United States, we found that the case group using SEER demonstrates significantly more eco-friendly consumption behavior than the control group using a traditional e-commerce setting. While there are challenges in generating reliable explanations and environmental ratings for products, if implemented, in the United States alone, SEER has the potential to reduce approximately 2.88 million tonnes of carbon emission every year. "	
LegalBench: Prototyping a Collaborative Benchmark for Legal Reasoning	http://arxiv.org/abs/2209.06120v1	2022-09-13T16:11:54Z	2022-09-13T16:11:54Z	  Can foundation models be guided to execute tasks involving legal reasoning? We believe that building a benchmark to answer this question will require sustained collaborative efforts between the computer science and legal communities. To that end, this short paper serves three purposes. First, we describe how IRAC-a framework legal scholars use to distinguish different types of legal reasoning-can guide the construction of a Foundation Model oriented benchmark. Second, we present a seed set of 44 tasks built according to this framework. We discuss initial findings, and highlight directions for new tasks. Finally-inspired by the Open Science movement-we make a call for the legal and computer science communities to join our efforts by contributing new tasks. This work is ongoing, and our progress can be tracked here: https://github.com/HazyResearch/legalbench. 	
"A Distributed Acoustic Sensor System for Intelligent Transportation
  using Deep Learning"	http://arxiv.org/abs/2209.05978v1	2022-09-13T13:23:30Z	2022-09-13T13:23:30Z	  Intelligent transport systems (ITS) are pivotal in the development of sustainable and green urban living. ITS is data-driven and enabled by the profusion of sensors ranging from pneumatic tubes to smart cameras. This work explores a novel data source based on optical fibre-based distributed acoustic sensors (DAS) for traffic analysis. Detecting the type of vehicle and estimating the occupancy of vehicles are prime concerns in ITS. The first is motivated by the need for tracking, controlling, and forecasting traffic flow. The second targets the regulation of high occupancy vehicle lanes in an attempt to reduce emissions and congestion. These tasks are often conducted by individuals inspecting vehicles or through the use of emerging computer vision technologies. The former is not scale-able nor efficient whereas the latter is intrusive to passengers' privacy. To this end, we propose a deep learning technique to analyse DAS signals to address this challenge through continuous sensing and without exposing personal information. We propose a deep learning method for processing DAS signals and achieve 92% vehicle classification accuracy and 92-97% in occupancy detection based on DAS data collected under controlled conditions. 	
"Don't Complete It! Preventing Unhelpful Code Completion for Productive
  and Sustainable Neural Code Completion Systems"	http://arxiv.org/abs/2209.05948v2	2023-02-01T09:52:21Z	2022-09-13T12:43:41Z	  Currently, large pre-trained language models are widely applied in neural code completion systems. Though large code models significantly outperform their smaller counterparts, around 70% displayed code completions from Copilot are not accepted by developers. Being reviewed but not accepted, their help to developer productivity is considerably limited. Even worse, considering the high cost of the large code models, it is a huge waste of computing resources and energy. To fill this significant gap, we first investigate the prompts of unhelpful code completions, and empirically find four observable patterns that cause such prompts, all of which are inherent, namely, they can hardly be addressed by improving the accuracy of the model. This demonstrates the feasibility of identifying such prompts based on the prompts themselves. Motivated by this finding, we propose an early-rejection mechanism to turn down low-return prompts by foretelling the code completion qualities without sending them to the code completion system. Furthermore, we propose a lightweight Transformer-based estimator to demonstrate the feasibility of the mechanism. The experimental results show that the proposed estimator helps save 23.3% of computational cost measured in floating-point operations for the code completion systems, and 80.2% of rejected prompts lead to unhelpful completion 	
Sustainable Venture Capital	http://arxiv.org/abs/2209.10518v1	2022-09-13T01:17:39Z	2022-09-13T01:17:39Z	  Sustainability initiatives are set to benefit greatly from the growing involvement of venture capital, in the same way that other technological endeavours have been enabled and accelerated in the post-war period. With the spoils increasingly being shared between shareholders and other stakeholders, this requires a more nuanced view than the finance-first methodologies deployed to date. Indeed, it is possible for a venture-backed sustainability startup to deliver outstanding results to society in general without returning a cent to investors, though the most promising outcomes deliver profit with purpose, satisfying all stakeholders in ways that make existing 'extractive' venture capital seem hollow.   To explore this nascent area, a review of related research was conducted and social entrepreneurs & investors interviewed to construct a questionnaire assessing the interests and intentions of current & future ecosystem participants. Analysis of 114 responses received via several sampling methods revealed statistically significant relationships between investing preferences and genders, generations, sophistication, and other variables, all the way down to the level of individual UN Sustainable Development Goals (SDGs). 	
"The assembly of dusty galaxies at $z \geq 4$: the build-up of stellar
  mass and its scaling relations with hints from early JWST data"	http://arxiv.org/abs/2209.05496v2	2022-12-16T15:14:06Z	2022-09-12T18:00:01Z	  The increasing number of distant galaxies observed with ALMA by the ALPINE and REBELS surveys and the early release observations of the JWST promise to revolutionize our understanding of cosmic star formation and the assembly of normal, dusty galaxies. Here we introduce a new suite of cosmological simulations performed with \texttt{dustyGadget} to interpret high-redshift data. We investigate the comoving star formation history, the stellar mass density and a number of galaxy scaling relations such as the galaxy main sequence, the stellar-to-halo mass and dust-to-stellar mass relations at $z > 4$. The predicted star formation rate and total stellar mass density rapidly increase in time with a remarkable agreement with available observations, including recent JWST ERO and DD-ERS data at $z \geq 8$. A well defined galaxy main sequence is found already at $z < 10$ following a non evolving power-law, which - if extrapolated at high-mass end - is in agreement with JWST, REBELS, and ALPINE data. This is consistent with a star formation efficiently sustained by gas accretion and a specific star formation rate increasing with redshift, as established by recent observations. A population of low-mass galaxies ($8 < \rm{Log(M_\star/M_\odot)} < 9$) at $z \leq 6 - 7$ that exceeds some of the current estimates of the stellar mass function is also at the origin of the scatter in the stellar-to-halo mass relation. Future JWST observations will provide invaluable constraints on these low-mass galaxies, helping to shed light on their role in cosmic evolution. 	
"Merging and disconnecting resonance tongues in a pulsing excitable
  microlaser with delayed optical feedback"	http://arxiv.org/abs/2209.05304v1	2022-09-12T15:12:06Z	2022-09-12T15:12:06Z	  Excitability, encountered in numerous fields from biology to neurosciences and optics, is a general phenomenon characterized by an all-or-none response of a system to an external perturbation. When subject to delayed feedback, excitable systems can sustain multistable pulsing regimes, which are either regular or irregular time sequences of pulses reappearing every delay time. Here, we investigate an excitable microlaser subject to delayed optical feedback and study the emergence of complex pulsing dynamics, including periodic, quasiperiodic and irregular pulsing regimes. This work is motivated by experimental observations showing these different types of pulsing dynamics. A suitable mathematical model, written as a system of delay differential equations, is investigated through an in-depth bifurcation analysis. We demonstrate that resonance tongues play a key role in the emergence of complex dynamics, including non-equidistant periodic pulsing solutions and chaotic pulsing. The structure of resonance tongues is shown to depend very sensitively on the pump parameter. Successive saddle transitions of bounding saddle-node bifurcations constitute a merging process that results in unexpectedly large locking regions, which subsequently disconnect from the relevant torus bifurcation curve; the existence of such unconnected regions of periodic pulsing is in excellent agreement with experimental observations. As we show, the transition to unconnected resonance regions is due to a general mechanism: the interaction of resonance tongues locally at an extremum of the rotation number on a torus bifurcation curve. We present and illustrate the two generic cases of disconnecting and of disappearing resonance tongues. Moreover, we show how a maximum and a minimum of the rotation number appears naturally when two torus bifurcation curves undergo a saddle transition (where they connect differently). 	
"Sustaining Dynamic Traffic in Dense Urban Areas with High Altitude
  Platform Stations (HAPS)"	http://arxiv.org/abs/2209.05127v2	2023-02-24T10:06:57Z	2022-09-12T10:19:10Z	  The impact of information and communication technologies on global energy consumption is increasing every year, and mobile networks account for a significant portion of it. More than 50% of the total energy consumption of mobile networks is issued from radio access networks (RANs), due mainly to the rapid penetration of data-intensive applications and the increasing heterogeneity, dynamicity, and unpredictability of traffic. To tackle these high-demanding problems, RAN densification through the installation of additional base stations in high-demand areas is conventionally used. However, this leads to inefficient energy use and over-provisioning issues. In this context, high altitude platform stations (HAPS) may be used to complement RANs and sustain their services in densely populated areas, where traffic can peak unpredictably. Due to their wide coverage areas, substantial communication payloads, and green energy model, HAPS super macro base stations (SMBSs) are capable of handling the massive and dynamic mobile data traffic of ground users. In this paper, we show how HAPS-SMBSs can complement RANs and serve the dynamic and unpredictable traffic demands of users in an energy-efficient manner. Through the simulation of a case study, we demonstrate the performance of a HAPS-SMBS compared to the conventional RAN densification method and analyze the two approaches in terms of sustainability. 	
"Empirically grounded agent-based policy evaluation of the adoption of
  sustainable lighting under the European Ecodesign Directive"	http://arxiv.org/abs/2209.05109v1	2022-09-12T09:32:17Z	2022-09-12T09:32:17Z	  Twelve years ago, the European Union began with the gradual phase-out of energy-inefficient incandescent light bulbs under the Ecodesign Directive. In this work, we implement an agent-based simulation to model the consumer behaviour in the EU lighting market with the goal to explain consumer behaviour and explore alternative policies. Agents are based on the Consumat II model, have individual preferences based on empirical market research, gather experience from past actions, and socially interact with each other in a dynamic environment. Our findings suggest that the adoption of energy-friendly lighting alternatives was hindered by a low level of consumer interest combined with high-enough levels of satisfaction about incandescent bulbs and that information campaigns can partially address this. These findings offer insight into both individual-level driving forces of behaviour and society-level outcomes in a niche market. With this, our work demonstrates the strengths of agent-based models for policy generation and evaluation. 	
"Systems-theoretic Hazard Analysis of Digital Human-System Interface
  Relevant to Reactor Trip"	http://arxiv.org/abs/2209.05480v1	2022-09-11T22:05:31Z	2022-09-11T22:05:31Z	  Human-system interface is one of the key advanced design features applied to modern digital instrumentation and control systems of nuclear power plants. The conventional design is based on a compact workstation-based system within the control room. The compact workstation provides both a strategic operating environment while also a convenient display for plant status information necessary to the operator. The control environment is further enhanced through display panels, visual and auditory alarms, and procedure systems. However, just like the legacy control, the HSI should incorporate diversity to demonstrate sufficient defense-in-depth protection against common cause failures of the safety system. Furthermore, the vulnerability of the HSI is affected by a plethora of factors, such as human error, cyberattacks, software common cause failures, etc., that complicate the design and analysis. Therefore, this work aims to identify and evaluate existing system vulnerabilities to support the licensing, deployment and operation of HSI designs, especially the functions that are relevant to a reactor trip. We performed a systematic hazard analysis to investigate potential vulnerabilities within the HSI design using the novel redundancy-guided systems-theoretic hazard analysis. This method was developed and demonstrated by Idaho National Laboratory under a project initiated by the Risk-Informed Systems Analysis Pathway of the U.S. Department of Energy's Light Water Reactor Sustainability Program. The goal of the project is to develop a strong technical basis for risk assessment strategies to support effective, reliable, and licensable digital instrumentation and control technologies. 	
"PyPSA-Earth. A New Global Open Energy System Optimization Model
  Demonstrated in Africa"	http://arxiv.org/abs/2209.04663v1	2022-09-10T13:14:20Z	2022-09-10T13:14:20Z	  Macro-energy system modelling is used by decision-makers to steer the global energy transition toward an affordable, sustainable and reliable future. Closed-source models are the current standard for most policy and industry decisions. However, open models have proven to be competitive alternatives that promote science, robust technical analysis, collaboration and transparent policy decision-making. Yet, two issues slow the adoption: open models are often designed with limited geographic scope, hindering synergies from collaboration, or are based on low spatially resolved data, limiting their use. Here we introduce PyPSA-Earth, the first open-source global energy system model with data in high spatial and temporal resolution. It enables large-scale collaboration by providing a tool that can model the world energy system or any subset of it. This work is derived from the European PyPSA-Eur model using new data and functions. It is suitable for operational as well as combined generation, storage and transmission expansion studies. The model provides two main features: (1) customizable data extraction and preparation scripts with global coverage and (2) a PyPSA energy modelling framework integration. The data includes electricity demand, generation and medium to high-voltage networks from open sources, yet additional data can be further integrated. A broad range of clustering and grid meshing strategies help adapt the model to computational and practical needs. A data validation for the entire African continent is performed and the optimization features are tested with a 2060 net-zero planning study for Nigeria. The demonstration shows that the presented developments can build a highly detailed energy system model for energy planning studies to support policy and technical decision-making. We welcome joining forces to address the challenges of the energy transition together. 	
"A Power Efficiency Metric for Comparing Energy Consumption in Future
  Wireless Networks in the Millimeter Wave and Terahertz bands"	http://arxiv.org/abs/2209.04627v2	2023-01-14T11:22:06Z	2022-09-10T09:00:37Z	"  Future wireless cellular networks will utilize millimeter-wave and sub-THz frequencies and deploy small-cell base stations to achieve data rates on the order of hundreds of Gigabits per second per user. The move to sub-THz frequencies will require attention to sustainability and reduction of power whenever possible to reduce the carbon footprint while maintaining adequate battery life for the massive number of resource-constrained devices to be deployed. This article analyzes power consumption of future wireless networks using a new metric, the power waste factor ($ W $), which shows promise for the study and development of ""green G"" - green technology for future wireless networks. Using $ W $, power efficiency can be considered by quantifying the power wasted by all devices on a signal path in a cascade. We then show that the consumption efficiency factor ($CEF$), defined as the ratio of the maximum data rate achieved to the total power consumed, is a novel and powerful measure of power efficiency that shows less energy per bit is expended as the cell size shrinks and carrier frequency and channel bandwidth increase. Our findings offer a standard approach to calculating and comparing power consumption and energy efficiency. "	
Social Shaping of Dynamic Multi-Agent Systems over a Finite Horizon	http://arxiv.org/abs/2209.04621v1	2022-09-10T08:43:18Z	2022-09-10T08:43:18Z	  This paper studies self-sustained dynamic multiagent systems (MAS) for decentralized resource allocation operating at a competitive equilibrium over a finite horizon. The utility of resource consumption, along with the income from resource exchange, forms each agent's payoff which is aimed to be maximized. Each utility function is parameterized by individual preferences which can be designed by agents independently. By shaping these preferences and proposing a set of utility functions, we can guarantee that the optimal resource price at the competitive equilibrium always remains socially acceptable, i.e., it never violates a given threshold that indicates affordability. First, we show this problem is solvable at the conceptual level under some convexity assumptions. Then, as a benchmark case, we consider quadratic MAS and formulate the associated social shaping problem as a multi-agent LQR problem which enables us to propose explicit utility sets using quadratic programming and dynamic programming. Finally, a numerical algorithm is presented for calculating the range of the preference function parameters which guarantee a socially accepted price. Some illustrative examples are given to examine the effectiveness of the proposed methods. 	
"Visible Light-Driven C-C Coupling Reaction of Terminal Alkynes at
  Atmospheric Temperature and Pressure Reaction Conditions using Hybrid Cu2O-Pd
  Nanostructures"	http://arxiv.org/abs/2209.04568v1	2022-09-10T01:24:57Z	2022-09-10T01:24:57Z	  Carbon-carbon (C-C) coupling reactions are widely used reactions in the production of fine chemicals, agrochemicals, and pharmaceuticals. In our recent contribution (Green Chemistry, 2019, 21, 5284-5290), cuprous oxide (Cu2O) nanospheres are shown to be efficient catalysts for C-C coupling reactions of terminal alkynes such as phenylacetylene. Specifically, Cu2O nanospheres are shown to successfully catalyze oxidative C-C homocoupling reaction of phenylacetylene to form a coupling product, diphenyl diacetylene (DPDA). However, these Cu2O nanocatalyst requires a relatively high temperature of ~110 0C. Herein, we report that photocatalysts built on hybrid palladium nanoclusters decorated on Cu2O (i.e., Cu2O-Pd) can utilize visible light as energy input and successfully catalyze oxidative homocoupling of phenylacetylene at atmospheric temperature and pressure reaction condition. This was displayed by the comparison of oxidative homocoupling reactions both in the presence and without the presence of visible light. Our findings indicate that photocatalysts through Cu2O-Pd nanospheres present to be a logical substitute, moving toward more efficient and sustainable industrial processes. 	
"Evolution, structure and topology of self-generated turbulent
  reconnection layers"	http://arxiv.org/abs/2209.04492v1	2022-09-09T18:44:37Z	2022-09-09T18:44:37Z	"  We present a 3D MHD simulation of two merging flux ropes exhibiting self-generated and self-sustaining turbulent reconnection (SGTR) that is fully 3D and fast. The exploration of SGTR is crucial for understanding the relationship between MHD turbulence and magnetic reconnection in astrophysical contexts including the solar corona. We investigate the pathway towards SGTR and apply novel tools to analyse the structure and topology of the reconnection layer. The simulation proceeds from 2.5D Sweet-Parker reconnection to 2.5D nonlinear tearing, followed by a dynamic transition to a final SGTR phase that is globally quasi-stationary. The transition phase is dominated by a kink instability of a large ""cat-eye"" flux rope and the proliferation of a broad stochastic layer. The reconnection layer has two general characteristic thickness scales which correlate with the reconnection rate and differ by a factor of approximately six: an inner scale corresponding with current and vorticity densities, turbulent fluctuations, and outflow jets, and an outer scale associated with field line stochasticity. The effective thickness of the reconnection layer is the inner scale of the effective reconnection electric field produced by turbulent fluctuations, not the stochastic thickness. The dynamics within the reconnection layer are closely linked with flux rope structures that are highly topologically complicated. Explorations of the flux rope structures and distinctive intermediate regions between the inner core and stochastic separatrices (""SGTR wings"") are potentially key to understanding SGTR. The study concludes with a discussion on the apparent dualism between plasmoid-mediated and stochastic perspectives on SGTR. "	
"Magnetically confined mountains on accreting neutron stars with
  multipole magnetic fields"	http://arxiv.org/abs/2209.04352v1	2022-09-09T15:29:39Z	2022-09-09T15:29:39Z	  Magnetically confined mountains on accreting neutron stars are candidates for producing continuous gravitational waves. We formulate a magnetically confined mountain on a neutron star with strong multipole magnetic fields and obtain some sequences of numerical solutions. We find that the mass ellipticity of the mountain increases by one order of magnitude if the neutron star has strong multipole magnetic fields. As matter accretes on to the magnetic pole, the size of the mountain increases and the magnetic fields are buried. If the neutron star has a dipole magnetic field, the dipole magnetic field is buried and transformed into multipole components. By contrast, if the neutron star has both dipole and strong multipole magnetic fields, the multipole magnetic fields are buried and transformed into a negative dipole component. We also calculate magnetically confined mountains with toroidal magnetic fields and find that the ellipticity becomes slightly smaller when the mountain has toroidal magnetic fields. If the multipole magnetic fields are buried, they sustain the intense toroidal magnetic field near the stellar surface, and the ratio of the toroidal magnetic field to the poloidal magnetic field is close to 100. The hidden strong toroidal magnetic fields are sustained by the buried multipole magnetic fields. 	
"Directly tracing cool filamentary accretion over >100 kpc into the
  interstellar medium of a quasar host at z=1"	http://arxiv.org/abs/2209.04245v2	2022-11-11T17:45:26Z	2022-09-09T11:13:57Z	  We report the discovery of giant (50-100 kpc) [O II] emitting nebulae with the Multi-Unit Spectroscopic Explorer (MUSE) in the field of TXS 0206-048, a luminous quasar at z=1.13. Down-the-barrel UV spectra of the quasar show absorption at velocities coincident with those of the extended nebulae, enabling new insights into inflows and outflows around the quasar host. One nebula exhibits a filamentary morphology extending over 120 kpc from the halo toward the quasar and intersecting with another nebula surrounding the quasar host with a radius of 50 kpc. This is the longest cool filament observed to-date and arises at higher redshift and in a less massive system than those in cool-core clusters. The filamentary nebula has line-of-sight velocities >300 km/s from nearby galaxies but matches that of the nebula surrounding the quasar host where they intersect, consistent with accretion of cool inter- or circum-galactic medium or cooling hot halo gas. The kinematics of the nebulae surrounding the quasar host are unusual and complex, with redshifted and blueshifted spiral-like structures. The emission velocities at 5-10 kpc from the quasar match those of inflowing absorbing gas observed in UV spectra of the quasar. Together, the extended nebulae and associated redshifted absorption represent a compelling case of cool, filamentary gas accretion from halo scales into the extended interstellar medium and toward the nucleus of a massive quasar host. The inflow rate implied by the combined emission and absorption constraints is well below levels required to sustain the quasar's radiative luminosity, suggesting anisotropic or variable accretion. 	
"Impact of automation during innovative remanufacturing processes in
  circular economy: a state of the art"	http://arxiv.org/abs/2209.04040v1	2022-09-08T21:39:09Z	2022-09-08T21:39:09Z	  With the increasing demand of raw materials nowadays, and the decrease in supplies, the industrial sector is suffering. The environment and the society are also indirectly affected. The goal to reach a sustainable development imposes several studies on the economic, environmental and community level. The aim of this paper is to provide an overview of the existing body of literature on automated remanufacturing, and its potential impacts on the three pillars of sustainability. A particular interest is given to the growing use of cobots promoted by the principle of industry 4.0. The investigation that covers each part of the remanufacturing process will help in formalizing an approach about the automation of such processes. It highlights the challenges found and aims to improve the remanufacturing sector towards a more sustainable industry. 	
Ultimate Limit of Future Colliders	http://arxiv.org/abs/2209.04009v1	2022-09-08T19:22:05Z	2022-09-08T19:22:05Z	  With seven operational colliders in the world and two under construction, the international particle physics community not only actively explores options for the next facilities for detailed studies of the Higgs/electroweak physics and beyond-the-LHC energy frontier, but also seeks a clear picture of the limits of the colliding beams method. In this paper, we try to consolidate various recent efforts in identifying physics limits of colliders in conjunction with societal sustainability, and share our thoughts about the perspective of reaching the ultimate collider that is at the quantum limit. 	
Dynamics of real-time forecasting failure and recovery due to data gaps	http://arxiv.org/abs/2209.03413v1	2022-09-08T12:57:57Z	2022-09-08T12:57:57Z	  Real-time forecasting is important to the society. It uses continuous data streams to update forecasts for sustained accuracy. But the data source is vulnerable to attacks or accidents and the dynamics of forecasting failure and recovery due to data gaps is poorly understood. As the first systematic study, a Lorenz model-based forecasting system was disrupted with data gaps of various lengths and timing. The restart time of data assimilation is found to be the most important factor. The forecasting accuracy is found not returning to the original even long after the data assimilation recovery. 	
Advancing Theory and Modeling Efforts in Heliophysics	http://arxiv.org/abs/2209.03611v1	2022-09-08T07:25:54Z	2022-09-08T07:25:54Z	  Heliophysics theory and modeling build understanding from fundamental principles to motivate, interpret, and predict observations. Together with observational analysis, they constitute a comprehensive scientific program in heliophysics. As observations and data analysis become increasingly detailed, it is critical that theory and modeling develop more quantitative predictions and iterate with observations. Advanced theory and modeling can inspire and greatly improve the design of new instruments and increase their chance of success. In addition, in order to build physics-based space weather forecast models, it is important to keep developing and testing new theories, and maintaining constant communications with theory and modeling. Maintaining a sustainable effort in theory and modeling is critically important to heliophysics. We recommend that all funding agencies join forces and consider expanding current and creating new theory and modeling programs--especially, 1. NASA should restore the HTMS program to its original support level to meet the critical needs of heliophysics science; 2. a Strategic Research Model program needs to be created to support model development for next-generation basic research codes; 3. new programs must be created for addressing mission-critical theory and modeling needs; and 4. enhanced programs are urgently required for training the next generation of theorists and modelers. 	
"On the Nature of Flow Curve and Categorization of Thixotropic Yield
  Stress Materials"	http://arxiv.org/abs/2209.03586v2	2023-01-12T08:16:47Z	2022-09-08T06:18:51Z	  Thixotropy is a phenomenon related to time dependent change in viscosity in presence or absence of flow. The yield stress, on the other hand, represents the minimum value of stress above which steady flow can be sustained. In addition, the yield stress of a material may also change as a function of time. Both these characteristic features in a material strongly influence the steady state flow curve of the same. This study aims to understand the interrelation between thixotropy, yield stress and their relation with the flow curve. In this regard, we study five thixotropic materials that show yield stress. The relaxation time of all the five systems shows power-law dependence on aging time with behaviors ranging from weaker than linear, linear to stronger than linear. Furthermore, the elastic modulus and yield stress has been observed to be constant for some systems while time dependent for the others. We also analyze the experimental behavior through a viscoelastic thixotropic structural kinetic model that predicts the observed experimental behavior of constant as well as time-dependent yield stress quite well. These findings indicate that a non-monotonic steady-state flow curve in a structural kinetic formalism necessarily leads to time-dependent yield stress, while constant yield stress is predicted by a monotonic steady-state flow curve with stress plateau in the limit of low shear rates. The present work, therefore, shows that thixotropic materials may exhibit either monotonic or non-monotonic flow curves. Consequently, thixotropic materials may show no yield stress, constant yield stress or time-dependent yield stress. 	
"The Science Gateway Community Institute's Consulting Services Program:
  Lessons for Research Software Engineering Organizations"	http://arxiv.org/abs/2209.03958v1	2022-09-07T20:46:30Z	2022-09-07T20:46:30Z	  The Science Gateways Community Institute (SGCI) is an NSF Software Infrastructure for Sustained Innovation (S2I2) funded project that leads and supports the science gateway community. Major activities for SGCI include a) sustainability training, including the Focus Week week-long course designed to help science gateway operators develop sustainability plans, and the Jumpstart virtual short-course; b) usability and user experience consulting; c) a community catalog of science gateways and science gateway software; d) workforce development activities, including a coding institute for students, internship opportunities, and hackathons; e) an annual conference; and f) in-depth technical support for client gateway projects. The goals of SGCI's Embedded Technical Support component are to help the institute's clients to create new science gateways or to significantly enhance existing science gateways. Examples of the latter include helping to implement major new capabilities and to implement significant usability improvements suggested by SGCI's usability consultants. The Embedded Technical Support component was managed by Indiana University and involved research software engineers at San Diego Supercomputer Center, Texas Advanced Computing Center, Indiana University, and Purdue University (through 2019). Since 2016, the component has involved 20 research software engineers as consultants and has conducted 59 client consultations. This short paper provides a summary of lessons learned from the Embedded Technical Support program that may be useful for the research software engineering community. 	
"Ultrahigh breakdown current density of van der Waals One Dimensional
  $\mathrm{PdBr_2}$"	http://arxiv.org/abs/2209.03296v6	2022-11-16T21:31:30Z	2022-09-07T16:55:55Z	"  One-dimensional (1D) van der Waals (vdW) materials offer nearly defect-free strands as channel material in the field-effect transistor (FET) devices and probably, a better interconnect than conventional copper with higher current density and resistance to electro-migration with sustainable down-scaling. We report a new halide based ""truly"" 1D few-chain atomic thread, PdBr$_2$, isolable from its bulk which crystallizes in a monoclinic space group C2/c. Liquid phase exfoliated nanowires with mean length (20$\pm$1)$\mu$m transferred onto SiO$_2$/Si wafer with a maximum aspect ratio of 5000 confirms the lower cleavage energy perpendicular to chain direction. Moreover, an isolated nanowire can also sustain current density of 200 MA/cm$^\mathrm{2}$ which is atleast one-order higher than typical copper interconnects. However, local transport measurement via conducting atomic force microscopy (CAFM) tip along the cross direction of the single chain records a much lower current density due to the anisotropic electronic band structure. While 1D nature of the nanoobject can be linked with non-trivial collective quantum behavior, vdW nature could be beneficial for the new pathways in interconnect fabrication strategy with better control of placement in an integrated circuit (IC). "	
Multimodal Speech Enhancement Using Burst Propagation	http://arxiv.org/abs/2209.03275v1	2022-09-07T16:27:34Z	2022-09-07T16:27:34Z	  This paper proposes the MBURST, a novel multimodal solution for audio-visual speech enhancements that consider the most recent neurological discoveries regarding pyramidal cells of the prefrontal cortex and other brain regions. The so-called burst propagation implements several criteria to address the credit assignment problem in a more biologically plausible manner: steering the sign and magnitude of plasticity through feedback, multiplexing the feedback and feedforward information across layers through different weight connections, approximating feedback and feedforward connections, and linearizing the feedback signals. MBURST benefits from such capabilities to learn correlations between the noisy signal and the visual stimuli, thus attributing meaning to the speech by amplifying relevant information and suppressing noise. Experiments conducted over a Grid Corpus and CHiME3-based dataset show that MBURST can reproduce similar mask reconstructions to the multimodal backpropagation-based baseline while demonstrating outstanding energy efficiency management, reducing the neuron firing rates to values up to \textbf{$70\%$} lower. Such a feature implies more sustainable implementations, suitable and desirable for hearing aids or any other similar embedded systems. 	
"Technical and Economic Feasibility Analysis of Underground Hydrogen
  Storage: A Case Study in Intermountain-West Region USA"	http://arxiv.org/abs/2209.03239v1	2022-09-07T15:47:46Z	2022-09-07T15:47:46Z	  Hydrogen is an integral component of the current energy transition roadmap to decarbonize the economy and create an environmentally-sustainable future. However, surface storage options (e.g., tanks) do not provide the required capacity or durability to deploy a regional or nationwide hydrogen economy. In this study, we have analyzed the techno-economic feasibility of the geologic storage of hydrogen in depleted gas reservoirs, salt caverns, and aquifers in the Intermountain-West (I-WEST) region. We have identified the most favorable candidate sites for hydrogen storage and estimated the volumetric storage capacity. Our results show that the geologic storage of hydrogen can provide at least 72% of total energy consumption of I-WEST region in 2020. We also calculated the capital and levelized costs of each storage option. We found that a depleted gas reservoir is the most cost-effective candidate among the three geologic storage options. Interestingly, the cushion gas type and volume play a significant role in the storage cost when we consider hydrogen storage in saline aquifers. The levelized costs of hydrogen storage in depleted gas reservoirs, salt caverns, and saline aquifers with large-scale storage capacity are approximately $1.3, $2.3, and $3.4 per kg of H2, respectively. This work provides essential guidance for the geologic hydrogen storage in the I-WEST region. 	
Hot Earth or Young Venus? A nearby transiting rocky planet mystery	http://arxiv.org/abs/2209.03105v2	2022-11-28T20:10:15Z	2022-09-07T12:40:01Z	  Venus and Earth provide astonishingly different views of the evolution of a rocky planet, raising the question of why these two rocky worlds evolved so differently. The recently discovered transiting Super-Earth LP 890-9c (TOI-4306c, SPECULOOS-2c) is a key to the question. It circles a nearby M6V star in 8.46 days. LP890-9c receives similar flux as modern Earth, which puts it very close to the inner edge of the Habitable Zone (HZ), where models differ strongly in their prediction of how long rocky planets can hold onto their water. We model the atmosphere of a hot LP890-9c at the inner edge of the HZ, where the planet could sustain several very different environments. The resulting transmission spectra differ considerably between a hot, wet exo-Earth, a steamy planet caught in a runaway greenhouse, and an exo-Venus. Distinguishing these scenarios from the planet's spectra will provide critical new insights into the evolution of hot terrestrial planets into exo-Venus. Our model and spectra are available online as a tool to plan observations. They show that observing LP890-9c can provide key insights into the evolution of a rocky planet at the inner edge of the HZ as well as the long-term future of Earth. 	
"Efficient sunlight promoted nitrogen fixation from air under room
  temperature and ambient pressure via Ti/Mo composites"	http://arxiv.org/abs/2209.03086v1	2022-09-07T11:52:28Z	2022-09-07T11:52:28Z	  Photocatalytic nitrogen fixation is an important pathway for carbon neutralization and sustainable development. Inspired by nitrogenase, the participation of molybdenum can effectively activate nitrogen. A novel Ti/Mo composites photocatalyst is designed by sintering the molybdenum acetylacetonate precursor with TiO$_{2}$. The special carbon-coated hexagonal photocatalyst is obtained which photocatalytic nitrogen fixation performance is enhanced 16 times compared to pure TiO$_{2}$ at room temperature and ambient pressure. The abundant surface defects in this composite were confirmed to be the key factor for nitrogen fixation. The $^{15}$N$_{2}$ isotope labeling experiment was used to demonstrate the feasibility of nitrogen to ammonia conversion. Also, modelling on the interactions between light and the synthesized photocatalyst particle was examined for the light absorption. The optimum nitrogen fixation conditions have been examined, and the nitrogen fixation performance can reach up to 432 ${\mu}$g$\cdot$g$_{\text{cat}}^{-1}\cdot$h$^{-1}$. Numerical simulations via the field-only surface integral method were also carried out to study the interactions between light and the photocatalytic particles to further confirm that it can be a useful material for photocatalyst. This newly developed Ti/Mo composites provide a simple and effective strategy for photocatalytic nitrogen fixation from air directly under ambient conditions. 	
"An End-to-End Solution for Enabling Urban Cyclability: The Bike2Work
  Experience"	http://arxiv.org/abs/2209.02755v1	2022-09-06T18:21:06Z	2022-09-06T18:21:06Z	  Mobility plays a fundamental role in modern cities. How citizens experience the city, access its core services, and participate in city life, strongly depends on its mobility organization and efficiency. The challenges that municipalities face are very ambitious: on the one hand, administrators must guarantee their citizens the right to mobility and to easily access local services; on the other hand, they need to minimize the economic, social, and environmental costs of the mobility system. Municipalities are increasingly facing problems of traffic congestion, road safety, energy dependency and air pollution, and therefore encouraging a shift towards sustainable mobility habits based on active mobility is of central importance. Active modes, such as cycling, should be particularly encouraged, especially for local recurrent journeys (i.e., home-to-school, home-to-work). In this context, addressing and mitigating commuter-generated traffic requires engaging public and private stakeholders through innovative and collaborative approaches that focus not only on supply (e.g., roads and vehicles) but also on transportation demand management. In this paper, we propose an end-to-end solution for enabling urban cyclability. It supports the companies' Mobility Managers (MMs) acting on the promotion of active mobility for home-to-work commuting, helps the city administrators to understand the needed urban planning interventions, and motivates the citizens to sustainable mobility. To evaluate the effectiveness of the proposed solution we developed two analyses: the first to accurately analyze the user experience and any behaviour change related to the BIKE2WORK initiative, and the second to demonstrate how exploiting the collected data we can inform and possible guide the involved municipality (i.e., Ferrara, a city in Northern Italy) in improving the urban cyclability. 	
"An Optimized and Safety-aware Maintenance Framework: A Case Study on
  Aircraft Engine"	http://arxiv.org/abs/2209.02678v1	2022-09-06T17:47:39Z	2022-09-06T17:47:39Z	  The COVID-19 pandemic has recently exacerbated the fierce competition in the transportation businesses. The airline industry took one of the biggest hits as the closure of international borders forced aircraft operators to suspend their international routes, keeping aircraft on the ground without generating revenues while at the same time still requiring adequate maintenance. To maintain their operational sustainability, finding a good balance between cost reductions measure and safety standards fulfillment, including its maintenance procedure, becomes critical. This paper proposes an AI-assisted predictive maintenance scheme that synthesizes prognostics modeling and simulation-based optimization to help airlines decide their optimal engine maintenance approach. The proposed method enables airlines to utilize their diagnostics measurements and operational settings to design a more customized maintenance strategy that takes engine operations conditions into account. Our numerical experiments on the proposed approach resulted in significant cost savings without compromising the safety standards. The experiments also show that maintenance strategies tailored to the failure mode and operational settings (that our framework enables) yield 13% more cost savings than generic optimal maintenance strategies. The generality of our proposed framework allows the extension to other intelligent, safety-critical transportation systems. 	
Jet-ISM interaction in NGC 1167 / B2 0258+35, A LINER with an AGN past	http://arxiv.org/abs/2209.02549v1	2022-09-06T14:57:39Z	2022-09-06T14:57:39Z	  We report the results of joint Chandra/ACIS - NuSTAR deep observations of NGC 1167, the host galaxy of the young radio jet B2 0258+35. In the ACIS data we detect X-ray emission, extended both along and orthogonal to the jet. At the end of the SE radio jet, we find lower-energy X-ray emission that coincides with a region of CO turbulence and fast outflow motions. This suggests that the hot Interstellar Medium (ISM) may be compressed by the jet and molecular outflow, resulting in more efficient cooling. Hydrodynamic simulations of jet-ISM interaction tailored to NGC 1167 are in agreement with this conclusion and with the overall morphology and spectra of the X-ray emission. The faint hard nuclear source detected with Chandra and the stringent NuSTAR upper limits on the harder X-ray emission show that the active galactic nucleus (AGN) in NGC 1167 is in a very low-accretion state. However, the characteristics of the extended X-ray emission are more consonant to those of luminous Compton Thick AGNs, suggesting that we may be observing the remnants of a past high accretion rate episode, with sustained strong activity lasting ~ 2 x 103 yr. We conclude that NGC1167 is presently a LINER, but was an AGN in the past, given the properties of the extended X-ray emission and their similarity with those of CT AGN extended emission. 	
An Integrated Solar Battery based on a Charge Storing 2D Carbon Nitride	http://arxiv.org/abs/2209.02530v1	2022-09-06T14:35:09Z	2022-09-06T14:35:09Z	  Solar batteries capable of harvesting sunlight and storing solar energy present an attractive vista to transition our energy infrastructure into a sustainable future. We present an integrated, fully earth-abundant solar battery design based on a bifunctional (light absorbing and charge storing) carbon nitride (K-PHI) photoanode, combined with all-organic hole transfer and storage materials. An internal ladder-type hole transfer cascade via a hole transport layer is used to shuttle the photogenerated holes to the PEDOT:PSS cathode. This concept differs from previous designs such as light-assisted battery schemes or photocapacitors and allows charging with only light or light-assisted during electrical charging and discharging, thus substantially increasing the energy output of the cell. Compared to battery operation in the dark, light-assisted (dis)charging increases charge output by 243 %, thereby increasing the electric coulombic efficiency from 68.3 % in the dark to 231 %, leading to energy improvements of 94.1 % under illumination. 	
"Multiwavelength modeling the SED of Luminous Supersoft X-ray Sources in
  Large Magellanic Cloud and Small Magellanic Cloud"	http://arxiv.org/abs/2209.02524v1	2022-09-06T14:29:23Z	2022-09-06T14:29:23Z	  Classical supersoft X-ray sources (SSSs) are understood as close binary systems in which a massive white dwarf (WD) accretes from its companion at rates sustaining steady hydrogen burning on its surface generating bolometric luminosities of $10^{36}-2\times10^{38}$ erg/s. Here, we perform for the first time the global supersoft X-rays to near-infrared (NIR) spectral energy distribution (SED) for the brightest SSSs in LMC and SMC. We test a model in which the ultraviolet--NIR is dominated by the emission from a compact (unresolved) circumstellar nebula represented by the ionized gas out-flowing from the SSS. The SED models correspond to luminosities of SSSs a few times $10^{38}-10^{39}$ erg/s, radiating at blackbody temperatures of $\approx 3\times 10^{5}$ K, and indicate nebular continuum, whose emission measure of $\gtrsim 2\times10^{60}$ cm$^{-3}$ corresponds to a wind mass-loss at rates $\gtrsim 2\times 10^{-6}$ $M_{\odot}\,{\rm yr}^{-1}$. Such extreme parameters suggest that the brightest SSSs could be unidentified optical novae in a post-nova SSS state sustained at a high long-lasting luminosity by resumed accretion, possibly at super-Eddington rates. New observations and theoretical multiwavelength modeling of the global SED of SSSs are needed to reliably determine their parameters, and thus understand their proper stage in stellar evolution. 	
"Direct collapse of exceptionally heavy black holes in the merger-driven
  scenario"	http://arxiv.org/abs/2209.02358v2	2023-01-03T13:34:31Z	2022-09-06T10:39:55Z	  We revisit the conditions present in supermassive discs (SMDs) formed by the merger of gas-rich, metal-enriched galaxies at red-shift $z\sim 10$. We find that SMDs naturally form hydrostatic cores which go through a rapidly accreting supermassive star phase, before directly collapsing into massive black holes via the general relativistic instability. The growth and collapse of the cores occurs within $\sim 5\times 10^5$ yr from the formation of the SMD, producing bright electromagnetic, neutrino and gravitational wave transients with a typical duration of a few minutes and, respectively, a typical flux and a typical strain amplitude at Earth of $\sim 10^{-8}$ erg s$^{-1}$ cm$^{-2}$ and $\sim4\times 10^{-21}$. We provide a simple fitting formula for the the resulting black hole masses, which range from a few $10^6$ M$_{\odot}$ to $10^8$ M$_{\odot}$ depending on the initial SMD configuration. Crucially, our analysis does not require any specific assumption on the thermal properties of the gas, nor on the angular momentum loss mechanisms within the SMD. Led by these findings, we argue that the merger-driven scenario provides a robust pathway for the rapid formation of supermassive black holes at $z > 6$. It provides an explanation for the origin of the brightest and oldest quasars without the need of a sustained growth phase from a much smaller seed. Its smoking gun signatures can be tested directly via multi-messenger observations. 	
"Can we start sharing our rides again? The postpandemic ride-pooling
  market"	http://arxiv.org/abs/2209.02229v1	2022-09-06T05:40:54Z	2022-09-06T05:40:54Z	  Before the pandemic ride-pooling was a promising emerging mode in urban mobility. It started reaching the critical mass with a growing number of service providers and the increasing number of travellers (needed to ensure ride-pooling efficiency and sustainability). However, the COVID pandemic was disruptive for ride-pooling. Many services were cancelled, several operators needed to change their business models and travellers started avoiding those services. In the postpandemic period, we need to understand what is the future of ride-pooling: whether the ride-pooling system can recover and remain a relevant part of future mobility. Here we provide an overview of the postpandemic ride-pooling market based on the analysis of three components: a) literature review, b) empirical pooling availability survey and c) travellers' behaviour studies.   We conclude that the core elements of the ride-pooling business model were not affected by the pandemic. It remains a promising option for all the parties involved, with a great potential to become attractive for travellers, drivers, TNC platforms and policymakers. The travel behaviour changes due to the pandemic seem not to be long-lasting, our virus awareness is no anymore the key concern and our willingness to share and reduce fares seem to be high again. Yet, whether ride-pooling will get another chance to grow remains open. The number of launches of ride-pooling start-ups is unprecedented, yet the financial perspectives are unclear. 	
"Data-driven prediction of room temperature density for multicomponent
  silicate-based glasses"	http://arxiv.org/abs/2209.02046v1	2022-09-05T16:34:52Z	2022-09-05T16:34:52Z	  Density is one of the most commonly measured or estimated materials properties, especially for glasses and melts that are of significant interest to many fields, including metallurgy, geology, materials science and sustainable cements. Here, two types of machine learning (ML) models (i.e., random forest (RF) and artificial neural network (ANN)) have been developed to predict the room-temperature density of glasses in the compositional space of CaO-MgO-Al2O3-SiO2-TiO2-FeO-Fe2O3-Na2O-K2O-MnO (CMASTFNKM), based on ~2100 data points mined from ~140 literature studies. The results show that the RF and ANN models give accurate predictions of glass density with R2 values, RMSE, and MAPE of ~0.96-0.98, ~0.02-0.03 g/cm3 and ~0.59-0.79%, respectively, for the 15% testing set, which are more accurate compared with empirical density models based on ionic packing ratio (with R2 values, RMSE, and MAPE of ~0.28-0.91, ~0.05-0.15 g/cm3, and ~1.40-4.61%, respectively). Furthermore, glass density is shown to be a reliable reactivity indicator for a range of CaO-Al2O3-SiO2 (CAS) and volcanic glasses due to its strong correlation (R2 values above ~0.90) with the average metal-oxygen dissociation energy (a structural descriptor) of these glasses. Analysis of the predicted density-composition relationships from these models (for selected compositional subspaces) suggests that the ANN model exhibits a certain level of transferability (i.e., ability to extrapolate to compositional space not (or less) covered in the database) and captures known features including the mixed alkaline earth effects for (CaO-MgO)0.5-(Al2O3-SiO2)0.5 glasses. 	
Gather -- a better way to codehack online	http://arxiv.org/abs/2209.01927v1	2022-09-05T12:12:25Z	2022-09-05T12:12:25Z	  A virtual hands-on computer laboratory has been designed within the Gather online meeting platform. Gather's features such as spatial audio, private spaces and interactable objects offer scope for great improvements over currently used platforms, especially for small-group based teaching. We describe our experience using this virtual computer laboratory for a recent 'Python for Beginners' workshop held as part of the Software Sustainability Institute's 2022 Research Software Camp. 	
Modular Vehicle Routing for Combined Passenger and Freight Transport	http://arxiv.org/abs/2209.01461v1	2022-09-03T16:39:25Z	2022-09-03T16:39:25Z	  The continuous increase in urban deliveries and the ongoing urbanization of large cities require the development of efficient and sustainable transportation solutions. This study investigates the impact of modular vehicle concepts and the consolidation of different demand types in the route planning on the efficiency of the urban freight and passenger transportation system. Modularity is achieved by connecting multiple vehicles together to form a platoon. The consolidation of different demand types is realized by simultaneously consider passenger and freight demand in the optimization algorithm. The considered vehicles are specific for each demand type by can be connected freely, hence it is possible to transport different demand types in the same platoon. The cost terms in the problem formulation are comprised of travel time costs, travel distance costs, fleet size costs, and cost considering unserved requests. The modular vehicle operations are modeled in a novel pickup and delivery problem which is solved using CPLEX and Adaptive Large Neighborhood Search. In an extensive scenario study and case study in Stockholm, the potentials of the new modular vehicle type are explored for different spatial and temporal demand distributions. A parameter study on vehicle capacity, vehicle range and cost saving assumptions is performed to study their influence on the efficiency. The experiments carried out indicate a general cost savings of 48% due to modularity and an additional 9% due to consolidation. The reduction mainly stems from reduced operating costs and reduced trip duration, while the same number of requests can be served in all cases. Empty vehicle kilometers are reduced by more than 60% by consolidation and modularity. The proposed model and optimization framework can be used by companies and policy makers to identify required fleet sizes, optimal vehicle routes and cost savings. 	
"SaleNet: A low-power end-to-end CNN accelerator for sustained attention
  level evaluation using EEG"	http://arxiv.org/abs/2209.01386v1	2022-09-03T09:49:37Z	2022-09-03T09:49:37Z	  This paper proposes SaleNet - an end-to-end convolutional neural network (CNN) for sustained attention level evaluation using prefrontal electroencephalogram (EEG). A bias-driven pruning method is proposed together with group convolution, global average pooling (GAP), near-zero pruning, weight clustering and quantization for the model compression, achieving a total compression ratio of 183.11x. The compressed SaleNet obtains a state-of-the-art subject-independent sustained attention level classification accuracy of 84.2% on the recorded 6-subject EEG database in this work. The SaleNet is implemented on a Artix-7 FPGA with a competitive power consumption of 0.11 W and an energy-efficiency of 8.19 GOps/W. 	
"FedAR+: A Federated Learning Approach to Appliance Recognition with
  Mislabeled Data in Residential Buildings"	http://arxiv.org/abs/2209.01338v1	2022-09-03T06:07:27Z	2022-09-03T06:07:27Z	  With the enhancement of people's living standards and rapid growth of communication technologies, residential environments are becoming smart and well-connected, increasing overall energy consumption substantially. As household appliances are the primary energy consumers, their recognition becomes crucial to avoid unattended usage, thereby conserving energy and making smart environments more sustainable. An appliance recognition model is traditionally trained at a central server (service provider) by collecting electricity consumption data, recorded via smart plugs, from the clients (consumers), causing a privacy breach. Besides that, the data are susceptible to noisy labels that may appear when an appliance gets connected to a non-designated smart plug. While addressing these issues jointly, we propose a novel federated learning approach to appliance recognition, called FedAR+, enabling decentralized model training across clients in a privacy preserving way even with mislabeled training data. FedAR+ introduces an adaptive noise handling method, essentially a joint loss function incorporating weights and label distribution, to empower the appliance recognition model against noisy labels. By deploying smart plugs in an apartment complex, we collect a labeled dataset that, along with two existing datasets, are utilized to evaluate the performance of FedAR+. Experimental results show that our approach can effectively handle up to $30\%$ concentration of noisy labels while outperforming the prior solutions by a large margin on accuracy. 	
Ultramassive black holes formed by triple quasar mergers at $z\sim 2$	http://arxiv.org/abs/2209.01249v2	2022-09-07T02:40:54Z	2022-09-02T19:22:34Z	  The origin of rare and elusive ultramassive black holes (UMBH, with MBH > 1e10 Msun) is an open question. Using the large volume cosmological hydrodynamic simulation ASTRID, we report on the formation of an extremely massive UMBH with MBH ~ 1e11 Msun at z~2. The UMBH is assembled as a result of two successive mergers of massive galaxies each with stellar mass M* > 3e11 Msun that also produces a bright, rare triple quasar system powered by three ~10^9 Msun black holes. The second merger of supermassive black holes (SMBHs) follows the first after 150 Myrs. The merger events lead to sustained Eddington accretion onto the central SMBH, forming an UMBH in the center of a massive compact stellar core with M* > 2e12 Msun. The strong feedback of the UMBH quenches the surrounding star formation to < 10 Msun/yr in the inner 50 kpc/h region. There are two more UMBHs with MBH > 5e10 Msun at z>2 in ASTRID which are also produced by major mergers of galaxies, and their progenitors can be observed as quasar triplets of lower luminosity. The rarely observed quasar multiples can be the cradle of UMBHs at high redshift, and likely end up in the center of the most massive clusters. 	
Time Evolution of a Supply Chain Network: Kinetic Modeling	http://arxiv.org/abs/2209.01138v1	2022-09-02T15:50:47Z	2022-09-02T15:50:47Z	  Resilient supply chains are often inherently dependent on the nature of their complex interconnected networks that are simultaneously multi-dimensional and multi-layered. This article presents a Supply Chain Network (SCN) model that can be used to regulate downstream relationships towards a sustainable SME using a 4-component cost function structure - Environmental (E), Demand (D), Economic (E), and Social (S). As a major generalization to the existing practice of using phenomenological interrelationships between the EDES cost kernels, we propose a complementary time varying model of a cost function, based on Lagrangian mechanics (incorporating SCN constraints through Lagrange multipliers), to analyze the time evolution of the SCN variables to interpret the competition between economic inertia and market potential. Multicriteria decision making, based on an Analytic Hierarchy Process (AHP), ranks performance quality, identifying key business decision makers. The model is first solved numerically and then validated against real data pertaining to two Small and Medium Enterprises (SMEs) from diverse domains, establishing the domain-independent nature of the model. The results quantify how increases in a production line without appropriate consideration of market volatility can lead to bankruptcy, and how high transportation cost together with increased production may lead to a break-even state. The model also predicts the time it takes a policy change to reinvigorate sales, thereby forecasting best practice operational procedure that ensures holistic sustainability on all four sustainability fronts. 	
Tuning nucleation kinetics via nonequilibrium chemical reactions	http://arxiv.org/abs/2209.00542v2	2023-01-08T19:53:31Z	2022-09-01T15:38:56Z	  Unlike fluids at thermal equilibrium, biomolecular mixtures in living systems can sustain nonequilibrium steady states, in which active processes modify the conformational states of the constituent molecules. Despite qualitative similarities between liquid--liquid phase separation in these systems, the extent to which the phase-separation kinetics differ remains unclear. Here we show that inhomogeneous chemical reactions can alter the nucleation kinetics of liquid--liquid phase separation in a manner that is consistent with classical nucleation theory, but can only be rationalized by introducing a nonequilibrium interfacial tension. We identify conditions under which nucleation can be accelerated without changing the energetics or supersaturation, thus breaking the correlation between fast nucleation and strong driving forces that is typical of phase separation and self-assembly at thermal equilibrium. 	
The Nudging Effect on Tracking Activity	http://arxiv.org/abs/2209.00394v1	2022-09-01T12:17:26Z	2022-09-01T12:17:26Z	  Wearables activity trackers are becoming widely adopted to understand individual behavior. Understanding behavior may help in self-regulation such as self-monitoring, goal-setting, self-corrective, etc.; Nevertheless, challenges exist in attaining consistent use and adoption of wearables, which hinders behavior understanding. Research has suggested that nudging strategies may change and sustain human engagement. However, it is still unknown how nudging may affect human wearing behavior on an individual level. We conducted a six-month study in which we tested several nudging techniques on the same participants. The preliminary results of our research show that participants perform better when a nudging strategy is applied. In addition, participants responded differently to different nudging techniques. Future research can focus on developing an individual-based nudging mechanism to encourage users to wear their devices consistently. 	
"Implications of electron and hole doping on the magnetic properties of
  spin-orbit entangled Ca$_\text{4}$IrO$_\text{6}$ from DFT calculations"	http://arxiv.org/abs/2209.00239v1	2022-09-01T06:00:00Z	2022-09-01T06:00:00Z	  We investigate the electronic structure and magnetic properties of a $J_\text{eff} = 1/2$ iridate Ca$_4$IrO$_6$ and the implications of doping electrons and holes using ab initio density functional theory. Our calculations considering spin-orbit interaction reveal that although the Mott-insulating parent compound transforms into a conductor upon doping, antiferromagnetism sustains in the doped system, albeit with a grossly noncollinear arrangement of the spins. We find a strong spin-orbit interaction and magneto-crystalline anisotropy, causing frustration in the system, possibly leading to the highly noncollinear arrangement of spins upon non-magnetic doping. Our results may be important from the viewpoint of spintronics using iridates or other $5d$ materials. 	
"Understanding the dynamic impact of COVID-19 through competing risk
  modeling with bivariate varying coefficients"	http://arxiv.org/abs/2209.00181v1	2022-09-01T02:21:22Z	2022-09-01T02:21:22Z	  The coronavirus disease 2019 (COVID-19) pandemic has exerted a profound impact on patients with end-stage renal disease relying on kidney dialysis to sustain their lives. Motivated by a request by the U.S. Centers for Medicare & Medicaid Services, our analysis of their postdischarge hospital readmissions and deaths in 2020 revealed that the COVID-19 effect has varied significantly with postdischarge time and time since the onset of the pandemic. However, the complex dynamics of the COVID-19 effect trajectories cannot be characterized by existing varying coefficient models. To address this issue, we propose a bivariate varying coefficient model for competing risks within a cause-specific hazard framework, where tensor-product B-splines are used to estimate the surface of the COVID-19 effect. An efficient proximal Newton algorithm is developed to facilitate the fitting of the new model to the massive Medicare data for dialysis patients. Difference-based anisotropic penalization is introduced to mitigate model overfitting and the wiggliness of the estimated trajectories; various cross-validation methods are considered in the determination of optimal tuning parameters. Hypothesis testing procedures are designed to examine whether the COVID-19 effect varies significantly with postdischarge time and the time since pandemic onset, either jointly or separately. Simulation experiments are conducted to evaluate the estimation accuracy, type I error rate, statistical power, and model selection procedures. Applications to Medicare dialysis patients demonstrate the real-world performance of the proposed methods. 	
RAPTOR: Ravenous Throughput Computing	http://arxiv.org/abs/2209.00114v1	2022-08-31T21:01:48Z	2022-08-31T21:01:48Z	  We describe the design, implementation and performance of the RADICAL-Pilot task overlay (RAPTOR). RAPTOR enables the execution of heterogeneous tasks -- i.e., functions and executables with arbitrary duration -- on HPC platforms, providing high throughput and high resource utilization. RAPTOR supports the high throughput virtual screening requirements of DOE's National Virtual Biotechnology Laboratory effort to find therapeutic solutions for COVID-19. RAPTOR has been used on $>8000$ compute nodes to sustain 144M/hour docking hits, and to screen $\sim$10$^{11}$ ligands. To the best of our knowledge, both the throughput rate and aggregated number of executed tasks are a factor of two greater than previously reported in literature. RAPTOR represents important progress towards improvement of computational drug discovery, in terms of size of libraries screened, and for the possibility of generating training data fast enough to serve the last generation of docking surrogate models. 	
"Global GIS-based potential analysis and cost assessment of Power-to-X
  fuels in 2050"	http://arxiv.org/abs/2208.14887v1	2022-08-31T14:26:16Z	2022-08-31T14:26:16Z	  Electricity-based fuels from renewable energies are regarded as a key instrument for climate protection. These Power-to-X (PtX) products are to replace fossil fuels in sectors where direct use of electricity from renewable energies is not possible. We investigate the production potential of PtX fuels from onshore wind energy and ground-mounted photovoltaic energy for all countries outside the European Economic Area along 14 PtX production pathways. These include hydrogen, several hydrocarbons and ammonia. The technical and economic potential assessment is based on data with hourly temporal and high spatial resolution. The analysis considers various criteria, including weather conditions, nature conservation concerns and land use. The results show the production quantities and costs of climate-friendly fuel production under strict sustainability criteria and locate them spatially. It is shown that many regions of the world are well suited to produce PtX products. The production quantity outside Europe is up to 120,000 TWh/yr of hydrogen or 87,000 TWh/yr of hydrocarbons in the long term. We identify 97 countries with potentials, of which 38 countries possess relevant potentials of more than 100 TWh/yr. The largest suitable areas are in the United States, Australia and Argentina. The production costs vary a lot across the different regions. The lowest production costs for PtX generation are in Latin America (Chile, Argentina and Venezuela) and Mauritania with a lower limit of 42.3 EUR/MWh to 46.5 EUR/MWh for gaseous hydrogen and 84 EUR/MWh to 89.1 EUR/MWh for Fischer-Tropsch fuels. All best sites are pure wind or combined wind and photovoltaic sites. Moreover, we show import options of these PtX products to Europe considering socioeconomic factors and transport costs. All investigation results are freely accessible via the Global PtX Atlas on https://maps.iee.fraunhofer.de/ptx-atlas/. 	
Predicting spatial distribution of Palmer Drought Severity Index	http://arxiv.org/abs/2208.14833v2	2022-09-01T05:17:31Z	2022-08-31T13:01:42Z	  The probability of a drought for a particular region is crucial when making decisions related to agriculture. Forecasting this probability is critical for management and challenging at the same time. The prediction model should consider multiple factors with complex relationships across the region of interest and neighbouring regions.   We approach this problem by presenting an end-to-end solution based on a spatio-temporal neural network. The model predicts the Palmer Drought Severity Index (PDSI) for subregions of interest. Predictions by climate models provide an additional source of knowledge of the model leading to more accurate drought predictions.   Our model has better accuracy than baseline Gradient boosting solutions, as the $R^2$ score for it is $0.90$ compared to $0.85$ for Gradient boosting. Specific attention is on the range of applicability of the model. We examine various regions across the globe to validate them under different conditions.   We complement the results with an analysis of how future climate changes for different scenarios affect the PDSI and how our model can help to make better decisions and more sustainable economics. 	
"Integrating wind variability to modelling wind-ramp events using a
  non-binary ramp function and deep learning models"	http://arxiv.org/abs/2211.17017v1	2022-08-31T10:40:35Z	2022-08-31T10:40:35Z	  The forecasting of large ramps in wind power output known as ramp events is crucial for the incorporation of large volumes of wind energy into national electricity grids. Large variations in wind power supply must be compensated by ancillary energy sources which can include the use of fossil fuels. Improved prediction of wind power will help to reduce dependency on supplemental energy sources along with their associated costs and emissions. In this paper, we discuss limitations of current predictive practices and explore the use of Machine Learning methods to enhance wind ramp event classification and prediction. We additionally outline a design for a novel approach to wind ramp prediction, in which high-resolution wind fields are incorporated to the modelling of wind power. 	
Thermophysical evolution of planetesimals in the Primordial Disk	http://arxiv.org/abs/2208.14628v1	2022-08-31T04:27:33Z	2022-08-31T04:27:33Z	"  The Primordial Disk of small icy planetesimals, once located at 15-30 AU from the Sun, was disrupted by giant planet migration in the early Solar System. The Primordial Disk thereby became the source region of objects in the current-day Kuiper Belt, Scattered Disk, and Oort Cloud. I present the thermophysics code ""Numerical Icy Minor Body evolUtion Simulator"", or NIMBUS, and use it to study the thermophysical evolution of planetesimals in the Primordial Disk prior to its disruption. Such modelling is mandatory in order to understand the behaviour of dynamically new comets from the Oort Cloud, as well as the activity of Centaurs and short-period comets from the Scattered Disk, that return pre-processed to the vicinity of the Sun. I find that bodies in the midst of the Primordial Disk with diameters ranging 4-200 km lost all their CO ice on time-scales of order 0.1-10 Myr depending on size, through a combination of protosolar and long-lived radionuclide heating. CO and other hypervolatiles therefore require a less volatile host for their storage. I consider two possible hosts: amorphous water ice and CO2 ice. Because of the high luminosity of the protosun, some Primordial Disk bodies may have sustained significant crystallisation, CO:CO2 segregation, and CO2 sublimation in the uppermost few tens of meters. I discuss how this may affect coma abundance ratios and distant activity in dynamically new comets. "	
Backflipping motion of air bubbles colliding with a tilted wall	http://arxiv.org/abs/2208.14486v1	2022-08-30T18:23:56Z	2022-08-30T18:23:56Z	  Oblique collision of solid particles with surfaces has been a topic of extensive study in Newtonian mechanics, which also explains the motion of bubbles and droplets to some extent. Here, we observe that air bubbles exhibit a backflipping behavior when they collide with a tilted surface. Our experiments reveal that bubbles with radii 0.6-0.7 mm undergo backflipping when they collide with surfaces at an angle of up to 15^o with the strongest backflipping at 3^o. Particle image velocimetry reveals that the backflipping behavior is caused by wake-induced circulation around the bubble, which applies a lift force on the bubble. We develop a theoretical model that incorporates potential flow theory to characterize the circulation caused by the interaction between the bouncing bubble and its wake. The theoretical results are in good agreement with the experiments confirming the key role of the wake-induced lift force in backflipping. Finally, we show that the backflipping behavior of air bubbles can be leveraged for sustainable cleaning of a biological surface coated with a protein solution. 	
"Ionization waves (striations) in low-current DC discharges in noble
  gases obtained with a hybrid kinetic-fluid model"	http://arxiv.org/abs/2208.14321v3	2022-12-11T16:58:03Z	2022-08-30T15:00:13Z	  A hybrid kinetic-fluid model is used to study ionization waves (striations) in a low-current plasma column of DC discharges in noble gases. Coupled solutions of a kinetic equation for electrons, a drift-diffusion equation of ions, and a Poisson equation for the electric field are obtained to clarify the nature of plasma stratification in the positive column and near-electrode effects. A simplified two-level excitation-ionization model is used for the conditions when the nonlinear effects due to stepwise ionization, gas heating, and Coulomb interactions among electrons are negligible. It is confirmed that the nonlocal effects are responsible for the formation of moving striations in DC discharges at low plasma densities. The calculated properties of self-excited waves of S, P, and R types in Neon and S type in Argon agree with available experimental data. The reason for Helium plasma stability to stratification is clarified. It is shown that sustaining stratified plasma is more efficient than striation-free plasma when the ionization rate is a nonlinear function of the electric field. However, the nonlinear dependence of the ionization rate on the electric field is not required for plasma stratification. Striations of S, P, and R types in Neon exist with minimal or no ionization enhancement. Effects of the column length on the wave properties have been demonstrated in our simulations. 	
"Foreseeing the Impact of the Proposed AI Act on the Sustainability and
  Safety of Critical Infrastructures"	http://arxiv.org/abs/2208.14451v3	2022-09-12T12:16:29Z	2022-08-30T14:55:51Z	  The AI Act has been recently proposed by the European Commission to regulate the use of AI in the EU, especially on high-risk applications, i.e. systems intended to be used as safety components in the management and operation of road traffic and the supply of water, gas, heating and electricity. On the other hand, IEC 61508, one of the most adopted international standards for safety-critical electronic components, seem to mostly forbid the use of AI in such systems. Given this conflict between IEC 61508 and the proposed AI Act, also stressed by the fact that IEC 61508 is not an harmonised European standard, with the present paper we study and analyse what is going to happen to industry after the entry into force of the AI Act. In particular, we focus on how the proposed AI Act might positively impact on the sustainability of critical infrastructures by allowing the use of AI on an industry where it was previously forbidden. To do so, we provide several examples of AI-based solutions falling under the umbrella of IEC 61508 that might have a positive impact on sustainability in alignment with the current long-term goals of the EU and the Sustainable Development Goals of the United Nations, i.e., affordable and clean energy, sustainable cities and communities. 	
"Long-term variation of population exposure to PM2.5 in Eastern China: A
  perspective from SDG 11.6.2"	http://arxiv.org/abs/2208.14275v1	2022-08-30T13:53:38Z	2022-08-30T13:53:38Z	  Air pollution (e.g., PM2.5) has a negative effect on human health. Recently, the population-weighted annual mean PM2.5 concentration (PWAM) has been selected as an indicator 11.6.2 in Sustainable Development Goals (SDGs), for various countries to perfrom a long-term monitoring of population exposure to PM2.5 in cities. However, few studies have employed this indicator for a city-level analysis and also in a long-time series (e.g., for decades). To fill this research gap, this study investigates the long-term (2000-2020) variation of population exposure to PM2.5 in Eastern China (including 318 prefecture-level cities). Three categories of open geospatial data (including high-resolution and long-term PM2.5 and population data, and administrative boundary data of cities) are involved for analysis. We found that: 1) A considerable decrease has been observed for the PWAM during 2014-2020. 2) In 2020, the PWAM is for the first time lower than the interim target-1 (35 {\mu}g/m3) defined by the World Health Organization for 214 prefecture-level cities in Eastern China, which accounts for 67% of the total population. The results indicates a considerable improvement of air quality in Eastern China. More important, this study illustrates the feasibility of using open geospatial data to monitor the SDG indicator 11.6.2. 	
"Building the Learning Environment for Sustainable Development: a
  Co-creation approach"	http://arxiv.org/abs/2208.14151v2	2022-09-06T12:35:26Z	2022-08-30T11:11:01Z	  Education for sustainable development supports the improvement of knowledge, skills, attitudes and behaviors related to global challenges such as climate change, global warming and environmental degradation, among others. It is increasingly taking place through projects based on information and communication technologies. The effectiveness of the actions taken depends not only on the quality of the project activities or the sophistication of the innovative tools used. Social commitment also depends on the beliefs and moral judgements manifested by potential recipients of educational activities on environmental issues. This study aimed to identify the beliefs and moral judgements that may facilitate or hinder the implementation of educational activities based on information and communication technology, shaping pro-environmental attitudes and behavior among city dwellers. Based on the co-creation workshops conducted, five general categories emerged: responsibility, sense of empowerment, local leadership, real eco-approach, and eco-knowledge. The research findings may contribute to the design of educational activities dedicated to shaping the pro-environmental behavior of city dwellers. 	
"Improving Operational Efficiency In EV Ridepooling Fleets By Predictive
  Exploitation of Idle Times"	http://arxiv.org/abs/2208.14852v1	2022-08-30T08:41:40Z	2022-08-30T08:41:40Z	  In ridepooling systems with electric fleets, charging is a complex decision-making process. Most electric vehicle (EV) taxi services require drivers to make egoistic decisions, leading to decentralized ad-hoc charging strategies. The current state of the mobility system is often lacking or not shared between vehicles, making it impossible to make a system-optimal decision. Most existing approaches do not combine time, location and duration into a comprehensive control algorithm or are unsuitable for real-time operation. We therefore present a real-time predictive charging method for ridepooling services with a single operator, called Idle Time Exploitation (ITX), which predicts the periods where vehicles are idle and exploits these periods to harvest energy. It relies on Graph Convolutional Networks and a linear assignment algorithm to devise an optimal pairing of vehicles and charging stations, in pursuance of maximizing the exploited idle time. We evaluated our approach through extensive simulation studies on real-world datasets from New York City. The results demonstrate that ITX outperforms all baseline methods by at least 5% (equivalent to $70,000 for a 6,000 vehicle operation) per week in terms of a monetary reward function which was modeled to replicate the profitability of a real-world ridepooling system. Moreover, ITX can reduce delays by at least 4.68% in comparison with baseline methods and generally increase passenger comfort by facilitating a better spread of customers across the fleet. Our results also demonstrate that ITX enables vehicles to harvest energy during the day, stabilizing battery levels and increasing resilience to unexpected surges in demand. Lastly, compared to the best-performing baseline strategy, peak loads are reduced by 17.39% which benefits grid operators and paves the way for more sustainable use of the electrical grid. 	
"Reliable and Resilient AI and IoT-based Personalised Healthcare
  Services: A Survey"	http://arxiv.org/abs/2209.05457v1	2022-08-29T23:14:02Z	2022-08-29T23:14:02Z	  Recent technological and economic developments have transformed the healthcare sector towards more personalized and IoT-based healthcare services. These services are realized through control and monitoring applications that are typically developed using artificial intelligence/machine learning-based algorithms, which play a significant role in highlighting the efficiency of traditional healthcare systems. Current personalized healthcare services are dedicated to a specific environment to support technological personalization. However, they are unable to consider different interrelated health conditions, leading to inappropriate diagnoses and affecting sustainability and the long-term health of patients. To this end, current Healthcare 5.0 technology has evolved that supersede previous healthcare technologies. The goal of healthcare 5.0 is to achieve an autonomous healthcare service, that takes into account the interdependent effect of different health conditions of a patient. This paper conducts a comprehensive survey on personalized healthcare services. In particular, we first present an overview of key requirements of comprehensive personalized healthcare services in modern healthcare Internet of Things (HIoT), including the definition of personalization and an example use case scenario as a representative for modern HIoT. Second, we explored a fundamental three-layer architecture for IoT-based healthcare systems using AI and non-AI-based approaches, considering key requirements for CPHS followed by their strengths and weaknesses in the frame of personalized healthcare services. Third, we highlighted different security threats against each layer of IoT architecture along with the possible AI and non-AI-based solutions. Finally, we propose a methodology to develop reliable, resilient, and personalized healthcare services that address the identified weaknesses of existing approaches. 	
PGNAA Spectral Classification of Metal with Density Estimations	http://arxiv.org/abs/2208.13836v2	2023-02-05T11:05:12Z	2022-08-29T18:58:59Z	  For environmental, sustainable economic and political reasons, recycling processes are becoming increasingly important, aiming at a much higher use of secondary raw materials. Currently, for the copper and aluminium industries, no method for the non-destructive online analysis of heterogeneous materials are available. The Prompt Gamma Neutron Activation Analysis (PGNAA) has the potential to overcome this challenge. A difficulty when using PGNAA for online classification arises from the small amount of noisy data, due to short-term measurements. In this case, classical evaluation methods using detailed peak by peak analysis fail. Therefore, we propose to view spectral data as probability distributions. Then, we can classify material using maximum log-likelihood with respect to kernel density estimation and use discrete sampling to optimize hyperparameters. For measurements of pure aluminium alloys we achieve near perfect classification of aluminium alloys under 0.25 second. 	
"Efficient Vision-Language Pretraining with Visual Concepts and
  Hierarchical Alignment"	http://arxiv.org/abs/2208.13628v2	2022-10-05T11:35:46Z	2022-08-29T14:24:08Z	  Vision and Language Pretraining has become the prevalent approach for tackling multimodal downstream tasks. The current trend is to move towards ever larger models and pretraining datasets. This computational headlong rush does not seem reasonable in the long term to move toward sustainable solutions, and de facto excludes academic laboratories with limited resources. In this work, we propose a new framework, dubbed ViCHA, that efficiently exploits the input data to boost the learning by: (a) a new hierarchical cross-modal alignment loss, (b) new self-supervised scheme based on masked image modeling, (c) leveraging image-level annotations, called Visual Concepts, obtained with existing foundation models such as CLIP to boost the performance of the image encoder. Although pretrained on four times less data, our ViCHA strategy outperforms other approaches on several downstream tasks such as Image-Text Retrieval, VQA, Visual Reasoning, Visual Entailment and Visual Grounding. The code will be made publicly available here: https://github.com/mshukor/ViCHA 	
Lunar Samples are Time Capsules of the Sun	http://arxiv.org/abs/2208.13307v2	2022-09-07T21:35:29Z	2022-08-28T23:00:31Z	  The Heliophysics Decadal survey should embrace the coming opportunity of sustained lunar surface exploration and facilitate cross-disciplinary efforts to unlock the secrets of the Sun that are held by the lunar surface. With planned Artemis efforts that include prioritization of samples of high interest and protocols for sample handling and analysis, input into the relevant solar signatures that would be most diagnostic and how best to obtain/retain them is incredibly important. Finally, leveraging the theoretical expertise of the two communities in ways that bring them together, such as through dedicated conferences and workshops, will let the two communities help each other learn more than they could alone. 	
"Revisiting the definition of rapid intensification of tropical cyclones
  by clustering the initial intensity and inner-core size"	http://arxiv.org/abs/2208.13140v1	2022-08-28T04:40:01Z	2022-08-28T04:40:01Z	  Rapid intensification (RI) of tropical cyclones (TCs) provides a great challenge in operational forecasting and contributes significantly to the development of major TCs. RI is commonly defined as an increase in the maximum sustained surface wind speed beyond a certain threshold within 24 h. The most widely used threshold is 30 kt (15.4 m/s), which was determined statistically. Here we propose a new definition for RI by objectively clustering TCs using the intensification rate, initial intensity, and radius of the maximum wind speed. A group of 770 samples is separated at a threshold of 45 kt (23.2 m/s). The threshold is 40 kt (20.6 m/s) for the western North Atlantic, where TC size measurements are more reliable. Monte Carlo experiments demonstrate that the proposed threshold is robust even considering the uncertainty in RMW of as high as 30 km. We show that, when a TC undergoes RI, its maximum wind speed is approximately 60+/-15 kt (30.9+/-7.7 m/s) and the radius of the maximum wind speed is 45+/-20 km. The new threshold outperforms the conventional threshold of 30 kt/24h in (1) describing the bimodal distribution of lifetime maximum intensity, and (2) explaining the annual count of Category 5 TCs. This new definition provides a more physically-based threshold and describes a more reliable representation to the extreme events. Although more comparisons are needed for operational application, it is likely to be desirable for process-based case studies, and could provide a more valuable metric for TC intensification classification and research. 	
"Assessment of Biomechanical Properties for Corneal Post Refractive
  Surgery"	http://arxiv.org/abs/2208.12958v1	2022-08-27T08:01:59Z	2022-08-27T08:01:59Z	  A stable shape for corneas experiencing refractive surgery has to be sustained so as to elude post-refractive surgery de-compensation. This de-compensation leads to visual complications and unsatisfactory procedure recovery. Variation in corneal lamellae and collagen fibres is induced by recent LASER refractive surgical procedures utilizing LASER ablation and disruption techniques. Conserving a steady response of central apex flattening and peripheral steepening in an elastic cornea pre- and post- procedure is the ultimate purpose of successful refractive surgery. Early diagnosis of ectatic corneal disorders and better understanding of corneal pathogenesis is achieved by assessment of corneal biomechanical properties. The ultimate objective of this research is to estimate the biomechanical properties for both normal and pathogenic corneal tissue pre- and post-operative refractive surgery. This achieved using ultrasonic acoustic radiation force impulse as a non-invasive method accounting for its high localization. Induced displacement tracking methods will be utilized for assessment of soft tissue biomechanical properties related to the investigated soft tissue. Ultrasound probe simulations will be carried out to optimize the probe design. FEM simulations will take place to precisely estimate in-situ corneal tissue biomechanics. In this research, corneal biomechanical properties are studied and estimated using acoustic radiation force impulse. This is achieved either by estimating the focal peak axial deformation value or by estimating the shear wave speed for the resulting propagating deformation wave. 	
"Conditional investment strategy in evolutionary trust games with
  repeated group interactions"	http://arxiv.org/abs/2208.12953v1	2022-08-27T07:46:10Z	2022-08-27T07:46:10Z	  It has a long tradition to study trust behavior among humans or artificial agents by investigating the trust game. Although previous studies based on evolutionary game theory have revealed that trust and trustworthiness can be promoted if network structure or reputation is considered, they often assume that interactions among agents are one-shot and investors do not consider the investment environment before making decisions, which collide with many realistic situations. In this paper, we introduce the conditional investment strategy into the repeated N-player trust game, in which conditional investors decide to invest or not depending on their assessment of the trustworthiness level of the group. By using the approach of the Markov decision process, we study the evolutionary dynamics of trust in repeated group interactions with the conditional investment strategy. We find that conditional investors can form an effective alliance with trustworthy trustees, hence they can sweep out untrustworthy trustees. Moreover, we verify that such alliance can exist in a wide range of model parameters. These results may explain why trusting in others and reciprocating them with trustworthy actions can be sustained in game interactions among intelligent agents. 	
Mel Spectrogram Inversion with Stable Pitch	http://arxiv.org/abs/2208.12782v1	2022-08-26T17:01:57Z	2022-08-26T17:01:57Z	  Vocoders are models capable of transforming a low-dimensional spectral representation of an audio signal, typically the mel spectrogram, to a waveform. Modern speech generation pipelines use a vocoder as their final component. Recent vocoder models developed for speech achieve a high degree of realism, such that it is natural to wonder how they would perform on music signals. Compared to speech, the heterogeneity and structure of the musical sound texture offers new challenges. In this work we focus on one specific artifact that some vocoder models designed for speech tend to exhibit when applied to music: the perceived instability of pitch when synthesizing sustained notes. We argue that the characteristic sound of this artifact is due to the lack of horizontal phase coherence, which is often the result of using a time-domain target space with a model that is invariant to time-shifts, such as a convolutional neural network. We propose a new vocoder model that is specifically designed for music. Key to improving the pitch stability is the choice of a shift-invariant target space that consists of the magnitude spectrum and the phase gradient. We discuss the reasons that inspired us to re-formulate the vocoder task, outline a working example, and evaluate it on musical signals. Our method results in 60% and 10% improved reconstruction of sustained notes and chords with respect to existing models, using a novel harmonic error metric. 	
"Half-integer vs. integer effects in quantum synchronization of spin
  systems"	http://arxiv.org/abs/2208.12766v2	2022-12-22T13:34:09Z	2022-08-26T16:23:38Z	  We study the quantum synchronization of a single spin driven by an external semiclassical signal for spin numbers larger than $S = 1$, the smallest system to host a quantum self-sustained oscillator. The occurrence of interference-based quantum synchronization blockade is found to be qualitatively different for integer vs. half-integer spin number $S$. We explain this phenomenon as the interplay between the external signal and the structure of the limit cycle in the generation of coherence in the system. Moreover, we show that the same dissipative limit-cycle stabilization mechanism leads to very different levels of quantum synchronization for integer vs. half-integer $S$. However, by choosing an appropriate limit cycle for each spin number, comparable levels of quantum synchronization can be achieved for both integer and half-integer spin systems. 	
Machine Learning Decoder for 5G NR PUCCH Format 0	http://arxiv.org/abs/2209.07861v1	2022-08-26T13:34:23Z	2022-08-26T13:34:23Z	  5G cellular systems depend on the timely exchange of feedback control information between the user equipment and the base station. Proper decoding of this control information is necessary to set up and sustain high throughput radio links. This paper makes the first attempt at using Machine Learning techniques to improve the decoding performance of the Physical Uplink Control Channel Format 0. We use fully connected neural networks to classify the received samples based on the uplink control information content embedded within them. The trained neural network, tested on real-time wireless captures, shows significant improvement in accuracy over conventional DFT-based decoders, even at low SNR. The obtained accuracy results also demonstrate conformance with 3GPP requirements. 	
"Toward Robust Graph Semi-Supervised Learning against Extreme Data
  Scarcity"	http://arxiv.org/abs/2208.12422v2	2022-12-11T07:29:56Z	2022-08-26T03:36:01Z	  The success of graph neural networks on graph-based web mining highly relies on abundant human-annotated data, which is laborious to obtain in practice. When only few labeled nodes are available, how to improve their robustness is a key to achieve replicable and sustainable graph semi-supervised learning. Though self-training has been shown to be powerful for semi-supervised learning, its application on graph-structured data may fail because (1) larger receptive fields are not leveraged to capture long-range node interactions, which exacerbates the difficulty of propagating feature-label patterns from labeled nodes to unlabeled nodes; and (2) limited labeled data makes it challenging to learn well-separated decision boundaries for different node classes without explicitly capturing the underlying semantic structure. To address the challenges of capturing informative structural and semantic knowledge, we propose a new graph data augmentation framework, AGST (Augmented Graph Self-Training), which is built with two new (i.e., structural and semantic) augmentation modules on top of a decoupled GST backbone. In this work, we investigate whether this novel framework can learn a robust graph predictive model under the low-data context. We conduct comprehensive evaluations on semi-supervised node classification under different scenarios of limited labeled-node data. The experimental results demonstrate the unique contributions of the novel data augmentation framework for node classification with few labeled data. 	
Sustaining Fairness via Incremental Learning	http://arxiv.org/abs/2208.12212v2	2023-01-23T16:50:51Z	2022-08-25T17:02:37Z	  Machine learning systems are often deployed for making critical decisions like credit lending, hiring, etc. While making decisions, such systems often encode the user's demographic information (like gender, age) in their intermediate representations. This can lead to decisions that are biased towards specific demographics. Prior work has focused on debiasing intermediate representations to ensure fair decisions. However, these approaches fail to remain fair with changes in the task or demographic distribution. To ensure fairness in the wild, it is important for a system to adapt to such changes as it accesses new data in an incremental fashion. In this work, we propose to address this issue by introducing the problem of learning fair representations in an incremental learning setting. To this end, we present Fairness-aware Incremental Representation Learning (FaIRL), a representation learning system that can sustain fairness while incrementally learning new tasks. FaIRL is able to achieve fairness and learn new tasks by controlling the rate-distortion function of the learned representations. Our empirical evaluations show that FaIRL is able to make fair decisions while achieving high performance on the target task, outperforming several baselines. 	
"The Sustainable Response Strategy to COVID-19: Pandemic Urban Zoning
  Based on Multimodal Transport Data"	http://arxiv.org/abs/2208.12119v1	2022-08-25T14:28:28Z	2022-08-25T14:28:28Z	  Since the outbreak of COVID-19, it has rapidly evolved into a sudden and major public health emergency globally. With the variants of COVID-19, the difficulty of pandemic control continues to increase, which has brought significant costs to the society. The existing pandemic control zoning method ignores the impact on residents'lives. In this study, we propose a refined and low-cost pandemic control method by scientifically delineating zoning areas. First, a spatial interaction network is built up based on the multimodal transport travel data in Nanjing, China, and an improved Leiden community detection method based on the gravity model is used to obtain a preliminary zoning scheme. Then, we use spatial constraints to correct the results with the discrete spatial distribution. Finally, reasonable zones for pandemic control are obtained. The modularity of the algorithm results is 0.4185, proving that the proposed method is suitable for pandemic control zoning. The proposed method is also demonstrated to be able to minimize traffic flows between pandemic control areas and only 24.8% of travel connections are cut off, thus reducing the impact of pandemic control on residents'daily life and reducing the cost of pandemic control. The findings can help to inform sustainable strategies and suggestions for the pandemic control. 	
"WISE/NEOWISE Multi-Epoch Imaging of the Potentially Geminid-related
  Asteroids: (3200) Phaethon, 2005 UD and 1999 YC"	http://arxiv.org/abs/2208.12089v1	2022-08-25T13:43:30Z	2022-08-25T13:43:30Z	  We present space-based thermal infrared observations of the presumably Geminid-associated asteroids: (3200)Phaethon, 2005 UD and 1999 YC using WISE/NEOWISE. The images were taken at the four wavelength bands 3.4$\mu$m(W1),4.6$\mu$m(W2),12$\mu$m(W3),and 22$\mu$m(W4). We find no evidence of lasting mass-loss in the asteroids over the decadal multi-epoch datasets. We set an upper limit to the mass-loss rate in dust of Q<2kg s$^{-1}$ for Phaethon and <0.1kg s$^{-1}$ for both 2005 UD and 1999 YC, respectively, with little dependency over the observed heliocentric distances of R=1.0$-$2.3au. For Phaethon, even if the maximum mass-loss was sustained over the 1000(s)yr dynamical age of the Geminid stream, it is more than two orders of magnitude too small to supply the reported stream mass (1e13$-$14kg). The Phaethon-associated dust trail (Geminid stream) is not detected at R=2.3au, corresponding an upper limit on the optical depth of $\tau$<7e-9. Additionally, no co-moving asteroids with radii r<650m were found. The DESTINY+ dust analyzer would be capable of detecting several of the 10$\mu$m-sized interplanetary dust particles when at far distances(>50,000km) from Phaethon. From 2005 UD, if the mass-loss rate lasted over the 10,000yr dynamical age of the Daytime Sextantid meteoroid stream, the mass of the stream would be ~1e10kg. The 1999 YC images showed neither the related dust trail ($\tau$<2e-8) nor co-moving objects with radii r<170m at R=1.6au. Estimated physical parameters from these limits do not explain the production mechanism of the Geminid meteoroid stream. Lastly, to explore the origin of the Geminids, we discuss the implications for our data in relation to the possibly sodium (Na)-driven perihelion activity of Phaethon. 	
"Towards Sustainable Internet of Underwater Things: UAV-aided Energy
  Efficient Wake-up Solutions"	http://arxiv.org/abs/2208.12065v1	2022-08-25T12:54:57Z	2022-08-25T12:54:57Z	  With the advancements in underwater wireless communications, internet of underwater things (IoUT) realization is inevitable to enable many practical applications, such as exploring ocean resources, ocean monitoring, underwater navigation, and surveillance. The IoUT network comprises battery-operated sensor nodes, and replacing or charging such batteries is challenging due to the harsh ocean environment. Hence, an energy-efficient IoUT network development becomes vital to improve the network lifetime. Therefore, this paper proposes unmanned aerial vehicle (UAV)-aided energy-efficient wake-up designs to activate the underwater IoT nodes on-demand and reduce their energy consumption. Specifically, the UAV communicates with water surface nodes, i.e., buoys, to send wake-up signals to activate the IoUT sensor nodes from sleep mode. We present three different technologies to enable underwater wake-up: acoustic, optical, and magnetic induction-based solutions. Moreover, we verify the significance of each technology through simulations using the performance metrics of received power and lifetime. Also, the results of the proposed on-demand wake-up approach are compared to conventional duty cycling, showing the superior performance of the proposed schemes. Finally, we present some exciting research challenges and future directions. 	
Null and time-like geodesics in Kerr-Newman black hole exterior	http://arxiv.org/abs/2208.11906v1	2022-08-25T07:41:06Z	2022-08-25T07:41:06Z	  We study the null and time-like geodesics of the light and the neutral particles respectively in the exterior of Kerr-Newman black holes. The geodesic equations are known to be written as a set of first-order differential equations in Mino time from which the angular and radial potentials can be defined. We classify the roots for both potentials, and mainly focus on those of the radial potential with an emphasis on the effect from the charge of the black holes. We then obtain the solutions of the trajectories in terms of the elliptical integrals and the Jacobian elliptic functions for both null and time-like geodesics, which are manifestly real functions of the Mino time that the initial conditions can be explicitly specified. We also describe the details of how to reduce those solutions into the cases of the spherical orbits. The effect of the black hole's charge decreases the radii of the spherical motion of the light and the particle for both direct and retrograde motions. In particular, we focus on the light/particle boomerang of the spherical orbits due to the frame dragging from the back hole's spin with the effect from the charge of the black hole. To sustain the change of the azimuthal angle of the light rays, say for example $\Delta \phi=\pi$ during the whole trip, the presence of the black hole's charge decreases the radius of the orbit and consequently reduces the needed values of the black hole's spin. As for the particle boomerang, the particle's inertia renders smaller change of the angle $\Delta \phi$ as compared with the light boomerang. Moreover, the black hole's charge also results in the smaller angle change $\Delta \phi$ of the particle than that in the Kerr case. The implications of the obtained results to observations are discussed. 	
Heliosphere Meets Interstellar Medium, in a Galactic Context	http://arxiv.org/abs/2208.11804v1	2022-08-25T00:15:09Z	2022-08-25T00:15:09Z	  The physical conditions within our heliosphere are driven by the Sun's motion through an evolving interstellar environment that remains largely unexplored. The next generation of outer heliosphere and interstellar explorers will answer fundamental questions about the heliosphere's relationship with the very local interstellar medium (VLISM) by diving deeper into the Sun's interstellar surroundings. The impact of these future missions will be vastly enhanced by concurrent, interdisciplinary studies that examine the direct connections between conditions within the heliosphere, the heliosphere's immediate interstellar environment, and the larger-scale Galactic ISM. Comparisons of the heliosphere and VLISM to their analogs across the Galaxy will constrain the global processes shaping both stellar astrospheres and their sustained impact on the ISM. 	
"Room-temperature coherent optical manipulation of single-hole spins in
  solution-grown perovskite quantum dots"	http://arxiv.org/abs/2208.11614v1	2022-08-24T15:32:24Z	2022-08-24T15:32:24Z	  Manipulation of solid-state spin coherence is an important paradigm for quantum information processing. Current systems either operate at very low temperatures or are difficult to scale-up. Developing low-cost, scalable materials whose spins can be coherently manipulated at room temperature is thus highly-attractive for a sustainable future of quantum information science. Here we report ambient-condition all-optical initialization, manipulation and readout of single-hole spins in an ensemble of solution-grown CsPbBr3 perovskite QDs. Single-hole spins are obtained by sub-picosecond electron scavenging following a circularly-polarized femtosecond-pulse excitation. A transversal magnetic field induces spin precession, and a second off-resonance femtosecond-pulse coherently rotates hole spins via strong light-matter interaction. These operations accomplish nearly complete quantum-state control of single-hole spins at room temperature. 	
"Panacea or Placebo? Exploring Causal Effects of Nonlocal Vehicle Driving
  Restriction Policies on Traffic Congestion Using Difference-in-differences
  Approach"	http://arxiv.org/abs/2208.11577v2	2023-01-15T10:06:15Z	2022-08-24T14:32:02Z	  Car dependence has been threatening transportation sustainability as it contributes to congestion and associated externalities. In response, various transport policies that restrict the use of private vehicle have been implemented. However, empirical evaluations of such policies have been limited. To assess these policies' benefits and costs, it is imperative to accurately evaluate how such policies affect traffic conditions. In this study, we compile a refined spatio-temporal resolution data set of the floating-vehicle-based traffic performance index to examine the effects of a recent nonlocal vehicle driving restriction policy in Shanghai, one of most populous cities in the world. Specifically, we explore whether and how the policy impacted traffic speeds in the short term by employing a quasi-experimental difference-in-differences modeling approach. We find that: (1) In the first month, the policy led to an increase of the network-level traffic speed by 1.47% (0.352 km/h) during evening peak hours (17:00-19:00) but had no significant effects during morning peak hours (7:00-9:00). (2) The policy also helped improve the network-level traffic speed in some unrestricted hours (6:00, 12:00, 14:00, and 20:00) although the impact was marginal. (3) The short-term effects of the policy exhibited heterogeneity across traffic analysis zones. The lower the metro station density, the greater the effects were. We conclude that driving restrictions for non-local vehicles alone may not significantly reduce congestion, and their effects can differ both temporally and spatially. However, they can have potential side effects such as increased purchase and usage of new energy vehicles, owners of which can obtain a local license plate of Shanghai for free. 	
"LEFM is agnostic to geometrical nonlinearities arising at atomistic
  crack tips"	http://arxiv.org/abs/2208.11462v1	2022-08-24T12:06:42Z	2022-08-24T12:06:42Z	  Various fields such as mechanical engineering, materials science, etc., have seen a widespread use of linear elastic fracture mechanics (LEFM) at the continuum scale. LEFM is also routinely applied to the atomic scale. However, its applicability at this scale remains less well studied, with most studies focusing on non-linear elastic effects. Using a harmonic (snapping spring) nearest-neighbor potential which provides the closest match to LEFM on a discrete lattice, we show that the discrete nature of an atomic lattice leads to deviations from the LEFM displacement field during energy minimization. We propose that these deviations can be ascribed to geometrical nonlinearities since the material does not have a nonlinear elastic response prior to bond breaking. We demonstrate that crack advance and the critical stress intensity factor in an incremental loading scenario is governed by the collectively loaded region, and can not be determined analytically from the properties (max. elongation, max. sustained force, etc.) of the stressed crack tip bond alone. 	
"Development of a Scanning Tunneling Microscope for Variable Temperature
  Electron Spin Resonance"	http://arxiv.org/abs/2208.11234v1	2022-08-23T23:42:54Z	2022-08-23T23:42:54Z	  Recent advances in increasing the spectroscopic energy resolution in scanning tunneling microscopy (STM) have been achieved by integrating electron spin resonance (ESR) with STM. Here, we demonstrate the design and performance of a home-built STM capable of ESR at temperatures ranging from 1 K to 10 K. The STM is incorporated with a home-built Joule-Thomson refrigerator and a 2-axis vector magnet. Our STM design allows for the deposition of atoms and molecules directly into the cold STM, eliminating the need to extract the sample for deposition. In addition, we adopt two methods to apply radio-frequency (RF) voltages to the tunnel junction, the early design of wiring to the STM tip directly, and a more recent idea to use an RF antenna. Direct comparisons of ESR results measured using the two methods and simulations of electric field distribution around the tunnel junction show that, despite their different designs and capacitive couplings to the tunnel junction, there is no discernible difference in the driving and detection of ESR. Furthermore, at a magnetic field of 1.6 T, we observe ESR signals (near 40 GHz) sustained up to 10 K, which is the highest temperature for ESR-STM measurement reported to date, to the best of our knowledge. Although the ESR intensity exponentially decreases with increasing temperature, our ESR-STM system with low noise at the tunnel junction allows us to measure weak ESR signals with intensities in the sub-fA range. Our new design of ESR-STM, which is operational in a large frequency and temperature range, can broaden the use of ESR spectroscopy in STM and enable the simple modification of existing STM systems, which will hopefully accelerate a generalized use of ESR-STM. 	
Limits of Entrainment of Circadian Neuronal Networks	http://arxiv.org/abs/2208.11119v1	2022-08-23T17:57:21Z	2022-08-23T17:57:21Z	  Circadian rhythmicity lies at the center of various important physiological and behavioral processes in mammals, such as sleep, metabolism, homeostasis, mood changes and more. It has been shown that this rhythm arises from self-sustained biomolecular oscillations of a neuronal network located in the Suprachiasmatic Nucleus (SCN). Under normal circumstances, this network remains synchronized to the day-night cycle due to signaling from the retina. Misalignment of these neuronal oscillations with the external light signal can disrupt numerous physiological functions and take a long-lasting toll on health and well-being. In this work, we study a modern computational neuroscience model to determine the limits of circadian synchronization to external light signals of different frequency and duty cycle. We employ a matrix-free approach to locate periodic steady states of the high-dimensional model for various driving conditions. Our algorithmic pipeline enables numerical continuation and construction of bifurcation diagrams w.r.t. forcing parameters. We computationally explore the effect of heterogeneity in the circadian neuronal network, as well as the effect of corrective therapeutic interventions, such as that of the drug molecule Longdaysin. Lastly, we employ unsupervised learning to construct a data-driven embedding space for representing neuronal heterogeneity. 	
"AI and 6G into the Metaverse: Fundamentals, Challenges and Future
  Research Trends"	http://arxiv.org/abs/2208.10921v2	2022-09-24T15:38:57Z	2022-08-23T12:48:53Z	  Since Facebook was renamed Meta, a lot of attention, debate, and exploration have intensified about what the Metaverse is, how it works, and the possible ways to exploit it. It is anticipated that Metaverse will be a continuum of rapidly emerging technologies, usecases, capabilities, and experiences that will make it up for the next evolution of the Internet. Several researchers have already surveyed the literature on artificial intelligence (AI) and wireless communications in realizing the Metaverse. However, due to the rapid emergence and continuous evolution of technologies, there is a need for a comprehensive and in-depth survey of the role of AI, 6G, and the nexus of both in realizing the immersive experiences of Metaverse. Therefore, in this survey, we first introduce the background and ongoing progress in augmented reality (AR), virtual reality (VR), mixed reality (MR) and spatial computing, followed by the technical aspects of AI and 6G. Then, we survey the role of AI in the Metaverse by reviewing the state-of-the-art in deep learning, computer vision, and Edge AI to extract the requirements of 6G in Metaverse. Next, we investigate the promising services of B5G/6G towards Metaverse, followed by identifying the role of AI in 6G networks and 6G networks for AI in support of Metaverse applications, and the need for sustainability in Metaverse. Finally, we enlist the existing and potential applications, usecases, and projects to highlight the importance of progress in the Metaverse. Moreover, in order to provide potential research directions to researchers, we underline the challenges, research gaps, and lessons learned identified from the literature review of the aforementioned technologies. 	
"A Platform-Free Proof of Federated Learning Consensus Mechanism for
  Sustainable Blockchains"	http://arxiv.org/abs/2208.12046v3	2022-10-29T07:00:15Z	2022-08-23T10:08:03Z	  Proof of work (PoW), as the representative consensus protocol for blockchain, consumes enormous amounts of computation and energy to determine bookkeeping rights among miners but does not achieve any practical purposes. To address the drawback of PoW, we propose a novel energy-recycling consensus mechanism named platform-free proof of federated learning (PF-PoFL), which leverages the computing power originally wasted in solving hard but meaningless PoW puzzles to conduct practical federated learning (FL) tasks. Nevertheless, potential security threats and efficiency concerns may occur due to the untrusted environment and miners' self-interested features. In this paper, by devising a novel block structure, new transaction types, and credit-based incentives, PF-PoFL allows efficient artificial intelligence (AI) task outsourcing, federated mining, model evaluation, and reward distribution in a fully decentralized manner, while resisting spoofing and Sybil attacks. Besides, PF-PoFL equips with a user-level differential privacy mechanism for miners to prevent implicit privacy leakage in training FL models. Furthermore, by considering dynamic miner characteristics (e.g., training samples, non-IID degree, and network delay) under diverse FL tasks, a federation formation game-based mechanism is presented to distributively form the optimized disjoint miner partition structure with Nash-stable convergence. Extensive simulations validate the efficiency and effectiveness of PF-PoFL. 	
"A Survey and Framework of Cooperative Perception: From Heterogeneous
  Singleton to Hierarchical Cooperation"	http://arxiv.org/abs/2208.10590v1	2022-08-22T20:47:35Z	2022-08-22T20:47:35Z	  Perceiving the environment is one of the most fundamental keys to enabling Cooperative Driving Automation (CDA), which is regarded as the revolutionary solution to addressing the safety, mobility, and sustainability issues of contemporary transportation systems. Although an unprecedented evolution is now happening in the area of computer vision for object perception, state-of-the-art perception methods are still struggling with sophisticated real-world traffic environments due to the inevitably physical occlusion and limited receptive field of single-vehicle systems. Based on multiple spatially separated perception nodes, Cooperative Perception (CP) is born to unlock the bottleneck of perception for driving automation. In this paper, we comprehensively review and analyze the research progress on CP and, to the best of our knowledge, this is the first time to propose a unified CP framework. Architectures and taxonomy of CP systems based on different types of sensors are reviewed to show a high-level description of the workflow and different structures for CP systems. Node structure, sensor modality, and fusion schemes are reviewed and analyzed with comprehensive literature to provide detailed explanations of specific methods. A Hierarchical CP framework is proposed, followed by a review of existing Datasets and Simulators to sketch an overall landscape of CP. Discussion highlights the current opportunities, open challenges, and anticipated future trends. 	
"Transonic buffet characteristics under conditions of free and forced
  transition"	http://arxiv.org/abs/2208.10452v1	2022-08-22T17:11:48Z	2022-08-22T17:11:48Z	  Transonic buffet is commonly associated with self-sustained flow unsteadiness involving shock-wave/boundary-layer interaction over aerofoils and wings. The phenomenon has been classified as either laminar or turbulent based on the state of the boundary layer immediately upstream of the shock foot and distinct mechanisms for the two types have been suggested. The turbulent case is known to be associated with a global linear instability. Herein, large-eddy simulations are used for the first time to make direct comparisons of the two types by examining free- and forced-transition conditions. Corresponding simulations based on the Reynolds-averaged Navier--Stokes equations for the forced-transition case are also performed for comparison with the scale-resolving approach and for linking the findings with existing literature. Coherent flow features are scrutinised using both data-based spectral proper orthogonal decomposition of the time-marched results and operator-based global linear stability and resolvent analyses within the Reynolds-averaged Navier--Stokes framework. It is demonstrated that the essential dynamic features remain the same for the two buffet types (and for the two levels of the aerodynamic modelling hierarchy), suggesting that both types arise due to the same fundamental mechanism. 	
A Survey of Distributed Ledger Technology for IoT Verticals	http://arxiv.org/abs/2208.10120v1	2022-08-22T07:49:30Z	2022-08-22T07:49:30Z	  The Internet of Things (IoT) and Distributed ledger technology (DLT) have significantly changed our daily lives. Due to their distributed operational environment and naturally decentralized applications, the convergence of these two technologies indicates a more lavish arrangement for the future. This article develops a comprehensive survey to investigate and illustrate state-of-the-art DLT for various IoT use cases, from smart homes to autonomous vehicles and smart cities. We develop a novel framework for conducting a systematic and comprehensive review of DLT over IoT by extending the knowledge graph approach. With relevant insights from this review, we extract innovative and pragmatic techniques to DLT design that enable high-performance, sustainable, and highly scalable IoT systems. Our findings support designing an end-to-end IoT-native DLT architecture for the future that fully coordinates network-assisted functionalities. 	
"A Survey on Intelligent Computation Offloading and Pricing Strategy in
  UAV-Enabled MEC Network: Challenges and Research Directions"	http://arxiv.org/abs/2208.10072v1	2022-08-22T06:14:20Z	2022-08-22T06:14:20Z	  The Mobile Network Operator (MNO) must select how to delegate Mobile Device (MD) queries to its Mobile Edge Computing (MEC) server in order to maximize the overall benefit of admitted requests with varying latency needs. Unmanned Aerial Vehicles (UAVs) and Artificial Intelligent (AI) can increase MNO performance because of their flexibility in deployment, high mobility of UAV, and efficiency of AI algorithms. There is a trade-off between the cost incurred by the MD and the profit received by the MNO. Intelligent computing offloading to UAV-enabled MEC, on the other hand, is a promising way to bridge the gap between MDs' limited processing resources, as well as the intelligent algorithms that are utilized for computation offloading in the UAV-MEC network and the high computing demands of upcoming applications. This study looks at some of the research on the benefits of computation offloading process in the UAV-MEC network, as well as the intelligent models that are utilized for computation offloading. In addition, this article examines several intelligent pricing techniques in different structures in the UAV-MEC network. Finally, this work highlights some important open research issues and future research directions of Artificial Intelligent (AI) in computation offloading and applying intelligent pricing strategies in the UAV-MEC network. 	
"Towards Unifying Resilience and Sustainability for Transportation
  Infrastructure Systems: Conceptual Framework, Critical Indicators, and
  Research Needs"	http://arxiv.org/abs/2208.10039v1	2022-08-22T03:48:28Z	2022-08-22T03:48:28Z	  Sustainability aspects of transportation infrastructure systems primarily focus on system performance based on environmental, social, and economic impacts. In contrast, resilience aspects demonstrate the ability to withstand external shocks i.e. robustness as well as to recover from the loss of functionality due to such disruptions i.e. rapidity. Therefore, sustainability and resilience are two key aspects which should be given adequate attention during the planning, design, construction, operations, and maintenance phases of any civil infrastructure system. As both concepts are equally important to sustain an infrastructure for a longer duration, their concurrent assessments within a unified framework are highly desirable. While there has been a recent focus towards solving this dilemma, review of existing studies revealed the lack of such unifying frameworks that can quantify sustainability and resilience indicators to simultaneously assess system performance. Moreover, a single decision or performance indicator could reinforce one and undermine another. As such, this study proposed a forward-looking unification framework, where the sustainability and resilience of transportation infrastructure systems can be analyzed simultaneously. In this regard, the proposed unifying framework is explained using seven critical indicators including emission, speed, temperature, energy consumption, delay, mobility, and accessibility. This study also investigates the interdependencies, relationships, and tradeoffs between sustainability and resilience based on these indices. While some indices would help the system to attain both at the same time, they are compromised in some cases. Finally, the study identifies immediate research needs as well as the ones in the long-term. 	
Friendliness Of Stack Overflow Towards Newbies	http://arxiv.org/abs/2208.10488v1	2022-08-21T05:10:19Z	2022-08-21T05:10:19Z	  In today's modern digital world, we have a number of online Question and Answer platforms like Stack Exchange, Quora, and GFG that serve as a medium for people to communicate and help each other. In this paper, we analyzed the effectiveness of Stack Overflow in helping newbies to programming. Every user on this platform goes through a journey. For the first 12 months, we consider them to be a newbie. Post 12 months they come under one of the following categories: Experienced, Lurkers, or Inquisitive. Each question asked has tags assigned to it and we observe that questions with some specific tags have a faster response time indicating an active community in that field over others. The platform had a steady growth up to 2013 after which it started declining, but recently during the pandemic 2020, we can see rejuvenated activity on the platform. 	
"Preemptive Scheduling of EV Charging for Providing Demand Response
  Services"	http://arxiv.org/abs/2208.09790v2	2022-11-30T18:08:31Z	2022-08-21T03:25:12Z	  We develop a new algorithm for scheduling the charging process of a large number of electric vehicles (EVs) over a finite horizon. We assume that EVs arrive at the charging stations with different charge levels and different flexibility windows. The arrival process is assumed to have a known distribution and that the charging process of EVs can be preemptive. We pose the scheduling problem as a dynamic program with constraints. We show that the resulting formulation leads to a monotone dynamic program with Lipschitz continuous value functions that are robust against perturbation of system parameters. We propose a simulation based fitted value iteration algorithm to determine the value function approximately, and derive the sample complexity for computing the approximately optimal solution. 	
Autonomous waves and global motion modes in living active solids	http://arxiv.org/abs/2208.09664v2	2022-08-26T04:16:19Z	2022-08-20T11:52:12Z	  Elastic active matter or active solid consists of self-propelled units embedded in an elastic matrix. Active solid resists deformation; the shape-preserving property and the intrinsic non-equilibrium nature make active solids a superior component for self-driven devices. Nonetheless, the mechanical properties and emergent behavior of active solids are poorly understood. Using a biofilm-based bacterial active solid, here we discovered self-sustained elastic waves with unique wave properties not seen in passive solids, such as power-law scaling of wave speed with activity. Under isotropic confinement, the active solid develops two topologically distinct global motion modes that can be selectively excited, with a surprising step-like frequency jump at mode transition. Our findings reveal novel spatiotemporal order in elastic active matter and may guide the development of solid-state adaptive or living materials. 	
Dense Nuclear Matter with Baryon Overlap	http://arxiv.org/abs/2208.09331v1	2022-08-19T13:18:53Z	2022-08-19T13:18:53Z	  The possibility of new short-distance physics applicable inside the cores of NS is incorporated into the equation of state generated by the quark-meson coupling model. The contribution of this new physics to the energy density is taken to be proportional to the amount of overlap between the quark cores of the baryons involved. With no change to the properties of symmetric nuclear matter at saturation density, including an incompressibility compatible with data on giant monopole resonances, one can sustain neutron stars with a maximum mass $M_{max}>2.1$ M$_\odot$, even when hyperons are included. 	
"Large-scale influence of numerical noises as artificial stochastic
  disturbances on a sustained turbulence"	http://arxiv.org/abs/2208.11487v1	2022-08-19T07:27:39Z	2022-08-19T07:27:39Z	"  We investigate the large-scale influence of numerical noises as tiny artificial stochastic disturbances on a sustained turbulence. Using the two-dimensional (2D) turbulent Rayleigh-B\'enard (RB) convection as an example, we numerically solve the NS equations, separately, by means of a traditional algorithm with double precision (marked by RKwD) and the so-called clean numerical simulation (CNS). The numerical simulation given by the RKwD is a mixture of the ""true"" physical solution and the ""false"" numerical noises that is random and can be regarded as a kind of artificial stochastic disturbances: unfortunately, the ""true"" physical solution is mostly at the same level as the ""false"" numerical noises. By contrast, the CNS can greatly reduce the background numerical noise to any a required level so that the ""false"" numerical noises are negligible compared with the ""true"" physical solution and thus the CNS solution can be used as a ""clean"" benchmark solution for comparison. It is found that the numerical noises as tiny artificial stochastic disturbances could indeed lead to large-scale deviations of simulations not only in spatio-temporal trajectories but also even in statistics. Especially, these numerical noises (as artificial stochastic disturbances) even lead to different types of flows: the shearing convection occurs for the RKwD simulations, and its corresponding flow field turns to a kind of zonal flow thereafter, however the CNS benchmark solution always sustains the non-shearing vortical/roll-like convection during the whole process of simulation. Thus, we provide a rigorous evidence that numerical noises as a kind of small-scale artificial stochastic disturbances have quantitatively and qualitatively large-scale influences on a sustained turbulence, i.e. the 2D turbulent RB convection considered in this paper. "	
"Integrated modelling approaches for sustainable agri-economic growth and
  environmental improvement: Examples from Canada, Greece, and Ireland"	http://arxiv.org/abs/2208.09087v1	2022-08-18T22:54:20Z	2022-08-18T22:54:20Z	  Complex agricultural problems concern many countries, as the economic motives are increasingly higher, and at the same time the consequences from the irrational resources use and emissions are becoming more evident. In this work we study three of the most common agricultural problems and model them through optimization techniques, showing ways to assess conflicting objectives together as a system and provide overall optimum solutions. The studied problems refer to: i) a water-scarce area with overexploited surface and groundwater resources due to over-pumping for irrigation (Central Greece), ii) a water-abundant area with issues of water quality deterioration caused by agriculture (Southern Ontario, Canada), iii) and a case of intensified agriculture based on animal farming that causes issues of water, soil quality degradation, and increased greenhouse gases emissions (Central Ireland). Linear, non-linear, and Goal Programming optimization techniques have been developed and applied for each case to maximize farmers welfare, make a less intensive use of environmental resources, and control the emission of pollutants. The proposed approaches and their solutions are novel applications for each case-study, compared to the existing literature and practice. Furthermore, they provide useful insights for most countries facing similar problems, they are easily applicable, and developed and solved in publicly available tools such as Python. 	
"Droplet Migration in the Presence of a Reacting Surfactant at Low
  Pclet Numbers"	http://arxiv.org/abs/2208.09071v1	2022-08-18T21:16:04Z	2022-08-18T21:16:04Z	  A surfactant-laden droplet of one fluid dispersed in another immiscible fluid serves as an artificial model system capable of mimicking microbial swimmers. Either an interfacial chemical reaction or the process of solubilization generates gradients in interfacial tension resulting in a Marangoni flow. The resulting fluid flow propels the droplet toward a region of lower interfacial tension. The advective transport of surfactants sustains the active propulsion of these droplets. In these systems, the local interfacial tension is affected by the interfacial reaction kinetics as well as convection and diffusion induced concentration gradients. The migration of such a surfactant-laden viscous droplet undergoing an interfacial reaction, suspended in a background Poiseuille flow is investigated. The focus is specifically on the role of the surface reaction that generates a non-uniform interfacial coverage of the surfactant, which in turn dictates the migration velocity of the droplet in the background flow. Assuming negligible interface deformation and fluid inertia, the Lorentz reciprocal theorem is used to analytically determine the migration velocity of the droplet using regular perturbation expansion in terms of the surface P\'eclet number. We show that the presence of interfacial reaction affects the magnitude of both stream-wise and cross-stream migration velocity of the droplet in a background Poiseuille flow. We conclude that the stream-wise migration velocity is not of sufficient strength to exhibit positive rheotaxis as observed in recent experimental observations. Additional effects such as the hydrodynamic interactions with the adjacent wall may be essential to capture the same. 	
"Construction of a traversable wormhole from a suitable embedding
  function"	http://arxiv.org/abs/2208.09048v1	2022-08-18T20:36:35Z	2022-08-18T20:36:35Z	  In this work, we construct a traversable wormhole by providing a suitable embedding function ensuring the fulfilling of the flaring--out condition. The solution contains free parameters that are reduced through the study of the acceptable conditions of a traversable wormhole. We compute both the quantifier of exotic matter and the quasi--normal modes through the $13^{th}$ order WKB as a function of the remaining free parameters. We obtain that the wormhole geometry can be sustained by a finite amount of exotic matter and seems to be stable under scalar perturbations. 	
k-Dimensional Agreement in Multiagent Systems	http://arxiv.org/abs/2208.08999v1	2022-08-18T18:00:02Z	2022-08-18T18:00:02Z	  We study the problem of k-dimensional linear agreement, whereby a group of agents is interested in computing k independent weighted means of a global vector whose entries are known only by individual agents. This problem is motivated by applications in distributed computing and sensing, where agents seek to evaluate multiple independent functions at a common vector point by running a single distributed algorithm. We propose the use of linear network protocols for this task, and we show that linear dynamics can agree on quantities that are oblique projections of the global vector onto certain subspaces. Moreover, we provide algebraic necessary and sufficient conditions that characterize all agreement protocols that are consistent with a certain graph, we propose a design procedure for constructing such protocols, and we study what classes of graphs can achieve agreement on arbitrary weights. Overall, our results suggest that k-dimensional agreement requires the use of communication graphs with higher connectivity compared to standard consensus algorithms; more precisely, we relate the existence of Hamiltonian decompositions in a graph with the capability of that graph to sustain an agreement protocol. The applicability of the framework is illustrated via simulations for two problems in robotic formation and in distributed regression. 	
A semantic web approach to uplift decentralized household energy data	http://arxiv.org/abs/2208.10265v2	2022-08-26T22:48:54Z	2022-08-18T17:21:18Z	  In a decentralized household energy system comprised of various devices such as home appliances, electric vehicles, and solar panels, end-users are able to dig deeper into the system's details and further achieve energy sustainability if they are presented with data on the electric energy consumption and production at the granularity of the device. However, many databases in this field are siloed from other domains, including solely information pertaining to energy. This may result in the loss of information (e.g. weather) on each device's energy use. Meanwhile, a large number of these datasets have been extensively used in computational modeling techniques such as machine learning models. While such computational approaches achieve great accuracy and performance by concentrating only on a local view of datasets, model reliability cannot be guaranteed since such models are very vulnerable to data input fluctuations when information omission is taken into account. This article tackles the data isolation issue in the field of smart energy systems by examining Semantic Web methods on top of a household energy system. We offer an ontology-based approach for managing decentralized data at the device-level resolution in a system. As a consequence, the scope of the data associated with each device may easily be expanded in an interoperable manner throughout the Web, and additional information, such as weather, can be obtained from the Web, provided that the data is organized according to W3C standards. 	
"Detecting Environmental Violations with Satellite Imagery in Near Real
  Time: Land Application under the Clean Water Act"	http://arxiv.org/abs/2208.08919v1	2022-08-18T15:42:02Z	2022-08-18T15:42:02Z	"  This paper introduces a new, highly consequential setting for the use of computer vision for environmental sustainability. Concentrated Animal Feeding Operations (CAFOs) (aka intensive livestock farms or ""factory farms"") produce significant manure and pollution. Dumping manure in the winter months poses significant environmental risks and violates environmental law in many states. Yet the federal Environmental Protection Agency (EPA) and state agencies have relied primarily on self-reporting to monitor such instances of ""land application."" Our paper makes four contributions. First, we introduce the environmental, policy, and agricultural setting of CAFOs and land application. Second, we provide a new dataset of high-cadence (daily to weekly) 3m/pixel satellite imagery from 2018-20 for 330 CAFOs in Wisconsin with hand labeled instances of land application (n=57,697). Third, we develop an object detection model to predict land application and a system to perform inference in near real-time. We show that this system effectively appears to detect land application (PR AUC = 0.93) and we uncover several outlier facilities which appear to apply regularly and excessively. Last, we estimate the population prevalence of land application events in Winter 2021/22. We show that the prevalence of land application is much higher than what is self-reported by facilities. The system can be used by environmental regulators and interest groups, one of which piloted field visits based on this system this past winter. Overall, our application demonstrates the potential for AI-based computer vision systems to solve major problems in environmental compliance with near-daily imagery. "	
"Exploring Nanofibrous Networks with X-ray Photon Correlation
  Spectroscopy"	http://arxiv.org/abs/2208.08817v1	2022-08-18T13:17:02Z	2022-08-18T13:17:02Z	  Nanofibrous networks are the foundation and natural building strategy for all life forms on our planet. Apart from providing structural integrity to cells and tissues, they also provide a porous scaffold allowing transport of substances, where the resulting properties rely on the nanoscale network structure. Recently, there has been a great deal of interest in extracting and reassembling biobased nanofibers to create sustainable, advanced materials with applications ranging from high-performance textiles to artificial tissues. However, achieving structural control of the extracted nanofibers is challenging as it is strongly dependent on the extraction methods and source materials. Furthermore, the small nanofiber cross-sections and fast Brownian dynamics make them notoriously difficult to characterize in dispersions. In this work, we study the diffusive motion of spherical gold nanoparticles in semi-dilute networks of cellulose nanofibers (CNFs) using X-ray Photon Correlation Spectroscopy (XPCS). We find that the motion becomes increasingly subdiffusive with higher CNF concentration, where the dynamics can be decomposed into several superdiffusive relaxation modes in reciprocal space. Using simulations of confined Brownian dynamics in combination with simulated XPCS-experiments, we observe that the dynamic modes can be connected to pore sizes and inter-pore transport properties in the network. The demonstrated analytical strategy by combining experiments using tracer particles with a digital twin may be the key to understand nanoscale properties of nanofibrous networks. 	
Migratory Outbursting Quasi-Hilda Object 282P/(323137) 2003 BM80	http://arxiv.org/abs/2208.08592v1	2022-08-18T01:49:34Z	2022-08-18T01:49:34Z	  We report object 282P/(323137) 2003 BM80 is undergoing a sustained activity outburst, lasting over 15 months thus far. These findings stem in part from our NASA Partner Citizen Science project Active Asteroids (http://activeasteroids.net), which we introduce here. We acquired new observations of 282P via our observing campaign (Vatican Advanced Technology Telescope, Lowell Discovery Telescope, and the Gemini South telescope), confirming 282P was active on UT 2022 June 7, some 15 months after 2021 March images showed activity in the 2021/2022 epoch. We classify 282P as a member of the Quasi-Hilda Objects, a group of dynamically unstable objects found in an orbital region similar to, but distinct in their dynamical characteristics to, the Hilda asteroids (objects in 3:2 resonance with Jupiter). Our dynamical simulations show 282P has undergone at least five close encounters with Jupiter and one with Saturn over the last 180 years. 282P was most likely a Centaur or Jupiter Family Comet (JFC) 250 years ago. In 350 years, following some 15 strong Jovian interactions, 282P will most likely migrate to become a JFC or, less likely, a main-belt asteroid. These migrations highlight a dynamical pathway connecting Centaurs and JFC with Quasi-Hildas and, potentially, active asteroids. Synthesizing these results with our thermodynamical modeling and new activity observations, we find volatile sublimation is the primary activity mechanism. Observations of a quiescent 282P, which we anticipate will be possible in 2023, will help confirm our hypothesis by measuring a rotation period and ascertaining spectral type. 	
Understanding Scaling Laws for Recommendation Models	http://arxiv.org/abs/2208.08489v1	2022-08-17T19:13:17Z	2022-08-17T19:13:17Z	  Scale has been a major driving force in improving machine learning performance, and understanding scaling laws is essential for strategic planning for a sustainable model quality performance growth, long-term resource planning and developing efficient system infrastructures to support large-scale models. In this paper, we study empirical scaling laws for DLRM style recommendation models, in particular Click-Through Rate (CTR). We observe that model quality scales with power law plus constant in model size, data size and amount of compute used for training. We characterize scaling efficiency along three different resource dimensions, namely data, parameters and compute by comparing the different scaling schemes along these axes. We show that parameter scaling is out of steam for the model architecture under study, and until a higher-performing model architecture emerges, data scaling is the path forward. The key research questions addressed by this study include: Does a recommendation model scale sustainably as predicted by the scaling laws? Or are we far off from the scaling law predictions? What are the limits of scaling? What are the implications of the scaling laws on long-term hardware/system development? 	
"Urban feature analysis from aerial remote sensing imagery using
  self-supervised and semi-supervised computer vision"	http://arxiv.org/abs/2208.08047v1	2022-08-17T03:41:56Z	2022-08-17T03:41:56Z	  Analysis of overhead imagery using computer vision is a problem that has received considerable attention in academic literature. Most techniques that operate in this space are both highly specialised and require expensive manual annotation of large datasets. These problems are addressed here through the development of a more generic framework, incorporating advances in representation learning which allows for more flexibility in analysing new categories of imagery with limited labeled data. First, a robust representation of an unlabeled aerial imagery dataset was created based on the momentum contrast mechanism. This was subsequently specialised for different tasks by building accurate classifiers with as few as 200 labeled images. The successful low-level detection of urban infrastructure evolution over a 10-year period from 60 million unlabeled images, exemplifies the substantial potential of our approach to advance quantitative urban research. 	
Vehicle Electrification Solutions: review and open challenges	http://arxiv.org/abs/2208.07986v2	2022-08-19T13:18:28Z	2022-08-16T22:58:22Z	  An Electric Vehicle usually refers to any vehicle that is partially or fully powered by a battery that can be directly plugged into the mains. Therefore, the new vehicles provide various benefits, including convenience, efficiency, sustainability, and economy. The present study concerns a comprehensive review of vehicle electrification solutions. Indeed, the major electric vehicle technologies are presented. Moreover, based on several research works from the literature, the main electrification solutions are illustrated, including degree of electrification, battery system management, onboard chargers, and power converters. In addition, these solutions, as well as the open challenges, are discussed and evaluated. 	
Worldwide scaling of waste generation in urban systems	http://arxiv.org/abs/2208.07917v1	2022-08-16T19:27:25Z	2022-08-16T19:27:25Z	  The production of waste as a consequence of human activities is one of the most fundamental challenges facing our society and global ecological systems. Waste generation is rapidly increasing, with corresponding shifts in the structure of our societies where almost all nations are moving from rural agrarian societies to urban and technological ones. However, the connections between these radical societal shifts and waste generation have not yet been described. Here we apply scaling theory to establish a new understanding of waste in urban systems. We identify universal scaling laws of waste generation across diverse urban systems worldwide for three forms of waste: wastewater, municipal solid waste, and greenhouse gasses. We show that wastewater generation scales superlinearly, municipal solid waste scales linearly, and greenhouse gasses scales sublinearly with city size. In specific cases production can be understood in terms of city size coupled with financial and natural resources. For example, wastewater generation can be understood in terms of the increased economic activity of larger cities, and the deviations around the scaling relationship - indicating relative efficiency - depend on GDP per person and local rainfall. We also show how the temporal evolution of these scaling relationships reveals a loss of economies of scale and the general increase in waste production, where sublinear scaling relationships become linear. Our findings suggest general mechanisms controlling waste generation across diverse cities and global urban systems. Our approach offers a systematic approach to uncover these underlying mechanisms that might be key to reducing waste and pursing a more sustainable future. 	
"Synthetic control of structure and conduction properties in Na-Y-Zr-Cl
  solid electrolytes"	http://arxiv.org/abs/2208.07823v1	2022-08-16T16:09:14Z	2022-08-16T16:09:14Z	  In the development of low cost, sustainable, and energy-dense batteries, chloride-based compounds are promising catholyte materials for solid-state batteries owing to their high Na-ion conductivities and oxidative stabilities. The ability to further improve Na-ion conduction, however, requires an understanding of the impact of long-range and local structural features on transport in these systems. In this study, we leverage different synthesis methods to control polymorphism and cation disorder in Na-Y-Zr-Cl solid electrolytes and interrogate the impact on Na-ion conduction. We demonstrate the existence of a more conductive P2$_1$/n polymorph of Na$_2$ZrCl$_6$ formed upon ball milling. In Na$_3$YCl$_6$, the R$\bar{3}$ polymorph is shown to be more conductive than its P2$_1$/n counterpart owing to the presence of intrinsic vacancies and disorder on the Y sublattice. Transition metal ordering in the Na$_{2.25}$Y$_{0.25}$Zr$_{0.75}$Cl$_6$ composition strongly impacts Na-ion transport, where a greater mixing of Y$^{3+}$ and Zr$^{4+}$ on the transition metal sublattice facilitates ion migration through partial activation of Cl rotations at relevant temperatures. Overall, Na-ion transport sensitively depends on the phases and transition metal distributions stabilized during synthesis. These results are likely generalizable to other halide compositions and indicate that achieving control over the synthetic protocol and resultant structure is key in the pursuit of improved catholytes for high voltage solid-state sodium-ion batteries. 	
"Analysing Factors Affecting the Adoption of Ride-Hailing Services (RHS)
  in India? A Step-Wise LCCA-MCDM Modeling Approach"	http://arxiv.org/abs/2208.07804v1	2022-08-16T15:33:39Z	2022-08-16T15:33:39Z	  The study examines heterogeneity in travel behaviour among ride-hailing services (RHS) users by including attitudes, in order to reinforce conventional user-segmentation approaches. Simultaneously, prioritization of ride-hailing specific attributes was carried out to assess how RHS will operate in a sustainable way. 	
"A Research Software Engineering Workflow for Computational Science and
  Engineering"	http://arxiv.org/abs/2208.07460v1	2022-08-15T22:33:07Z	2022-08-15T22:33:07Z	  University research groups in Computational Science and Engineering (CSE) generally lack dedicated funding and personnel for Research Software Engineering (RSE), which, combined with the pressure to maximize the number of scientific publications, shifts the focus away from sustainable research software development and reproducible results. The neglect of RSE in CSE at University research groups negatively impacts the scientific output: research data - including research software - related to a CSE publication cannot be found, reproduced, or re-used, different ideas are not combined easily into new ideas, and published methods must very often be re-implemented to be investigated further. This slows down CSE research significantly, resulting in considerable losses in time and, consequentially, public funding.   We propose a RSE workflow for Computational Science and Engineering (CSE) that addresses these challenges, that improves the quality of research output in CSE. Our workflow applies established software engineering practices adapted for CSE: software testing, result visualization, and periodical cross-linking of software with reports/publications and data, timed by milestones in the scientific publication process. The workflow introduces minimal work overhead, crucial for university research groups, and delivers modular and tested software linked to publications whose results can easily be reproduced. We define research software quality from a perspective of a pragmatic researcher: the ability to quickly find the publication, data, and software related to a published research idea, quickly reproduce results, understand or re-use a CSE method, and finally extend the method with new research ideas. 	
"A sustainable waste-to-protein system to maximise waste resource
  utilisation for developing food- and feed-grade protein solutions"	http://arxiv.org/abs/2208.07703v1	2022-08-15T14:46:42Z	2022-08-15T14:46:42Z	  A waste-to-protein system that integrates a range of waste-to-protein upgrading technologies has the potential to converge innovations on zero-waste and protein security to ensure a sustainable protein future. We present a global overview of food-safe and feed-safe waste resource potential and technologies to sort and transform such waste streams with compositional quality characteristics into food-grade or feed-grade protein. The identified streams are rich in carbon and nutrients and absent of pathogens and hazardous contaminants, including food waste streams, lignocellulosic waste from agricultural residues and forestry, and contaminant-free waste from the food and drink industry. A wide range of chemical, physical, and biological treatments can be applied to extract nutrients and convert waste-carbon to fermentable sugars or other platform chemicals for subsequent conversion to protein. Our quantitative analyses suggest that the waste-to-protein system has the potential to maximise recovery of various low-value resources and catalyse the transformative solutions toward a sustainable protein future. However, novel protein regulation processes remain expensive and resource intensive in many countries, with protracted timelines for approval. This poses a significant barrier to market expansion, despite accelerated research and development in waste-to-protein technologies and novel protein sources. Thus, the waste-to-protein system is an important initiative to promote metabolic health across the lifespan and tackle the global hunger crisis. 	
"New near-analytical path to the threshold size of spherical random
  lasing via geometric-distribution-probability weighting of the diffusive
  photon fluence rate"	http://arxiv.org/abs/2209.06164v1	2022-08-15T14:44:37Z	2022-08-15T14:44:37Z	  We demonstrate a new near-analytical path to the threshold-size of random-lasing for the case of a uniform and isotropic-scattering sphere. We assess a geometric-distribution-probability (GDP) weighted integration of the diffusion-equation derived time-dependent photon fluence-rate at a spherical boundary, in response to uniform, synchronous, and Delta-functional photon generations within the sphere. The GDP weights the contribution of the modeled Delta-functional photon sources to the temporal behavior of the photon fluence rate at the spherical boundary-domain based on the line-of-sight distance between the modeled-photon source and the same field point. The integral manifests a bi-phasic pattern versus time with a global minimum followed by an exponential growth. The line-of-sight length that corresponds to the time of global minimum decreases monotonically as the size of the sphere increases. The condition that this line-of-sight length equaling the radius of the sphere is hypothesized to indicate a threshold whereby the medium can sustain the growth of the photon fluence-rate at the boundary over time. This threshold line-of-sight length is assessed over a gain/scattering ratio of [0.001, 10000] covering the diffusive to quasi-ballistic regimes. The threshold line-of-sight length applied with a simple empirical gain/scattering ratio predicts the threshold size over the diffusive region and outperforms the threshold size given by the eigen-mode-decomposition in the semi-ballistic region, when compared to the radiative transfer approach. The method sheds new insights to amplified diffusion process in a scattering medium with gain. 	
Nanomechanical Resonators: Toward Atomic Scale	http://arxiv.org/abs/2208.07164v3	2022-11-20T11:34:04Z	2022-08-15T13:06:20Z	  The quest for realizing and manipulating ever smaller man-made movable structures and dynamical machines has spurred tremendous endeavors, led to important discoveries, and inspired researchers to venture to new grounds. Scientific feats and technological milestones of miniaturization of mechanical structures have been widely accomplished by advances in machining and sculpturing ever shrinking features out of bulk materials such as silicon. With the flourishing multidisciplinary field of low-dimensional nanomaterials, including one-dimensional (1D) nanowires/nanotubes, and two-dimensional (2D) atomic layers such as graphene/phosphorene, growing interests and sustained efforts have been devoted to creating mechanical devices toward the ultimate limit of miniaturization--genuinely down to the molecular or even atomic scale. These ultrasmall movable structures, particularly nanomechanical resonators that exploit the vibratory motion in these 1D and 2D nano-to-atomic-scale structures, offer exceptional device-level attributes, such as ultralow mass, ultrawide frequency tuning range, broad dynamic range, and ultralow power consumption, thus holding strong promises for both fundamental studies and engineering applications. In this Review, we offer a comprehensive overview and summary of this vibrant field, present the state-of-the-art devices and evaluate their specifications and performance, outline important achievements, and postulate future directions for studying these miniscule yet intriguing molecular-scale machines. 	
"Handling Interference in Integrated HAPS-Terrestrial Networks through
  Radio Resource Management"	http://arxiv.org/abs/2208.06971v3	2022-09-27T02:08:18Z	2022-08-15T02:08:07Z	  Vertical heterogeneous networks (vHetNets) are promising architectures to bring significant advantages for 6G and beyond mobile communications. High altitude platform station (HAPS), one of the nodes in the vHetNets, can be considered as a complementary platform for terrestrial networks to meet the ever-increasing dynamic capacity demand and provide sustainable wireless networks for future. However, the problem of interference is the bottleneck for the optimal operation of such an integrated network. Thus, designing efficient interference management techniques is inevitable. In this work, we aim to design a joint power-subcarrier allocation scheme in order to achieve fairness for all users. We formulate the max-min fairness (MMF) optimization problem and develop a rapid converging iterative algorithm to solve it. Numerical results validate the superiority of the proposed algorithm and show better performance over other conventional network scenarios. 	
Pulsating active matter	http://arxiv.org/abs/2208.06831v2	2022-12-12T16:28:25Z	2022-08-14T11:24:38Z	  Cells in tissues consume fuel to sustain periodic mechanical deformation. The combination of individual deformation and local interactions yields contraction waves, propagating throughout tissues with only negligible cell displacement. We consider a model of dense repulsive particles whose activity drives periodic change in size of each individual. It reveals that, in dense environments, pulsation of synchronised particles is a generic route to contraction waves. The competition between repulsion and synchronisation triggers an instability which promotes a wealth of dynamical patterns, ranging from spiral waves to defect turbulence. We identify the mechanisms underlying the emergence of patterns, and characterize the corresponding transitions. We derive the hydrodynamics of our model, and propose an analogy with that of reaction-diffusion systems. 	
A mushy source for the geysers of Enceladus	http://arxiv.org/abs/2208.06714v1	2022-08-13T19:15:36Z	2022-08-13T19:15:36Z	  Enceladus is a primary target for astrobiology due to the salty plume ejecta measured by the Cassini spacecraft and the inferred subsurface ocean sustained by tidal heating. Sourcing the plumes via a direct connection from the ocean to the surface requires a fracture through the entire ice shell ($\sim$10 km). Here we explore an alternative mechanism in which shear heating within the shallower tiger stripe fractures produces partial melting in the ice shell, allowing the interstitial fluid to be ejected as geysers. We use a two-dimensional multiphase reactive transport model to simulate the thermomechanics of a mushy region generated by localized shear heating in a salty ice shell. From our model, we predict the temperature, porosity, melting rate, and liquid volume of an intrashell mushy zone surrounding a fracture. We find that there is sufficient brine volume within the mushy zone to sustain the geysers for $\sim250$ kyr, without additional melting, and that the rate of internal melting can match the observed ice ejection rate. The composition of the liquid brine within the mushy zone is, however, distinct from the ocean, due to partial melting. This shear heating mechanism for geyser formation applies to Enceladus and other moons and has implications for our understanding of the geophysical processes and astrobiological potential of icy satellites. 	
"Self-Sustained Non-Equilibrium Co-existence of Fluid and Solid States in
  a Strongly Coupled Complex Plasma System"	http://arxiv.org/abs/2208.06605v1	2022-08-13T09:12:06Z	2022-08-13T09:12:06Z	  A complex (dusty) plasma system is well known as a paradigmatic model for studying the kinetics of solid-liquid phase transitions in inactive condensed matter. At the same time, under certain conditions a complex plasma system can also display characteristics of an active medium with the micron-sized particles converting energy of the ambient environment into motility and thereby becoming active. We present a detailed analysis of the experimental complex plasmas system that shows evidence of a non-equilibrium stationary coexistence between a cold crystalline and a hot fluid state in the structure due to the conversion of plasma energy into the motion energy of microparticles in the central region of the system. The plasma mediated non-reciprocal interaction between the dust particles is the underlying mechanism for the enormous heating of the central subsystem, and it acts as a micro-scale energy source that keeps the central subsystem in the molten state. Accurate multiscale simulations of the system based on combined molecular dynamics and particle-in-cell approaches show that strong structural nonuniformity of the system under the action of electostatic trap makes development of instabilities a local process. We present both experimental tests conducted with a complex plasmas system in a DC glow discharge plasma and a detailed theoretical analysis. 	
Double Auctions with Two-sided Bandit Feedback	http://arxiv.org/abs/2208.06536v1	2022-08-13T01:03:34Z	2022-08-13T01:03:34Z	  Double Auction enables decentralized transfer of goods between multiple buyers and sellers, thus underpinning functioning of many online marketplaces. Buyers and sellers compete in these markets through bidding, but do not often know their own valuation a-priori. As the allocation and pricing happens through bids, the profitability of participants, hence sustainability of such markets, depends crucially on learning respective valuations through repeated interactions. We initiate the study of Double Auction markets under bandit feedback on both buyers' and sellers' side. We show with confidence bound based bidding, and `Average Pricing' there is an efficient price discovery among the participants. In particular, the buyers and sellers exchanging goods attain $O(\sqrt{T})$ regret in $T$ rounds. The buyers and sellers who do not benefit from exchange in turn only experience $O(\log{T}/ \Delta)$ regret in $T$ rounds where $\Delta$ is the minimum price gap. We augment our upper bound by showing that even with a known fixed price of the good -- a simpler learning problem than Double Auction -- $\omega(\sqrt{T})$ regret is unattainable in certain markets. 	
"Robotic Inspection and Characterization of Subsurface Defects on
  Concrete Structures Using Impact Sounding"	http://arxiv.org/abs/2208.06305v1	2022-08-12T14:43:52Z	2022-08-12T14:43:52Z	  Impact-sounding (IS) and impact-echo (IE) are well-developed non-destructive evaluation (NDE) methods that are widely used for inspections of concrete structures to ensure the safety and sustainability. However, it is a tedious work to collect IS and IE data along grid lines covering a large target area for characterization of subsurface defects. On the other hand, data processing is very complicated that requires domain experts to interpret the results. To address the above problems, we present a novel robotic inspection system named as Impact-Rover to automate the data collection process and introduce data analytics software to visualize the inspection result allowing regular non-professional people to understand. The system consists of three modules: 1) a robotic platform with vertical mobility to collect IS and IE data in hard-to-reach locations, 2) vision-based positioning module that fuses the RGB-D camera, IMU and wheel encoder to estimate the 6-DOF pose of the robot, 3) a data analytics software module for processing the IS data to generate defect maps. The Impact-Rover hosts both IE and IS devices on a sliding mechanism and can perform move-stop-sample operations to collect multiple IS and IE data at adjustable spacing. The robot takes samples much faster than the manual data collection method because it automatically takes the multiple measurements along a straight line and records the locations. This paper focuses on reporting experimental results on IS. We calculate features and use unsupervised learning methods for analyzing the data. By combining the pose generated by our vision-based localization module and the position of the head of the sliding mechanism we can generate maps of possible defects. The results on concrete slabs demonstrate that our impact-sounding system can effectively reveal shallow defects. 	
"Short time existence of a quasi-stationary fluid-structure interaction
  problem for plaque growth"	http://arxiv.org/abs/2208.06280v1	2022-08-12T14:03:09Z	2022-08-12T14:03:09Z	  We address a quasi-stationary fluid-structure interaction problem coupled with cell reactions and growth, which comes from the plaque formation during the stage of the atherosclerotic lesion in human arteries. The blood is modeled by the incompressible Navier--Stokes equation, while the motion of vessels is captured by a quasi-stationary equation of nonlinear elasticity. The growth happens when both cells in fluid and solid react, diffuse and transport across the interface, resulting in the accumulation of foam cells, which are exactly seen as the plaques. Via a fixed-point argument, we derive the local well-posedness of the nonlinear system, which is sustained by the analysis of decoupled linear systems. 	
"Comparison of Forecasting Methods of House Electricity Consumption for
  Honda Smart Home"	http://arxiv.org/abs/2208.07217v1	2022-08-11T19:04:41Z	2022-08-11T19:04:41Z	  The electricity consumption of buildings composes a major part of the city's energy consumption. Electricity consumption forecasting enables the development of home energy management systems resulting in the future design of more sustainable houses and a decrease in total energy consumption. Energy performance in buildings is influenced by many factors like ambient temperature, humidity, and a variety of electrical devices. Therefore, multivariate prediction methods are preferred rather than univariate. The Honda Smart Home US data set was selected to compare three methods for minimizing forecasting errors, MAE and RMSE: Artificial Neural Networks, Support Vector Regression, and Fuzzy Rule-Based Systems for Regression by constructing many models for each method on a multivariate data set in different time terms. The comparison shows that SVR is a superior method over the alternatives. 	
"Solar-like to Antisolar Differential Rotation: A Geometric
  Interpretation"	http://arxiv.org/abs/2208.05591v1	2022-08-10T23:47:13Z	2022-08-10T23:47:13Z	  The solar convection zone rotates differentially, with its equatorial region rotating more rapidly than the polar regions. This form of differential rotation, also observed in many other low-mass stars, is understood to arise when Coriolis effects are stronger than those associated with buoyant driving of the convection. When buoyancy dominates, a so-called antisolar state of differential rotation results, characterized by rapidly-rotating poles and a slow equator. The transition between these two states has been shown to occur when the intensity of these two forces is roughly equal or, equivalently, when the convective Rossby number of the system is unity. Here we consider an alternative view of the transition that relates this phenomenon to convective structure and convective-zone depth. Using a series of 3-D rotating convection-zone simulations, we demonstrate that the solar/antisolar transition occurs when the columnar convective structures characteristic of rotating convection attain a diameter roughly equivalent to the shell depth. When the characteristic convective wavelength exceeds twice the shell depth, we find that the coherent convective structures necessary to sustain an equatorward Reynolds stress are lost, and an antisolar state results. We conclude by presenting a force-balance analysis that relates this geometric interpretation of the transition to the convective-Rossby-number criteria identified in previous studies. 	
"Regular and sparse neuronal synchronization are described by identical
  mean field dynamics"	http://arxiv.org/abs/2208.05515v2	2022-08-12T08:19:57Z	2022-08-10T18:24:17Z	  Fast neuronal oscillations (>30~Hz) are very often characterized by a dichotomy between macroscopic and microscopic dynamics. At the macroscopic level oscillations are highly periodic, while individual neurons display very irregular spike discharges at a rate that is low compared to the global oscillation frequency. Theoretical work revealed that this dynamical state robustly emerges in large networks of inhibitory neurons with strong feedback inhibition and significant levels of noise. This so-called `sparse synchronization' is considered to be at odds with the classical theory of collective synchronization of heterogeneous self-sustained oscillators, where synchronized neurons fire regularly. By means of an exact mean field theory for populations of heterogeneous, quadratic integrate-and-fire (QIF) neurons -- that here we extend to include Cauchy noise -- , we show that networks of stochastic QIF neurons showing sparse synchronization are governed by exactly the same mean field equations as deterministic networks displaying regular, collective synchronization. Our results reconcile two traditionally confronted views on neuronal synchronization, and upgrade the applicability of exact mean field theories to describe a broad range of biologically realistic neuronal states. 	
"CLARION2-TRINITY: a Compton-suppressed HPGe and GAGG:Ce-Si-Si array for
  absolute cross-section measurements with heavy ions"	http://arxiv.org/abs/2208.05449v1	2022-08-10T17:05:45Z	2022-08-10T17:05:45Z	  The design and performance of a new Compton-suppressed HPGe and charged-particle array, CLARION2-TRINITY, are described. The TRINITY charged-particle array is comprised of 64 Cerium-doped Gadolinium Aluminium Gallium Garnet (GAGG:Ce) crystals configured into five rings spanning 7-54 degrees, and two annular silicon detectors that can shadow or extend the angular coverage to backward angles with minimal $\gamma$-ray attenuation. GAGG:Ce is a non-hygroscopic, bright, and relatively fast scintillator with a light distribution well matched to SiPMs. Count rates up to 40 kHz per crystal are sustainable. Fundamental characteristics of GAGG:Ce are measured and presented, including light- and heavy-ion particle identification (PID) capability, pulse-height defects, radiation hardness, and emission spectra. The CLARION2 array consists of up to 16 Compton-suppressed HPGe Clover detectors ($\approx4\%$ efficiency at 1 MeV) configured into four rings (eight HPGe crystal rings) using a non-Archimedean geometry that suppresses back-to-back coincident 511-keV gamma rays. The entire array is instrumented with 100- and 500-MHz (14 bit) waveform digitizers which enable triggerless operation, pulse-shape discrimination, fast timing, and pileup correction. Finally, two examples of experimental data taken during the commissioning of the CLARION2-TRINITY system are given: a PID spectrum from $^{16}$O + $^{18}$O fusion-evaporation, and PID and Doppler-corrected $\gamma$-ray spectra from $^{48}$Ti + $^{12}$C Coulomb excitation. 	
"Self-Assembled Fatty Acid Crystalline Coatings Display Non-Toxic
  Superhydrophobic Antimicrobial Properties"	http://arxiv.org/abs/2208.08895v1	2022-08-10T12:15:19Z	2022-08-10T12:15:19Z	  Superhydrophobcity is a well-known wetting phenomenon found in numerous plants and insects. It is achieved by the combination of the surfaces chemical properties and its surface roughness. Inspired by nature, numerous synthetic superhydrophobic surfaces have been developed for various applications. Designated surface coating is one of the fabrication routes to achieve the superhydrophobicity. Yet, many of these coatings, such as fluorine-based formulations, may pose severe health and environmental risks, limiting the applicability. Herein, we present a new family of superhydrophobic coatings comprised of natural saturated fatty acids, which are not only a part of our daily diet, but can be produced from renewable feedstock, providing a safe and sustainable alternative to existing state-of-the-art. These crystalline coatings are readily fabricated via single-step deposition routes, thermal deposition or spray-coating. The fatty acids self-assemble into highly hierarchical crystalline structures exhibiting a water contact angle of about 165 degrees and contact angle hysteresis lower than 6 degrees, while their properties and morphology depend on the specific fatty acid used as well as on the deposition technique. Moreover, the fatty acid coatings demonstrate excellent thermal stability. Importantly these new family of coatings displays excellent anti-biofouling and antimicrobial properties against Escherichia coli and Listeria innocua, used as relevant model Gram-negative and Gram-positive bacteria, respectively. We believe that these coatings have a great application potential in the fields, where other alternatives are prohibited due to safety limitations, while at the same time their usage in other regulation-free applications is not limited. 	
Measuring Race in US Economic Statistics: What Do We Know?	http://arxiv.org/abs/2208.05252v1	2022-08-10T10:08:01Z	2022-08-10T10:08:01Z	  This article is an edited transcript of the session of the same name at the 38th Annual NABE Economic Policy Conference: Policy Options for Sustainable and Inclusive Growth. The panelists are experts from government and private research organizations. 	
"Preserving the beamforming effect for spatial cue-based pseudo-binaural
  dereverberation of a single source"	http://arxiv.org/abs/2208.05184v1	2022-08-10T07:07:05Z	2022-08-10T07:07:05Z	  Reverberations are unavoidable in enclosures, resulting in reduced intelligibility for hearing impaired and non native listeners and even for the normal hearing listeners in noisy circumstances. It also degrades the performance of machine listening applications. In this paper, we propose a novel approach of binaural dereverberation of a single speech source, using the differences in the interaural cues of the direct path signal and the reverberations. Two beamformers, spaced at an interaural distance, are used to extract the reverberations from the reverberant speech. The interaural cues generated by these reverberations and those generated by the direct path signal act as a two class dataset, used for the training of U-Net (a deep convolutional neural network). After its training, the beamformers are removed and the trained U-Net along with the maximum likelihood estimation (MLE) algorithm is used to discriminate between the direct path cues from the reverberation cues, when the system is exposed to the interaural spectrogram of the reverberant speech signal. Our proposed model has outperformed the classical signal processing dereverberation model weighted prediction error in terms of cepstral distance (CEP), frequency weighted segmental signal to noise ratio (FWSEGSNR) and signal to reverberation modulation energy ratio (SRMR) by 1.4 points, 8 dB and 0.6dB. It has achieved better performance than the deep learning based dereverberation model by gaining 1.3 points improvement in CEP with comparable FWSEGSNR, using training dataset which is almost 8 times smaller than required for that model. The proposed model also sustained its performance under relatively similar unseen acoustic conditions and at positions in the vicinity of its training position. 	
Scavengers in the human-dominated landscape: an experimental study	http://arxiv.org/abs/2208.05030v2	2022-08-11T09:33:47Z	2022-08-09T20:22:03Z	  Rapid urbanization is a major cause of habitat and biodiversity loss and human-animal conflict. While urbanization is inevitable, we need to develop a good understanding of the urban ecosystem and the urban-adapted species in order to ensure sustainable cities for our future. Scavengers play a major role in urban ecosystems, and often, urban adaptation involves a shift towards scavenging behaviour in wild animals. We carried out an experiment at different sites in the state of West Bengal, India, to identify the scavenging guild within urban habitats, in response to human provided food. Our study revealed a total of 17 different vertebrate species were identified across sites over 498 sessions of observations. We carried out network analysis to understand the dynamics of the system, and found that the free-ranging dog and common mynah were key species within the scavenging networks. This study revealed the complexity of scavenging networks within human-dominated habitats. 	
"Hyper-Eddington Black Hole Growth in Star-Forming Molecular Clouds and
  Galactic Nuclei: Can It Happen?"	http://arxiv.org/abs/2208.05025v2	2022-11-04T21:25:39Z	2022-08-09T20:05:39Z	"  Formation of supermassive black holes (BHs) remains a theoretical challenge. In many models, especially beginning from stellar relic ""seeds,"" this requires sustained super-Eddington accretion. While studies have shown BHs can violate the Eddington limit on accretion disk scales given sufficient ""fueling"" from larger scales, what remains unclear is whether or not BHs can actually capture sufficient gas from their surrounding ISM. We explore this in a suite of multi-physics high-resolution simulations of BH growth in magnetized, star-forming dense gas complexes including dynamical stellar feedback from radiation, stellar mass-loss, and supernovae, exploring populations of seeds with masses $\sim 1-10^{4}\,M_{\odot}$. In this initial study, we neglect feedback from the BHs: so this sets a strong upper limit to the accretion rates seeds can sustain. We show that stellar feedback plays a key role. Complexes with gravitational pressure/surface density below $\sim 10^{3}\,M_{\odot}\,{\rm pc^{-2}}$ are disrupted with low star formation efficiencies so provide poor environments for BH growth. But in denser cloud complexes, early stellar feedback does not rapidly destroy the clouds but does generate strong shocks and dense clumps, allowing $\sim 1\%$ of randomly-initialized seeds to encounter a dense clump with low relative velocity and produce runaway, hyper-Eddington accretion (growing by orders of magnitude). Remarkably, mass growth under these conditions is almost independent of initial BH mass, allowing rapid IMBH formation even for stellar-mass seeds. This defines a necessary (but perhaps not sufficient) set of criteria for runaway BH growth: we provide analytic estimates for the probability of runaway growth under different ISM conditions. "	
"Direct and diffuse shading factors modelling for the most representative
  agrivoltaic system layouts"	http://arxiv.org/abs/2208.04886v1	2022-08-09T16:31:26Z	2022-08-09T16:31:26Z	  Agrivoltaic systems are becoming more popular as a critical technology for attaining several sustainable development goals such as affordable and clean energy, zero hunger, clean water and sanitation, and climate action. However, understanding the shading effects on crops is fundamental to choosing an optimal agrivoltaic system as a wrong choice could lead to severe crop reductions. In this study, fixed vertical, one-axis tracking, and two-axis tracking photovoltaic arrays for agrivoltaic applications are developed to analyse the shading conditions on the ground used for crop production. The models have shown remarkably similar accuracy compared to commercial software such as PVsyst and SketchUp. The developed models will help reduce the crop yield uncertainty under agrivoltaic systems by providing accurate photosynthetically active radiation distribution at the crop level. The distribution was further analysed using a light homogeneity index and calculating the yearly photosynthetically active radiation reduction. The homogeneity and photosynthetically active radiation reduction varied significantly depending on the agrivoltaic system design, from 91% to 95% and 11% to 34%, respectively. To identify the most suitable agrivoltaic system layout dependent on crop and geographical location, it is of fundamental importance to study the effect of shadings with distribution analysis. 	
"Assigning Shadow Prices to Synthetic Inertia and Frequency Response
  Reserves from Renewable Energy Sources"	http://arxiv.org/abs/2208.04869v1	2022-08-09T15:58:34Z	2022-08-09T15:58:34Z	  Modern electricity grids throughout the world, particularly in islands such as Great Britain, face a major problem on the road to decarbonisation: the significantly reduced level of system inertia due to integration of Renewable Energy Sources (RES). Given that most RES such as wind and solar are decoupled from the grid through power electronics converters, they do not naturally contribute to system inertia. However, RES could support grid stability through appropriately controlling the converters, but currently no market incentives exist for RES to provide this support. In this paper we develop a methodology to optimally clear a market of ancillary services for frequency control, while explicitly considering the participation of grid-forming and grid-following inverter-based technologies. We propose a mathematical framework that allows to compute shadow prices for ancillary services offered by a pool of diverse providers: synchronous and synthetic inertia, enhanced frequency response (e.g. from curtailed RES) and traditional primary frequency response (e.g. by thermal generators). Several case studies are run on a simplified Great Britain system, to illustrate the applicability and benefits of this pricing scheme. 	
"Geometric-anisotropy induced high-order topological insulators in
  nonsymmorphic photonic crystals"	http://arxiv.org/abs/2208.04816v1	2022-08-09T14:52:36Z	2022-08-09T14:52:36Z	  To a significant extent, the rich physical properties of photonic crystals are determined by the underlying geometry, in which the composed symmetry operators and their combinations contribute to the unique topological invariant to characterize the topological phases. Particularly, the inter- and intra-coupling modulation in the two-dimensional (2D) Su-Schrieffer-Heeger model yields the topological phase transition, and exhibit first-order edge localized states and second-order corner localized corner states. In this work, we use the geometric anisotropy into the 2D square lattice composed of four rectangle blocks. We show a variety of topological phase transitions in designed nonsymmorphic photonic crystals (PCs) and these transitions shall be understood in terms of the Zak phase and Chern number in synthetic space, as well as the pseudospin-2 concept, combinationally. Furthermore, Zak phase winding in the periodic synthetic parameter space yields high-order Chern number and double interface states. Based on the extended Zak phase and pseudo-spin Hall effect, higher-order topological insulator is constructed in the PC system. The intriguing and abundant topological features are also sustained in the corresponding three-dimensional PC slab, which makes it a very interesting platform to control the flow of optical signals. 	
"""Is It My Turn?"" Assessing Teamwork and Taskwork in Collaborative
  Immersive Analytics"	http://arxiv.org/abs/2208.04764v1	2022-08-09T13:19:46Z	2022-08-09T13:19:46Z	  Immersive analytics has the potential to promote collaboration in machine learning (ML). This is desired due to the specific characteristics of ML modeling in practice, namely the complexity of ML, the interdisciplinary approach in industry, and the need for ML interpretability. In this work, we introduce an augmented reality-based system for collaborative immersive analytics that is designed to support ML modeling in interdisciplinary teams. We conduct a user study to examine how collaboration unfolds when users with different professional backgrounds and levels of ML knowledge interact in solving different ML tasks. Specifically, we use the pair analytics methodology and performance assessments to assess collaboration and explore their interactions with each other and the system. Based on this, we provide qualitative and quantitative results on both teamwork and taskwork during collaboration. Our results show how our system elicits sustained collaboration as measured along six distinct dimensions. We finally make recommendations how immersive systems should be designed to elicit sustained collaboration in ML modeling. 	
"Challenges and Opportunities for Simultaneous Multi-functional Networks
  in the UHF Bands"	http://arxiv.org/abs/2208.04247v1	2022-08-08T16:18:30Z	2022-08-08T16:18:30Z	  Multi-functional wireless networks are rapidly evolving and aspire to become a promising attribute of the upcoming 6G networks. Enabling multiple simultaneous networking functions with a single radio fosters the development of more integrated and simpler equipment, overcoming design and technology barriers inherited from radio systems of the past. We are seeing numerous trends exploiting these features in newly designed radios, such as those operating on the mmWave band. In this article, however, we carefully analyze the challenges and opportunities for multi-functional wireless networks in UHF bands, advocating the reuse of existing infrastructures and technologies, and exploring the possibilities of expanding their functionality without requiring architectural changes. We believe that both modern and legacy technologies can be turned into multi-functional systems if the right scientific and technological challenges are properly addressed. This transformation can foster the development of new applications and extend the useful life of these systems, contributing to a more sustainable digitization by delaying equipment obsolescence. 	
"Observation of inverse Anderson transitions in Aharonov-Bohm
  topolectrical circuits"	http://arxiv.org/abs/2208.03950v1	2022-08-08T07:26:51Z	2022-08-08T07:26:51Z	  It is well known that Anderson transition is a disorder-induced metal-insulator transition.Contrary to this conventional wisdom, some investigations have shown that disorders could destroy the phase coherence of localized modes in flatbands, making the localized states melt into extended states. This phenomenon is called the inverse Anderson transition. While, to date, the experimental observation of inverse Anderson transitions is still lacking. In this work, we report the implementation of inverse Anderson transitions based on Aharonov-Bohm topolectrical circuits. Different types of disorders, including symmetric-correlated, antisymmetric-correlated and uncorrelated disorders, can be easily implemented in Aharonov-Bohm circuits by engineering the spatial distribution of ground settings. Through the direct measurements of frequency-dependent impedance responses and time-domain voltage dynamics, the inverse Anderson transitions induced by antisymmetric-correlated disorders are clearly observed. Moreover, the flat bands and associated spatial localizations are also fulfilled in clean Aharonov-Bohm circuits or Aharonov-Bohm circuits sustaining symmetric-correlated and uncorrelated disorders, respectively. Our proposal provides a flexible platform to investigate the interplay between the geometric localization and Anderson localization, and could have potential applications in electronic signal control. 	
"Temperature and Field Dependence of Ferromagnetic Magnon in Monolayer
  Honeycomb Spin Lattice"	http://arxiv.org/abs/2208.03913v1	2022-08-08T04:37:22Z	2022-08-08T04:37:22Z	  Temperature and field dependence of collective spin excitations or magnon in monolayer honeycomb spin lattices is investigated using an anisotropic exchange XZ-Heisenberg model in an external field. Magnetic phase transition in the presence of the transverse field is the spin reorientation (SR) transition with magnon intensity existing above the SR temperature. The transverse field either decreases or sustains the spin-wave intensity in the temperature region below or above the SR temperature, respectively. The gap of the zero-momentum low-energy magnon branch closes at the SR transverse field, which is the critical quantum phase transition field at zero temperature. The application of the model to a two-dimensional CrI$_3$ explains the existence of the zero-momentum magnon mode above the Curie temperature and shows the suitable values of the exchange parameters compared with the DFT calculations. The estimated magnon velocity near the Dirac point in this material is about 1.74 km/s. 	
"Radiative Cooling with Angular Shields: Mitigating Atmospheric Radiation
  and Parasitic Heating"	http://arxiv.org/abs/2208.03797v1	2022-08-07T20:08:47Z	2022-08-07T20:08:47Z	  Radiative cooling emerged as a possible sustainable solution to the energy hungry vapor compression-based cooling. However, realizing subfreezing temperatures through radiative cooling remains challenging in environments with high humidity and often requires extreme heat management, e.g., by placing the thermal emitter in ultrahigh vacuum conditions. This work theoretically investigates the introduction of angular selective thermal emission through surrounding the emitter with an angular shield. The effect of the spectral selectivity of the emitter, the humidity of the environment, and the introduction of parasitic heating on the cooling performance is studied. The optimal angle for the shield under ideal conditions is shown to be 45{\deg}. In addition, spectral selectivity of thermal emission is necessary to obtain noticeable improvement in the minimum equilibrium temperature. In humid environments, angular selectivity through engineering the thermal emissivity function of the emitter provides a better cooling performance compared to angular shields. Conversely, angular shields performance is superior when introducing parasitic heating. Using angular shields enables cooling emitters to subfreezing temperatures without vacuum and under humid levels higher than the global average. 	
Fueling limits in a cylindrical viscosity-limited reactor	http://arxiv.org/abs/2208.03780v2	2022-08-15T00:52:03Z	2022-08-07T18:00:04Z	"  Recently, a method to achieve a ""natural hot-ion mode"" was suggested, by utilizing ion viscous heating in a rotating plasma with a fixed boundary. We explore the steady-state solution to the Braginskii equations and find the parameter regime in which a significant temperature difference between ions and electrons can be sustained in a driven steady state. The threshold for this effect occurs at $\rho_i\gtrsim0.1R$. An analytic, leading order low flow solution is obtained, and a numerical, moderate Mach number $M\lesssim2$ is investigated. The limitation is found to be at moderate Mach numbers. "	
Responsible Urban Intelligence: Towards a Research Agenda	http://arxiv.org/abs/2208.04727v1	2022-08-07T13:19:23Z	2022-08-07T13:19:23Z	  Acceleration of urbanisation is posing great challenges to sustainable development. Growing accessibility to big data and artificial intelligence (AI) technologies have revolutionised many fields and offered great potential for addressing pressing urban problems. However, using these technologies without explicitly considering responsibilities would bring new societal and environmental issues. To fully harness the potential of big data and AI without creating new problems, we envisage a conceptual framework of Responsible Urban Intelligence (RUI) and advocate an agenda for action. We first define RUI as consisting of three major components including urban problems, enabling technologies, and responsibilities; then introduce transparency, fairness, and eco-friendliness as the three dimensions of responsibilities which naturally link with the human, space, and time dimensions of cities; and further develop a four-stage implementation framework for responsibilities as consisting of solution design, data preparation, model building, and practical application; and finally present a research agenda for RUI addressing challenging issues including data and model transparency, tension between performance and fairness, and solving urban problems in an eco-friendly manner. 	
"Trust-Aware Control of Automated Vehicles in Car-Following Interactions
  with Human Drivers"	http://arxiv.org/abs/2208.03385v1	2022-08-05T21:00:00Z	2022-08-05T21:00:00Z	  Trust is essential for automated vehicles (AVs) to promote and sustain technology acceptance in human-dominated traffic scenarios. However, computational trust dynamic models describing the interactive relationship between the AVs and surrounding human drivers in traffic rarely exist. This paper aims to fill this gap by developing a quantitative trust dynamic model of the human driver in the car-following interaction with the AV and incorporating the proposed trust dynamic model into the AV's control design. The human driver's trust level is modeled as a plan evaluation metric that measures the explicability of the AV's plan from the human driver's perspective, and the explicability score of the AV's plan is integrated into the AV's decision-making process. With the proposed approach, trust-aware AVs generate explicable plans by optimizing both predefined plans and explicability of the plans in the car-following interactions with the following human driver. The results collectively demonstrate that the trust-aware AV can generate more explicable plans and achieve a higher trust level for the human driver compared to trust-unaware AV in human-AV interactions. 	
"Detection of companion galaxies around hot dust-obscured hyper-luminous
  galaxy W0410-0913"	http://arxiv.org/abs/2208.03248v1	2022-08-05T15:59:21Z	2022-08-05T15:59:21Z	  The phase transition between galaxies and quasars is often identified with the rare population of hyper-luminous, hot dust-obscured galaxies. Galaxy formation models predict these systems to grow via mergers, that can deliver large amounts of gas toward their centers, induce intense bursts of star formation and feed their supermassive black holes. Here we report the detection of 24 galaxies emitting Lyman-alpha emission on projected physical scales of about 400 kpc around the hyper-luminous hot dust-obscured galaxy W0410-0913, at redshift z = 3.631, using Very Large Telescope observations. While this indicates that W0410-0913 evolves in a very dense environment, we do not find clear signs of mergers that could sustain its growth. Data suggest that if mergers occurred, as models expect, these would involve less massive satellites, with only a moderate impact on the internal interstellar medium of W0410-0913, which is sustained by a rotationally-supported fast-rotating molecular disk, as Atacama Large Millimeter Array observations suggest. 	
Localized energy absorbers in Hertzian chains	http://arxiv.org/abs/2208.02666v1	2022-08-04T13:54:48Z	2022-08-04T13:54:48Z	  Energy absorbers and energy-harvesting devices have been under the scope of scientists and engineers for decades to fulfill specific technological needs, mainly concerned with sound and vibration absorbers, and efficient mechanical energy converters. In this paper, as a proof of concept, we build a mass-in-mass device to study the response of a linear absorber immersed in one of the spheres composing a linear array of equal elastic spheres. Spheres barely touch one another and can thus sustain nonlinear solitary wave propagation only. The linear intruder absorbs a given amount of energy depending on the frequency content of the incident solitary wave. A numerical simulation is developed to account for the experimental finding. The validation of the numerical model allows for the theoretical study of the energy absorbed by any number of intruders, and to demonstrate that the former increases exponentially with the latter, indicating that only ten of the intruders is enough to absorb the system energy. A detailed study of the transmitted energy from an external source into the chain reveals that, due to nonlinearity, the array of spheres is able to convert almost any mechanical shock to a well defined solitary or trains of solitary waves, whose frequency content is nearly independent on the excitation amplitude. This property leads to the design of a device, which is optimized to absorb energy over a broad frequency range. 	
"Resilient Risk based Adaptive Authentication and Authorization (RAD-AA)
  Framework"	http://arxiv.org/abs/2208.02592v3	2022-11-29T15:52:22Z	2022-08-04T11:44:29Z	  In recent cyber attacks, credential theft has emerged as one of the primary vectors of gaining entry into the system. Once attacker(s) have a foothold in the system, they use various techniques including token manipulation to elevate the privileges and access protected resources. This makes authentication and token based authorization a critical component for a secure and resilient cyber system. In this paper we discuss the design considerations for such a secure and resilient authentication and authorization framework capable of self-adapting based on the risk scores and trust profiles. We compare this design with the existing standards such as OAuth 2.0, OpenID Connect and SAML 2.0. We then study popular threat models such as STRIDE and PASTA and summarize the resilience of the proposed architecture against common and relevant threat vectors. We call this framework as Resilient Risk based Adaptive Authentication and Authorization (RAD-AA). The proposed framework excessively increases the cost for an adversary to launch and sustain any cyber attack and provides much-needed strength to critical infrastructure. We also discuss the machine learning (ML) approach for the adaptive engine to accurately classify transactions and arrive at risk scores. 	
Evolutionary bagging for ensemble learning	http://arxiv.org/abs/2208.02400v3	2022-09-06T01:31:38Z	2022-08-04T01:52:57Z	  Ensemble learning has gained success in machine learning with major advantages over other learning methods. Bagging is a prominent ensemble learning method that creates subgroups of data, known as bags, that are trained by individual machine learning methods such as decision trees. Random forest is a prominent example of bagging with additional features in the learning process. Evolutionary algorithms have been prominent for optimisation problems and also been used for machine learning. Evolutionary algorithms are gradient-free methods that work with a population of candidate solutions that maintain diversity for creating new solutions. In conventional bagged ensemble learning, the bags are created once and the content, in terms of the training examples, are fixed over the learning process. In our paper, we propose evolutionary bagged ensemble learning, where we utilise evolutionary algorithms to evolve the content of the bags in order to iteratively enhance the ensemble by providing diversity in the bags. The results show that our evolutionary ensemble bagging method outperforms conventional ensemble methods (bagging and random forests) for several benchmark datasets under certain constraints. We find that evolutionary bagging can inherently sustain a diverse set of bags without reduction in performance accuracy. 	
"Graph Neural Networks Extract High-Resolution Cultivated Land Maps from
  Sentinel-2 Image Series"	http://arxiv.org/abs/2208.02349v1	2022-08-03T21:19:06Z	2022-08-03T21:19:06Z	  Maintaining farm sustainability through optimizing the agricultural management practices helps build more planet-friendly environment. The emerging satellite missions can acquire multi- and hyperspectral imagery which captures more detailed spectral information concerning the scanned area, hence allows us to benefit from subtle spectral features during the analysis process in agricultural applications. We introduce an approach for extracting 2.5 m cultivated land maps from 10 m Sentinel-2 multispectral image series which benefits from a compact graph convolutional neural network. The experiments indicate that our models not only outperform classical and deep machine learning techniques through delivering higher-quality segmentation maps, but also dramatically reduce the memory footprint when compared to U-Nets (almost 8k trainable parameters of our models, with up to 31M parameters of U-Nets). Such memory frugality is pivotal in the missions which allow us to uplink a model to the AI-powered satellite once it is in orbit, as sending large nets is impossible due to the time constraints. 	
"Towards Generating Large Synthetic Phytoplankton Datasets for Efficient
  Monitoring of Harmful Algal Blooms"	http://arxiv.org/abs/2208.02332v1	2022-08-03T20:15:55Z	2022-08-03T20:15:55Z	  Climate change is increasing the frequency and severity of harmful algal blooms (HABs), which cause significant fish deaths in aquaculture farms. This contributes to ocean pollution and greenhouse gas (GHG) emissions since dead fish are either dumped into the ocean or taken to landfills, which in turn negatively impacts the climate. Currently, the standard method to enumerate harmful algae and other phytoplankton is to manually observe and count them under a microscope. This is a time-consuming, tedious and error-prone process, resulting in compromised management decisions by farmers. Hence, automating this process for quick and accurate HAB monitoring is extremely helpful. However, this requires large and diverse datasets of phytoplankton images, and such datasets are hard to produce quickly. In this work, we explore the feasibility of generating novel high-resolution photorealistic synthetic phytoplankton images, containing multiple species in the same image, given a small dataset of real images. To this end, we employ Generative Adversarial Networks (GANs) to generate synthetic images. We evaluate three different GAN architectures: ProjectedGAN, FastGAN, and StyleGANv2 using standard image quality metrics. We empirically show the generation of high-fidelity synthetic phytoplankton images using a training dataset of only 961 real images. Thus, this work demonstrates the ability of GANs to create large synthetic datasets of phytoplankton from small training datasets, accomplishing a key step towards sustainable systematic monitoring of harmful algal blooms. 	
"Regular black holes, universes without singularities, and phantom-scalar
  field transitions"	http://arxiv.org/abs/2208.02280v2	2023-01-06T20:25:15Z	2022-08-03T18:03:56Z	  We consider a procedure of elimination of cosmological singularities similar to that suggested in the recent paper by Simpson and Visser for the construction of regular black holes. It is shown that by imposing a non-singular cosmological evolution with a bounce in a flat Friedmann universe filled with a minimally coupled scalar field, we obtain a transition between the standard scalar field and its phantom counterpart. In this case, the potential of the scalar field has a non-analyticity of the cusp type. This result is also readily reproduced in the case of an anisotropic Bianchi I universe. We have also found a spherically symmetric static solution of the Einstein equations, free of singularities and sustained by a scalar field. 	
Child Care Provider Survival Analysis	http://arxiv.org/abs/2208.02154v1	2022-08-03T15:42:53Z	2022-08-03T15:42:53Z	  The aggregate ability of child care providers to meet local demand for child care is linked to employment rates in many sectors of the economy. Amid growing concern regarding child care provider sustainability due to the COVID-19 pandemic, state and local governments have received large amounts of new funding to better support provider stability. In response to this new funding aimed at bolstering the child care market in Florida, this study was devised as an exploratory investigation into features of child care providers that lead to business longevity. In this study we used optimal survival trees, a machine learning technique designed to better understand which providers are expected to remain operational for longer periods of time, supporting stabilization of the child care market. This tree-based survival analysis detects and describes complex interactions between provider characteristics that lead to differences in expected business survival rates. Results show that small providers who are religiously affiliated, and all providers who are serving children in Florida's universal Prekindergarten program and/or children using child care subsidy, are likely to have the longest expected survival rates. 	
"Evaluating and improving social awareness of energy communities through
  semantic network analysis of online news"	http://arxiv.org/abs/2208.01892v1	2022-08-03T07:43:31Z	2022-08-03T07:43:31Z	  The implementation of energy communities represents a cross-disciplinary phenomenon that has the potential to support the energy transition while fostering citizens' participation throughout the energy system and their exploitation of renewables. An important role is played by online information sources in engaging people in this process and increasing their awareness of associated benefits. In this view, this work analyses online news data on energy communities to understand people's awareness and the media importance of this topic. We use the Semantic Brand Score (SBS) indicator as an innovative measure of semantic importance, combining social network analysis and text mining methods. Results show different importance trends for energy communities and other energy and society-related topics, also allowing the identification of their connections. Our approach gives evidence to information gaps and possible actions that could be taken to promote a low-carbon energy transition. 	
"Sustaining Open Data as a Digital Common -- Design principles for Common
  Pool Resources applied to Open Data Ecosystems"	http://arxiv.org/abs/2208.01694v2	2022-08-09T07:50:38Z	2022-08-02T18:46:06Z	  Motivation. Digital commons is an emerging phenomenon and of increasing importance, as we enter a digital society. Open data is one example that makes up a pivotal input and foundation for many of today's digital services and applications. Ensuring sustainable provisioning and maintenance of the data, therefore, becomes even more important. Aim. We aim to investigate how such provisioning and maintenance can be collaboratively performed in the community surrounding a common. Specifically, we look at Open Data Ecosystems (ODEs), a type of community of actors, openly sharing and evolving data on a technological platform. Method. We use Elinor Ostrom's design principles for Common Pool Resources as a lens to systematically analyze the governance of earlier reported cases of ODEs using a theory-oriented software engineering framework. Results. We find that, while natural commons must regulate consumption, digital commons such as open data maintained by an ODE must stimulate both use and data provisioning. Governance needs to enable such stimulus while also ensuring that the collective action can still be coordinated and managed within the frame of available maintenance resources of a community. Subtractability is, in this sense, a concern regarding the resources required to maintain the quality and value of the data, rather than the availability of data. Further, we derive empirically-based recommended practices for ODEs based on the design principles by Ostrom for how to design a governance structure in a way that enables a sustainable and collaborative provisioning and maintenance of the data. Conclusion. ODEs are expected to play a role in data provisioning which democratize the digital society and enables innovation from smaller commercial actors. Our empirically based guidelines intend to support this development. 	
"Sensor Deployment and Link Analysis in Satellite IoT Systems for
  Wildfire Detection"	http://arxiv.org/abs/2208.01632v2	2022-08-05T10:30:20Z	2022-08-02T17:59:30Z	  Climate change has been identified as one of the most critical threats to human civilization and sustainability. Wildfires, which produce huge amounts of carbon emission, are both drivers and results of climate change. An early and timely wildfire detection system can constrain fires to short and small ones and yield significant carbon reduction. In this paper, we propose to use ground sensor deployment and satellite Internet of Things (IoT) technologies for wildfire detection by taking advantage of satellites' ubiquitous global coverage. We first develop an optimal IoT sensor placement strategy based on fire ignition and detection models. Then, we analyze the uplink satellite communication budget and the bandwidth required for wildfire detection under the narrowband IoT (NB-IoT) radio interface. Finally, we conduct simulations on the California wildfire database and quantify the potential economical benefits by factoring in carbon emission reductions and sensor/bandwidth costs. 	
"Research Contribution of major Centrally Funded Institution Systems of
  India"	http://arxiv.org/abs/2208.01588v1	2022-08-02T16:52:56Z	2022-08-02T16:52:56Z	  India is now among the major knowledge producers of the world, ranking among the top 5 countries in total research output, as per some recent reports. The institutional setup for Research & Development (R&D) in India comprises a diverse set of Institutions, including Universities, government departments, research laboratories, and private sector institutions etc. It may be noted that more than 45% share of India's Gross Expenditure on Research and Development (GERD) comes from the central government. In this context, this article attempts to explore the quantum of research contribution of centrally funded institutions and institution systems of India. The volume, proportionate share and growth patterns of research publications from the major centrally funded institutions, organised in 16 groups, is analysed. These institutions taken together account for 67.54% of Indian research output during 2001 to 2020. The research output of the centrally funded institutions in India has increased steadily since 2001 with a good value for CAGR. The paper presents noteworthy insights about scientific research production of India that may be useful to policymakers, researchers and science practitioners in India. It presents a case for increased activity by the state governments and private sector to further the cause of sustainable and inclusive research and development in the country. 	
"Transient Structure in the Non-linear Superradiance Regime of Widely
  Doppler Broadened Media"	http://arxiv.org/abs/2208.01523v1	2022-08-02T15:21:31Z	2022-08-02T15:21:31Z	  We investigate transient radiation processes in the non-linear superradiance (SR) regime of the Doppler broadened Maxwell-Bloch equations when the velocity distribution is of total bandwidth greatly exceeding that of the transient process itself. We demonstrate the formation of global polarisation phase correlation and the quenching of temporal structure if a smooth distribution is inverted above the critical threshold required to enter the non-linear SR regime. We propose candidate stochastic velocity distributions capable of sustaining finite temporal structure in the non-linear emission process. We develop a novel algorithm for simulating the Doppler broadened Maxwell-Bloch equations which is $O(n)$ complex in the number of velocity channels $n$ whenever the emerging polarisation correlation is of moderate bandwidth, and we apply it to a stochastic velocity distribution in order to demonstrate sustained delay and duration of peak intensity in the widely Doppler broadened limit. We discuss the transverse inversion process and recognise an autoregulation mechanism on the number of molecules cooperatively participating in SR emission. This mechanism has the effect of limiting the temporal duration of the intensity pulse to a lower bound proportional to the length of the sample, which we confirm through simulation. 	
"MBSE analysis for energy sustainability improvement in manufacturing
  industry"	http://arxiv.org/abs/2208.01514v1	2022-08-02T15:00:13Z	2022-08-02T15:00:13Z	  With the ever increasing complexity of Industry 4.0 systems, plant energy management systems developed to improve energy sustainability become equally complex. Based on a Model-Based Systems Engineering analysis, this paper aims to provide a general approach to perform holistic development of an autonomous energy management system for manufacturing industries. This Energy Management System (EMS) will be capable of continuously improving its ability to assess, predict, and act, in order to improve by monitoring and controlling the energy sustainability of manufacturing systems. The approach was implemented with the System Modeling Language (SysML). 	
"Highly Efficient and Selective Extraction of Gold by Reduced Graphene
  Oxide"	http://arxiv.org/abs/2208.01435v1	2022-08-02T13:11:37Z	2022-08-02T13:11:37Z	  Materials that are capable of extracting gold from complex sources, especially electronic waste (e-waste) with high efficiency are needed for gold resource sustainability and effective e-waste recycling. However, it remains challenging to achieve high extraction capacity to trace amount of gold, and precise selectivity to gold over a wide range of complex co-existing elements. Here we report a reduced graphene oxide (rGO) material that has an ultrahigh extraction capacity for trace amounts of gold (1,850 mg/g and 1,180 mg/g to 10 ppm and 1 ppm gold). The excellent gold extraction behavior is accounted to the graphene areas and oxidized regions of rGO. The graphene areas spontaneously reduce gold ions to metallic gold, and the oxidized regions provide a good dispersibility so that efficient adsorption and reduction of gold ions by the graphene area can be realized. The rGO is also highly selective to gold ions. By controlling the protonation process of the functional groups on the oxidized regions of rGO, it shows an exclusive gold extraction without adsorption of 14 co-existing elements seen in e-waste. These discoveries are further exploited in highly efficient, continuous gold recycling from e-waste with good scalability and economic viability, as exemplified by extracting gold from e-waste using a rGO membrane based flow-through process. 	
Inertialess Gyrating Engines	http://arxiv.org/abs/2208.01292v1	2022-08-02T07:33:49Z	2022-08-02T07:33:49Z	  A typical model for a gyrating engine consists of an inertial wheel powered by an energy source that generates an angle-dependent torque. Examples of such engines include a pendulum with an externally applied torque, Stirling engines, and the Brownian gyrating engine. Variations in the torque are averaged out by the inertia of the system to produce limit cycle oscillations. While torque generating mechanisms are also ubiquitous in the biological world, where they typically feed on chemical gradients, inertia is not a property that one naturally associates with such processes. In the present work, seeking ways to dispense of the need for inertial effects, we study an inertia-less concept where the combined effect of coupled torque-producing components averages out variations in the ambient potential and helps overcome dissipative forces to allow sustained operation for vanishingly small inertia. We exemplify this inertia-less concept through analysis of two of the aforementioned engines, the Stirling engine and the Brownian gyrating engine. An analogous principle may be sought in biomolecular processes as well as in modern-day technological engines, where for the latter, the coupled torque-producing components reduce vibrations that stem from the variability of the generated torque. 	
"Simulating the magnetorotational instability on a moving-mesh with the
  shearing box approximation"	http://arxiv.org/abs/2208.01065v1	2022-08-01T18:01:27Z	2022-08-01T18:01:27Z	  The magnetorotational instability (MRI) is an important process in sufficiently ionized accretion disks, as it can create turbulence that acts as an effective viscosity, mediating angular momentum transport. Due to its local nature, it is often analyzed in the shearing box approximation with Eulerian methods, which otherwise would suffer from large advection errors in global disk simulations. In this work, we report on an extensive study that applies the quasi-Lagrangian, moving-mesh code ${\rm \small AREPO}$, combined with the Dedner cleaning scheme to control deviations from $\nabla \cdot B = 0$, to the problem of magnetized flows in shearing boxes. We find that we can resolve the analytical linear growth rate of the MRI with mean background magnetic field well. In the zero net flux case, there is a threshold value for the strength of the divergence cleaning above which the turbulence eventually dies out, and in contrast to previous Eulerian simulations, the strength of the MRI does not decrease with increasing resolution. If we increase the vertical aspect ratio of our box we find the mean-field dynamo described in Shi et al. (2016), as well as an active shear current effect that can sustain MRI turbulence for at least 200 orbits. In stratified simulations, we obtain an active $\alpha \omega$ dynamo and the characteristic butterfly diagram, again for at least 200 orbits. Our results compare well with previous results obtained with static grid codes such as ${\rm\small ATHENA}$. We thus conclude that ${\rm \small AREPO}$ represents a particularly attractive alternative for global disk simulations, where the method benefits from its quasi-Lagrangian nature, as well as for shearing box simulations with large density variations, where ${\rm \small AREPO}$'s continuously adaptive resolution is advantageous. 	
"PRODIGE -- Envelope to disk with NOEMA I. A 3000 au streamer feeding a
  Class I protostar"	http://arxiv.org/abs/2208.01023v1	2022-08-01T17:55:04Z	2022-08-01T17:55:04Z	  Context. In the past few years, there has been a rise in the detection of streamers, asymmetric flows of material directed toward the protostellar disk with material from outside the star's natal core. It is unclear how they affect the process of mass accretion, in particular beyond the Class 0 phase. Aims. We investigate the gas kinematics around Per-emb-50, a Class I source in the crowded star-forming region NGC 1333. Our goal is to study how the mass infall proceeds from envelope to disk scales in this source. Results. We discover a streamer delivering material toward Per-emb-50 in H$_2$CO and C$^{18}$O emission. The streamer's emission can be well described by the analytic solutions for an infalling parcel of gas along a streamline with conserved angular momentum, both in the image plane and along the line of sight velocities. The streamer has a mean infall rate of $1.3 \times 10^{ -6}$ M$_{ \odot}$ yr$^{ -1}$, $5 -10$ times higher than the current accretion rate of the protostar. SO and SO$_2$ emission reveal asymmetric infall motions in the inner envelope, additional to the streamer around Per-emb-50. Furthermore, the presence of SO$_2$ could mark the impact zone of the infalling material. Conclusions. The streamer delivers sufficient mass to sustain the protostellar accretion rate and might produce an accretion burst, which would explain the protostar's high luminosity with respect to other Class I sources. Our results highlight the importance of late infall for protostellar evolution: streamers might provide a significant amount of mass for stellar accretion after the Class 0 phase. 	
Effective Gesture Based Framework for Capturing User Input	http://arxiv.org/abs/2208.00913v1	2022-08-01T14:58:17Z	2022-08-01T14:58:17Z	  Computers today aren't just confined to laptops and desktops. Mobile gadgets like mobile phones and laptops also make use of it. However, one input device that hasn't changed in the last 50 years is the QWERTY keyboard. Users of virtual keyboards can type on any surface as if it were a keyboard thanks to sensor technology and artificial intelligence. In this research, we use the idea of image processing to create an application for seeing a computer keyboard using a novel framework which can detect hand gestures with precise accuracy while also being sustainable and financially viable. A camera is used to capture keyboard images and finger movements which subsequently acts as a virtual keyboard. In addition, a visible virtual mouse that accepts finger coordinates as input is also described in this study. This system has a direct benefit of reducing peripheral cost, reducing electronics waste generated due to external devices and providing accessibility to people who cannot use the traditional keyboard and mouse. 	
"Declining hydrologic function of coastal wetlands in response to
  saltwater intrusion"	http://arxiv.org/abs/2208.00903v2	2022-09-23T21:24:18Z	2022-08-01T14:43:37Z	  Salinity and submergence have shaped coastal wetlands into one of the most productive and yet fragile ecotones worldwide. Sea-level rise alters both salinity and submersion regimes, threatening the future existence of these habitats. Still, the magnitude of the impacts is elusive. A current paradigm is that coastal communities will keep pace with sea-level rise through soil accretion, a process largely sustained by the interaction of plants and geomorphology. This thesis, however, rests on the assumption that submersion is the main driver of bio-geomorphic processes and does not include the effects of salinity on plant hydrologic function. Here, we show that salinity has a major influence on how tidal vegetation controls the depth of the water table - a key ecohydrological process regulating plant establishment, survival rate, and productivity. Our findings rely on long-term observations from the Florida Everglades and modeling results. They indicate that altered salinity regimes can suppress transpiration, undermining in this way the ability of tidal ecosystems to control water table movements and contrast other forms of plant stress like waterlogging. This effect is apparent in the mangroves of the Everglades' tidal fringe, where salinization has already yielded extensive decoupling between plant hydraulics and groundwater dynamics. This mechanism leads to shallow water tables and poor soil-aeration conditions, with sizable impacts on coastal wetlands' hydrologic function and elasticity. 	
Domain Analysis of Ethical, Social and Environmental Accounting Methods	http://arxiv.org/abs/2208.00721v1	2022-08-01T10:12:01Z	2022-08-01T10:12:01Z	  Ethical, social and environmental accounting is the practice of assessing and reporting organisations' performance on environmental, social and governance topics. There are ample methods that describe how to perform such sustainability assessments. This report presents a domain analysis of ethical, social and environmental accounting methods. Our analysis contains 21 methods. Each method is modelled as a process deliverable diagram. The diagrams have been validated by experts in the methods. The diagrams lay the foundation for further analysis and software development. In this report, we touch upon the ethical, social and environmental accounting method ontology that has been created based on the domain analysis. 	
"Sustainable steel through hydrogen plasma reduction of iron ore:
  process, kinetics, microstructure, chemistry"	http://arxiv.org/abs/2208.00661v1	2022-08-01T07:50:51Z	2022-08-01T07:50:51Z	  Fe- and steelmaking is the largest single industrial CO2 emitter, accounting for 6.5% of all CO2 emissions on the planet. This fact challenges the current technologies to achieve carbon-lean steel production and to align with the requirement of a drastic reduction of 80% in all CO2 emissions by around 2050. Thus, alternative reduction technologies have to be implemented for extracting iron from its ores. The H-based direct reduction has been explored as a sustainable route to mitigate CO2 emissions, where the reduction kinetics of the intermediate oxide product FexO wustite into Fe is the rate-limiting step of the process. The total reaction has an endothermic net energy balance. Reduction based on a H plasma may offer an attractive alternative. Here, we present a study about the reduction of hematite using H plasma. The evolution of both, chemical composition and phase transformations was investigated in several intermediate states. We found that hematite reduction kinetics depends on the balance between the initial input mass and the arc power. For an optimized input mass-arc power ratio, complete reduction was obtained within 15 min of exposure to the H plasma. The wustite reduction is also the rate-limiting step towards complete reduction. Nonetheless, the reduction reaction is exothermic, and its rates are comparable with those found in H-based direct reduction. Chemical and microstructure analysis revealed that the gangue elements partition to the remaining oxide regions, probed by energy dispersive spectroscopy and atom probe tomography. Si-enrichment was observed in the interdendritic fayalite domains, at the wustite/Fe hetero-interfaces and in the primarily solidified oxide particles inside the Fe. With proceeding reduction, however, such elements are gradually removed from the samples so that the final iron product is nearly free of gangue-related impurities. 	
Sustainability of large scale waste heat harvesting using thermoelectric	http://arxiv.org/abs/2208.00616v1	2022-08-01T05:33:56Z	2022-08-01T05:33:56Z	  The amount of waste heat exergy generated globally is 69.058 EJ which can be divided into, low temperature 373 K, 30.496 EJ, medium temperature 373 K to 573 K, 14.431 EJ and high temperature 573 K, 24.131 EJ. These values of exergy have been used to determine the minimum number of pn junctions required to convert the exergy into electrical power. It is found that the number of junctions required to convert high temperature exergy increases from 8.22x10^11 to 24.66x10^11 when the aspect ratio of the legs increases from 0.5 cm^1 to 1.5 cm^1. To convert the low temperature exergy, 81.76x10^11 to 245.25x10^11 junctions will be required depending on the legs aspect ratio. The quantity of alloys containing elements such as Pb, Bi, Te, Sb, Se and Sn required to synthesize these junctions therefore is of the order of millions of tons which means the elements required is also of similar magnitude. The current world production of these elements however falls far short of this requirement, indicating significant supply chain risk. The production of these elements, even if resources are available, will emit millions of tons of CO2 showing that current alloys are non-sustainable for waste heat recovery. 	
A Real-time Edge-AI System for Reef Surveys	http://arxiv.org/abs/2208.00598v1	2022-08-01T04:06:14Z	2022-08-01T04:06:14Z	  Crown-of-Thorn Starfish (COTS) outbreaks are a major cause of coral loss on the Great Barrier Reef (GBR) and substantial surveillance and control programs are ongoing to manage COTS populations to ecologically sustainable levels. In this paper, we present a comprehensive real-time machine learning-based underwater data collection and curation system on edge devices for COTS monitoring. In particular, we leverage the power of deep learning-based object detection techniques, and propose a resource-efficient COTS detector that performs detection inferences on the edge device to assist marine experts with COTS identification during the data collection phase. The preliminary results show that several strategies for improving computational efficiency (e.g., batch-wise processing, frame skipping, model input size) can be combined to run the proposed detection model on edge hardware with low resource consumption and low information loss. 	
"A Contribution Management Framework for Firms Engaged in Open Source
  Software Ecosystems -- A Research Preview"	http://arxiv.org/abs/2208.02630v1	2022-07-31T20:14:04Z	2022-07-31T20:14:04Z	  Context and motivation: Contribution Management helps firms engaged in Open Source Software (OSS) ecosystems to motivate what they should contribute and when, but also what they should focus their resources on and to what extent. Such guidelines are also referred to as contribution strategies. The motivation for developing tailored contribution strategies is to maximize return on investment and sustain the influence needed in the ecosystem. Question/Problem: We aim to develop a framework to help firms understand their current situation and create a starting point to develop an effective contribution management process. Principal ideas/results: Through a design science approach, a prototype framework is created based on literature and validated iteratively with expert opinions through interviews. Contribution: In this research preview, we present our initial results after our first design cycle and consultation with one experienced OSS manager at a large OSS oriented software-intensive firm. The initial validation highlights importance of stakeholder identification and analysis, as well as the general need for contribution management and alignment with internal product planning. This encourages future work to develop the framework further using expert and case validation. 	
"A Hetero-functional Graph Structural Analysis of the American
  Multi-modal Energy System"	http://arxiv.org/abs/2208.06430v1	2022-07-31T19:27:55Z	2022-07-31T19:27:55Z	"  As one of the most pressing challenges of the 21st century, global climate change demands a host of changes across four critical energy infrastructures: the electric grid, the natural gas system, the oil system, and the coal system. Unfortunately, these four systems are often studied individually, and rarely together as integrated systems. Instead, holistic multi-energy system models can serve to improve the understanding of these interdependent systems and guide policies that shape the systems as they evolve into the future. The NSF project entitled ""American Multi-Modal Energy System Synthetic \& Simulated Data (AMES-3D)"" seeks to fill this void with an open-source, physically-informed, structural and behavioral machine-learning model of the AMES. To that end, this paper uses a GIS-data-driven, model-based system engineering approach to develop structural models of the American Multi-Modal Energy System (AMES). This paper produces and reports the hetero-functional incidence tensor, hetero-functional adjacency matrix, and the formal graph adjacency matrix in terms of their statistics. This work compares these four hetero-functional graph models across the states of New York (NY), California (CA), Texas (TX), and the United States of America (USA) as a whole. From the reported statistics, the paper finds that the geography and the sustainable energy policies of these states are deeply reflected in the structure of their multi-energy infrastructure systems and impact the full USA's structure. "	
"Eco2AI: carbon emissions tracking of machine learning models as the
  first step towards sustainable AI"	http://arxiv.org/abs/2208.00406v2	2022-08-03T22:48:23Z	2022-07-31T09:34:53Z	  The size and complexity of deep neural networks continue to grow exponentially, significantly increasing energy consumption for training and inference by these models. We introduce an open-source package eco2AI to help data scientists and researchers to track energy consumption and equivalent CO2 emissions of their models in a straightforward way. In eco2AI we put emphasis on accuracy of energy consumption tracking and correct regional CO2 emissions accounting. We encourage research community to search for new optimal Artificial Intelligence (AI) architectures with a lower computational cost. The motivation also comes from the concept of AI-based green house gases sequestrating cycle with both Sustainable AI and Green AI pathways. 	
"Motivating the Contributions: An Open Innovation Perspective on What to
  Share as Open Source Software"	http://arxiv.org/abs/2208.00308v1	2022-07-30T20:54:25Z	2022-07-30T20:54:25Z	  Open Source Software (OSS) ecosystems have reshaped the ways how software-intensive firms develop products and deliver value to customers. However, firms still need support for strategic product planning in terms of what to develop internally and what to share as OSS. Existing models accurately capture commoditization in software business, but lack operational support to decide what contribution strategy to employ in terms of what and when to contribute. This study proposes a Contribution Acceptance Process (CAP) model from which firms can adopt contribution strategies that align with product strategies and planning. In a design science influenced case study executed at Sony Mobile, the CAP model was iteratively developed in close collaboration with the firm's practitioners. The CAP model helps classify artifacts according to business impact and control complexity so firms may estimate and plan whether an artifact should be contributed or not. Further, an information meta-model is proposed that helps operationalize the CAP model at the organization. The CAP model provides an operational OI perspective on what firms involved in OSS ecosystems should share, by helping them motivate contributions through the creation of contribution strategies. The goal is to help maximize return on investment and sustain needed influence in OSS ecosystems. 	
"How to Make Users Adopt More Sustainable Cryptocurrencies: Evidence from
  Nigeria"	http://arxiv.org/abs/2208.00280v2	2023-01-27T21:00:11Z	2022-07-30T17:30:45Z	  Some of the most popular decentralised cryptocurrency networks have drawn widespread criticism for consuming vast amounts of electricity and have thus become targets of regulatory interest. Attempts to influence cryptocurrency network operations via policy in the pursuit of sustainability in the past, however, have been widely unsuccessful. Some were abandoned out of fear of jeopardising innovation while others failed due to the highly globalised nature of decentralised systems. In search of a more effective angle for energy policy measures, this study follows a consumer-focused approach by analysing the sentiments of Nigerian cryptocurrency users (${N=158}$) regarding their perceptions of the sustainability of Bitcoin, an archetypal cryptocurrency with high electricity consumption. Three main findings emerged: 1) Despite self-reporting as highly knowledgeable, most participants significantly underestimated the energy demand of Bitcoin. 2) Those who accurately assessed the energy demand of Bitcoin were more likely to support measures targeting its energy demand than those who misestimated it. 3) Those who supported measures predominantly held private actors responsible. In light of these findings, we conclude that the primary task of policymakers in the context of cryptocurrency sustainability may be to improve consumer education. 	
Machine and quantum learning for diamond-based quantum applications	http://arxiv.org/abs/2208.00256v1	2022-07-30T15:36:26Z	2022-07-30T15:36:26Z	  In recent years, machine and quantum learning have gained considerable momentum sustained by growth in computational power and data availability and have shown exceptional aptness for solving recognition- and classification-type problems, as well as problems that require complex, strategic planning. In this work, we discuss and analyze the role machine and quantum learning are playing in the development of diamond-based quantum technologies. This matters as diamond and its optically-addressable spin defects are becoming prime hardware candidates for solid state-based applications in quantum information, computing and metrology. Through a selected number of demonstrations, we show that machine and quantum learning are leading to both practical and fundamental improvements in measurement speed and accuracy. This is crucial for quantum applications, especially for those where coherence time and signal-to-noise ratio are scarce resources. We summarize some of the most prominent machine and quantum learning approaches that have been conducive to the presented advances and discuss their potential for proposed and future quantum applications. 	
"A holistic solution to icing by acoustic waves: de-icing, active
  anti-icing, sensing with piezoelectric crystals, and synergy with thin film
  passive anti-icing solutions"	http://arxiv.org/abs/2207.14783v2	2022-08-15T11:05:32Z	2022-07-29T16:58:46Z	  Icing has become a hot topic both in academia and in the industry given its implications in strategic sectors such as transport, robotics, wind turbines, photovoltaics, and electricity supply. Recently proposed de-icing solutions involving the propagation of acoustic waves (AWs) at suitable substrates may open the path for a sustainable alternative to standard de-icing or anti-icing protocols. Herein we experimentally unravel some of the basic interactions that contribute to the de-icing and/or hinder the icing (ice accretion) on AW-activated substrates. The response toward icing of a model substrate system consisting of a piezoelectric LiNbO3 plate AW activated by radio-frequency (rf) signaling to planar electrodes has been characterized both at a laboratory scale and in an icing wind tunnel under forced convection conditions. Main features related to de-icing mechanisms, a decrease of ice adhesion, or the avoidance of ice accretion have been disclosed by this holistic investigation. Furthermore, additional experiments have shown that the piezoelectric substrate surfaces modified with a fluorinated ZnO thin film or a ZnO/CFx bilayer present anti-icing functionality and a synergistic response when activated with AWs. A careful analysis of the dependence of resonance frequency of the piezoelectric substrates on experimental variables such as temperature, ice formation, or wind velocity shows that this parameter can be used as an internal control procedure for real-time monitoring of icing processes onto AW-activated devices 	
"Sustainable Development Goals as unifying narratives in large UK firms'
  Twitter discussions"	http://arxiv.org/abs/2207.14664v1	2022-07-29T13:18:39Z	2022-07-29T13:18:39Z	  Since 2015, the United Nations have called for a global effort to reach Sustainable Development Goals (SDGs). Firms play a vital role in contributing to SDGs. While many empirical approaches were used to map firms' contributions to SDGs, online social networks are an underexplored but promising setting. This paper maps large UK firms' discussions on Twitter, specifically focusing on their SDG-related discussions, with complex network methods from statistical physics. Results show that: 1) SDGs are the topics that tie conversations among major UK firms together; 2) compared to the environmental and economic dimensions, the social dimension is predominant; 3) the attention to different SDGs varies depending on the community and sector firms belong to; 4) the use of retweets on SDGs-related tweets highlights a high stakeholder engagement on global challenges; 5) large UK companies and stakeholders generally behave differently from Italian ones. This paper provides theoretical contributions, combining institutional, stakeholder and legitimacy theories. It also contributes to developing the literature on businesses and SDGs with an interdisciplinary approach. It offers practical implications and a big-data based tool to monitor firms' discussions on SDGs on Twitter. Last, the paper proposes new avenues for further research. 	
"What X-ray absorption spectroscopy can tell us about the active state of
  earth-abundant electrocatalysts for the oxygen evolution reaction"	http://arxiv.org/abs/2207.14360v1	2022-07-28T19:31:04Z	2022-07-28T19:31:04Z	  Chemical energy storage is an attractive solution to secure a sustainable energy supply. It requires an electrocatalyst to be implemented efficiently. In order to rationally improve the electrocatalyst materials and thereby the reaction efficiency, one must reveal the nature of the electrocatalyst under reaction conditions, i.e., its active state. For a better understanding of earth-abundant metal oxides as electrocatalysts for the oxygen evolution reaction (OER), the combination of electrochemical (EC) methods and X-ray absorption spectroscopy (XAS) has been very insightful and still holds untapped potential. Herein, we concisely introduce the basics of EC and XAS and provide the necessary framework to discuss changes that electrocatalytic materials undergo, presenting manganese oxides as examples. Such changes may occur during preparation and storage, during immersion in an electrolyte, as well as during application of potentials without or with catalytic reactions. We conclude with a concise summary of how EC and XAS are currently combined to elucidate the active state as well as an outlook on future opportunities to understand the mechanisms of electrocatalysis using combined operando EC-XAS experiments. 	
"To tread or not to tread: comparison between water treading and
  conventional flapping wing kinematics"	http://arxiv.org/abs/2207.14257v2	2022-09-22T17:49:51Z	2022-07-28T17:44:15Z	  Hovering insects are limited by their physiology and need to rotate their wings at the end of each back and forth motion to keep the wing's leading edge ahead of its trailing edge. The wing rotation at the end of each half-stroke pushes the leading edge vortex away from the wing which leads to a loss in the lift. Unlike biological fliers, human-engineered flapping wing micro air vehicles have different design limitations. They can be designed to avoid the end of stroke wing rotation and use so-called water-treading flapping kinematics. Flapping wings using conventional flapping kinematics have a designated leading and trailing edge. In the water-treading mode, the role of the leading and trailing edges are continuously alternated throughout the stroke. Here, we compare velocity field and force measurements for a rectangular flapping wing conducting normal hovering and water-treading kinematics to study the difference in fluid dynamic performance between the two types of flapping kinematics. We show that for similar power consumption, the water-treading mode produces more lift than the conventional hovering mode and is 50% more efficient for symmetric pitching kinematics. In the water-treading mode, the leading edge vortex from the previous stroke is not pushed away but is captured and keeps the newly formed leading edge vortex closer to the wing, leading to a more rapid increase of the lift coefficient which is sustained for longer. This makes the water-treading mode a promising alternative for human-engineered flapping wing vehicles. 	
Scalable photonic platform for real-time quantum reservoir computing	http://arxiv.org/abs/2207.14031v2	2023-01-08T18:38:36Z	2022-07-28T11:44:44Z	  Quantum Reservoir Computing (QRC) exploits the information processing capabilities of quantum systems to solve non-trivial temporal tasks, improving over their classical counterparts. Recent progress has shown the potential of QRC exploiting the enlarged Hilbert space, but real-time processing and the achievement of a quantum advantage with efficient use of resources are prominent challenges towards viable experimental realizations. In this work, we propose a photonic platform suitable for real-time QRC based on a physical ensemble of reservoirs in the form of identical optical pulses recirculating through a closed loop. While ideal operation achieves maximum capacities, statistical noise is shown to undermine a quantum advantage. We propose a strategy to overcome this limitation and sustain the QRC performance when the size of the system is scaled up. The platform is conceived for experimental implementations to be viable with current technology. 	
"A health telemonitoring platform based on data integration from
  different sources"	http://arxiv.org/abs/2207.13913v2	2022-08-26T07:46:49Z	2022-07-28T07:13:04Z	  The management of people with long-term or chronic illness is one of the biggest challenges for national health systems. In fact, these diseases are among the leading causes of hospitalization, especially for the elderly, and huge amount of resources required to monitor them leads to problems with sustainability of the healthcare systems. The increasing diffusion of portable devices and new connectivity technologies allows the implementation of telemonitoring system capable of providing support to health care providers and lighten the burden on hospitals and clinics. In this paper, we present the implementation of a telemonitoring platform for healthcare, designed to capture several types of physiological health parameters from different consumer mobile and custom devices. Consumer medical devices can be integrated into the platform via the Google Fit ecosystem that supports hundreds of devices, while custom devices can directly interact with the platform with standard communication protocols. The platform is designed to process the acquired data using machine learning algorithms, and to provide patients and physicians the physiological health parameters with a user-friendly, comprehensive, and easy to understand dashboard which monitors the parameters through time. Preliminary usability tests show a good user satisfaction in terms of functionality and usefulness. 	
"EOSC-LIFE WP4 TOOLBOX: Toolbox for sharing of sensitive data -- a
  concept description"	http://arxiv.org/abs/2207.14296v1	2022-07-28T07:09:27Z	2022-07-28T07:09:27Z	  The Horizon 2020 project EOSC-Life brings together the 13 Life Science 'ESFRI' research infrastructures to create an open, digital and collaborative space for biological and medical research. Sharing sensitive data is a specific challenge within EOSC-Life. For that reason, a toolbox is being developed, providing information to researchers who wish to share and/or use sensitive data in a cloud environment in general, and the European Open Science Cloud in particular. The sensitivity of the data may arise from its personal nature but can also be caused by intellectual property considerations, biohazard concerns, or the Nagoya protocol. The toolbox will not create new content, instead, it will allow researchers to find existing resources that are relevant for sharing sensitive data across all participating research infrastructures (F in FAIR). The toolbox will provide links to recommendations, procedures, and best practices, as well as to software (tools) to support data sharing and reuse. It will be based upon a tagging (categorisation) system, allowing consistent labelling and categorisation of resources. The current design document provides an outline for the anticipated toolbox, as well as its basic principles regarding content and sustainability. 	
"Tuning electronic and magnetic properties of FeRh alloy by chemical and
  physical method"	http://arxiv.org/abs/2207.13900v2	2022-07-29T15:34:49Z	2022-07-28T06:32:43Z	  The electronic, magnetic, and thermodynamic properties of ordered and chemically disordered FeRh alloy is studied using ab-initio methods. The equiatomic Fe$_{50}$Rh$_{50}$ composition is reported for both ordered and disordered phases. Chemically disordered Fe$_x$Rh$_{100-x}$ is reported and the effect of disorder on electronic and magnetic properties is discussed. Further, We have reported the effects of stress and strain in both the order and disorder phases. The result is only for the cubic phase and no distortion has been taken into consideration. This study is motivated by the recent resurgence in FeRh study motivated by the fact that the barocaloric properties can be possible to sustain over the cycle. Hence, we have discussed the properties of Fe$_x$ Rh${100-x}$ with chemical disorder and pressure together, to gain an insight into the compound effect and the interplay between them 	
"Escape of cosmic rays from perpendicular shocks in the circumstellar
  magnetic field"	http://arxiv.org/abs/2207.13896v1	2022-07-28T06:19:05Z	2022-07-28T06:19:05Z	  We investigate the escape process of cosmic rays (CRs) from perpendicular shock regions of a spherical shock propagating to a circumstellar medium with the Parker-spiral magnetic field. The diffusive shock acceleration in perpendicular shocks of supernova remnants (SNRs) is expected to accelerate CRs up to PeV without upstream magnetic field amplification. Red supergiants (RSGs) and Wolf-Rayet (WR) stars are considered as progenitors in this work. We perform test particle simulations to investigate the escape process and escape-limited maximum energy without magnetic field amplification in the upstream region, where the magnetic field strength and rotation period expected from observations of RSGs and WR stars are used. We show that particles escape to the far upstream region while moving along the equator or poles and the maximum energy is about $10-100~{\rm TeV}$ when SNRs propagate to free wind regions of RSGs and WR stars. In most cases, the escape-limited maximum energy is given by the potential difference between the equator and pole. If progenitors are oblique rotators and SNRs are in the early phase just after the supernova explosion, the escape-limited maximum energy is limited by the half wavelength of the wavy current sheet. In addition, for RSGs, we show that the luminosity of CRs accelerated in the wind region is sufficient to supply the observed CR flux above $10~{\rm TeV}$ if a strong magnetic field strength is sustained in most RSGs. In terms of the CR luminosity, SNRs propagating to the free wind of WR stars can contribute to PeV CRs. As long as no magnetic field amplification works around SNR shocks, the maximum energy is decided by the magnetic field strength in the wind region, which depends on the rotation period, stellar wind, and surface magnetic field of RSGs and WR stars. Therefore, we need to observe these quantities to understand the origin of CRs. 	
Adaptive Second Order Coresets for Data-efficient Machine Learning	http://arxiv.org/abs/2207.13887v1	2022-07-28T05:43:09Z	2022-07-28T05:43:09Z	  Training machine learning models on massive datasets incurs substantial computational costs. To alleviate such costs, there has been a sustained effort to develop data-efficient training methods that can carefully select subsets of the training examples that generalize on par with the full training data. However, existing methods are limited in providing theoretical guarantees for the quality of the models trained on the extracted subsets, and may perform poorly in practice. We propose AdaCore, a method that leverages the geometry of the data to extract subsets of the training examples for efficient machine learning. The key idea behind our method is to dynamically approximate the curvature of the loss function via an exponentially-averaged estimate of the Hessian to select weighted subsets (coresets) that provide a close approximation of the full gradient preconditioned with the Hessian. We prove rigorous guarantees for the convergence of various first and second-order methods applied to the subsets chosen by AdaCore. Our extensive experiments show that AdaCore extracts coresets with higher quality compared to baselines and speeds up training of convex and non-convex machine learning models, such as logistic regression and neural networks, by over 2.9x over the full data and 4.5x over random subsets. 	
Elastic membranes spanning deformable boundaries	http://arxiv.org/abs/2207.13614v1	2022-07-27T16:23:25Z	2022-07-27T16:23:25Z	  We perform a variational analysis of an elastic membrane spanning a curve which may sustain bending and torsion. First, we deal with parametrized curves and linear elastic membranes proving the existence of equilibria and finding first-order necessary conditions for minimizers computing the first variation. Second, we study a more general case, both for the boundary curve and the membrane, using the framed curve approach. The infinite dimensional version of the Lagrange multipliers' method is applied to get the first-order necessary conditions. Finally, a numerical approach is presented and employed in several numerical test cases. 	
NLOS Transmission Analysis for Mobile SLIPT Using Resonant Beam	http://arxiv.org/abs/2207.13578v1	2022-07-27T15:20:06Z	2022-07-27T15:20:06Z	  Simultaneous lightwave information and power transfer (SLIPT) is a potential way to meet the demands of sustainable power supply and high-rate data transfer in next-generation networks. Although resonant beam-based SLIPT (RB-SLIPT) can realize high-power energy transfer, high-rate data transfer, human safety, and self-alignment simultaneously, mobile transmission channel (MTC) analysis under non-line-of-sight (NLOS) propagation has not been investigated. In this paper, we propose analytical models and simulation tools for reflector-assisted NLOS transmission of RB-SLIPT, where transmission loss and accurate beam field profile of NLOS MTC can be obtained with a receiver at arbitrary positions and attitude angles. We establish analytical models relying on full diffraction theory for beam propagation between tilted or off-axis planes. Then, we provide three numerical methods (i.e., NUFFT-based, cubic interpolation-based, and linear interpolation-based methods) in simulations. Moreover, to deal with the contradiction between limited computing memory and high sampling requirements for long-range transmission analysis, we propose a multi-hop sliding window approach, which can reduce the sampling number by a factor of thousands. Finally, numerical results demonstrate that RB-SLIPT can achieve $4$W charging power and $12$bit/s/Hz data rate over $2$m distance in NLOS scenarios. 	
"Challenges and Opportunities of Computational Social Science for
  Official Statistics"	http://arxiv.org/abs/2207.13508v1	2022-07-27T13:20:09Z	2022-07-27T13:20:09Z	  The vast amount of data produced everyday (so-called 'digital traces') and available nowadays represent a gold mine for the social sciences, especially in a computational context, that allows to fully extract their informational and knowledge value. In the latest years, statistical offices have made efforts to profit from harnessing the potential offered by these new sources of data, with promising results. But how difficult is this integration process? What are the challenges that statistical offices would likely face to profit from new data sources and analytical methods? This chapter will start by setting the scene of the current official statistics system, with a focus on its fundamental principles and dimensions relevant to the use of non-traditional data. It will then present some experiments and proofs of concept in the context of data innovation for official statistics, followed by a discussion on prospective challenges related to sustainable data access, new technical and methodological approaches and effective use of new sources of data. 	
"Self-sustainment of coherent structures in counter-rotating
  Taylor-Couette flow"	http://arxiv.org/abs/2207.12990v1	2022-07-26T15:50:53Z	2022-07-26T15:50:53Z	  We investigate the local self-sustained process underlying spiral turbulence in counter-rotating Taylor-Couette flow using a periodic annular domain, shaped as a parallelogram, two of whose sides are aligned with the cylindrical helix described by the spiral pattern. The primary focus of the study is placed on the emergence of drifting-rotating waves ({\sc drw}) that capture, in a relatively small domain, the main features of coherent structures typically observed in developed turbulence. The transitional dynamics of the subcritical region, far below the first instability of the laminar circular Couette flow, is determined by the upper and lower branches of {\sc drw} solutions originated at saddle-node bifurcations. The mechanism whereby these solutions self-sustain, and the chaotic dynamics they induce, are conspicuously reminiscent of other subcritical shear flows. Remarkably, the flow properties of {\sc drw} persist even as the Reynolds number is increased beyond the linear stability threshold of the base flow. Simulations in a narrow parallelogram domain stretched in the azimuthal direction to revolve around the apparatus a full turn confirm that self-sustained vortices eventually concentrate into a localised pattern. The resulting statistical steady state satisfactorily reproduces qualitatively, and to a certain degree also quantitatively, the topology and properties of spiral turbulence as calculated in a large periodic domain of sufficient aspect ratio that is representative of the real system 	
Quantum tunneling of three-spine solitons through excentric barriers	http://arxiv.org/abs/2207.12972v1	2022-07-26T15:34:24Z	2022-07-26T15:34:24Z	  Macromolecular protein complexes catalyze essential physiological processes that sustain life. Various interactions between protein subunits could increase the effective mass of certain peptide groups, thereby compartmentalizing protein $\alpha$-helices. Here, we study the differential effects of applied massive barriers upon the soliton-assisted energy transport within proteins. We demonstrate that excentric barriers, localized onto a single spine in the protein $\alpha$-helix, reflect or trap three-spine solitons as effectively as concentric barriers with comparable total mass. Furthermore, wider protein solitons, whose energy is lower, require heavier massive barriers for soliton reflection or trapping. Regulation of energy transport, delivery and utilization at protein active sites could thus be achieved through control of the soliton width, or of the effective mass of the protein subunits. 	
Let it RAIN for Social Good	http://arxiv.org/abs/2208.04697v1	2022-07-26T13:37:13Z	2022-07-26T13:37:13Z	  Artificial Intelligence (AI) as a highly transformative technology take on a special role as both an enabler and a threat to UN Sustainable Development Goals (SDGs). AI Ethics and emerging high-level policy efforts stand at the pivot point between these outcomes but is barred from effect due the abstraction gap between high-level values and responsible action. In this paper the Responsible Norms (RAIN) framework is presented, bridging this gap thereby enabling effective high-level control of AI impact. With effective and operationalized AI Ethics, AI technologies can be directed towards global sustainable development. 	
SIViDet: Salient Image for Efficient Weaponized Violence Detection	http://arxiv.org/abs/2207.12850v5	2023-02-22T04:26:03Z	2022-07-26T12:31:01Z	  In every connected smart city around the world, CCTVs have played a pivotal role in enforcing the safety and security of the citizens by recording unlawful activities for the authorities to take action. To ensure the efficiency and effectiveness of CCTVs in this domain, different DNN architectures were created and used by researchers and developers to either detect violence or detect weapons using bounding boxes or masks. These weapons are limited to guns, knives, and other obvious handheld weapons. To remove these limits and detect weapons more efficiently, non-weaponized violence footage from CCTV must be differentiable from weaponized ones. Since there are no current datasets that are tailored to this purpose of generalizability in weaponized violence detection, we introduced a new dataset that contains videos depicting weaponized violence, non-weaponized violence, and non-violent events. We also propose a novel data-centric method that arranges video frames into salient images while minimizing information loss for comfortable inference by SOTA image classifiers. This was done to simplify video classification tasks and optimize inference latency to improve sustainability in smart cities. Our experiments show that Image Classifiers can efficiently detect and distinguish violence with weapons from violence without weapons with performances as high as 99\% on our dataset, which are comparable with current SOTA 3D networks for action recognition and video classification. 	
"Convolutional neural networks and multi-threshold analysis for
  contamination detection in the apparel industry"	http://arxiv.org/abs/2207.12720v1	2022-07-26T08:21:41Z	2022-07-26T08:21:41Z	  Quality control of apparel items is mandatory in modern textile industry, as consumer's awareness and expectations about the highest possible standard is constantly increasing in favor of sustainable and ethical textile products. Such a level of quality is achieved by checking the product throughout its life cycle, from raw materials to boxed stock. Checks may include color shading tests, fasteners fatigue tests, fabric weigh tests, contamination tests, etc. This work deals specifically with the automatic detection of contaminations given by small parts in the finished product such as raw material like little stones and plastic bits or materials from the construction process, like a whole needle or a clip. Identification is performed by a two-level processing of X-ray images of the items: in the first, a multi-threshold analysis recognizes the contaminations by gray level and shape attributes; the second level consists of a deep learning classifier that has been trained to distinguish between true positives and false positives. The automatic detector was successfully deployed in an actual production plant, since the results satisfy the technical specification of the process, namely a number of false negatives smaller than 3% and a number of false positives smaller than 15%. 	
"Integration of Renewable Energy Sources for Low Emission Microgrids in
  Canadian Remote Communities"	http://arxiv.org/abs/2207.13092v1	2022-07-26T05:53:11Z	2022-07-26T05:53:11Z	  In recent years, the electrification of Canadian Remote Communities (RCs) has received significant attention, as their current electric energy systems are not only expensive, but are also highly polluting due to the prevalence of diesel generators. In addition, RCs' inherent geographic characteristics impose a series of challenges that must be considered when planning their electricity supply. Thus, in this paper, an optimization model for the long-term planning of RC Microgrids (MGs) including Renewable Energy Sources (RESs) and Energy Storage Systems (ESSs) is proposed, with the objective of reducing costs and emissions. The proposed model considers lithium-ion batteries and hydrogen systems as part of ESSs technologies. The model is used to investigate the feasibility of integrating RESs and ESSs in an MG in Sanikiluaq, an RC in the Nunavut territory in Northern Canada. The results show that wind resources along with solar and storage technologies can play a key role in satisfying RC electricity demand, while significantly reducing costs and Greenhouse Gas Emissions (GHG). In addition, insights on sustainable and affordable policies for RC MGs are provided. 	
A Learning and Control Perspective for Microfinance	http://arxiv.org/abs/2207.12631v2	2022-12-12T07:55:52Z	2022-07-26T03:35:18Z	  Microfinance, despite its significant potential for poverty reduction, is facing sustainability hardships due to high default rates. Although many methods in regular finance can estimate credit scores and default probabilities, these methods are not directly applicable to microfinance due to the following unique characteristics: a) under-explored (developing) areas such as rural Africa do not have sufficient prior loan data for microfinance institutions (MFIs) to establish a credit scoring system; b) microfinance applicants may have difficulty providing sufficient information for MFIs to accurately predict default probabilities; and c) many MFIs use group liability (instead of collateral) to secure repayment. Here, we present a novel control-theoretic model of microfinance that accounts for these characteristics. We construct an algorithm to learn microfinance decision policies that achieve financial inclusion, fairness, social welfare, and sustainability. We characterize the convergence conditions to Pareto-optimum and the convergence speeds. We demonstrate, in numerous real and synthetic datasets, that the proposed method accounts for the complexities induced by group liability to produce robust decisions before sufficient loans are given to establish credit scoring systems and for applicants whose default probability cannot be accurately estimated due to missing information. To the best of our knowledge, this paper is the first to connect microfinance and control theory. We envision that the connection will enable safe learning and control techniques to help modernize microfinance and alleviate poverty. 	
"Inverse cascades of kinetic energy and thermal variance in
  three-dimensional horizontally extended turbulent convection"	http://arxiv.org/abs/2207.12606v2	2022-10-20T15:33:16Z	2022-07-26T02:08:13Z	  Inverse cascades of kinetic energy and thermal variance in the subset of vertically homogeneous modes in spectral space are found to cause a slow aggregation to a pair of convective supergranules that eventually fill the whole horizontally extended, three-dimensional, turbulent Rayleigh-B\'{e}nard convection layer when a heat flux is prescribed at the top and bottom. An additional weak rotation of the layer around the vertical axis stops this aggregation at a scale that is smaller than the lateral domain extension and ceases the inverse cascade for the thermal variance. The inverse cascade for the kinetic energy remains intact, even for times at which the root mean square values of temperature and velocity have reached the statistically steady state. This kinetic energy inverse cascade sustains the horizontally extended convection patterns which are best visible in the temperature field. The resulting characteristic length of the aggregated convection patterns depends on the thermal driving and linearly on the strength of rotation. Our study demonstrates the importance of inverse energy cascades beyond the two-dimensional turbulence case in a three-dimensional convection flow that is subject to a multi-scale energy injection by thermal plumes and driven by boundary heat fluxes as typically present in natural geo- and astrophysical systems, such as solar convection. 	
"Optimality and sustainability of hybrid limit cycles in the pollution
  control problem with regime shifts"	http://arxiv.org/abs/2207.12486v1	2022-07-25T19:25:24Z	2022-07-25T19:25:24Z	  In this paper, we consider the problem of pollution control in a system that undergoes regular regime shifts. We first show that the optimal policy of pollution abatement is periodic as well, and is described by the unique hybrid limit cycle. We next introduce the notion of an environmentally sustainable solution, and demonstrate that such a policy is the only one that yields the best possible trade-off between steadily achieving profit and ensuring environmental preservation. In contrast to that, the policy that is not environmentally sustainable eventually enters stagnation. To further illustrate our findings, we compare the optimal periodic solution with a myopic one. Interestingly enough, the myopic solution yields higher overall payoff in the short-run, but completely fails in the long-run, while the environmentally sustainable policy yields maximal payoff and preserves the environment over the infinite time interval. 	
MIGHTEE: the nature of the radio-loud AGN population	http://arxiv.org/abs/2207.12379v1	2022-07-25T17:48:20Z	2022-07-25T17:48:20Z	  We study the nature of the faint radio source population detected in the MeerKAT International GHz Tiered Extragalactic Exploration (MIGHTEE) Early Science data in the COSMOS field, focusing on the properties of the radio-loud active galactic nuclei (AGN). Using the extensive multi-wavelength data available in the field, we are able to classify 88 per cent of the 5223 radio sources in the field with host galaxy identifications as AGN (35 per cent) or star-forming galaxies (54 per cent). We select a sample of radio-loud AGN with redshifts out to $z \sim 6$ and radio luminosities $10^{20} < \textrm{L}_{1.4~\textrm{GHz}} / \textrm{W Hz}^{-1} < 10^{27}$ and classify them as high-excitation and low-excitation radio galaxies (HERGs and LERGs). The classification catalogue is released with this work. We find no significant difference in the host galaxy properties of the HERGs and LERGs in our sample. In contrast to previous work, we find that the HERGs and LERGs have very similar Eddington-scaled accretion rates; in particular we identify a population of very slowly accreting AGN that are formally classified as HERGs at these low radio luminosities, where separating into HERGs and LERGs possibly becomes redundant. We investigate how black hole mass affects jet power, and find that a black hole mass $\gtrsim 10^{7.8}~\textrm{M}_\odot$ is required to power a jet with mechanical power greater than the radiative luminosity of the AGN ($L_\textrm{mech}/L_\textrm{bol} > 1$). We discuss that both a high black hole mass and black hole spin may be necessary to launch and sustain a dominant radio jet. 	
"Unleashing the potential of price-based congestion management schemes: a
  unifying approach to compare alternative models under multiple objectives"	http://arxiv.org/abs/2207.12041v1	2022-07-25T10:30:58Z	2022-07-25T10:30:58Z	  A wide range of price-based congestion management schemes were proposed in the literature ranging from marginal cost road pricing to trip based multimodal pricing. The underlying models were formulated under different theoretical assumptions and with varying, and sometimes conflicting objectives. This paper presents a unifying framework under which different approaches can be compared based on their respective assumptions. The unifying modelling framework is referred to as trip pricing model, which extends path-differentiated pricing to multimodal paths, i.e., trips on whatever mode or combinations of modes, and generalizes road pricing schemes (which are shown to be a special case). By setting both positive (tolls) and negative (incentives) prices, revenue-neutral schemes are also shown to be special cases, with no a-priori assumption on which paths/modes to toll/incentivize. For model comparison, the pricing design problem is formulated in a multi-objective optimization framework, which combines traffic efficiency, environmental sustainability, users' acceptance, social and spatial equity, as pricing objectives. The trip pricing scheme is compared with traditional road pricing schemes, and with their revenue-neutral variants. First-best and second-best pricing schemes, designed in single- and multi-objective optimization frameworks, are compared on the Nguyen-Dupuis network. Results suggest a vast potential for multi-objective trip congestion pricing over single-objective road pricing. In addition, the application of both positive and negative prices is shown to significantly increase the expected acceptance of pricing schemes and to preserve efficiency and sustainability objectives. The results should promote the design of more effective pricing policies, i.e., set of pricing rules easier to communicate, based on now available technologies of passengers' tracking and pricing. 	
"Distributed Nonlinear State Estimation in Electric Power Systems using
  Graph Neural Networks"	http://arxiv.org/abs/2207.11465v2	2022-09-08T07:55:48Z	2022-07-23T08:54:24Z	  Nonlinear state estimation (SE), with the goal of estimating complex bus voltages based on all types of measurements available in the power system, is usually solved using the iterative Gauss-Newton method. The nonlinear SE presents some difficulties when considering inputs from both phasor measurement units and supervisory control and data acquisition system. These include numerical instabilities, convergence time depending on the starting point of the iterative method, and the quadratic computational complexity of a single iteration regarding the number of state variables. This paper introduces an original graph neural network based SE implementation over the augmented factor graph of the nonlinear power system SE, capable of incorporating measurements on both branches and buses, as well as both phasor and legacy measurements. The proposed regression model has linear computational complexity during the inference time once trained, with a possibility of distributed implementation. Since the method is noniterative and non-matrix-based, it is resilient to the problems that the Gauss-Newton solver is prone to. Aside from prediction accuracy on the test set, the proposed model demonstrates robustness when simulating cyber attacks and unobservable scenarios due to communication irregularities. In those cases, prediction errors are sustained locally, with no effect on the rest of the power system's results. 	
Propagation of Partially Coherent Light in non-Hermitian Lattices	http://arxiv.org/abs/2207.11086v1	2022-07-22T13:52:34Z	2022-07-22T13:52:34Z	  Band theory for partially coherent light is introduced by using the formalism of second-order classical coherence theory under paraxial approximation. It is demonstrated that the cross-spectral density function, describing correlations between pairs of points in the field, can have bands and gaps and form a correlation band structure. The propagation of a partially coherent beam in non-Hermitian periodic structures is considered to elucidate the interplay between the degree of coherence and the gain/loss present in the lattice. We apply the formalism to study partially coherent Bloch oscillations in lattices having parity-time symmetry and demonstrate that the oscillations can be sustained in such media but they are strongly dependent upon the spatial correlations of the beam. A transition between breathing and oscillating modes is shown to be induced by the degree of spatial coherence. 	
"Static Hovering Realization for Multirotor Aerial Vehicles with Tiltable
  Propellers"	http://arxiv.org/abs/2207.10929v2	2022-11-28T12:06:01Z	2022-07-22T08:04:50Z	  This paper presents a theoretical study on the ability of multi-rotor aerial vehicles (MRAVs) with tiltable propellers to achieve and sustain static hovering at different orientations. To analyze the ability of MRAVs with tiltable propellers to achieve static hovering, a novel linear map between the platform's control inputs and applied forces and moments is introduced. The relation between the introduced map and the platform's ability to hover at different orientations is developed. Correspondingly, the conditions for MRAVs with tiltable propellers to realize and sustain static hovering are detailed. A numerical metric is then introduced, which reflects the ability of MRAVs to sustain static hovering at different orientations. A subclass of MRAVs with tiltable propellers is defined as the Critically Statically Hoverable platforms (CSH), where CSH platforms are MRAVs that cannot sustain static hovering with fixed propellers, but can achieve static hovering with tilting propellers. Finally, extensive simulations are conducted to test and validate the above findings, and to demonstrate the effect of the proposed numerical metric on the platform's dynamics. 	
Kinetically-driven ekpyrosis	http://arxiv.org/abs/2207.10808v2	2022-08-09T23:07:28Z	2022-07-21T23:50:37Z	"  We explore the possibility of a scalar field driving ekpyrotic contraction through a non-canonical kinetic energy density rather than a negative potential. We find that this kinetically-driven ekpyrosis (""k-ekpyrosis"") can be achieved in a variety of models, including scalar field theories with power-law, polynomial, or DBI-like kinetic terms in the action. Of these examples, the ekpyrotic phase is best sustained in power-law models, which can generate large and constant equation-of-state parameters, followed by DBI-like models, which can exhibit dynamical attractors toward similarly large equations of state. We show that for a broad class of theories including these examples, phases of k-ekpyrosis are accompanied by preceding or concurrent phases of superluminality. "	
"GreenDB -- A Dataset and Benchmark for Extraction of Sustainability
  Information of Consumer Goods"	http://arxiv.org/abs/2207.10733v3	2022-08-16T16:46:42Z	2022-07-21T19:59:42Z	  The production, shipping, usage, and disposal of consumer goods have a substantial impact on greenhouse gas emissions and the depletion of resources. Machine Learning (ML) can help to foster sustainable consumption patterns by accounting for sustainability aspects in product search or recommendations of modern retail platforms. However, the lack of large high quality publicly available product data with trustworthy sustainability information impedes the development of ML technology that can help to reach our sustainability goals. Here we present GreenDB, a database that collects products from European online shops on a weekly basis. As proxy for the products' sustainability, it relies on sustainability labels, which are evaluated by experts. The GreenDB schema extends the well-known schema.org Product definition and can be readily integrated into existing product catalogs. We present initial results demonstrating that ML models trained with our data can reliably (F1 score 96%) predict the sustainability label of products. These contributions can help to complement existing e-commerce experiences and ultimately encourage users to more sustainable consumption patterns. 	
"Artificial intelligence enables mobile soil analysis for sustainable
  agriculture"	http://arxiv.org/abs/2207.10537v1	2022-07-21T15:21:39Z	2022-07-21T15:21:39Z	  For optimizing production yield while limiting negative environmental impact, sustainable agriculture benefits greatly from real-time, on-the-spot analysis of soil at low cost. Colorimetric paper sensors are ideal candidates for cheap and rapid chemical spot testing. However, their field application requires previously unattained paper sensor reliability and automated readout and analysis by means of integrated mobile communication, artificial intelligence, and cloud computing technologies. Here, we report such a mobile chemical analysis system based on colorimetric paper sensors that operates under tropical field conditions. By mapping topsoil pH in a field with an area of 9 hectares, we have benchmarked the mobile system against precision agriculture standards following a protocol with reference analysis of compound soil samples. As compared with routine lab analysis, our mobile soil analysis system has correctly classified soil pH in 97% of cases while reducing the analysis turnaround time from days to minutes. Moreover, by performing on-the-spot analyses of individual compound sub-samples in the field, we have achieved a 9-fold increase of spatial resolution that reveals pH-variations not detectable in compound mapping mode. Our mobile system can be extended to perform multi-parameter chemical tests of soil nutrients for applications in environmental monitoring at marginal manufacturing cost. 	
"Correlation-temperature phase diagram of prototypical infinite layer
  rare earth nickelates"	http://arxiv.org/abs/2207.10527v1	2022-07-21T15:07:35Z	2022-07-21T15:07:35Z	  The discovery of superconductivity in hole-doped infinite layer nickelates, RNiO2 (R = Nd, Pr, La) has garnered sustained interest in the field. A definitive picture of low-energy many-body states has not yet emerged. We provide new insights into the low-energy physics, based on our embedded dynamical mean-field theory calculations, and propose a correlation (U)-temperature (T) phase diagram. The key features are a low-T Fermi liquid (FL) phase, a high-T Curie-Weiss regime, and an antiferromagnetic phase in a narrow U-T region. We associate the onset of the FL phase with partial screening of Ni-d moments; however, full screening occurs at lower temperatures. This may be related to insufficiency of conduction electrons to effectively screen the Ni-d moments, suggestive of Nozieres Exhaustion Principle. Our results suggest that RNiO2 are in the paramagnetic state, close to an antiferromagnetic dome, making magnetic fluctuations feasible. This may be consequential for superconductivity. 	
Secure Lightweight Authentication for Multi User IoT Environment	http://arxiv.org/abs/2207.10353v1	2022-07-21T08:15:54Z	2022-07-21T08:15:54Z	  The Internet of Things (IoT) is giving a boost to a plethora of new opportunities for the robust and sustainable deployment of cyber physical systems. The cornerstone of any IoT system is the sensing devices. These sensing devices have considerable resource constraints, including insufficient battery capacity, CPU capability, and physical security. Because of such resource constraints, designing lightweight cryptographic protocols is an opportunity. Remote User Authentication ensures that two parties establish a secure and durable session key. This study presents a lightweight and safe authentication strategy for the user-gateway (U GW) IoT network model. The proposed system is designed leveraging Elliptic Curve Cryptography (ECC). We undertake a formal security analysis with both the Automated Validation of Internet Security Protocols (AVISPA) and Burrows Abadi Needham (BAN) logic tools and an information security assessment with the Delev Yao channel. We use publish subscribe based Message Queuing Telemetry Transport (MQTT) protocol for communication. Additionally, the performance analysis and comparison of security features show that the proposed scheme is resilient to well known cryptographic threats. 	
"Anomalous Absorption in Arrays of Metallic Nanoparticles: A Powerful
  Tool for Quantum Dot Optoelectronics"	http://arxiv.org/abs/2207.10328v1	2022-07-21T06:50:03Z	2022-07-21T06:50:03Z	  Periodic arrays of noble metal nanoparticles are emblematic nanostructures in photonics. Their ability to sustain localized surface plasmon resonances has been used throughout the years to demonstrate a variety of passive and active functionalities such as enhanced luminescence in dipolar media and LEDs as well as higher responsivities in photoconductive detectors. Here, we show that additional magnetic resonances, associated with inductive current loops between the nanoparticles and accessible with transverse electric waves, emerge in the limit of dense arrays with subwavelength periods. Moreover, their interplay with the plasmons of the system results in spectrally sharp analogues of electromagnetically induced absorption (EIA). We use these metasurfaces to induce changes and enhancements in the emission, absorption, photoconduction, and polarization properties of active layers of PbS nanocrystals, illustrating the potential of EIA beyond the passive functionalities demonstrated so far in literature. 	
"Learning to identify cracks on wind turbine blade surfaces using
  drone-based inspection images"	http://arxiv.org/abs/2207.11186v1	2022-07-20T18:37:25Z	2022-07-20T18:37:25Z	  Wind energy is expected to be one of the leading ways to achieve the goals of the Paris Agreement but it in turn heavily depends on effective management of its operations and maintenance (O&M) costs. Blade failures account for one-third of all O&M costs thus making accurate detection of blade damages, especially cracks, very important for sustained operations and cost savings. Traditionally, damage inspection has been a completely manual process thus making it subjective, error-prone, and time-consuming. Hence in this work, we bring more objectivity, scalability, and repeatability in our damage inspection process, using deep learning, to miss fewer cracks. We build a deep learning model trained on a large dataset of blade damages, collected by our drone-based inspection, to correctly detect cracks. Our model is already in production and has processed more than a million damages with a recall of 0.96. We also focus on model interpretability using class activation maps to get a peek into the model workings. The model not only performs as good as human experts but also better in certain tricky cases. Thus, in this work, we aim to increase wind energy adoption by decreasing one of its major hurdles - the O\&M costs resulting from missing blade failures like cracks. 	
Peculiar velocities in the early universe	http://arxiv.org/abs/2207.09824v3	2022-10-20T00:53:08Z	2022-07-20T11:18:59Z	  Large-scale peculiar motions are commonplace in our universe. Nevertheless, their origin, evolution and implications are still largely unknown. It is generally assumed that bulk motions are a relatively recent addition to the universal kinematics, triggered by the increasing inhomogeneity and anisotropy of the post-recombination epoch. In this work, we focus on the linear evolution of peculiar velocities prior to recombination, namely in the late radiation era and also during a phase of de Sitter inflation. We begin by showing/confirming that bulk motions are triggered and sustained by the non-gravitational forces developed during structure formation. Since density and therefore peculiar-velocity perturbations cannot grow in the baryonic sector before recombination, we consider drift motions in non-baryonic species, which can start growing in the late radiation era. Using relativistic linear cosmological perturbation theory, we find that peculiar motions in the low-energy dark component exhibit power-law growth, which increases further after equipartition. Turning to the very early universe, we consider the evolution of linear peculiar velocities during a phase of de Sitter inflation. We find that typical slow-roll scenarios do not source peculiar motions. Moreover, even if the latter were to be present at the onset of the de Sitter phase, the subsequent exponential expansion should quickly wash away any traces of peculiar-velocity perturbations. 	
Initializing BSQ with Open-Source ICCING	http://arxiv.org/abs/2207.09604v2	2022-07-25T14:39:43Z	2022-07-20T00:49:38Z	  While it is well known that there is a significant amount of conserved charges in the initial state of nuclear collisions, the production of these due to gluon splitting has yet to be thoroughly investigated. The ICCING (Initial Conserved Charges in Nuclear Geometry) algorithm reconstructs these quark distributions, providing conserved strange, baryon, and electric charges, by sampling a given model for the $g \rightarrow q\bar{q}$ splitting function over the initial energy density, which is valid at top collider energies, even when $\mu_B=0$. The ICCING algorithm includes fluctuations in the gluon longitudinal momenta, a structure that supports the implementation of dynamical processes, and the c++ version is now open-source. A full analysis of parameter choices on the model has been done to quantify the effect these have on the underlying physics. We find there is a sustained difference across the different charges that indicates sensitivity to hot spot geometry. 	
"Quantum coherence-control of thermal energy transport: The V model as a
  case study"	http://arxiv.org/abs/2207.09512v1	2022-07-19T18:50:14Z	2022-07-19T18:50:14Z	  Here, we study a minimal model, the three-level V system coupled to two heat baths, and investigate the role of quantum coherences in heat transport in both the transient regime and in the nonequilibrium steady-state. In our model, energy is exchanged between the baths through two parallel pathways, which can be made distinct through the nondegeneracy of excited levels (energy splitting $\Delta$) and a control parameter $\alpha$, which adjusts the strength of one of the arms. Using a nonsecular quantum master equation of Redfield form, we succeed in deriving closed-form expressions for the quantum coherences and the heat current in the steady state limit for closely degenerate excited levels. By including three ingredients in our analysis: nonequilibrium baths, nondegeneracy of levels, and asymmetry of pathways, we show that quantum coherences are generated and sustained in the V model in the steady-state limit if three conditions, conjoining thermal and coherent effects are simultaneously met: (i) The two baths are held at different temperatures. (ii) Bath-induced pathways do not interfere destructively. (iii) Thermal rates do not mingle with the control parameter $\alpha$ to destroy interferences through an effective local equilibrium condition. We find that coherences are maximized when the heat current is suppressed. On the other hand, the secular Redfield quantum master equation is shown to fail in a broad range of parameters. Although we mainly focus on analytical results in the steady state limit, numerical simulations reveal that the transient behavior of coherences contrasts the steady-state limit, suggesting that different mechanisms are at play in these two regimes. Enhancing either the lifetime of transient coherences or their magnitude at steady state thus requires the control and optimization of different physical parameters. 	
"Contaminant source identification in groundwater by means of artificial
  neural network"	http://arxiv.org/abs/2207.09459v1	2022-07-19T14:51:30Z	2022-07-19T14:51:30Z	  In a desired environmental protection system, groundwater may not be excluded. In addition to the problem of over-exploitation, in total disagreement with the concept of sustainable development, another not negligible issue concerns the groundwater contamination. Mainly, this aspect is due to intensive agricultural activities or industrialized areas. In literature, several papers have dealt with transport problem, especially for inverse problems in which the release history or the source location are identified. The innovative aim of the paper is to develop a data-driven model that is able to analyze multiple scenarios, even strongly non-linear, in order to solve forward and inverse transport problems, preserving the reliability of the results and reducing the uncertainty. Furthermore, this tool has the characteristic of providing extremely fast responses, essential to identify remediation strategies immediately. The advantages produced by the model were compared with literature studies. In this regard, a feedforward artificial neural network, which has been trained to handle different cases, represents the data-driven model. Firstly, to identify the concentration of the pollutant at specific observation points in the study area (forward problem); secondly, to deal with inverse problems identifying the release history at known source location; then, in case of one contaminant source, identifying the release history and, at the same time, the location of the source in a specific sub-domain of the investigated area. At last, the observation error is investigated and estimated. The results are satisfactorily achieved, highlighting the capability of the ANN to deal with multiple scenarios by approximating nonlinear functions without the physical point of view that describes the phenomenon, providing reliable results, with very low computational burden and uncertainty. 	
"Adoption of Sustainable Agricultural Practices among Kentucky Farmers
  and Their Perception about Farm Sustainability"	http://arxiv.org/abs/2207.08053v1	2022-07-17T02:01:21Z	2022-07-17T02:01:21Z	  The purpose of this research was to identify commonly adopted SAPs and their adoption among Kentucky farmers. The specific objectives were to explore farmers' Perceptions about farm and farming practice sustainability, to identify predictors of SAPs adoption using farm attributes, farmers' attitudes and behaviors, socioeconomic and demographic factors, and knowledge, and to evaluate adoption barriers of SAPs among Kentucky Farmers. Farmers generally perceive that their farm and farming activities attain the objectives of sustainable agriculture. Inadequate knowledge, perceived difficulty of implementation, lack of market, negative attitude about technologies, and lack of technologies were major adoption barriers of SAPs in Kentucky. 	
"The Roads One Must Walk Down: Commute and Depression for Beijing's
  Residents"	http://arxiv.org/abs/2207.07990v1	2022-07-16T17:44:39Z	2022-07-16T17:44:39Z	  As a vital aspect of individual's quality of life, mental health has been included as an important component of the U.N. Sustainable Development Goals. This study focuses on a specific aspect of mental health: depression, and examines its relationship with commute patterns. Using survey data from 1,528 residents in Beijing, China, we find that every 10 additional minutes of commute time is associated with 1.1% higher likelihood of depression. We test for the mechanisms of the commute-depression link and find that commute is associated with depression as a direct stressor rather than triggering higher work stress. When decomposing commute time into mode-specific time, we found that time on mopeds/motorcycles has the strongest association with depression. Moreover, the commute-depression associations are stronger for older workers and blue-collar workers. Hence, policies that could reduce commute time, encourage work from home, improve job-housing balance or increase motorcyclists' safety would help promote mental health. 	
"Characteristics of remnant radio galaxies detected in the deep radio
  continuum observations from the SKA pathfinders"	http://arxiv.org/abs/2207.07871v1	2022-07-16T07:55:52Z	2022-07-16T07:55:52Z	  The cessation of AGN activity in radio galaxies leads to a remnant phase during which jets are no longer sustained, but lobes can be detected for a period of time before they fade away due to radiative and dynamical energy losses. The time-scale of the remnant phase and AGN duty cycle are vital to understanding the evolution of radio galaxies. In this paper, we report new band-3 observations with the upgraded Giant Meterwave Radio Telescope (uGMRT) for five remnant radio galaxies. Our uGMRT observations reveal emission of low-surface-brightness in all five remnants with 400 MHz surface brightness in the range of 36$-$201 mJy arcmin$^{-2}$. With band-3 uGMRT observations, we discover wing-shaped radio morphology in one of our sample sources. Using radio observations at 150 MHz, 325 MHz, 400 MHz, and 1.5 GHz, we model the radio spectral energy distributions (SEDs) of our sample sources with the continuous injection-off model (CI$_{\rm OFF}$), that assumes an active phase with continuous injection followed by a remnant phase. We obtain total source ages ($t_{\rm s}$) in the range of 20.3 Myr to 41.4 Myr with $t_{\rm OFF}$/$t_{\rm s}$ distributed in the range of 0.16 to 0.63, which in turn suggests them to belong to different evolutionary phases. We note that, in comparison to the remnants reported in the literature, our sample sources tend to show lower spectral ages that can be explained by the combined effects of more dominant inverse Compton losses for our sources present at the relatively higher redshifts and possible rapid expansion of lobes in their less dense environments. 	
"On Scheduling Ring-All-Reduce Learning Jobs in Multi-Tenant GPU Clusters
  with Communication Contention"	http://arxiv.org/abs/2207.07817v2	2022-08-14T22:32:07Z	2022-07-16T02:49:40Z	"  Powered by advances in deep learning (DL) techniques, machine learning and artificial intelligence have achieved astonishing successes. However, the rapidly growing needs for DL also led to communication- and resource-intensive distributed training jobs for large-scale DL training, which are typically deployed over GPU clusters. To sustain the ever-increasing demand for DL training, the so-called ""ring-all-reduce"" (RAR) technologies have recently emerged as a favorable computing architecture to efficiently process network communication and computation load in GPU clusters. The most salient feature of RAR is that it removes the need for dedicated parameter servers, thus alleviating the potential communication bottleneck. However, when multiple RAR-based DL training jobs are deployed over GPU clusters, communication bottlenecks could still occur due to contentions between DL training jobs. So far, there remains a lack of theoretical understanding on how to design contention-aware resource scheduling algorithms for RAR-based DL training jobs, which motivates us to fill this gap in this work. Our main contributions are three-fold: i) We develop a new analytical model that characterizes both communication overhead related to the worker distribution of the job and communication contention related to the co-location of different jobs; ii) Based on the proposed analytical model, we formulate the problem as a non-convex integer program to minimize the makespan of all RAR-based DL training jobs. To address the unique structure in this problem that is not amenable for optimization algorithm design, we reformulate the problem into an integer linear program that enables provable approximation algorithm design called SJF-BCO (Smallest Job First with Balanced Contention and Overhead); and iii) We conduct extensive experiments to show the superiority of SJF-BCO over existing schedulers. "	
"Blockchain-enabled tokenization for sustainable and inclusive
  infrastructure investment"	http://arxiv.org/abs/2208.04709v1	2022-07-16T01:39:33Z	2022-07-16T01:39:33Z	  Infrastructure is critical for enabling society to function and the economy to thrive, but there is an increasing mismatch between the need for infrastructure investments and available capital, which is in consequence of constraints on public resources and limited capacity to leverage the private sector co-financing under the current system. With the emergence of distributed ledger technology, such as blockchain-enabled tokenization, there is a significant potential to improve investment liquidity, transparency, efficiency and create new economic models to integrate non-financial values to promote sustainability and inclusiveness. This research analyzed 21 projects to investigate how tokenization is implemented in energy infrastructure projects. Exploratory case study analyses were conducted, which shows the diversity of tokenization arrangements. The state of the art, potential benefits, implications, and obstacles associated with the application of tokenization in infrastructure investment and development are discussed. The purpose of this research is to understand tokenization within the context of the energy sector but also to forecast its application in a broad spectrum of infrastructure projects (e.g., transportation, telecommunication, healthcare, education). 	
Characterizing and Optimizing End-to-End Systems for Private Inference	http://arxiv.org/abs/2207.07177v2	2023-02-16T20:20:08Z	2022-07-14T19:38:40Z	  In two-party machine learning prediction services, the client's goal is to query a remote server's trained machine learning model to perform neural network inference in some application domain. However, sensitive information can be obtained during this process by either the client or the server, leading to potential collection, unauthorized secondary use, and inappropriate access to personal information. These security concerns have given rise to Private Inference (PI), in which both the client's personal data and the server's trained model are kept confidential. State-of-the-art PI protocols consist of a pre-processing or offline phase and an online phase that combine several cryptographic primitives: Homomorphic Encryption (HE), Secret Sharing (SS), Garbled Circuits (GC), and Oblivious Transfer (OT). Despite the need and recent performance improvements, PI remains largely arcane today and is too slow for practical use.   This paper addresses PI's shortcomings with a detailed characterization of a standard high-performance protocol to build foundational knowledge and intuition in the systems community. Our characterization pinpoints all sources of inefficiency -- compute, communication, and storage. In contrast to prior work, we consider inference request arrival rates rather than studying individual inferences in isolation and we find that the pre-processing phase cannot be ignored and is often incurred online as there is insufficient downtime to hide pre-compute latency. Finally, we leverage insights from our characterization and propose three optimizations to address the storage (Client-Garbler), computation (layer-parallel HE), and communication (wireless slot allocation) overheads. Compared to the state-of-the-art PI protocol, these optimizations provide a total PI speedup of 1.8$\times$ with the ability to sustain inference requests up to a 2.24$\times$ greater rate. 	
"XMem: Long-Term Video Object Segmentation with an Atkinson-Shiffrin
  Memory Model"	http://arxiv.org/abs/2207.07115v2	2022-07-18T17:56:53Z	2022-07-14T17:59:37Z	  We present XMem, a video object segmentation architecture for long videos with unified feature memory stores inspired by the Atkinson-Shiffrin memory model. Prior work on video object segmentation typically only uses one type of feature memory. For videos longer than a minute, a single feature memory model tightly links memory consumption and accuracy. In contrast, following the Atkinson-Shiffrin model, we develop an architecture that incorporates multiple independent yet deeply-connected feature memory stores: a rapidly updated sensory memory, a high-resolution working memory, and a compact thus sustained long-term memory. Crucially, we develop a memory potentiation algorithm that routinely consolidates actively used working memory elements into the long-term memory, which avoids memory explosion and minimizes performance decay for long-term prediction. Combined with a new memory reading mechanism, XMem greatly exceeds state-of-the-art performance on long-video datasets while being on par with state-of-the-art methods (that do not work on long videos) on short-video datasets. Code is available at https://hkchengrex.github.io/XMem 	
Equation of state of the running vacuum	http://arxiv.org/abs/2207.07111v3	2022-12-06T08:43:34Z	2022-07-14T17:59:09Z	  Recent studies of quantum field theory in FLRW spacetime suggest that the cause of the speeding up of the universe is the running vacuum (RV). Appropriate renormalization of the energy-momentum tensor shows that the vacuum energy density is a smooth function of the Hubble rate and its derivatives: $\rho_{\rm vac}=\rho_{\rm vac}(H, \dot{H},\ddot{H},...)$. This is because in QFT the quantum scaling of $\rho_{\rm vac}$ with the renormalization point turns into cosmic evolution with $H$. As a result, any two nearby points of the cosmic expansion during the standard FLRW epoch are smoothly related through $\delta\rho_{\rm vac}\sim {\cal O}(H^2)$. In our approach, what we call the `cosmological constant' $\Lambda$ is just the nearly sustained value of $8\pi G(H)\rho_{\rm vac}(H)$ around (any) given epoch, where $G(H)$ is the running gravitational coupling. In the present study, after summarizing the main QFT calculations supporting the RV approach, we focus on the calculation of the equation of state (EoS) of the RV for the entire cosmic history within such a QFT framework. In particular, in the very early universe, where higher (even) powers $\rho_{\rm vac}\sim{\cal O}(H^N)$ ($N=4,6,\dots$) triggered inflation during a short period in which $H=$const, the vacuum EoS is very close to $w_{\rm vac}=-1$. This ceases to be true during the FLRW era, where it adopts the EoS of matter during the relativistic ($w_{\rm vac}=1/3$) and non-relativistic ($w_{\rm vac}=0$) epochs. Interestingly enough, we find that in the late universe the EoS becomes mildly dynamical and mimics quintessence, $w_{\rm vac}\gtrsim-1$. It finally asymptotes to $-1$ in the remote future, but in the transit the RV helps alleviating the $H_0$ and $\sigma_8$ tensions. 	
"Tidally-induced Magnetar Super Flare at the Eve of Coalescence with Its
  Compact Companion"	http://arxiv.org/abs/2207.12324v3	2022-11-04T09:48:59Z	2022-07-14T13:10:46Z	  In the late inspiral phase of a double neutron star (NS) or NS-black hole system in which one NS is a magnetar, the tidal force on the magnetar arisen from its companion will increase dramatically as the binary approaches. The tidal-induced deformation may surpass the maximum that the magnetar's crust can sustain just seconds or subseconds before the coalescence. A catastrophic global crust destruction may thus occur, and the magnetic energy stored in the magnetar's interior will have the opportunity to be released, which would be observed as a superflare with energy 100s of times larger than giant flares of magnetars. Such a mechanism can naturally explain the recently observed precursor of GRB 211211A, including its quasiperiodic oscillation. We predict that in the coming gravitational wave O4/O5 period, there could be a fraction of detected double NS mergers associated with such super flares. If observed, copious information on the structure and magnetic field in an NS interior can be obtained, which is hard to study elsewhere. 	
Network bypasses sustain complexity	http://arxiv.org/abs/2207.06813v1	2022-07-14T10:39:20Z	2022-07-14T10:39:20Z	  Real-world networks are neither regular nor random, a fact elegantly explained by mechanisms such as the Watts-Strogatz or the Barabasi-Albert models. Both mechanisms naturally create shortcuts and hubs, which enhance network's navigability. They also tend to be overused during geodesic navigational processes, making the networks fragile against jamming. Why, then, networks with complex topologies are ubiquitous? Here we show that these models entropically generate network bypasses: alternative routes to shortest paths which are topologically longer but easier to navigate. We develop a mathematical theory that elucidates the emergence and consolidation of network bypasses and measures their navigability gain. We apply our theory to a wide range of real-world networks and find that they sustain complexity by different amounts of network bypasses. At the top of this complexity ranking we found the human brain, what points out the importance of these results to understand the plasticity of complex systems. 	
"Electrically Conductive 2D Material Coatings for Flexible & Stretchable
  Electronics: A Comparative Review of Graphenes & MXenes"	http://arxiv.org/abs/2207.06776v1	2022-07-14T09:36:49Z	2022-07-14T09:36:49Z	  There is growing interest in transitioning electronic components and circuitry from stiff and rigid substrates to more flexible and stretchable platforms, such as thin plastics, textiles, and foams. In parallel, the push for more sustainable, biocompatible, and cost-efficient conductive inks to coat these substrates, has led to the development of formulations with novel nanomaterials. Among these, 2D materials, and particularly graphenes and MXenes, have received intense research interest due to their increasingly facile and scalable production, high electrical conductivity, and compatibility with existing manufacturing techniques. They enable a range of electronic devices, including strain and pressure sensors, supercapacitors, thermoelectric generators, and heaters. These new flexible and stretchable electronic devices developed with 2D material coatings are poised to unlock exciting applications in the wearable, healthcare and Internet of Things sectors. This review has surveyed key data from more than 200 articles published over the last 6 years, to provide a quantitative analysis of recent progress in the field and shade light on future directions and prospects of this technology. We find that despite the different chemical origins of graphenes and MXenes, their shared electrical properties and 2D morphology, guarantee intriguing performance in end applications, leaving plenty of space for shared progress and advancements in the future. 	
"A General Framework of Bound States in the Continuum in an Open Acoustic
  Resonator"	http://arxiv.org/abs/2208.01396v1	2022-07-14T05:34:04Z	2022-07-14T05:34:04Z	  Bound states in the continuum (BICs) provide a viable way of achieving high-Q resonances in both photonics and acoustics. In this work, we proposed a general method of constructing Friedrich-Wintgen (FW) BICs and accidental BICs in a coupled acoustic waveguide-resonator system. We demonstrated that FW BICs can be achieved with arbitrary two degenerate resonances in a closed resonator regardless of whether they have the same or opposite parity. Moreover, their eigenmode profiles can be arbitrarily engineered by adjusting the position of attached waveguide. That suggests an effective way of continuous switching the nature of BIC from FW BIC to symmetry-protected BIC or accidental BICs. Also, such BICs are sustained in the coupled waveguide-resonator system with shapes such as rectangle, ellipse, and rhomboid. These interesting phenomena are well explained by the two-level effective non Hermitian Hamiltonian, where two strongly coupled degenerate modes play a major role in forming such FW BICs. Besides, we found that such an open system also supports accidental BICs in geometry space instead of momentum space via tuning the position of attached waveguide, which are attributed to the quenched coupling between the waveguide and eigenmodes of the closed cavity. Finally, we fabricated a series of 3D coupled-resonator-waveguide and experimentally verified the existence of FW BICs and accidental BICs by measuring the transmission spectra. Our results complement the current BIC library in acoustics and provide new routes for designing novel acoustic devices, such as in acoustic absorbers, filters and sensors. 	
The Dynamical Viability of an Extended Jupiter Ring System	http://arxiv.org/abs/2207.06434v3	2022-08-25T06:27:50Z	2022-07-13T18:00:02Z	  Planetary rings are often speculated as being a relatively common attribute of giant planets, partly based on their prevalence within the Solar System. However, their formation and sustainability remain a topic of open discussion, and the most massive planet within our planetary system harbors a very modest ring system. Here, we present the results of a N-body simulation that explores dynamical constraints on the presence of substantial ring material for Jupiter. Our simulations extend from within the rigid satellite Roche limit to 10\% of the Jupiter Hill radius, and include outcomes from $10^6$ and $10^7$ year integrations. The results show possible regions of a sustained dense ring material presence around Jupiter that may comprise the foundation for moon formation. The results largely demonstrate the truncation of stable orbits imposed by the Galilean satellites, and dynamical desiccation of dense ring material within the range $\sim$3--29 Jupiter radii. We discuss the implications of these results for exoplanets, and the complex relationship between the simultaneous presence of rings and massive moon systems. 	
"Space debris through the prism of the environmental performance of space
  systems: the case of Sentinel-3 redesigned mission"	http://arxiv.org/abs/2207.06306v1	2022-07-13T15:58:25Z	2022-07-13T15:58:25Z	  Like any industry, space activities generate pressures on the environment and strives towards more sustainable activities. A consensus among the European industrial stakeholders and national agencies in the Space sector is emerging on the need to address eco-design through the prism of the environmental Life Cycle Assessment (LCA) methodology. While the use of LCA is being implemented within the sector, the current scope disregards the potential environmental impact in term of debris generated by space missions on the orbital environment. The paper highlights the relevance of applying LCA holistically during the design phase of space systems, considering potential impacts occurring in the orbital environment during the utilisation and disposal stages of a space mission. Based on the comparison of two mission designs, the aim is to consider potential emission of space debris into the LCA framework as a way of measuring the resource security for orbits and potential environmental impacts occurring in case of collision. 	
"$g-B_{3}C_{2}N_{3}$: A new potential two dimensional metal-free
  photocatalyst for overall water splitting"	http://arxiv.org/abs/2207.06232v1	2022-07-13T14:29:43Z	2022-07-13T14:29:43Z	  In this work, using a hybrid density functional theory (DFT) based calculation, we propose a new two-dimensional (2D) B-C-N material, $g-B_{3}C_{2}N_{3}$, with the promising prospect of metal-free photocatalysis. A comprehensive investigation demonstrates that it is a near ultraviolet (UV) absorbing direct band gap (3.69 eV) semiconductor with robust dynamical and mechanical stability. Estimating the band positions with respect to water oxidation and hydrogen reduction potential levels, we observe that $g-B_{3}C_{2}N_{3}$ monolayer shows the possibility to be used for hydrogen fuel generation through spontaneous solar water splitting, over a broad pH range. Upon biaxial strain application the band gap decreases with increase in tensile strain, leading to a subsequent red shift in absorption spectra, implying enhanced photon harvest under solar irradiation. Furthermore, due to a combined effect of band gap and work function variation, biaxial strain realigns the band positions, allowing one to control the reducing or oxidizing ability as per requirement to attain environmental sustainability. 	
DLCSS: Dynamic Longest Common Subsequences	http://arxiv.org/abs/2207.06061v2	2022-09-01T10:26:38Z	2022-07-13T09:12:33Z	  Autonomous driving is a key technology towards a brighter, more sustainable future. To enable such a future, it is necessary to utilize autonomous vehicles in shared mobility models. However, to evaluate, whether two or more route requests have the potential for a shared ride, is a compute-intensive task, if done by rerouting. In this work, we propose the Dynamic Longest Common Subsequences algorithm for fast and cost-efficient comparison of two routes for their compatibility, dynamically only incorporating parts of the routes which are suited for a shared trip. Based on this, one can also estimate, how many autonomous vehicles might be necessary to fulfill the local mobility demands. This can help providers to estimate the necessary fleet sizes, policymakers to better understand mobility patterns and cities to scale necessary infrastructure. 	
Nanoscale engineering of optical strong coupling inside metals	http://arxiv.org/abs/2207.05988v1	2022-07-13T06:48:12Z	2022-07-13T06:48:12Z	  Optical polaritons appear when a material excitation strongly couples to the optical mode. Such strong coupling between molecular transitions and optical cavities results in far-reaching opportunities in modifying fundamental properties of chemical matter. More recently an exciting prospect of cavity-free polaritons has emerged by matter sustaining the optical mode with its geometry. Here we show how strong coupling of the interband transition and surface plasmons can be engineered in nickel at the nanoscale to realize cavity-free optical polaritons inside metals. Using electron energy-loss spectroscopy, we demonstrate that in thin films and nanoantennas the propagation and radiation losses result in a broadening of the plasmon linewidth and a transition from strong to weak coupling. Further, higher-order plasmon resonances couple to the interband transition, and the multipolar coupled states acquire the field profile of the plasmon. Our results provide a fundamental understanding of plasmon-interband coupling in metals and establish the base for the design of unforeseen photocatalytic and magneto-optical nanosystems. 	
"Dam reservoir extraction from remote sensing imagery using tailored
  metric learning strategies"	http://arxiv.org/abs/2207.05807v1	2022-07-12T19:46:01Z	2022-07-12T19:46:01Z	  Dam reservoirs play an important role in meeting sustainable development goals and global climate targets. However, particularly for small dam reservoirs, there is a lack of consistent data on their geographical location. To address this data gap, a promising approach is to perform automated dam reservoir extraction based on globally available remote sensing imagery. It can be considered as a fine-grained task of water body extraction, which involves extracting water areas in images and then separating dam reservoirs from natural water bodies. We propose a novel deep neural network (DNN) based pipeline that decomposes dam reservoir extraction into water body segmentation and dam reservoir recognition. Water bodies are firstly separated from background lands in a segmentation model and each individual water body is then predicted as either dam reservoir or natural water body in a classification model. For the former step, point-level metric learning with triplets across images is injected into the segmentation model to address contour ambiguities between water areas and land regions. For the latter step, prior-guided metric learning with triplets from clusters is injected into the classification model to optimize the image embedding space in a fine-grained level based on reservoir clusters. To facilitate future research, we establish a benchmark dataset with earth imagery data and human labelled reservoirs from river basins in West Africa and India. Extensive experiments were conducted on this benchmark in the water body segmentation task, dam reservoir recognition task, and the joint dam reservoir extraction task. Superior performance has been observed in the respective tasks when comparing our method with state of the art approaches. 	
Structure of turbulence in the flow around a rectangular cylinder	http://arxiv.org/abs/2207.05799v1	2022-07-12T19:28:35Z	2022-07-12T19:28:35Z	  The separating and reattaching turbulent flow past a rectangular cylinder is studied to describe how small and large scales contribute to the sustaining mechanism of the velocity fluctuations. The work is based on the Anisotropic Generalised Kolmogorov Equations (AGKE), exact budget equations for the second-order structure function tensor in the space of scales and in the physical space. Scale-space energy fluxes show that forward and reverse energy transfers simultaneously occur in the flow, with interesting modelling implications.   Over the longitudinal cylinder side, the Kelvin-Helmholtz instability of the leading-edge shear layer generates large spanwise rolls, which get stretched into hairpin-like vortices and eventually break down into smaller streamwise vortices. Independent sources of velocity fluctuations act at different scales. The flow dynamics is dominated by pressure-strain: the flow impingement on the cylinder surface in the reattachment zone produces spanwise velocity fluctuations very close to the wall and, at larger wall distances, reorients them to feed streamwise-aligned vortices.   In the near wake, large von K\`arm\`an-like vortices are shed from the trailing edge and coexist with smaller turbulent structures, each with its own independent production mechanism. At the trailing edge, the sudden disappearance of the wall changes the structure of turbulence: streamwise vortices progressively vanish, while spanwise structures close to the wall are suddenly turned into vertical fluctuations by the pressure strain. 	
"A machine-learning-based tool for last closed-flux surface
  reconstruction on tokamaks"	http://arxiv.org/abs/2207.05695v2	2022-10-20T04:19:41Z	2022-07-12T17:15:29Z	  Nuclear fusion represents one of the best alternatives for a sustainable source of clean energy. Tokamaks allow to confine fusion plasma with magnetic fields and one of the main challenges in the control of the magnetic configuration is the prediction/reconstruction of the Last Closed-Flux Surface (LCFS). The evolution in time of the LCFS is determined by the interaction of the actuator coils and the internal tokamak plasma. This task requires real-time capable tools able to deal with high-dimensional data as well as with high resolution in time, where the interaction between a wide range of input actuator coils with internal plasma state responses add additional layer of complexity. In this work, we present the application of a novel state of the art machine learning model to the LCFS reconstruction in the Experimental Advanced Superconducting Tokamak (EAST) that learns automatically from the experimental data of EAST. This architecture allows not only offline simulation and testing of a particular control strategy, but can also be embedded in the real-time control system for online magnetic equilibrium reconstruction and prediction. In the real-time modeling test, our approach achieves very high accuracies, with over 99% average similarity in LCFS reconstruction of the entire discharge process. 	
"Identification and Control of a Soft-Robotic Bladder Towards
  Impedance-Style Haptic Terrain Display"	http://arxiv.org/abs/2207.05537v1	2022-07-12T13:58:19Z	2022-07-12T13:58:19Z	"  This paper evaluates the capabilities of a soft robotic pneumatic actuator derived from the terrain display haptic device, ""The Smart Shoe."" The bladder design of the Smart Shoe is upgraded to include a pressure supply and greater output flow capabilities. A bench top setup is created to rigorously test this new type of actuator. The bandwidth and stiffness capability of this new actuator are evaluated relative to forces and displacements encountered during human gait. Four force vs. displacement profiles relevant to haptic terrain display are proposed and tested using sliding-mode tracking control. It was found that the actuator could sustain a stiffness similar to a soft-soled shoe on concrete, as well as other terrain (sand, dirt, etc.), while the bandwidth of 7.3 Hz fell short of the goal bandwidth of 10 Hz. Compressions of the bladder done at 20 mm/s, which is similar to the speed of human gait, showed promising results in tracking a desired force trajectory. The results in this paper show this actuator is capable of displaying haptic terrain trajectories, providing a basis for futurep wearable haptic terrain display devices. "	
"Huqariq: A Multilingual Speech Corpus of Native Languages of Peru for
  Speech Recognition"	http://arxiv.org/abs/2207.05498v1	2022-07-12T12:37:12Z	2022-07-12T12:37:12Z	  The Huqariq corpus is a multilingual collection of speech from native Peruvian languages. The transcribed corpus is intended for the research and development of speech technologies to preserve endangered languages in Peru. Huqariq is primarily designed for the development of automatic speech recognition, language identification and text-to-speech tools. In order to achieve corpus collection sustainably, we employ the crowdsourcing methodology. Huqariq includes four native languages of Peru, and it is expected that by the end of the year 2022, it can reach up to 20 native languages out of the 48 native languages in Peru. The corpus has 220 hours of transcribed audio recorded by more than 500 volunteers, making it the largest speech corpus for native languages in Peru. In order to verify the quality of the corpus, we present speech recognition experiments using 220 hours of fully transcribed audio. 	
"Kinetic theory of one-dimensional inhomogeneous long-range interacting
  $N$-body systems at order $1/N^{2}$ without collective effects"	http://arxiv.org/abs/2207.05349v1	2022-07-12T07:28:15Z	2022-07-12T07:28:15Z	  Long-range interacting systems irreversibly relax as a result of their finite number of particles, $N$. At order $1/N$, this process is described by the inhomogeneous Balescu--Lenard equation. Yet, this equation exactly vanishes in one-dimensional inhomogeneous systems with a monotonic frequency profile and sustaining only 1:1 resonances. In the limit where collective effects can be neglected, we derive a closed and explicit $1/N^{2}$ collision operator for such systems. We detail its properties highlighting in particular how it satisfies an $H$-theorem for Boltzmann entropy. We also compare its predictions with direct $N$-body simulations. Finally, we exhibit a generic class of long-range interaction potentials for which this $1/N^{2}$ collision operator exactly vanishes. 	
"The X-shooter/ALMA Sample of Quasars in the Epoch of Reionization. II.
  Black Hole Masses, Eddington Ratios, and the Formation of the First Quasars"	http://arxiv.org/abs/2207.05113v2	2022-09-19T09:40:55Z	2022-07-11T18:08:49Z	  We present measurements of black hole masses and Eddington ratios for a sample of 38 bright (M$_{1450}$ < -24.4 mag) quasars at 5.8 < z < 7.5, derived from VLT/X-shooter near-IR spectroscopy of their broad CIV and MgII emission lines. The black hole masses (on average M$_{BH}$ ~ 4.6 x 10$^9$ M$_{\odot}$) and accretion rates (with Eddington ratios ranging between 0.1 and 1.0) are broadly consistent with that of similarly luminous 0.3 < z < 2.3 quasars, but there is evidence for a mild increase in the median Eddington ratio going towards z > 6. Combined with deep ALMA observations of the [CII] 158 $\mu$m line from the quasar host galaxies and VLT/MUSE investigations of the extended Ly$\alpha$ halos, this study provides fundamental clues to models of the formation and growth of the first massive galaxies and black holes. Compared to local scaling relations, z > 5.7 black holes appear to be over-massive with respect to their host galaxies, and their accretion properties do not change with host galaxy morphology. Under the assumption that the kinematics of the T ~ 10$^4$ K gas, traced by the extended Ly$\alpha$ halos, are dominated by the gravitational potential of the dark matter halo, we report a similar relation between the black hole mass and circular velocity to the one reported for z ~ 0 galaxies. These results paint a picture where the first supermassive black holes reside in massive halos at z > 6 and lead the first stages of galaxy formation by rapidly growing in mass with a duty cycle of order unity. However, this duty cycle needs to drastically drop towards lower redshifts, while the host galaxies continue forming stars at a rate of hundreds of solar masses per year, sustained by the large reservoirs of cool gas surrounding them. 	
"No self-shadowing instability in 2D radiation-hydrodynamical models of
  irradiated protoplanetary disks"	http://arxiv.org/abs/2207.05106v1	2022-07-11T18:00:34Z	2022-07-11T18:00:34Z	  Theoretical models of protoplanetary disks including stellar irradiation often show a spontaneous amplification of scale height perturbations, produced by the enhanced absorption of starlight in enlarged regions. In turn, such regions cast shadows on adjacent zones that consequently cool down and shrink, eventually leading to an alternating pattern of overheated and shadowed regions. Previous investigations have proposed this to be a real self-sustained process, the so-called self-shadowing or thermal wave instability, which could naturally form frequently observed disk structures such as rings and gaps, and even potentially enhance the formation of planetesimals. All of these, however, have assumed in one way or another vertical hydrostatic equilibrium and instantaneous radiative diffusion throughout the disk. In this work we present the first study of the stability of accretion disks to self-shadowing that relaxes these assumptions, relying instead on radiation-hydrodynamical simulations. We first construct hydrostatic disk configurations by means of an iterative procedure and show that the formation of a pattern of enlarged and shadowed regions is a direct consequence of assuming instantaneous radiative diffusion. We then let these solutions evolve in time, which leads to a fast damping of the initial shadowing features in layers close to the disk surface. These thermally relaxed layers grow towards the midplane until all temperature extrema in the radial direction are erased in the entire disk. Our results suggest that radiative cooling and gas advection at the disk surface prevent a self-shadowing instability from forming, by damping temperature perturbations before these reach lower, optically thick regions. 	
"Statistical Detection of Adversarial examples in Blockchain-based
  Federated Forest In-vehicle Network Intrusion Detection Systems"	http://arxiv.org/abs/2207.04843v1	2022-07-11T13:17:38Z	2022-07-11T13:17:38Z	  The internet-of-Vehicle (IoV) can facilitate seamless connectivity between connected vehicles (CV), autonomous vehicles (AV), and other IoV entities. Intrusion Detection Systems (IDSs) for IoV networks can rely on machine learning (ML) to protect the in-vehicle network from cyber-attacks. Blockchain-based Federated Forests (BFFs) could be used to train ML models based on data from IoV entities while protecting the confidentiality of the data and reducing the risks of tampering with the data. However, ML models created this way are still vulnerable to evasion, poisoning, and exploratory attacks using adversarial examples. This paper investigates the impact of various possible adversarial examples on the BFF-IDS. We proposed integrating a statistical detector to detect and extract unknown adversarial samples. By including the unknown detected samples into the dataset of the detector, we augment the BFF-IDS with an additional model to detect original known attacks and the new adversarial inputs. The statistical adversarial detector confidently detected adversarial examples at the sample size of 50 and 100 input samples. Furthermore, the augmented BFF-IDS (BFF-IDS(AUG)) successfully mitigates the adversarial examples with more than 96% accuracy. With this approach, the model will continue to be augmented in a sandbox whenever an adversarial sample is detected and subsequently adopt the BFF-IDS(AUG) as the active security model. Consequently, the proposed integration of the statistical adversarial detector and the subsequent augmentation of the BFF-IDS with detected adversarial samples provides a sustainable security framework against adversarial examples and other unknown attacks. 	
"A Baselined Gated Attention Recurrent Network for Request Prediction in
  Ridesharing"	http://arxiv.org/abs/2207.04709v2	2022-09-05T12:49:15Z	2022-07-11T08:41:24Z	  Ridesharing has received global popularity due to its convenience and cost efficiency for both drivers and passengers and its strong potential to contribute to the implementation of the UN Sustainable Development Goals. As a result, recent years have witnessed an explosion of research interest in the RSODP (Origin-Destination Prediction for Ridesharing) problem with the goal of predicting the future ridesharing requests and providing schedules for vehicles ahead of time. Most of the existing prediction models utilise Deep Learning. However, they fail to effectively consider both spatial and temporal dynamics. In this paper the Baselined Gated Attention Recurrent Network (BGARN), is proposed, which uses graph convolution with multi-head gated attention to extract spatial features, a recurrent module to extract temporal features, and a baselined transferring layer to calculate the final results. The model is implemented with PyTorch and DGL (Deep Graph Library) and is experimentally evaluated using the New York Taxi Demand Dataset. The results show that BGARN outperforms all the other existing models in terms of prediction accuracy. 	
Performance Bounds for Cooperative Localisation in the Starlink Network	http://arxiv.org/abs/2207.04691v1	2022-07-11T08:12:45Z	2022-07-11T08:12:45Z	  Mega-constellations in Low Earth Orbit have the potential to revolutionise worldwide internet access. The concomitant potential of these mega-constellations to impact space sustainability, however, has prompted concern from space actors as well as provoking concern in the ground-based astronomy community. Increasing the knowledge of the orbital state of satellites in mega-constellations improves space situations awareness, reducing the need for collision avoidance manoeuvres and allowing astronomers to prepare better observational mitigation strategies. In this paper, we create a model of Phase 1 of Starlink, one of the more well-studied megaconstellations, and investigate the potential of cooperative localisation using time-ofarrival measurements from the optical inter-satellite links in the constellation. To this end, we study the performance of any unbiased estimator for localisation, by calculating the instantaneous Cram$\acute{\text{e}}$r-Rao bound for two situations; one in which inter-satellite measurements and measurements from ground stations were considered, and one in which only relative navigation from inter-satellite measurements were considered. Our results show that localisation determined from a combination of inter-satellite measurements and ground stations can have at best an an average RMSE of approximately 10.15 metres over the majority of a satellite's orbit. Relative localisation using only inter-satellite measurements has a slightly poorer performance with an average RMSE of 10.68 metres. The results show that both anchored and anchorless inter-satellite cooperative localisation are dependent on the constellation's geometry and the characteristics of the inter-satellite links, both of which could inform the use of relative navigation in large satellite constellations in future. 	
"A Systematic Review and Thematic Analysis of Community-Collaborative
  Approaches to Computing Research"	http://arxiv.org/abs/2207.04171v1	2022-07-09T01:38:15Z	2022-07-09T01:38:15Z	  HCI researchers have been gradually shifting attention from individual users to communities when engaging in research, design, and system development. However, our field has yet to establish a cohesive, systematic understanding of the challenges, benefits, and commitments of community-collaborative approaches to research. We conducted a systematic review and thematic analysis of 47 computing research papers discussing participatory research with communities for the development of technological artifacts and systems, published over the last two decades. From this review, we identified seven themes associated with the evolution of a project: from establishing community partnerships to sustaining results. Our findings suggest that several tensions characterize these projects, many of which relate to the power and position of researchers, and the computing research environment, relative to community partners. We discuss the implications of our findings and offer methodological proposals to guide HCI, and computing research more broadly, towards practices that center communities. 	
Spatial Econometrics for Misaligned Data	http://arxiv.org/abs/2207.04082v1	2022-07-08T18:12:50Z	2022-07-08T18:12:50Z	  We produce methodology for regression analysis when the geographic locations of the independent and dependent variables do not coincide, in which case we speak of misaligned data. We develop and investigate two complementary methods for regression analysis with misaligned data that circumvent the need to estimate or specify the covariance of the regression errors. We carry out a detailed reanalysis of Maccini and Yang (2009) and find economically significant quantitative differences but sustain most qualitative conclusions. 	
"MeerKAT radio observations of the neutron star low-mass X-ray binary Cen
  X-4 at low accretion rates"	http://arxiv.org/abs/2207.03962v2	2022-08-22T14:43:19Z	2022-07-08T15:29:09Z	  Centaurus X-4 (Cen X-4) is a relatively nearby neutron star low-mass X-ray binary that showed outbursts in 1969 and 1979, but has not shown a full outburst since. Due to its proximity and sustained period of quiescence, it is a prime target to study the coupling between accretion and jet ejection in quiescent neutron star low-mass X-ray binaries. Here, we present four MeerKAT radio observations at 1.3 GHz of Cen X-4, combined with NICER and Swift X-ray monitoring. During the first and most sensitive observation, Cen X-4 was in a fully quiescent X-ray state. The three later and shorter observations targeted a brief period of faint X-ray activity in January 2021, which has been referred to as a 'mis-fired' outburst. Cen X-4 is not detected in any of the four MeerKAT observations. We place these radio non-detections on the X-ray -- radio luminosity diagram, improving the constraints on the correlation between the two luminosities from earlier quiescent radio studies. We confirm that Cen X-4 is radio fainter than the transitional milli-second pulsar PSR J1023+0038 at the same X-ray luminosity. We discuss the radio behaviour of accreting neutron stars at low X-ray luminosity more generally and finally comment on future observing campaigns. 	
"Sensemaking and Scientific Modeling: Intertwined processes analyzed in
  the context of physics problem solving"	http://arxiv.org/abs/2207.03939v3	2023-01-27T22:37:15Z	2022-07-08T14:44:53Z	  Researchers in physics education have advocated both for including modeling in science classrooms as well as promoting student engagement with sensemaking. These two processes facilitate the generation of new knowledge by connecting to one's existing ideas. Despite being two distinct processes, modeling is often described as sensemaking of the physical world. In the current work, we provide an explicit, framework-based analysis of the intertwining between modeling and sensemaking by analyzing think-aloud interviews of two students solving a physics problem. While one student completes the task, the other abandons their approach. The case studies reveal that particular aspects of modeling and sensemaking processes co-occur. For instance, the priming on the `given' information from the problem statement constituted the students' engagement with their mental models, and their attempts to resolve inconsistencies in understanding involved the use of external representations. We find that barriers experienced in modeling can inhibit students' sustained sensemaking. These results suggest ways for future research to support students' sensemaking in physics by promoting modeling practices. 	
The Dirty Secret of SSDs: Embodied Carbon	http://arxiv.org/abs/2207.10793v1	2022-07-08T12:45:11Z	2022-07-08T12:45:11Z	  Scalable Solid-State Drives (SSDs) have revolutionized the way we store and access our data across datacenters and handheld devices. Unfortunately, scaling technology can have a significant environmental impact. Across the globe, most semiconductor manufacturing use electricity that is generated from coal and natural gas. For instance, manufacturing a Gigabyte of Flash emits 0.16 Kg CO$_2$ and is a significant fraction of the total carbon emission in the system. We estimate that manufacturing storage devices has resulted in 20 million metric tonnes of CO$_2$ emissions in 2021 alone. To better understand this concern, this paper compares the sustainability trade-offs between Hard Disk Drives (HDDs) and SSDs and recommends methodologies to estimate the embodied carbon costs of the storage system. In this paper, we outline four possible strategies to make storage systems sustainable. First, this paper recommends directions that help select the right medium of storage (SSD vs HDD). Second, this paper proposes lifetime extension techniques for SSDs. Third, this paper advocates for effective and efficient recycling and reuse of high-density multi-level cell-based SSDs. Fourth, specifically for hand-held devices, this paper recommends leveraging elasticity in cloud storage. 	
"Performance Analysis of Vibrotactile and Slide-and-Squeeze Haptic
  Feedback Devices for Limbs Postural Adjustment"	http://arxiv.org/abs/2207.03787v1	2022-07-08T09:40:32Z	2022-07-08T09:40:32Z	  Recurrent or sustained awkward body postures are among the most frequently cited risk factors to the development of work-related musculoskeletal disorders (MSDs). To prevent workers from adopting harmful configurations but also to guide them toward more ergonomic ones, wearable haptic devices may be the ideal solution. In this paper, a vibrotactile unit, called ErgoTac, and a slide-and-squeeze unit, called CUFF, were evaluated in a limbs postural correction setting. Their capability of providing single-joint (shoulder or knee) and multi-joint (shoulder and knee at once) guidance was compared in twelve healthy subjects, using quantitative task-related metrics and subjective quantitative evaluation. An integrated environment was also built to ease communication and data sharing between the involved sensor and feedback systems. Results show good acceptability and intuitiveness for both devices. ErgoTac appeared as the suitable feedback device for the shoulder, while the CUFF may be the effective solution for the knee. This comparative study, although preliminary, was propaedeutic to the potential integration of the two devices for effective whole-body postural corrections, with the aim to develop a feedback and assistive apparatus to increase workers' awareness about risky working conditions and therefore to prevent MSDs. 	
"Bayesian Hyperparameter Optimization for Deep Neural Network-Based
  Network Intrusion Detection"	http://arxiv.org/abs/2207.09902v1	2022-07-07T20:08:38Z	2022-07-07T20:08:38Z	  Traditional network intrusion detection approaches encounter feasibility and sustainability issues to combat modern, sophisticated, and unpredictable security attacks. Deep neural networks (DNN) have been successfully applied for intrusion detection problems. The optimal use of DNN-based classifiers requires careful tuning of the hyper-parameters. Manually tuning the hyperparameters is tedious, time-consuming, and computationally expensive. Hence, there is a need for an automatic technique to find optimal hyperparameters for the best use of DNN in intrusion detection. This paper proposes a novel Bayesian optimization-based framework for the automatic optimization of hyperparameters, ensuring the best DNN architecture. We evaluated the performance of the proposed framework on NSL-KDD, a benchmark dataset for network intrusion detection. The experimental results show the framework's effectiveness as the resultant DNN architecture demonstrates significantly higher intrusion detection performance than the random search optimization-based approach in terms of accuracy, precision, recall, and f1-score. 	
"Cooperative Backscatter NOMA with Imperfect SIC: Towards Energy
  Efficient Sum Rate Maximization in Sustainable 6G Networks"	http://arxiv.org/abs/2207.03295v1	2022-07-07T13:43:22Z	2022-07-07T13:43:22Z	  The combination of backscatter communication with non-orthogonal multiple access (NOMA) has the potential to support low-powered massive connections in upcoming sixth-generation (6G) wireless networks. More specifically, backscatter communication can harvest and use the existing RF signals in the atmosphere for communication, while NOMA provides communication to multiple wireless devices over the same frequency and time resources. This paper has proposed a new resource management framework for backscatter-aided cooperative NOMA communication in upcoming 6G networks. In particular, the proposed work has simultaneously optimized the base station's transmit power, relaying node, the reflection coefficient of the backscatter tag, and time allocation under imperfect successive interference cancellation to maximize the sum rate of the system. To obtain an efficient solution for the resource management framework, we have proposed a combination of the bisection method and dual theory, where the sub-gradient method is adopted to optimize the Lagrangian multipliers. Numerical results have shown that the proposed solution provides excellent performance. When the performance of the proposed technique is compared to a brute-forcing search technique that guarantees optimal solution however, is very time-consuming, it was seen that the gap in performance is actually 0\%. Hence, the proposed framework has provided performance equal to a cumbersome brute-force search technique while offering much less complexity. The works in the literature on cooperative NOMA considered equal time distribution for cooperation and direct communication. Our results showed that optimizing the time-division can increase the performance by more than 110\% for high transmission powers. 	
gym-DSSAT: a crop model turned into a Reinforcement Learning environment	http://arxiv.org/abs/2207.03270v4	2022-09-27T12:05:28Z	2022-07-07T12:45:02Z	  Addressing a real world sequential decision problem with Reinforcement Learning (RL) usually starts with the use of a simulated environment that mimics real conditions. We present a novel open source RL environment for realistic crop management tasks. gym-DSSAT is a gym interface to the Decision Support System for Agrotechnology Transfer (DSSAT), a high fidelity crop simulator. DSSAT has been developped over the last 30 years and is widely recognized by agronomists. gym-DSSAT comes with predefined simulations based on real world maize experiments. The environment is as easy to use as any gym environment. We provide performance baselines using basic RL algorithms. We also briefly outline how the monolithic DSSAT simulator written in Fortran has been turned into a Python RL environment. Our methodology is generic and may be applied to similar simulators. We report on very preliminary experimental results which suggest that RL can help researchers to improve sustainability of fertilization and irrigation practices. 	
"Participatory Design Landscape for the Human-Machine Collaboration,
  Interaction and Automation at the Frontiers of HCI (PDL 2021)"	http://arxiv.org/abs/2207.03217v1	2022-07-07T10:44:14Z	2022-07-07T10:44:14Z	  We propose a one-day transdisciplinary creative workshop in the broad area of HCI focused on multiple opportunities of incorporating participatory design into research and industry practice. This workshop will become a venue to share experiences and novel ideas in this area. At the same time, we will brainstorm and explore frontiers of HCI related to engaging end users in design and development practices of established and emerging ICT solutions often overlooked in terms of co-design. We welcome a wide scope of contributions in HCI which explore sustainable opportunities for participatory design and development practices in the context of interconnected business, social, economic and environmental issues. The contributions ought to explore challenges and opportunities related to co-design at the frontiers of HCI - participatory design of newest and complex technologies, not easily explainable or intuitive, novel collaborative (remote or distributed) approaches to empowering users to prepare them to contribute as well as to engaging them directly in co-design. 	
"A scaling model for measuring the morphology of African cities:
  Implications for future energy needs"	http://arxiv.org/abs/2207.03003v2	2022-08-11T13:28:01Z	2022-07-06T22:35:59Z	  A large proportion of Africa's infrastructure is yet to be built. Where and how these new buildings are constructed matters since today's decisions will last for decades. The resulting morphology of cities has lasting implications for a city's energy needs. Estimating and projecting these needs has always been challenging in Africa due to the lack of data. Yet, given the sweeping urbanisation expected in Africa over the next three decades, this obstacle must be overcome to guide cities towards a trajectory of sustainability and resilience. Based on the location and surface of nearly 200 million buildings on the continent, we estimate the inter-building distance of almost six thousand cities. Buildings' footprint data enables the construction of urban form indicators to compare African cities' elongation, sprawl and emptiness. We establish the BASE model, where the mean distance between buildings is a functional relation to the number of Buildings and their average Area, as well as the Sprawl and the Elongation of its spatial arrangement. The mean distance between structures in cities -- our proxy for its energy demands related to mobility -- grows faster than the square root of its population, resulting from the combined impact of a sublinear growth in the number of buildings and a sublinear increase in building size and sprawl. We show that when a city doubles its population, it triples the energy demand related to commutes. 	
"Cascaded Deep Hybrid Models for Multistep Household Energy Consumption
  Forecasting"	http://arxiv.org/abs/2207.02589v2	2022-10-13T17:54:39Z	2022-07-06T11:02:23Z	  Sustainability requires increased energy efficiency with minimal waste. The future power systems should thus provide high levels of flexibility iin controling energy consumption. Precise projections of future energy demand/load at the aggregate and on the individual site levels are of great importance for decision makers and professionals in the energy industry. Forecasting energy loads has become more advantageous for energy providers and customers, allowing them to establish an efficient production strategy to satisfy demand. This study introduces two hybrid cascaded models for forecasting multistep household power consumption in different resolutions. The first model integrates Stationary Wavelet Transform (SWT), as an efficient signal preprocessing technique, with Convolutional Neural Networks and Long Short Term Memory (LSTM). The second hybrid model combines SWT with a self-attention based neural network architecture named transformer. The major constraint of using time-frequency analysis methods such as SWT in multistep energy forecasting problems is that they require sequential signals, making signal reconstruction problematic in multistep forecasting applications.The cascaded models can efficiently address this problem through using the recursive outputs. Experimental results show that the proposed hybrid models achieve superior prediction performance compared to the existing multistep power consumption prediction methods. The results will pave the way for more accurate and reliable forecasting of household power consumption. 	
5/6G: Networks of the Future or Defuturing Networks?	http://arxiv.org/abs/2207.02533v1	2022-07-06T09:22:51Z	2022-07-06T09:22:51Z	  Energy efficiency is at the core of sustainability solutions for 5/6G networks. We argue this is a too narrow perspective on sustainability, as it ignores the effects of the increased traffic demand these networks stimulate and the need for additional equipment that this demand requires. The hope is that techniques to reduce the network's energy consumption in operation will be able to compensate for increases in traffic demand. However, there are more challenges than just reducing the energy that the network requires to function and it is not clear whether higher energy efficiency will be able to cope with increasing demand. The need for more equipment related to deployment of 5/6G networks may result in important environmental impacts: i) increased pressures on material extraction, which imply socio-environmental conflicts, ecosystem destruction and displacement, ii) more manufacturing and shipment, with effects on greenhouse gas emissions and pollution; iii) increased disposal complexities and challenges to recycle components of such equipments. By extending our view on sustainability to include the aforementioned often ignored implications, we are able to identify design requirements and technical pillars of 5/6G networks that need to be rethought. We also devise new paths forward to address these challenges. We argue that it is crucial to think of alternative applications and requirements that aim to serve user demands explicitly, instead of incessantly creating new needs. We also claim that acknowledging material limitations in the production of new hardware is critical, promoting retrofitting and modular design in future network development. The conclusions of this article show that it is time to start rethinking the course of mobile network development in order to align it to current environmental objectives to tackle the climate emergency the world is experiencing. 	
The Development of Energy-Recovery Linacs	http://arxiv.org/abs/2207.02095v2	2022-09-27T12:39:54Z	2022-07-05T14:56:58Z	  Energy-recovery linacs (ERLs) have been emphasised by the recent (2020) update of the European Strategy for Particle Physics as one of the most promising technologies for the accelerator base of future high-energy physics. The current paper has been written as a base document to support and specify details of the recently published European roadmap for the development of energy-recovery linacs. The paper summarises the previous achievements on ERLs and the status of the field and its basic technology items. The main possible future contributions and applications of ERLs to particle and nuclear physics as well as industrial developments are presented. The paper includes a vision for the further future, beyond 2030, as well as a comparative data base for the main existing and forthcoming ERL facilities. A series of continuous innovations, such as on intense electron sources or high-quality superconducting cavity technology, will massively contribute to the development of accelerator physics at large. Industrial applications are potentially revolutionary and may carry the development of ERLs much further, establishing another shining example of the impact of particle physics on society and its technical foundation with a special view on sustaining nature. 	
"How sustainable is ""common"" data science in terms of power consumption?"	http://arxiv.org/abs/2207.01934v1	2022-07-05T10:15:22Z	2022-07-05T10:15:22Z	"  Continuous developments in data science have brought forth an exponential increase in complexity of machine learning models. Additionally, data scientists have become ubiquitous in the private market, academic environments and even as a hobby. All of these trends are on a steady rise, and are associated with an increase in power consumption and associated carbon footprint. The increasing carbon footprint of large-scale advanced data science has already received attention, but the latter trend has not. This work aims to estimate the contribution of the increasingly popular ""common"" data science to the global carbon footprint. To this end, the power consumption of several typical tasks in the aforementioned common data science tasks will be measured and compared to: large-scale ""advanced"" data science, common computer-related tasks, and everyday non-computer related tasks. This is done by converting the measurements to the equivalent unit of ""km driven by car"". Our main findings are: ""common"" data science consumes $2.57$ more power than regular computer usage, but less than some common everyday power-consuming tasks such as lighting or heating; large-scale data science consumes substantially more power than common data science. "	
Operando Methods and Probes for Battery Electrodes and Materials	http://arxiv.org/abs/2207.12098v1	2022-07-04T21:40:25Z	2022-07-04T21:40:25Z	  With the importance of Li-ion and emerging alternative batteries to our electric future, predicting new sustainable materials, electrolytes and complete cells that safely provide high performance, long life, energy dense capability is critically important. Understanding interface, microstructure of materials, the nature of electrolytes and factors that affect or limit long term performance are key to new battery chemistries, cell form factors and alternative materials. The electrochemical processes which cause these changes are also difficult to probe because of their metastability and lifetimes, which can be of nanosecond to sub nanosecond time domains. Consequently, developing and adapting high-resolution, non-destructive methods to capture these processes proves challenging, requiring state-of-the-art techniques.Recent progress is very promising, where optical spectroscopies, synchrotron radiation techniques, and energy-specific atom probe tomography and microscopy methods are just some of the approaches that are unravelling the true internal behaviour of battery cells in real-time.In this review, we overview many of the most promising non-destructive methods developed in recent years to assess battery material properties, interfaces, processes,and reactions under operando conditions in electrodes and full cells. 	
"Intelligent Exploration of Solution Spaces Exemplified by Industrial
  Reconfiguration Management"	http://arxiv.org/abs/2207.01693v1	2022-07-04T19:45:48Z	2022-07-04T19:45:48Z	  Many decision-making approaches rely on the exploration of solution spaces with regards to specified criteria. However, in complex environments, brute-force exploration strategies are usually not feasible. As an alternative, we propose the combination of an exploration task's vertical sub-division into layers representing different sequentially interdependent sub-problems of the paramount problem and a horizontal sub-division into self-sustained solution sub-spaces. In this paper, we present a universal methodology for the intelligent exploration of solution spaces and derive a use-case specific example from the field of reconfiguration management in industry 4.0. 	
"Time-consistent pension policy with minimum guarantee and sustainability
  constraint"	http://arxiv.org/abs/2207.01536v1	2022-07-04T15:54:39Z	2022-07-04T15:54:39Z	  This paper proposes and investigates an optimal pair investment/pension policy for a pay-as-you-go (PAYG) pension scheme. The social planner can invest in a buffer fund in order to guarantee a minimal pension amount. The model aims at taking into account complex dynamic phenomena such as the demographic risk and its evolution over time, the time and age dependence of agents preferences, and financial risks. The preference criterion of the social planner is modeled by a consistent dynamic utility defined on a stochastic domain, which incorporates the heterogeneity of overlapping generations and its evolution over time. The preference criterion and the optimization problem also incorporate sustainability, adequacy and fairness constraints. The paper designs and solves the social planner's dynamic decision criterion, and computes the optimal investment/pension policy in a general framework. A detailed analysis for the case of dynamic power utilities is provided. 	
"Analysis of public transport (in)accessibility and land-use pattern in
  different areas in Singapore"	http://arxiv.org/abs/2207.01445v1	2022-07-04T14:32:47Z	2022-07-04T14:32:47Z	  As more and more people continue to live in highly urbanised areas across the globe, reliable accessibility to amenities and services plays a vital role in sustainable development. One of the challenges in addressing this issue is the consistent and equal provision of public services, including transport for residents across the urban system. In this study, using a novel computational method combining geometrical analysis and information-theoretic measures, we analyse the accessibility to public transport in terms of the spatial coverage of the transport nodes (stops) and the quality of service at these nodes across different areas. Furthermore, using a network clustering procedure, we also characterise the land-use pattern of those areas and relate that to their public transport accessibility. Using Singapore as a case study, we find that the commercial areas in the CBD area expectedly have excellent accessibility and the residential areas also have good to very good accessibility. However, not every residential area is equally accessible. While the spatial coverage of stops in these areas is very good, the quality of service indicates substantial variation among different regions, with high contrast between the central and eastern areas compared to the others in the west and north of the city-state. We believe this kind of analysis could yield a good understanding of the current level of public transport services across the urban system, and their disparity will provide valuable and actionable insights into the future development plans. 	
Using contextual sentence analysis models to recognize ESG concepts	http://arxiv.org/abs/2207.01402v1	2022-07-04T13:33:21Z	2022-07-04T13:33:21Z	  This paper summarizes the joint participation of the Trading Central Labs and the L3i laboratory of the University of La Rochelle on both sub-tasks of the Shared Task FinSim-4 evaluation campaign. The first sub-task aims to enrich the 'Fortia ESG taxonomy' with new lexicon entries while the second one aims to classify sentences to either 'sustainable' or 'unsustainable' with respect to ESG (Environment, Social and Governance) related factors. For the first sub-task, we proposed a model based on pre-trained Sentence-BERT models to project sentences and concepts in a common space in order to better represent ESG concepts. The official task results show that our system yields a significant performance improvement compared to the baseline and outperforms all other submissions on the first sub-task. For the second sub-task, we combine the RoBERTa model with a feed-forward multi-layer perceptron in order to extract the context of sentences and classify them. Our model achieved high accuracy scores (over 92%) and was ranked among the top 5 systems. 	
Sustainable AI Processing at the Edge	http://arxiv.org/abs/2207.01209v1	2022-07-04T05:32:12Z	2022-07-04T05:32:12Z	  Edge computing is a popular target for accelerating machine learning algorithms supporting mobile devices without requiring the communication latencies to handle them in the cloud. Edge deployments of machine learning primarily consider traditional concerns such as SWaP constraints (Size, Weight, and Power) for their installations. However, such metrics are not entirely sufficient to consider environmental impacts from computing given the significant contributions from embodied energy and carbon. In this paper we explore the tradeoffs of convolutional neural network acceleration engines for both inference and on-line training. In particular, we explore the use of processing-in-memory (PIM) approaches, mobile GPU accelerators, and recently released FPGAs, and compare them with novel Racetrack memory PIM. Replacing PIM-enabled DDR3 with Racetrack memory PIM can recover its embodied energy as quickly as 1 year. For high activity ratios, mobile GPUs can be more sustainable but have higher embodied energy to overcome compared to PIM-enabled Racetrack memory. 	
"How Robust is Your Fairness? Evaluating and Sustaining Fairness under
  Unseen Distribution Shifts"	http://arxiv.org/abs/2207.01168v1	2022-07-04T02:37:50Z	2022-07-04T02:37:50Z	  Increasing concerns have been raised on deep learning fairness in recent years. Existing fairness-aware machine learning methods mainly focus on the fairness of in-distribution data. However, in real-world applications, it is common to have distribution shift between the training and test data. In this paper, we first show that the fairness achieved by existing methods can be easily broken by slight distribution shifts. To solve this problem, we propose a novel fairness learning method termed CUrvature MAtching (CUMA), which can achieve robust fairness generalizable to unseen domains with unknown distributional shifts. Specifically, CUMA enforces the model to have similar generalization ability on the majority and minority groups, by matching the loss curvature distributions of the two groups. We evaluate our method on three popular fairness datasets. Compared with existing methods, CUMA achieves superior fairness under unseen distribution shifts, without sacrificing either the overall accuracy or the in-distribution fairness. 	
"A multi-objective sustainable planning for a real hazardous waste
  production problem"	http://arxiv.org/abs/2207.01043v1	2022-07-03T13:40:52Z	2022-07-03T13:40:52Z	  A significant amount of hazardous waste generated from health sectors and industrial processes has posed a major threat to human health by causing environmental issues and contamination of air, soil, and water resources. This paper presents a multi-objective mixed-integer nonlinear programming (MINLP) formulation for a sustainable hazardous waste location-routing problem. The location of the facilities and routing decisions for transporting hazardous waste and the waste residue is considered to design a suitable waste collection system. The presented model simultaneously minimizes the total costs of the waste management system, total risks from transportation and facilities, along with CO2 emissions. A real-world case study is presented to illustrate the applicability of the proposed model. To illustrate the significance of sustainability, the results of the original model are compared with the results of the model without considering sustainability. It indicates that, under the condition when sustainability is not taken into account, total cost, transportation, and site risk along with CO2 emission increased, which in turn demonstrated the importance of sustainability. Furthermore, the managerial insights gained from the optimal results would enable the managers to make better decisions in the hazardous waste management system. 	
Personal Investigator: a Therapeutic 3D Game for Teenagers	http://arxiv.org/abs/2207.02310v1	2022-07-03T12:15:10Z	2022-07-03T12:15:10Z	  This position paper describes the implementation and initial findings of a game called Personal Investigator (PI). PI is an online 3D detective game that implements a model of Brief Solution Focused Therapy (BSFT). It aims to help teenagers overcome mental health problems and engage with traditional mental health care services. It is predicted that the combination of goal-oriented gaming with a model of goal-oriented therapy will help to attract and sustain the interest of teenagers, a group that therapists often have difficulty engaging with. PI is the first game to integrate this established psychotherapy approach into an engaging online 3D game. 	
"Using Self Determination Theory to Design to Support Young Peoples
  Online Help-Seeking"	http://arxiv.org/abs/2207.02299v1	2022-07-03T11:58:29Z	2022-07-03T11:58:29Z	  The application of Self-Determination Theory to understand online help-seeking and the design of online help-seeking technologies presents an interesting avenue for investigation. Improving motivation to engage in the help-seeking process could be achieved using the Basic Psychological Needs Theory as a structure to guide the design of online help-seeking technologies and online mental health resources. Positive online help-seeking experiences have an important role to play in sustained help-seeking and improved health outcomes. 	
"UTD-Yolov5: A Real-time Underwater Targets Detection Method based on
  Attention Improved YOLOv5"	http://arxiv.org/abs/2207.00837v1	2022-07-02T14:09:08Z	2022-07-02T14:09:08Z	  As the treasure house of nature, the ocean contains abundant resources. But the coral reefs, which are crucial to the sustainable development of marine life, are facing a huge crisis because of the existence of COTS and other organisms. The protection of society through manual labor is limited and inefficient. The unpredictable nature of the marine environment also makes manual operations risky. The use of robots for underwater operations has become a trend. However, the underwater image acquisition has defects such as weak light, low resolution, and many interferences, while the existing target detection algorithms are not effective. Based on this, we propose an underwater target detection algorithm based on Attention Improved YOLOv5, called UTD-Yolov5. It can quickly and efficiently detect COTS, which in turn provides a prerequisite for complex underwater operations. We adjusted the original network architecture of YOLOv5 in multiple stages, including: replacing the original Backbone with a two-stage cascaded CSP (CSP2); introducing the visual channel attention mechanism module SE; designing random anchor box similarity calculation method etc. These operations enable UTD-Yolov5 to detect more flexibly and capture features more accurately. In order to make the network more efficient, we also propose optimization methods such as WBF and iterative refinement mechanism. This paper conducts a lot of experiments based on the CSIRO dataset [1]. The results show that the average accuracy of our UTD-Yolov5 reaches 78.54%, which is a great improvement compared to the baseline. 	
"Economic Consequences of the COVID-19 Pandemic on Sub-Saharan Africa: A
  historical perspective"	http://arxiv.org/abs/2207.00666v1	2022-07-01T21:35:26Z	2022-07-01T21:35:26Z	  This paper examined the economic consequences of the COVID-19 pandemic on sub-Saharan Africa (SSA) using the historical approach and analysing the policy responses of the region to past crises and their economic consequences. The study employed the manufacturing-value-added share of GDP as a performance indicator. The analysis shows that the wrong policy interventions to past crises led the sub-Saharan African sub-region into its deplorable economic situation. The study observed that the region leapfrogged prematurely to import substitution, export promotion, and global value chains. Based on these experiences, the region should adopt a gradual approach in responding to the COVID-19 economic consequences. The sub-region should first address relevant areas of sustainability, including proactive investment in research and development to develop homegrown technology, upgrade essential infrastructural facilities, develop security infrastructure, and strengthen the financial sector. 	
Lifetime of the Outer Solar System Nebula From Carbonaceous Chondrites	http://arxiv.org/abs/2207.00649v1	2022-07-01T20:10:50Z	2022-07-01T20:10:50Z	  The evolution and lifetime of protoplanetary disks (PPDs) play a central role in the formation and architecture of planetary systems. Astronomical observations suggest that PPDs evolve in two timescales, accreting onto the star for up to several million years (Myr) followed by gas dissipation within <1 Myr. Because solar nebula magnetic fields are sustained by the gas of the protoplanetary disk, we can use paleomagnetic measurements to infer the lifetime of the solar nebula. Here, we use paleomagnetic measurements of meteorites to constrain this lifetime and investigate whether the solar nebula had a two-timescale evolution. We report on paleomagnetic measurements of bulk subsamples of two CO carbonaceous chondrites: Allan Hills A77307 and Dominion Range 08006. If magnetite in these meteorites can acquire a crystallization remanent magnetization that recorded the ambient field during aqueous alteration, our measurements suggest that the local magnetic field strength at the CO parent body location was <0.9 \muT at some time between 2.7 and 5.1 Myr after the formation of calcium-aluminum-rich inclusions. Coupled with previous paleomagnetic studies, we conclude that the dissipation of the solar nebula in the 3-7 AU region occurred <1.5 Myr after the dissipation of the nebula in the 1-3 AU region, suggesting that protoplanetary disks go through a two-timescale evolution in their lifetime, consistent with dissipation by photoevaporation and/or magnetohydrodynamic winds. We also discuss future directions necessary to obtain robust records of solar nebula fields using bulk chondrites, including obtaining ages from meteorites and experimental work to determine how magnetite acquires magnetization during chondrite parent body alteration. 	
"Vacillating about media bias: changing one's mind intermittently within
  a network of political allies and opponents"	http://arxiv.org/abs/2207.00372v1	2022-07-01T12:18:01Z	2022-07-01T12:18:01Z	  One form of long-term behavior revealed by opinion dynamics simulations is intermittency, where an individual cycles between eras of stable, constant beliefs and turbulent, fluctuating beliefs, for example when inferring the political bias of a media organization. We explore this phenomenon by building an idealized network of Bayesian learners, who infer the bias of a coin from observations of coin tosses and peer pressure from political allies and opponents. Numerical simulations reveal that three types of network structure lead to three different types of intermittency, which are caused by agents ``locking out'' opponents from sure beliefs in specific ways. The probability density functions of the dwell times, over which the learners sustain stable or turbulent beliefs, differ across the three types of intermittency. Hence, one can observe the dwell times of a learner to infer the underlying network structure, at least in principle. 	
Sustainable Computing -- Without the Hot Air	http://arxiv.org/abs/2207.00081v1	2022-06-30T19:48:33Z	2022-06-30T19:48:33Z	  The demand for computing is continuing to grow exponentially. This growth will translate to exponential growth in computing's energy consumption unless improvements in its energy-efficiency can outpace increases in its demand. Yet, after decades of research, further improving energy-efficiency is becoming increasingly challenging, as it is already highly optimized. As a result, at some point, increases in computing demand are likely to outpace increases in its energy-efficiency, potentially by a wide margin. Such exponential growth, if left unchecked, will position computing as a substantial contributor to global carbon emissions. While prominent technology companies have recognized the problem and sought to reduce their carbon emissions, they understandably focus on their successes, which has the potential to inadvertently convey the false impression that this is now, or will soon be, a solved problem. Such false impressions can be counterproductive if they serve to discourage further research in this area, since, as we discuss, eliminating computing's, and more generally society's, carbon emissions is far from a solved problem. To better understand the problem's scope, this paper distills the fundamental trends that determine computing's carbon footprint and their implications for achieving sustainable computing. 	
Measurement-induced nonlocality for observers near a black hole	http://arxiv.org/abs/2206.14787v2	2023-03-09T19:07:38Z	2022-06-29T17:41:49Z	  We present a systematic and complementary study of quantum correlations near a black hole by considering the measurement-induced nonlocality (MIN). The quantum measure of interest is discussed on the same footing for the fermionic, bosonic and mixed fermion-boson modes in relation to the Hawking radiation. The obtained results show that in the infinite Hawking temperature limit, the physically accessible correlations does not vanish only in the fermionic case. However, the higher frequency modes can sustain correlations for the finite Hawking temperature, with mixed system being more sensitive towards increase of the fermionic frequencies than the bosonic ones. Since the MIN for the latter modes quickly diminishes, the increased frequency may be a way to maintain nonlocal correlations for the scenarios at the finite Hawking temperature. 	
"Tailoring of rhenium oxidation state in ReOx thin films during reactive
  HiPIMS deposition process and following annealing"	http://arxiv.org/abs/2206.14665v1	2022-06-29T14:10:29Z	2022-06-29T14:10:29Z	  Bulk rhenium trioxide (ReO3) has an unusually high electrical conductivity and, being nanosized, has promising catalytic properties. However, the production of pure ReO3 thin films is challenging due to the difficulty to stabilize rhenium in a 6+ oxidation state. Here we present a novel approach for the deposition of ReOx (x = 1.6-2.9) thin films using reactive high power impulse magnetron sputtering (r-HiPIMS) from a metallic rhenium target in a mixed Ar/O2 atmosphere. The thin films were deposited in the gas-sustained self-sputtering regime, observed during r-HiPIMS process according to current waveforms. The influence of the substrate temperature, the oxygen-to-argon flow ratio and post-annealing at 250 {\deg}C in the air for 3 h on the properties of the films were studied. The as-deposited films have an X-ray amorphous structure (a-ReOx) when deposited at room temperature while a nano-crystalline \b{eta}-ReO2 phase when deposited at elevated temperatures (150 or 250 {\deg}C). The amorphous a-ReOx can be converted into the crystalline ReO3 with a lattice parameter of 3.75 {\AA} upon annealing in the air. The surface morphology of the films is dense without detectable voids when elevated substrate temperatures are used. Various Re oxidation states are observed on the surface of the films in different ratios depending on the deposition parameters. All samples exhibit electrical resistivity on the order of 10-3 Ohmxcm and optical properties typical for thin metallic films. 	
"Deep Active Visual Attention for Real-time Robot Motion Generation:
  Emergence of Tool-body Assimilation and Adaptive Tool-use"	http://arxiv.org/abs/2206.14530v1	2022-06-29T10:55:32Z	2022-06-29T10:55:32Z	  Sufficiently perceiving the environment is a critical factor in robot motion generation. Although the introduction of deep visual processing models have contributed in extending this ability, existing methods lack in the ability to actively modify what to perceive; humans perform internally during visual cognitive processes. This paper addresses the issue by proposing a novel robot motion generation model, inspired by a human cognitive structure. The model incorporates a state-driven active top-down visual attention module, which acquires attentions that can actively change targets based on task states. We term such attentions as role-based attentions, since the acquired attention directed to targets that shared a coherent role throughout the motion. The model was trained on a robot tool-use task, in which the role-based attentions perceived the robot grippers and tool as identical end-effectors, during object picking and object dragging motions respectively. This is analogous to a biological phenomenon called tool-body assimilation, in which one regards a handled tool as an extension of one's body. The results suggested an improvement of flexibility in model's visual perception, which sustained stable attention and motion even if it was provided with untrained tools or exposed to experimenter's distractions. 	
Dark topological valley Hall edge solitons	http://arxiv.org/abs/2206.14460v1	2022-06-29T08:23:24Z	2022-06-29T08:23:24Z	  Topological edge solitons propagating along the edge of a photonic topological insulator are localized self-sustained hybrid states that are immune to de-fects/disorders due to protection of the edge states stemming from nontrivial topology of the system. Here, we predict that exceptionally robust dark valley Hall edge solitons may form at the domain walls between two honeycomb lattices with broken inversion sym-metry. The underlying structure can be created with femtosecond laser inscription, it possesses large bandgap where well-localized dark edge solitons form, and in contrast to systems with broken time-reversal symmetry, it does not require external magnetic fields or complex longitudinal waveguide modulations for reali-zation of the topological phase. We present the enve-lope equation allowing to construct dark valley Hall edge solitons analytically. Such solitons propagate without radiation into the bulk of the lattice, and can circumvent sharp corners, that allows to observe their persistent circulation along the closed triangular domain wall boundary. They survive over huge distances even in the presence of disorder in the underlying lattice. We also investigate interactions of closely located dark topological valley Hall edge solitons and show that they are repulsive and lead to the formation of two grey edge solitons, moving with different group velocities depart-ing from group velocity of the linear edge state on which initial dark solitons were constructed. Our results illus-trate that nonlinear valley Hall systems can support rich variety of new self-sustained topological states and may inspire their investigation in other nonlinear systems, such as atomic vapours and polariton condensates. 	
"Reducing US Biofuels Requirements Mitigates Short-term Impacts of Global
  Population and Income Growth on Agricultural Environmental Outcomes"	http://arxiv.org/abs/2206.14321v1	2022-06-28T23:12:43Z	2022-06-28T23:12:43Z	  Biobased energy, particularly corn starch-based ethanol and other liquid renewable fuels, are a major element of federal and state energy policies in the United States. These policies are motivated by energy security and climate change mitigation objectives, but corn ethanol does not substantially reduce greenhouse gas emissions when compared to petroleum-based fuels. Corn production also imposes substantial negative externalities (e.g., nitrogen leaching, higher food prices, water scarcity, and indirect land use change). In this paper, we utilize a partial equilibrium model of corn-soy production and trade to analyze the potential of reduced US demand for corn as a biobased energy feedstock to mitigate increases in nitrogen leaching, crop production and land use associated with growing global populations and income from 2020 to 2050. We estimate that a 23% demand reduction would sustain land use and nitrogen leaching below 2020 levels through the year 2025, and a 41% reduction would do so through 2030. Outcomes are similar across major watersheds where corn and soy are intensively farmed. 	
"The Astropy Project: Sustaining and Growing a Community-oriented
  Open-source Project and the Latest Major Release (v5.0) of the Core Package"	http://arxiv.org/abs/2206.14220v1	2022-06-28T18:01:54Z	2022-06-28T18:01:54Z	  The Astropy Project supports and fosters the development of open-source and openly-developed Python packages that provide commonly needed functionality to the astronomical community. A key element of the Astropy Project is the core package $\texttt{astropy}$, which serves as the foundation for more specialized projects and packages. In this article, we summarize key features in the core package as of the recent major release, version 5.0, and provide major updates for the Project. We then discuss supporting a broader ecosystem of interoperable packages, including connections with several astronomical observatories and missions. We also revisit the future outlook of the Astropy Project and the current status of Learn Astropy. We conclude by raising and discussing the current and future challenges facing the Project. 	
"Building Matters: Spatial Variability in Machine Learning Based Thermal
  Comfort Prediction in Winters"	http://arxiv.org/abs/2206.14202v1	2022-06-28T17:07:35Z	2022-06-28T17:07:35Z	  Thermal comfort in indoor environments has an enormous impact on the health, well-being, and performance of occupants. Given the focus on energy efficiency and Internet-of-Things enabled smart buildings, machine learning (ML) is being increasingly used for data-driven thermal comfort (TC) prediction. Generally, ML-based solutions are proposed for air-conditioned or HVAC ventilated buildings and the models are primarily designed for adults. On the other hand, naturally ventilated (NV) buildings are the norm in most countries. They are also ideal for energy conservation and long-term sustainability goals. However, the indoor environment of NV buildings lacks thermal regulation and varies significantly across spatial contexts. These factors make TC prediction extremely challenging. Thus, determining the impact of the building environment on the performance of TC models is important. Further, the generalization capability of TC prediction models across different NV indoor spaces needs to be studied. This work addresses these problems. Data is gathered through month-long field experiments conducted in 5 naturally ventilated school buildings, involving 512 primary school students. The impact of spatial variability on student comfort is demonstrated through variation in prediction accuracy (by as much as 71%). The influence of building environment on TC prediction is also demonstrated through variation in feature importance. Further, a comparative analysis of spatial variability in model performance is done for children (our dataset) and adults (ASHRAE-II database). Finally, the generalization capability of thermal comfort models in NV classrooms is assessed and major challenges are highlighted. 	
"Meaning of the splitting process for the transition to self-sustained
  turbulence in a magnetized cylindrical plasma"	http://arxiv.org/abs/2206.14038v1	2022-06-28T14:32:52Z	2022-06-28T14:32:52Z	  When turbulent structures split more frequently before they decay, persistent turbulence forms in neutral fluid shear flows. Whether this concept can be extended to linear magnetized plasmas is investigated here and compared to the behavior of the pipe flow. With increasing control parameter the dynamics in the magnetized plasmas is known to undergo several changes from a quasiperiodic to a phase locked to a weakly turbulent regime. When the phase-locked regime breaks down, the splitting time approaches the decreasing lifetime reflecting self-sustained turbulence, as known from the pipe flow. 	
"Traffic Management of Autonomous Vehicles using Policy Based Deep
  Reinforcement Learning and Intelligent Routing"	http://arxiv.org/abs/2206.14608v1	2022-06-28T02:46:20Z	2022-06-28T02:46:20Z	  Deep Reinforcement Learning (DRL) uses diverse, unstructured data and makes RL capable of learning complex policies in high dimensional environments. Intelligent Transportation System (ITS) based on Autonomous Vehicles (AVs) offers an excellent playground for policy-based DRL. Deep learning architectures solve computational challenges of traditional algorithms while helping in real-world adoption and deployment of AVs. One of the main challenges in AVs implementation is that it can worsen traffic congestion on roads if not reliably and efficiently managed. Considering each vehicle's holistic effect and using efficient and reliable techniques could genuinely help optimise traffic flow management and congestion reduction. For this purpose, we proposed a intelligent traffic control system that deals with complex traffic congestion scenarios at intersections and behind the intersections. We proposed a DRL-based signal control system that dynamically adjusts traffic signals according to the current congestion situation on intersections. To deal with the congestion on roads behind the intersection, we used re-routing technique to load balance the vehicles on road networks. To achieve the actual benefits of the proposed approach, we break down the data silos and use all the data coming from sensors, detectors, vehicles and roads in combination to achieve sustainable results. We used SUMO micro-simulator for our simulations. The significance of our proposed approach is manifested from the results. 	
"Translucency and negative temperature-dependence for the slip length of
  water on graphene"	http://arxiv.org/abs/2206.13702v1	2022-06-28T02:26:08Z	2022-06-28T02:26:08Z	  Carbonous materials, such as graphene and carbon nanotube, have attracted tremendous attention in the fields of nanofluidics due to the slip at the interface between solid and liquid. The dependence of slip length for water on the types of supporting substrates and thickness of carbonous layer, which is critical for applications such as sustainable cooling of electronic devices, remains unknown. In this paper, using colloidal probe atomic force microscope, we measured the slip length of water on graphene ls supported by hydrophilic and hydrophobic substrates, i.e., SiO2 and octadecyltrimethoxysilane (OTS). The ls on single-layer graphene supported by SiO2 is found to be 1.6~1.9 nm, and by OTS is 8.5~0.9 nm. With the thickness of few-layer graphene increases to 3~4 layers, both ls gradually converge to the value of graphite (4.3~3.5 nm). Such thickness dependence is termed slip length translucency. Further, ls is found to decrease by about 70% with the temperature increases from 300 K to 350 K for 2-layer graphene supported by SiO2. These observations are explained by analysis based on Green-Kubo relation and McLachlan theory. Our results provide the first set of reference values for the slip length of water on supported few-layer graphene. They can not only serve as a direct experimental reference for solid-liquid interaction, but also provide guideline for the design of nanofluidics-based devices, for example the thermo-mechanical nanofluidic devices. 	
"Resolution Study of Thermonuclear Initiation in White Dwarf Tidal
  Disruption Events"	http://arxiv.org/abs/2206.13546v1	2022-06-27T18:00:09Z	2022-06-27T18:00:09Z	  We study the initiation of thermonuclear detonations in tidally disrupted white dwarf stars by intermediate-mass ($10^3 M_\odot$) black holes. The length scales required to resolve the initiation mechanism are not easily reached in three-dimensions, so instead we have devised two-dimensional proxy models which, together with a logarithmic gridding strategy, can adequately capture detonation wave fronts as material undergoes simultaneous compression and stretching from tidal forces. We consider 0.15 and 0.6 solar mass white dwarf stars parameterized by tidal strengths in the range $\beta=4~\text{to}~23$. High spatial resolution elucidates the manner and conditions leading to thermonuclear detonation, linking the initiation sequence to stellar composition and tidal strength. All of our models suffer sustained detonations triggered by a combination of adiabatic compression, mild thermonuclear preconditioning, and collisional heating, in degrees depending primarily on tidal strength. We find many diagnostics, such as temperature, total released energy, and iron group products, are fairly well-converged (better than 10%) at resolutions below 10 km along the scale height of the orbital plane. The exceptions are intermediate mass transients like calcium, which remain uncertain up to factors of two even at 1 km resolution. 	
Usability Testing untuk Mengukur Kepuasaan Pengguna Website Mailo Store	http://arxiv.org/abs/2207.00006v1	2022-06-27T07:05:11Z	2022-06-27T07:05:11Z	  Technological developments in the current era of globalization cannot be avoided, with increasingly rapid progress to become technology as a medium of information that is very much needed in life. Mailo store is one of the SMEs that have used the website and the internet as a medium for storing their information to the wider community, therefore an evaluation is needed to measure the ease of website users for users using Usability Testing which has 8 variables, namely learning (learnability), Efficiency (efficiency), Easy to remember (memorability), Errors and security (errors), Easy to understand (Understandability), Easy to operate (Operability), attract user attention (Attractiveness), Satisfaction (satisfaction). This research data was collected by distributing questionnaires to 109 respondents using a random sampling technique. Furthermore, the data obtained were processed using SPSS version 25 software. The data analysis method used was a quantitative analysis method using validity and reliability tests, classical assumption tests, multiple regression tests, and hypothesis testing. The results of the assessment of the usability testing method will be useful for the sustainability and development of the mailo store website in the future to make it even better. 	
Activity-suppressed phase separation	http://arxiv.org/abs/2206.12574v3	2022-12-22T22:30:10Z	2022-06-25T06:53:40Z	  We use a continuum model to examine the effect of activity on a phase separating mixture of an extensile active nematic and a passive fluid. We highlight the distinct role of previously considered interfacial active stresses and bulk active stresses that couple to liquid crystalline degrees of freedom. Interfacial active stresses can arrest phase separation, as previously demonstrated. Bulk extensile active stresses can additionally strongly suppress phase separation by sustained self-stirring of the fluid, substantially reducing the size of the coexistence region in the temperature/concentration plane relative to that of the passive system. The phase separated state is a dynamical emulsion-like steady state of continuously splitting and merging droplets, as suggested by recent experiments. Using scaling analysis and simulations, we identify various regimes for the dependence of droplet size on activity. These results can provide a criterion for identifying the mechanisms responsible for arresting phase separation in experiments. 	
"All-optical non-linear chiral ultrafast magnetization dynamics driven by
  circularly polarized magnetic fields"	http://arxiv.org/abs/2206.12238v1	2022-06-24T12:11:56Z	2022-06-24T12:11:56Z	  Ultrafast laser pulses provide unique tools to manipulate magnetization dynamics at femtosecond timescales, where the interaction of the electric field -- such as excitation of spin carriers to non-equilibrium states, generation of localized charge currents, demagnetization, or inverse Faraday effect -- dominates over the magnetic field. Recent proposals using structured laser beams have enlightened the possibility to generate intense femtosecond magnetic fields, spatially isolated from the electric field. Here we demonstrate the relevance of this novel scenario to femtomagnetism, unveiling the purely precessional, non-linear, chiral response of the magnetization when subjected to circularly polarized magnetic fields. This fundamental result not only opens an avenue in the study of laser-induced ultrafast magnetization dynamics, but also sustains technological implications as a route to promote all-optical non-thermal magnetization switching both at shorter timescales -- towards the attosecond regime -- and at THz frequencies. 	
Self-stabilizing positron acceleration in a plasma column	http://arxiv.org/abs/2206.11967v1	2022-06-23T20:31:59Z	2022-06-23T20:31:59Z	  Plasma accelerators sustain extreme field gradients, and potentially enable future compact linear colliders. Although tremendous progress has been achieved in accelerating electron beams in a plasma accelerator, positron acceleration with collider-relevant parameters is challenging. A recently proposed positron acceleration scheme relying on the wake generated by an electron drive beam in a plasma column has been shown to be able to accelerate positron witness beams with low emittance and low energy spread. However, since this scheme relies on cylindrical symmetry, it is possibly prone to transverse instabilities that could lead, ultimately, to beam break-up. In this article, we show that the witness beam itself is subject to various damping mechanisms and, therefore, this positron acceleration scheme is inherently stable towards misalignment of the drive and witness beams. This enables stable, high-quality plasma-based positron acceleration. 	
"Predicting the meal macronutrient composition from continuous glucose
  monitors"	http://arxiv.org/abs/2206.11878v1	2022-06-23T17:41:25Z	2022-06-23T17:41:25Z	  Sustained high levels of blood glucose in type 2 diabetes (T2DM) can have disastrous long-term health consequences. An essential component of clinical interventions for T2DM is monitoring dietary intake to keep plasma glucose levels within an acceptable range. Yet, current techniques to monitor food intake are time intensive and error prone. To address this issue, we are developing techniques to automatically monitor food intake and the composition of those foods using continuous glucose monitors (CGMs). This article presents the results of a clinical study in which participants consumed nine standardized meals with known macronutrients amounts (carbohydrate, protein, and fat) while wearing a CGM. We built a multitask neural network to estimate the macronutrient composition from the CGM signal, and compared it against a baseline linear regression. The best prediction result comes from our proposed neural network, trained with subject-dependent data, as measured by root mean squared relative error and correlation coefficient. These findings suggest that it is possible to estimate macronutrient composition from CGM signals, opening the possibility to develop automatic techniques to track food intake. 	
"The role of open data in the transformation to Society 5.0: a resource
  or a tool for SDG-compliant Smart Living?"	http://arxiv.org/abs/2206.11784v2	2022-08-10T10:05:01Z	2022-06-23T15:41:40Z	"  Open data are characterized by a number of economic, technological, innovative and social benefits. They are seen as a significant contributor to the city's transformation into Smart City. This is all the more so when the society is on the border of Society 5.0, i.e., shift from the information society to a super smart society or society of imagination takes place. However, the question constantly asked by open data experts is, what are the key factors to be met and satisfied in order to achieve promised benefits? The current trend of openness suggests that the principle of openness should be followed not only by data but also research, education, software, standard, hardware etc., it should become a philosophy to be followed at different levels, in different domains. This should ensure greater transparency, eliminating inequalities, promoting, and achieving sustainable development goals. Therefore, many agendas now have openness as a prerequisite. This chapter deals with concepts of open (government) data and Society 5.0 pointing to their common objectives, providing some success stories of open data use in smart cities or transformation of cities towards smart cities, mapping them to the features of the Society 5.0. We believe that this trend develops a new form of society, which we refer to as ""open data-driven society"". It forms a bridge from Society 4.0 to Society 5.0. This Chapter attempts to identify the role of openness in promoting human-centric Smart Society, Smart city, and Smart Living. "	
"Graph Neural Networks for Temperature-Dependent Activity Coefficient
  Prediction of Solutes in Ionic Liquids"	http://arxiv.org/abs/2206.11776v1	2022-06-23T15:27:29Z	2022-06-23T15:27:29Z	  Ionic liquids (ILs) are important solvents for sustainable processes and predicting activity coefficients (ACs) of solutes in ILs is needed. Recently, matrix completion methods (MCMs), transformers, and graph neural networks (GNNs) have shown high accuracy in predicting ACs of binary mixtures, superior to well-established models, e.g., COSMO-RS and UNIFAC. GNNs are particularly promising here as they learn a molecular graph-to-property relationship without pretraining, typically required for transformers, and are, unlike MCMs, applicable to molecules not included in training. For ILs, however, GNN applications are currently missing. Herein, we present a GNN to predict temperature-dependent infinite dilution ACs of solutes in ILs. We train the GNN on a database including more than 40,000 AC values and compare it to a state-of-the-art MCM. The GNN and MCM achieve similar high prediction performance, with the GNN additionally enabling high-quality predictions for ACs of solutions that contain ILs and solutes not considered during training. 	
"Large-Scale Direct Numerical Simulations of Turbulence Using GPUs and
  Modern Fortran"	http://arxiv.org/abs/2207.07098v1	2022-06-23T12:41:19Z	2022-06-23T12:41:19Z	  We present our approach to making direct numerical simulations of turbulence with applications in sustainable shipping. We use modern Fortran and the spectral element method to leverage and scale on supercomputers powered by the Nvidia A100 and the recent AMD Instinct MI250X GPUs, while still providing support for user software developed in Fortran. We demonstrate the efficiency of our approach by performing the world's first direct numerical simulation of the flow around a Flettner rotor at Re=30'000 and its interaction with a turbulent boundary layer. We present one of the first performance comparisons between the AMD Instinct MI250X and Nvidia A100 GPUs for scalable computational fluid dynamics. Our results show that one MI250X offers performance on par with two A100 GPUs and has a similar power efficiency. 	
"The Role of Emotional Intelligence in Handling Requirements Changes in
  Software Engineering"	http://arxiv.org/abs/2206.11603v1	2022-06-23T10:26:41Z	2022-06-23T10:26:41Z	  Background: Requirements changes (RCs) are inevitable in Software Engineering. Research shows that emotional intelligence (EI) should be used alongside agility and cognitive intelligence during RC handling. Objective: We wanted to study the role of EI in-depth during RC handling. Method: We conducted a socio-technical grounded theory study with eighteen software practitioners from Australia, New Zealand, Singapore, and Sri Lanka. Findings: We found causal condition (software practitioners handling RCs), intervening condition (mode of work), causes (being aware of own emotions, being aware of others' emotions), direct consequences (regulating own emotions, managing relationships), extended consequences (sustaining productivity, setting and sustaining team goals), and contingencies: strategies (open and regular communication, tracking commitments and issues, and ten other strategies) of using EI during RC handling. We also found the covariances where strategies co-vary with the causes and direct consequences, and ease/ difficulty in executing strategies co-vary with the intervening condition. Conclusion: Open and regular communication is key to EI during RC handling. To the best of our knowledge, the framework we present in this paper is the first theoretical framework on EI in Software Engineering research. We provide recommendations including a problem-solution chart in the form of causes, direct consequences, and mode of work against the contingencies: strategies for software practitioners to consider during RC handling, and future directions of research. 	
"A Reduced-Order Discrete-Vortex Method for Flows with Leading-Edge
  Vortex Shedding"	http://arxiv.org/abs/2206.11597v1	2022-06-23T10:17:25Z	2022-06-23T10:17:25Z	  The formation of the leading-edge vortex (LEV) is a key feature of unsteady flows past aerodynamic surfaces, but is expensive to model in high fidelity computations. Low-order methods based on discrete vortex elements are able to capture the physical behavior of these flows, in particular when enhanced with a criterion that models the ability of the leading edge to sustain suction. These models are significantly faster than high order methods, but their expense still grows as vortex elements are continuously shed and convected into the wake, in effect an $\mathcal{O}(n^2)$ problem. This work proposes accelerating the leading-edge suction parameter discrete vortex method (LDVM) by limiting the number of vortex elements in the LEV coherent structure to N, hence giving the name to the method N-LEV LDVM. The N-LEV LDVM method correctly approximates the flows in comparison with the original LDVM model and computational fluid dynamics (CFD) simulations until the point of LEV detachment, which N-LEV LDVM is unable to model. We propose reintroducing this behavior via two physical detachment criteria studied in LEV literature, a threshold of maximum circulation in the LEV and trailing edge flow reversal. We demonstrate the ability of the N-LEV LDVM method to accurately predict the instant in time this detachment occurs for both mechanisms in comparison with experimental results, laying the ground for their incorporation into the method. 	
"INTERPLAY: An Intelligent Model for Predicting Performance Degradation
  due to Multi-cache Way-disabling"	http://arxiv.org/abs/2206.11566v1	2022-06-23T09:26:31Z	2022-06-23T09:26:31Z	  Modern and future processors need to remain functionally correct in the presence of permanent faults to sustain scaling benefits and limit field returns. This paper presents a combined analytical and microarchitectural simulation-based framework called INTERPLAY, that can rapidly predict, at design-time, the performance degradation expected from a processor employing way-disabling to handle permanent faults in caches while in-the-field. The proposed model can predict a program's performance with an accuracy of up to 98.40% for a processor with a two-level cache hierarchy, when multiple caches suffer from faults and need to disable one or more of their ways. INTERPLAY is 9.2x faster than an exhaustive simulation approach since it only needs the training simulation runs for the single-cache way-disabling configurations to predict the performance for any multi-cache way-disabling configuration. 	
"Eliminating solvents and polymers in high-performance Si anodes by
  gas-phase assembly of nanowire fabrics"	http://arxiv.org/abs/2206.14577v1	2022-06-23T06:56:08Z	2022-06-23T06:56:08Z	  Developing sustainable battery electrode manufacturing methods is particularly pressing for alloying-type active materials, such as silicon, which often require additional energy-intensive and solvent-based processing to reinforce them with a buffer matrix. This work introduces a new method to fabricate Si anodes as continuous, tough fabrics of arbitrary thickness, without processing solvents, polymeric binders, carbon additive, or any reinforcing matrix. The anodes consist of percolated networks of long Si nanowires directly assembled from suspension in the gas phase, where they are grown via floating catalyst chemical vapour deposition. A high Si content above 75 wt.% in a textile-like network structure leads to high-performance electrode properties. Their gravimetric capacity is 2330 mAh g-1 at C/20 for all thicknesses produced, reaching areal capacities above 9.3 mAh cm-2 at C/20 and 3.4 mAh cm-2 at 1C (with 3.4 mg cm-2). Analysis of rating data gives a high transport coefficient (6.6x10-12 m2 s-1) due to a high out-of-plane electrical conductivity (0.6 S m-1) and short solid-state diffusion length. Si remains a percolated network of elongated elements after extended cycling, preserving electrical conductivity and leading to a capacity retention of 80% after 100 cycles at C/5 and ~60% after 500 cycles at C/2. When integrated with NMC111 cathode, a full cell gravimetric energy density of 480 Wh kg-1 is demonstrated. 	
"Continual Learning for Affective Robotics: A Proof of Concept for
  Wellbeing"	http://arxiv.org/abs/2206.11354v2	2022-08-30T12:11:22Z	2022-06-22T20:01:22Z	  Sustaining real-world human-robot interactions requires robots to be sensitive to human behavioural idiosyncrasies and adapt their perception and behaviour models to cater to these individual preferences. For affective robots, this entails learning to adapt to individual affective behaviour to offer a personalised interaction experience to each individual. Continual Learning (CL) has been shown to enable real-time adaptation in agents, allowing them to learn with incrementally acquired data while preserving past knowledge. In this work, we present a novel framework for real-world application of CL for modelling personalised human-robot interactions using a CL-based affect perception mechanism. To evaluate the proposed framework, we undertake a proof-of-concept user study with 20 participants interacting with the Pepper robot using three variants of interaction behaviour: static and scripted, using affect-based adaptation without personalisation, and using affect-based adaptation with continual personalisation. Our results demonstrate a clear preference in the participants for CL-based continual personalisation with significant improvements observed in the robot's anthropomorphism, animacy and likeability ratings as well as the interactions being rated significantly higher for warmth and comfort as the robot is rated as significantly better at understanding how the participants feel. 	
"Ant Hill Colonization optimization algorithm(AHCOA) for controlling the
  side lobe of a uniform linear array"	http://arxiv.org/abs/2207.02910v5	2022-11-29T16:45:09Z	2022-06-22T16:44:37Z	  This paper aims to introduce the Ant hill colonization optimization algorithm(AHCOA) to the electromagnetics and antenna community. The ant hill is built by special species of ants known as formicas ants(also meadow ants, fire ants and harvester ants). AHCOA is a novel new nature inspired algorithm mimicking how the ants built and sustain the ant hill for their survival and sustenance for many years. This problem solves constrained and unconstrained optimization problems with wide capability in diverse fields. AHCOA is used by writing equations of volumetric analysis of the ant hill mould the manner in which the structure is architected. In this paper, we have shown how AHCOA is better than the previous paper on ant lion optimizer for controlling side lobe in antenna pattern synthesis in paper [1]. The potential of AHCOA in synthesizing and analyzing for d/ varying from 1.1,0.6,0.5,0.3 and 0.1 linear array is also illustrated. Antenna side lobe level minimization is compared with ant lion optimizer showing why AHCOA is better than the previously simulated ant lion optimizer for side lobe control. The results show why linear arrays are better synthesized for AHCOA then other algorithms used in planar arrays. This paper shows why AHCOA is a strong candidate for antenna optimization used in linear arrays. 	
"An Energy and Carbon Footprint Analysis of Distributed and Federated
  Learning"	http://arxiv.org/abs/2206.10380v1	2022-06-21T13:28:49Z	2022-06-21T13:28:49Z	  Classical and centralized Artificial Intelligence (AI) methods require moving data from producers (sensors, machines) to energy hungry data centers, raising environmental concerns due to computational and communication resource demands, while violating privacy. Emerging alternatives to mitigate such high energy costs propose to efficiently distribute, or federate, the learning tasks across devices, which are typically low-power. This paper proposes a novel framework for the analysis of energy and carbon footprints in distributed and federated learning (FL). The proposed framework quantifies both the energy footprints and the carbon equivalent emissions for vanilla FL methods and consensus-based fully decentralized approaches. We discuss optimal bounds and operational points that support green FL designs and underpin their sustainability assessment. Two case studies from emerging 5G industry verticals are analyzed: these quantify the environmental footprints of continual and reinforcement learning setups, where the training process is repeated periodically for continuous improvements. For all cases, sustainability of distributed learning relies on the fulfillment of specific requirements on communication efficiency and learner population size. Energy and test accuracy should be also traded off considering the model and the data footprints for the targeted industrial applications. 	
FEAT: Fair Coordinated Iterative Water-Filling Algorithm	http://arxiv.org/abs/2206.10211v2	2022-06-22T20:07:30Z	2022-06-21T09:26:55Z	  In this paper, we consider a perfect coordinated water-filling game, where each user transmits solely on a given carrier. The main goal of the proposed algorithm (which we call FEAT) is to get close to the optimal, while keeping a decent level of fairness. The key idea within FEAT is to minimize the ratio between the best and the worst utilities of the users. This is done by ensuring that, at each iteration (channel assignment), a user is satisfied with this assignment as long as he does not loose much more than other users in the system. It has been shown that FEAT outperforms most related algorithms in many aspects, especially in interference-limited systems. Indeed, with FEAT we can ensure a near-optimal, fair and energy efficient solution with low computational complexity. In terms of robustness, it turns out that the balance between being nearly globally optimal and good from individual point of view seems hard to sustain with a significant number of users. Also notice that, in this regard, global optimality gets less affected than the individual one, which offers hope that such an accurate water-filling algorithm can be designed around competition in interference-limited systems. 	
"Electrochemical Parameter Identification for Lithium-ion Battery Sources
  in Self-Sustained Transportation Energy Systems"	http://arxiv.org/abs/2206.10099v2	2023-03-14T03:17:33Z	2022-06-21T04:07:59Z	  Lithium-ion battery (LIB) sources have played an essential role in self-sustained transportation energy systems and have been widely deployed in the last few years. To realize reliable battery maintenance, identifying its electrochemical parameters is necessary. However, the battery model contains many parameters while the measurable states are only the current and voltage, inducing the identification inherently an ill-conditioned problem. A parameter identification approach is proposed, including the experiment, model, and algorithm. Electrochemical parameters are first grouped manually based on the physical properties and assigned to two sequenced tests for identification. The two tests named the quasi-static test and the dynamic test, are compressed on time for practical implementation. Proper optimization models and a sensitivity-oriented stepwise (SSO) optimization algorithm are developed to search for the optimal parameters efficiently. Typically, the Sobol method is applied to conduct the sensitivity analysis. Based on the sensitivity indexes, the SSO algorithm can decouple the mixed impacts of different parameters during the identification. For validation, numerical experiments on a typical NCM811 battery at different life stages are conducted. The proposed approach saves about half the time finding the proper parameter value. The identification accuracy of crucial parameters related to battery degradation can exceed 95\%. Case study results indicate that the identified parameters can not only improve the accuracy of the battery model but also be used as the indicator of the battery SOH. 	
Threshold transient growth as a criterion for turbulent mean profiles	http://arxiv.org/abs/2206.09681v1	2022-06-20T09:47:24Z	2022-06-20T09:47:24Z	  Lozano-Duran et al (J. Fluid Mech., vol. 914, A8, 2021) have recently identified the ability of the streamwise-averaged streak fields $\cal{U}(y,z,t)\bf{\hat{x}}$ in minimal channels to produce short-term transient growth as the key linear mechanism needed to sustain turbulence at $Re_{\tau}=180$. Here, we model this streak transient growth as a two-stage process by first selecting the dominant streak structure expected to emerge over the eddy turnover time on the turbulent mean profile $U(y)\bf{\hat{x}}$, and then examining the secondary growth on this (frozen) streak field $\cal{U}(y,z)\bf{\hat{x}}$. Choosing the mean streak amplitude and eddy turnover time consistent with simulations recovers the growth thresholds found by Lozano-Duran et al. (2021) for sustained turbulence. Extending this analysis to $Re_{\tau}=360$ and $720$ suggests a Reynolds number independence of this threshold. This then indicates that the short-term growth properties of the turbulent mean profile $\cal{U}(y,z)\bf{\hat{x}}$ are a much more plausible criterion of turbulence existence than its linear stability characteristics as originally suggested by Malkus (J. Fluid Mech., vol. 521, 1, 1956). 	
"Experimental Demonstration of Delay-Bounded Wireless Network Based on
  Precise Time Synchronization"	http://arxiv.org/abs/2207.00158v2	2022-11-11T00:46:50Z	2022-06-20T06:37:38Z	  Low latency and reliable information transfer are highly demanded in fifth generation (5G) and beyond 5G wireless communications. A novel delay-bounded wireless media access control (MAC) protocol called Carrier Sense Multiple Access with Arbitration Point (CSMA/AP) was established to strictly ensure the upper boundary of communication delay. CSMA/AP enables collision-free and delay-bounded communications with a simple arbitration mechanism exploiting the precise time synchronization achieved by Wireless Two-Way Interferometry (Wi-Wi). Experimental demonstration and proving the feasibility in wireless environments are among the most critical steps before any further discussion of CSMA/AP and extension to various applications can take in place. In this work described in this paper, we experimentally demonstrated the fundamental principles of CSMA/AP by constructing a star-topology wireless network using software-defined radio terminals combined with precise time synchronization devices. We show that CSMA/AP was successfully operated, even with dynamic changes of the spatial position of the terminal or the capability to accommodate mobility, thanks to the real-time adaption to the dynamically changing environment by Wi-Wi. We also experimentally confirmed that the proposed CSMA/AP principle cannot be executed without Wi-Wi, which validates the importance of precise time synchronization. This study paves the way toward realizing delay-bounded wireless communications for future low-latency and highly reliable critical applications. 	
"Swinging a playground swing: torque controls for inducing sustained
  oscillations"	http://arxiv.org/abs/2206.09579v1	2022-06-20T05:53:38Z	2022-06-20T05:53:38Z	  Models of a playground swing have been studied since the 1960s. However, in most of them, the position of the swinger is controlled directly. This simplifies the problem but hides the mechanics of torques applied to keep the swing moving in a regular pattern. This article studies these mechanics. Two models of a swing with torques as controls that we consider are identical to popular models of modern robotics: the Acrobot and reaction wheel pendulum. However, the control task of sustaining the swing's regular oscillations by a static feedback control is new and challenging, especially when damping in the joint connecting the swing to the frame is considered. We develop two types of controls to accomplish this task. One works for small damping and is based on linearizing the undamped system by a suitable preliminary feedback control. The other works for large damping. In the steady state, the resulting closed-loop system describes a harmonically driven damped pendulum (a simple system known for its complex behavior), including chaotic motion for some parameter values. To address such complexities, we build free parameters into the controls, then adjust them based on simulations to avoid chaos and achieve regular oscillations that are seen on playgrounds. 	
The Gender Pay Gap in China: Insights from a Discrimination Perspective	http://arxiv.org/abs/2206.09306v1	2022-06-19T02:09:57Z	2022-06-19T02:09:57Z	  Equal pay is an essential component of gender equality, one of the Sustainable Development Goals of the United Nations. Using resume data of over ten million Chinese online job seekers in 2015, we study the current gender pay gap in China. The results show that on average women only earned 71.57\% of what men earned in China. The gender pay gap exists across all age groups and educational levels. Contrary to the commonly held view that developments in education, economy, and a more open culture would reduce the gender pay gap, the fusion analysis of resume data and socio-economic data presents that they have not helped reach the gender pay equality in China. China seems to be stuck in a place where traditional methods cannot make further progress. Our analysis further shows that 81.47\% of the variance in the gender pay gap can be potentially attributed to discrimination. In particular, compared with the unmarried, both the gender pay gap itself and proportion potentially attributed to discrimination of the married are larger, indicating that married women suffer greater inequality and more discrimination than unmarried ones. Taken together, we suggest that more research attention should be paid to the effect of discrimination in understanding gender pay gap based on the family constraint theory. We also suggest the Chinese government to increase investment in family-supportive policies and grants in addition to female education. 	
"Inferring oscillator's phase and amplitude response from a scalar signal
  exploiting test stimulation"	http://arxiv.org/abs/2206.09173v4	2022-12-06T21:21:49Z	2022-06-18T10:35:40Z	  The phase sensitivity curve or phase response curve (PRC) quantifies the oscillator's reaction to stimulation at a specific phase and is a primary characteristic of a self-sustained oscillatory unit. Knowledge of this curve yields a phase dynamics description of the oscillator for arbitrary weak forcing. Similar, though much less studied characteristic, is the amplitude response that can be defined either using an ad hoc approach to amplitude estimation or via the isostable variables. Here, we discuss the problem of the phase and amplitude response inference from observations using test stimulation. Although PRC determination for noise-free neuronal-like oscillators perturbed by narrow pulses is a well-known task, the general case remains a challenging problem. Even more challenging is the inference of the amplitude response. This characteristic is crucial, e.g., for controlling the amplitude of the collective mode in a network of interacting units -- a task relevant to neuroscience. Here, we compare the performance of different techniques suitable for inferring the phase and amplitude response, particularly with application to macroscopic oscillators. We suggest improvements to these techniques, e.g., demonstrating how to obtain the PRC in case of stimuli of arbitrary shape. Our main result is a novel technique denoted by IPID-1, based on the direct reconstruction of the Winfree equation and the analogous first-order equation for isostable dynamics. The technique works for signals with or without well-pronounced marker events and pulses of arbitrary shape; in particular, we consider charge-balanced pulses typical in neuroscience applications. Moreover, this technique is superior for noisy and high-dimensional systems. Additionally, we describe an error measure that can be computed solely from data and complements any inference technique. 	
"Interpretable and Actionable Vehicular Greenhouse Gas Emission
  Prediction at Road link-level"	http://arxiv.org/abs/2206.09073v1	2022-06-18T00:49:51Z	2022-06-18T00:49:51Z	  To help systematically lower anthropogenic Greenhouse gas (GHG) emissions, accurate and precise GHG emission prediction models have become a key focus of the climate research. The appeal is that the predictive models will inform policymakers, and hopefully, in turn, they will bring about systematic changes. Since the transportation sector is constantly among the top GHG emission contributors, especially in populated urban areas, substantial effort has been going into building more accurate and informative GHG prediction models to help create more sustainable urban environments. In this work, we seek to establish a predictive framework of GHG emissions at the urban road segment or link level of transportation networks. The key theme of the framework centers around model interpretability and actionability for high-level decision-makers using econometric Discrete Choice Modelling (DCM). We illustrate that DCM is capable of predicting link-level GHG emission levels on urban road networks in a parsimonious and effective manner. Our results show up to 85.4% prediction accuracy in the DCM models' performances. We also argue that since the goal of most GHG emission prediction models focuses on involving high-level decision-makers to make changes and curb emissions, the DCM-based GHG emission prediction framework is the most suitable framework. 	
"SwarmHawk: Self-Sustaining Multi-Agent System for Landing on a Moving
  Platform through an Agent Supervision"	http://arxiv.org/abs/2206.08874v1	2022-06-17T16:21:10Z	2022-06-17T16:21:10Z	  Heterogeneous teams of mobile robots and UAVs are offering a substantial benefit in an autonomous exploration of the environment. Nevertheless, although joint exploration scenarios for such systems are widely discussed, they are still suffering from low adaptability to changes in external conditions and faults of swarm agents during the UAV docking. We propose a novel vision-based drone swarm docking system for robust landing on a moving platform when one of the agents lost its position signal. The proposed SwarmHawk system relies on vision-based detection for the mobile platform tracking and navigation of its agents. Each drone of the swarm carries an RGB camera and AprilTag3 QR-code marker on board. SwarmHawk can switch between two modes of operation, acting as a homogeneous swarm in case of global UAV localization or assigning leader drones to navigate its neighbors in case of a camera fault in one of the drones or global localization failure. Two experiments were performed to evaluate SwarmHawk's performance under the global and local localization with static and moving platforms. The experimental results revealed a sufficient accuracy in the swarm landing task on a static mobile platform (error of 4.2 cm in homogeneous formation and 1.9 cm in leader-follower formation) and on moving platform (error of 6.9 cm in homogeneous formation and 4.7 cm in leader-follower formation). Moreover, the drones showed a good landing on a platform moving along a complex trajectory (average error of 19.4 cm) in leader-follower formation. The proposed SwarmHawk technology can be potentially applied in various swarm scenarios, including complex environment exploration, inspection, and drone delivery. 	
"SwarmHive: Heterogeneous Swarm of Drones for Robust Autonomous Landing
  on Moving Robot"	http://arxiv.org/abs/2206.08856v1	2022-06-17T15:56:29Z	2022-06-17T15:56:29Z	  The paper focuses on a heterogeneous swarm of drones to achieve a dynamic landing of formation on a moving robot. This challenging task was not yet achieved by scientists. The key technology is that instead of facilitating each agent of the swarm of drones with computer vision that considerably increases the payload and shortens the flight time, we propose to install only one camera on the leader drone. The follower drones receive the commands from the leader UAV and maintain a collision-free trajectory with the artificial potential field. The experimental results revealed a high accuracy of the swarm landing on a static mobile platform (RMSE of 4.48 cm). RMSE of swarm landing on the mobile platform moving with the maximum velocities of 1.0 m/s and 1.5 m/s equals 8.76 cm and 8.98 cm, respectively. The proposed SwarmHive technology will allow the time-saving landing of the swarm for further drone recharging. This will make it possible to achieve self-sustainable operation of a multi-agent robotic system for such scenarios as rescue operations, inspection and maintenance, autonomous warehouse inventory, cargo delivery, and etc. 	
"Channel-wise Mixed-precision Assignment for DNN Inference on Constrained
  Edge Nodes"	http://arxiv.org/abs/2206.08852v2	2023-01-25T07:42:35Z	2022-06-17T15:51:49Z	  Quantization is widely employed in both cloud and edge systems to reduce the memory occupation, latency, and energy consumption of deep neural networks. In particular, mixed-precision quantization, i.e., the use of different bit-widths for different portions of the network, has been shown to provide excellent efficiency gains with limited accuracy drops, especially with optimized bit-width assignments determined by automated Neural Architecture Search (NAS) tools. State-of-the-art mixed-precision works layer-wise, i.e., it uses different bit-widths for the weights and activations tensors of each network layer. In this work, we widen the search space, proposing a novel NAS that selects the bit-width of each weight tensor channel independently. This gives the tool the additional flexibility of assigning a higher precision only to the weights associated with the most informative features. Testing on the MLPerf Tiny benchmark suite, we obtain a rich collection of Pareto-optimal models in the accuracy vs model size and accuracy vs energy spaces. When deployed on the MPIC RISC-V edge processor, our networks reduce the memory and energy for inference by up to 63% and 27% respectively compared to a layer-wise approach, for the same accuracy. 	
Long-term future particle accelerators	http://arxiv.org/abs/2206.08834v1	2022-06-17T15:28:47Z	2022-06-17T15:28:47Z	  Particle accelerators have enabled forefront research in high energy physics and other research areas for more than half a century. Accelerators have directly contributed to 26 Nobel Prizes in Physics since 1939 as well as another 20 Nobel Prizes in Chemistry, Medicine and Physics with X-rays. Although high energy physics has been the main driving force for the development of the particle accelerators, accelerator facilities have continually been expanding applications in many areas of research and technology. For instance, active areas of accelerator applications include radiotherapy to treat cancer, production of short-lived medical isotopes, synchrotron light sources, free-electron lasers, beam lithography for microcircuits, thin-film technology and radiation processing of food. Currently, the largest and most powerful accelerator is the Large Hadron Collider (LHC) at CERN, which accelerates protons to multi-TeV energies in a 27 km high-vacuum ring. To go beyond the maximum capabilities of the LHC, the next generation of circular and linear particle colliders under consideration, based on radiofrequency acceleration, will require multi-billion investment, kilometric infrastructure and a massive power consumption. These factors pose serious challenges in an increasingly resource-limited world. Therefore, it is important to look for alternative and sustainable acceleration techniques. This review article pays special attention to novel accelerator techniques to overcome present acceleration limitations towards more compact and cost-effective long term future accelerators. 	
Relativistic quantum decryption of large-scale neural coding	http://arxiv.org/abs/2206.08824v16	2023-03-07T17:57:47Z	2022-06-17T15:08:12Z	  Spin-geometrical projections, from the study of the human universe onto the study of the self-organizing brain, are herein leveraged to address certain concerns raised in latest neuroscience research, namely (i) the extent to which neural codes are multidimensional; (ii) the functional role of neural dark matter; (iii) the challenge to classical model frameworks posed by the needs for accurate interpretation of large-scale neural recordings linking brain and behavior. On the grounds of (hyper-)self-duality under (hyper-)mirror supersymmetry, relativistic quantum principles are introduced, whose consolidation, as pillars of a graphical game-theoretical construction, is conducive to (i) the high-precision reproduction and reinterpretation of core experimental observations on neural coding in the self-organizing brain, with the instantaneous geometric dimensionality of neural representations of a spontaneous behavioral state being proven to be at most 16, unidirectionally; (ii) the coexistability of ordinary and dark neural coding for (co-)behavior; (iii) a possible role for spinor (co-)representations, as the latent building blocks of self-organizing cortical circuits subserving (co-)behavioral states; (iv) an early crystallization of pertinent multidimensional synaptic (co-)architectures, whereby Lorentz (co-)partitions are in principle verifiable; (v) the allusion to octonionic dynamics sustained by triality, as candidate dynamics underlying internal states or emotions; and, ultimately, (vi) potentially inverse insights into matter-antimatter asymmetry. New avenues for the decryption of large-scale neural coding in health and disease are being discussed. 	
"Supernova Precursor Emission and the Origin of Pre-Explosion Stellar
  Mass-Loss"	http://arxiv.org/abs/2206.08377v2	2022-08-23T18:15:05Z	2022-06-16T18:00:00Z	"  A growing number of core collapse supernovae (SNe) which show evidence for interaction with dense circumstellar material (CSM) are accompanied by ""precursor"" optical emission rising weeks to months prior to the explosion. The precursor luminosities greatly exceed the Eddington limit of the progenitor star, implying they are accompanied by substantial mass-loss. Here, we present a semi-analytic model for SN precursor light curves which we apply to constrain the properties and mechanisms of the pre-explosion mass-loss. We explore two limiting mass-loss scenarios: (1) an ""eruption"" arising from shock break-out following impulsive energy deposition below the stellar surface; (2) a steady ""wind"" due to sustained heating of the progenitor envelope. The eruption model, which resembles a scaled-down version of Type IIP SNe, can explain the luminosities and timescales of well-sampled precursors, for ejecta masses $\sim 0.1-1\,M_{\odot}$ and velocities $\sim 100-1000\,\rm km\,s^{-1}$. By contrast, the steady-wind scenario cannot explain the highest precursor luminosities $\gtrsim10^{41}\,\rm erg\,s^{-1}$, under the constraint that the total ejecta mass not exceed the entire progenitor mass (though the less-luminous SN 2020tlf precursor can be explained by a mass-loss rate $\sim1\,M_{\odot}\,\rm yr^{-1}$). However, shock interaction between the wind and pre-existing (earlier ejected) CSM may boost its radiative efficiency and mitigate this constraint. In both eruption and wind scenarios the precursor ejecta forms compact ($\lesssim10^{15}$ cm) optically-thick CSM at the time of core collapse; though only directly observable via rapid post-explosion spectroscopy ($\lesssim$ few days before being overtaken by the SN ejecta), this material can boost the SN luminosity via shock interaction. "	
"Real3D-Aug: Point Cloud Augmentation by Placing Real Objects with
  Occlusion Handling for 3D Detection and Segmentation"	http://arxiv.org/abs/2206.07634v2	2022-07-11T12:39:17Z	2022-06-15T16:25:30Z	"  Object detection and semantic segmentation with the 3D lidar point cloud data require expensive annotation. We propose a data augmentation method that takes advantage of already annotated data multiple times. We propose an augmentation framework that reuses real data, automatically finds suitable placements in the scene to be augmented, and handles occlusions explicitly. Due to the usage of the real data, the scan points of newly inserted objects in augmentation sustain the physical characteristics of the lidar, such as intensity and raydrop. The pipeline proves competitive in training top-performing models for 3D object detection and semantic segmentation. The new augmentation provides a significant performance gain in rare and essential classes, notably 6.65% average precision gain for ""Hard"" pedestrian class in KITTI object detection or 2.14 mean IoU gain in the SemanticKITTI segmentation challenge over the state of the art. "	
"Comparison between an exact and a heuristic neural mass model with
  second order synapses"	http://arxiv.org/abs/2206.07521v1	2022-06-15T13:14:11Z	2022-06-15T13:14:11Z	  Neural mass models (NMMs) are designed to reproduce the collective dynamics of neuronal populations. A common framework for NMMs assumes heuristically that the output firing rate of a neural population can be described by a static nonlinear transfer function (NMM1). However, a recent exact mean-field theory for quadratic integrate-and-fire (QIF) neurons challenges this view by showing that the mean firing rate is not a static function of the neuronal state but follows two coupled nonlinear differential equations (NMM2). Here we analyze and compare these two descriptions in the presence of second-order synaptic dynamics. First, we derive the mathematical equivalence between the two models in the infinitely slow synapse limit, i.e., we show that NMM1 is an approximation of NMM2 in this regime. Next, we evaluate the applicability of this limit in the context of realistic physiological parameter values by analyzing the dynamics of models with inhibitory or excitatory synapses. We show that NMM1 fails to reproduce important dynamical features of the exact model, such as the self-sustained oscillations of an inhibitory interneuron QIF network. Furthermore, in the exact model but not in the limit one, stimulation of a pyramidal cell population induces resonant oscillatory activity whose peak frequency and amplitude increase with the self-coupling gain and the external excitatory input. This may play a role in the enhanced response of densely connected networks to weak uniform inputs, such as the electric fields produced by non-invasive brain stimulation. 	
Collective excitability in highly diluted networks of rotators	http://arxiv.org/abs/2206.07112v1	2022-06-14T18:59:59Z	2022-06-14T18:59:59Z	  We report on collective excitable events in a highly-diluted random network of non-excitable nodes. Excitability arises thanks to a self-sustained local adaptation mechanism that drives the system on a slow time-scale across a hysteretic phase transition involving states with different degrees of synchronization. These phenomena have been investigated for the Kuramoto model with bimodal distribution of the natural frequencies and for the Kuramoto model with inertia and an unimodal frequency distribution. We consider global and local stimulation protocols and characterize the system response for different level of dilution. We compare the results with those obtained in the fully-coupled case showing that such collective phenomena are remarkably robust against network diluteness. 	
"Density jump as a function of magnetic field for switch-on collisionless
  shocks in pair plasmas"	http://arxiv.org/abs/2206.06989v1	2022-06-14T17:04:31Z	2022-06-14T17:04:31Z	  The properties of collisionless shocks, like the density jump, are usually derived from magnetohydrodynamics (MHD), where isotropic pressures are assumed. Yet, in a collisionless plasma, an external magnetic field can sustain a stable anisotropy. In \cite{BretJPP2018}, we devised a model for the kinetic history of the plasma through the shock front, allowing to self-consistently compute the downstream anisotropy, hence the density jump, in terms of the upstream parameters. This model dealt with the case of a parallel shock, where the magnetic field is normal to the front both in the upstream and the downstream. Yet, MHD also allows for shock solutions, the so-called switch-on solutions, where the field is normal to the front only in the upstream. This article consists in applying our model to these switch-on shocks. While MHD offers only 1 switch-on solution within a limited range of Alfv\'{e}n Mach numbers, our model offers 2 kinds of solutions within a slightly different range of Alfv\'{e}n Mach numbers. These 2 solutions are most likely the outcome of the intermediate and fast MHD shocks under our model. While the intermediate and fast shocks merge in MHD for the parallel case, they do not within our model. For simplicity, the formalism is restricted to non-relativistic shocks in pair plasmas where the upstream is cold. 	
"Optomechanical generation of coherent GHz vibrations in a phononic
  waveguide"	http://arxiv.org/abs/2206.06913v1	2022-06-14T15:16:57Z	2022-06-14T15:16:57Z	  Nanophononics has the potential for information transfer, in an analogous manner to its photonic and electronic counterparts. The adoption of phononic systems has been limited, due to difficulties associated with the generation, manipulation, and detection of phonons, especially at GHz frequencies. Existing techniques often require piezoelectric materials with an external radiofrequency excitation that are not readily integrated into existing CMOS infrastructures, while non-piezoelectric demonstrations have been inefficient. In this work, we explore the optomechanical generation of coherent phonons in a suspended 2D silicon phononic crystal cavity with a guided mode around 6.8 GHz. By incorporating an air-slot into this cavity, we turn the phononic waveguide into an optomechanical platform that exploits localized photonic modes resulting from inherent fabrication imperfections for the transduction of mechanics. Such a platform exhibits very fine control of phonons using light, and is capable of coherent self-sustained phonon generation via mechanical lasing around 6.8 GHz. The ability to generate high frequency coherent mechanical vibrations within such a simple 2D CMOS-compatible system could be a first step towards the development of sources in phononic circuitry and the coherent manipulation of other solid-state properties. 	
"Giant mid-IR resonant coupling to molecular vibrations in sub-nm gaps of
  plasmonic multilayer metafilms"	http://arxiv.org/abs/2206.06906v1	2022-06-14T15:01:10Z	2022-06-14T15:01:10Z	  Nanomaterials capable of confining light are desirable for enhancing spectroscopies such as Raman scattering, infrared absorption, and nonlinear optical processes. Plasmonic superlattices have shown the ability to host collective resonances in the mid-infrared, but require stringent fabrication processes to create well-ordered structures. Here, we demonstrate how short-range-ordered Au nanoparticle multilayers on a mirror, self-assembled by a sub-nm molecular spacer, support collective plasmon-polariton resonances in the visible and infrared, continuously tunable beyond 11 $\mu$m by simply varying the nanoparticle size and number of layers. The resulting molecule-plasmon system approaches vibrational strong coupling, and displays giant Fano dip strengths, SEIRA enhancement factors ~10$^6$, light-matter coupling strengths g~100 cm$^{-1}$, Purcell factors ~10$^6$, and mode volume compression factors ~10$^8$. The collective plasmon-polariton mode is highly robust to nanoparticle vacancy disorder and is sustained by the consistent gap size defined by the molecular spacer. Structural disorder efficiently couples light into the gaps between the multilayers and mirror, enabling Raman and infrared sensing of sub-picolitre sample volumes. 	
"Data security as a top priority in the digital world: preserve data
  value by being proactive and thinking security first"	http://arxiv.org/abs/2206.06814v1	2022-06-14T13:04:41Z	2022-06-14T13:04:41Z	  Today, large amounts of data are being continuously produced, collected, and exchanged between systems. As the number of devices, systems and data produced grows up, the risk of security breaches increases. This is all the more relevant in times of COVID-19, which has affected not only the health and lives of human beings' but also the lifestyle of society, i.e., the digital environment has replaced the physical. This has led to an increase in cyber security threats of various nature. While security breaches and different security protection mechanisms have been widely covered in the literature, the concept of a primitive artifact such as data management system seems to have been more neglected by researchers and practitioners. But are data management systems always protected by default? Previous research and regular updates on data leakages suggest that the number and nature of these vulnerabilities are high. It also refers to little or no DBMS protection, especially in case of NoSQL, which are thus vulnerable to attacks. The aim of this paper is to examine whether traditional vulnerability registries provide a sufficiently comprehensive view of DBMS security, or they should be intensively and dynamically inspected by DBMS owners by referring to Internet of Things Search Engines moving towards a sustainable and resilient digitized environment. The paper brings attention to this problem and makes the reader think about data security before looking for and introducing more advanced security and protection mechanisms, which, in the absence of the above, may bring no value. 	
"Classification of ECG based on Hybrid Features using CNNs for Wearable
  Applications"	http://arxiv.org/abs/2206.07648v1	2022-06-14T12:14:40Z	2022-06-14T12:14:40Z	  Sudden cardiac death and arrhythmia account for a large percentage of all deaths worldwide. Electrocardiography (ECG) is the most widely used screening tool for cardiovascular diseases. Traditionally, ECG signals are classified manually, requiring experience and great skill, while being time-consuming and prone to error. Thus machine learning algorithms have been widely adopted because of their ability to perform complex data analysis. Features derived from the points of interest in ECG - mainly Q, R, and S, are widely used for arrhythmia detection. In this work, we demonstrate improved performance for ECG classification using hybrid features and three different models, building on a 1-D convolutional neural network (CNN) model that we had proposed in the past. An RR interval features based model proposed in this work achieved an accuracy of 98.98%, which is an improvement over the baseline model. To make the model immune to noise, we updated the model using frequency features and achieved good sustained performance in presence of noise with a slightly lower accuracy of 98.69%. Further, another model combining the frequency features and the RR interval features was developed, which achieved a high accuracy of 99% with good sustained performance in noisy environments. Due to its high accuracy and noise immunity, the proposed model which combines multiple hybrid features, is well suited for ambulatory wearable sensing applications. 	
"Demand-driven design of bicycle infrastructure networks for improved
  urban bikeability"	http://arxiv.org/abs/2206.06708v1	2022-06-14T09:21:03Z	2022-06-14T09:21:03Z	  Cycling is a crucial part of sustainable urban transportation. Promoting cycling critically relies on a sufficiently developed bicycle infrastructure. However, designing efficient bike path networks constitutes a complex problem that requires balancing multiple constraints while still supporting all cycling demand. Here, we propose a framework to create families of efficient bike path networks by explicitly taking into account the demand distribution and cyclists' route choices based on safety preferences. By reversing the network formation process and iteratively removing bike paths from an initially complete bike path network and continually updating cyclists' route choices, we create a sequence of networks that is always adapted to the current cycling demand. We illustrate the applicability of this demand-driven planning scheme for two cities. A comparison of the resulting bike path networks with those created for homogenized demand enables us to quantify the importance of the demand distribution for network planning. The proposed framework may thus enable quantitative evaluation of the structure of current and planned bike path networks and support the demand-driven design of efficient infrastructures. 	
"Sustained unidirectional rotation of a self-organized DNA rotor on a
  nanopore"	http://arxiv.org/abs/2206.06613v1	2022-06-14T06:18:44Z	2022-06-14T06:18:44Z	  Flow-driven rotary motors drive functional processes in human society such as windmills and water wheels. Although examples of such rotary motors also feature prominently in cell biology, their synthetic construction at the nanoscale has thus far remained elusive. Here, we demonstrate flow-driven rotary motion of a self-organized DNA nanostructure that is docked onto a nanopore in a thin solid-state membrane. An elastic DNA bundle self assembles into a chiral conformation upon phoretic docking onto the solid-state nanopore, and subsequently displays a sustained unidirectional rotary motion of up to 20 revolutions/s. The rotors harness energy from a nanoscale water and ion flow that is generated by a static (electro)chemical potential gradient in the nanopore that is established through a salt gradient or applied voltage. These artificial nanoengines self-organize and operate autonomously in physiological conditions, paving a new direction in constructing energy-transducing motors at nanoscale interfaces. 	
A nanopore-powered DNA turbine	http://arxiv.org/abs/2206.06612v1	2022-06-14T06:17:31Z	2022-06-14T06:17:31Z	  Rotary motors play a key role in the transduction of energy, from macroscale windmills to nanoscale turbines such as ATP synthase in cells. Here, we demonstrate a rationally designed nanoscale DNA-origami turbine with three chiral blades that uses a transmembrane electrochemical potential across a nanopore to drive a DNA bundle into sustained unidirectional rotations of ~10 revolutions/s. All-atom molecular-dynamics simulations show how 20 hydrodynamic flows drive this turbine. The rotation direction is set by the designed chirality of the turbine, whereas at high salt concentrations, DNA-bound ions can reverse the flow and hence the rotation direction. Our artificial turbines operate autonomously in physiological conditions and convert energy from naturally abundant electrochemical potentials into mechanical work. The results open new possibilities for engineering active robotics at the nanoscale. 	
SEPnet: A sustainable model for a collaborative physics network	http://arxiv.org/abs/2206.06198v1	2022-06-13T14:31:44Z	2022-06-13T14:31:44Z	  The South East Physics network (SEPnet) is a collaboration between nine universities in the South East of England, working together to deliver excellence in physics. By sharing resources, we are able to add much more value to our departments, students, and subject than we could achieve individually. Our core ambitions include ensuring the sustainability of physics in our region, enhancing the employability of our students, delivering advanced training, securing the pipeline of future students, opening up new research opportunities and breaking down barriers to improve the accessibility of physics for everyone. We believe that SEPnet provides a tried and tested model that could be rolled out by others to improve the academic excellence of other disciplines in different regions. 	
"Satellite-based high-resolution maps of cocoa for Cte d'Ivoire and
  Ghana"	http://arxiv.org/abs/2206.06119v4	2022-10-10T07:57:34Z	2022-06-13T12:58:35Z	  C\^ote d'Ivoire and Ghana, the world's largest producers of cocoa, account for two thirds of the global cocoa production. In both countries, cocoa is the primary perennial crop, providing income to almost two million farmers. Yet precise maps of cocoa planted area are missing, hindering accurate quantification of expansion in protected areas, production and yields, and limiting information available for improved sustainability governance. Here, we combine cocoa plantation data with publicly available satellite imagery in a deep learning framework and create high-resolution maps of cocoa plantations for both countries, validated in situ. Our results suggest that cocoa cultivation is an underlying driver of over 37% and 13% of forest loss in protected areas in C\^ote d'Ivoire and Ghana, respectively, and that official reports substantially underestimate the planted area, up to 40% in Ghana. These maps serve as a crucial building block to advance understanding of conservation and economic development in cocoa producing regions. 	
"A facile approach for phase change material encapsulation into polymeric
  flexible fibers using microfluidic principles"	http://arxiv.org/abs/2206.06055v1	2022-06-13T11:40:35Z	2022-06-13T11:40:35Z	  It is widely agreed that phase change materials (PCMs) are of high interest for sustainable energy future. Many of the applications require anti-leakage properties of PCM, that can be accomplished through PCM encapsulation. In this study, scalable and considerably simplified approach based on the microfluidics principles was successfully designed for polyvinylidene fluoride (PVDF) hollow- and for leakage-free paraffin-core/PVDF-sheath fibers production. The required device can be as simple as syringe+tube+glass capillary. The fibers were created by PVDF/N,NDimethylformamide (DMF) solution and PVDF/DMF/paraffin emulsion injection in water followed by solvent extraction process. The proposed approach results in a hollow PVDF or PVDF/paraffin composite fibers with the PCM content between 32-47.5% according to DSC and TGA measurements. SEM study of the fibers morphology has shown that PCM is in the form of slugs along the fibers. Such PCM distribution is maintained until the first melting cycle. Later, molten PCM spreads within the fiber under capillary forces that was captured by infrared camera. Elastic modules and stress vs. strain were measured to characterise mechanical properties of designed fibers. Finally, the composite fibers have shown outstanding retention capacity with only 3.5% of PCM mass loose after 1000 melting/crystallisation cycles. 	
"Identifying and estimating effects of sustained interventions under
  parallel trends assumptions"	http://arxiv.org/abs/2206.05788v2	2022-09-29T18:34:01Z	2022-06-12T16:52:29Z	  Many research questions in public health and medicine concern sustained interventions in populations defined by substantive priorities. Existing methods to answer such questions typically require a measured covariate set sufficient to control confounding, which can be questionable in observational studies. Differences-in-differences relies instead on the parallel trends assumption, allowing for some types of time-invariant unmeasured confounding. However, most existing difference-in-differences implementations are limited to point treatments in restricted subpopulations. We derive identification results for population effects of sustained treatments under parallel trends assumptions. In particular, in settings where all individuals begin follow-up with exposure status consistent with the treatment plan of interest but may deviate at later times, a version of Robins' g-formula identifies the intervention-specific mean under SUTVA, positivity, and parallel trends. We develop consistent asymptotically normal estimators based on inverse-probability weighting, outcome regression, and a double robust estimator based on targeted maximum likelihood. Simulation studies confirm theoretical results and support the use of the proposed estimators at realistic sample sizes. As an example, the methods are used to estimate the effect of a hypothetical federal stay-at-home order on all-cause mortality during the COVID-19 pandemic in spring 2020 in the United States. 	
The Capacity of Low Earth Orbit Computed using Source-sink Modeling	http://arxiv.org/abs/2206.05345v1	2022-06-10T20:33:12Z	2022-06-10T20:33:12Z	  The increasing number of Anthropogenic Space Objects (ASOs) in Low Earth Orbit (LEO) poses a threat to the safety and sustainability of the space environment. Multiple companies are planning to launch large constellations of hundreds or thousands of satellites in the near future, increasing congestion in LEO and the risk of collisions and debris generation. This paper employs a new multi-shell multi-species evolutionary source-sink model, called MOCAT-3, to estimate LEO orbital capacity. In particular, a new definition of orbital capacity based on the stable equilibrium points of the system is provided. Moreover, an optimization approach is used to compute the maximum orbital capacity of the low region of LEO (200-900 km of altitude), considering the equilibrium solutions and the failure rate of satellites as a constraint. Hence, an estimate for the maximum number of satellites that it is possible to fit in LEO, considering the stability of the space environment, is obtained. As a result, considering 7% of failure rate, the maximum orbital capacity of LEO is estimated to be about 12.6 million satellites. Compatibility of future traffic launch, especially in terms of satellite constellations, is also analyzed and a strategy to accommodate for future traffic needs is proposed. 	
"Dynamics of sparse Boolean networks with multi-node and
  self-interactions"	http://arxiv.org/abs/2206.05228v1	2022-06-10T17:03:04Z	2022-06-10T17:03:04Z	  We analyse the equilibrium behaviour and non-equilibrium dynamics of sparse Boolean networks with self-interactions that evolve according to synchronous Glauber dynamics. Equilibrium analysis is achieved via a novel application of the cavity method to the temperature-dependent pseudo-Hamiltonian that characterises the equilibrium state of systems with parallel dynamics. Similarly, the non-equilibrium dynamics can be analysed by using the dynamical version of the cavity method. It is well known, however, that when self-interactions are present, direct application of the dynamical cavity method is cumbersome, due to the presence of strong memory effects, which prevent explicit analysis of the dynamics beyond a few time steps. To overcome this difficulty, we show that it is possible to map a system of $N$ variables to an equivalent bipartite system of $2N$ variables, for which the dynamical cavity method can be used under the usual one time approximation scheme. This substantial technical advancement allows for the study of transient and long-time behaviour of systems with self-interactions. Finally, we study the dynamics of systems with multi-node interactions, recently used to model gene regulatory networks, by mapping this to a bipartite system of Boolean variables with 2-body interactions. We show that when interactions have a degree of bidirectionality such systems are able to support a multiplicity of diverse attractors, an important requirement for a gene-regulatory network to sustain multi-cellular life. 	
"Enabling Heterogeneous Catalysis to Achieve Carbon Neutrality:
  Directional Catalytic Conversion of CO$_2$ into Carboxylic Acids"	http://arxiv.org/abs/2206.06130v1	2022-06-10T08:40:37Z	2022-06-10T08:40:37Z	  The increase in anthropogenic carbon dioxide (CO$_2$) emissions has exacerbated the deterioration of the global environment, which should be controlled to achieve carbon neutrality. Central to the core goal of achieving carbon neutrality is the utilization of CO$_2$ under economic and sustainable conditions. Recently, the strong need for carbon neutrality has led to a proliferation of studies on the direct conversion of CO$_2$ into carboxylic acids, which could effectively alleviate CO$_2$ emissions and create high-value chemicals. The purpose of this review is to present the application prospects of carboxylic acids and the basic principles of CO$_2$ conversion into carboxylic acids through photo-, electric-, and thermal catalysis. Special attention is focused on the regulation strategy of the activity of abundant catalysts at the molecular level, inspiring the preparation of high-performance catalysts. In addition, theoretical calculation, advanced technologies, and numerous typical examples are introduced to elaborate on the corresponding process and influencing factors of catalytic activity. Finally, challenges and prospects are provided for the future development of this field. It is hoped that this review contributes to a deeper understanding of the conversion of CO$_2$ into carboxylic acids and inspires more innovative breakthroughs 	
"Robot Control for Simultaneous Impact Tasks through Time-Invariant
  Reference Spreading"	http://arxiv.org/abs/2206.04852v2	2022-12-01T18:24:52Z	2022-06-10T02:58:45Z	  With the goal of enabling the exploitation of impacts in robotic manipulation, a new framework is presented for control of robotic manipulators that are tasked to execute nominally simultaneous impacts. In this framework, we employ tracking of time-invariant reference vector fields corresponding to the ante- and post-impact motion, increasing its applicability over similar conventional tracking control approaches. The ante- and post-impact references are coupled through a rigid impact map, and are extended to overlap around the area where the impact is expected to take place, such that the reference corresponding to the actual contact state of the robot can always be followed. As a sequence of impacts at the different contact points will typically occur, resulting in uncertainty of the contact mode and unreliable velocity measurements, a new interim control mode catered towards time-invariant references is formulated. In this mode, a position feedback signal is derived from the ante-impact velocity reference, which is used to enforce sustained contact in all contact points without using velocity feedback. With an eye towards real implementation, the approach is formulated using a QP control framework, and is validated using numerical simulations both on a rigid robot with a hard inelastic contact model and on a realistic robot model with flexible joints and compliant partially elastic contact model. 	
"Outsider Oversight: Designing a Third Party Audit Ecosystem for AI
  Governance"	http://arxiv.org/abs/2206.04737v1	2022-06-09T19:18:47Z	2022-06-09T19:18:47Z	  Much attention has focused on algorithmic audits and impact assessments to hold developers and users of algorithmic systems accountable. But existing algorithmic accountability policy approaches have neglected the lessons from non-algorithmic domains: notably, the importance of interventions that allow for the effective participation of third parties. Our paper synthesizes lessons from other fields on how to craft effective systems of external oversight for algorithmic deployments. First, we discuss the challenges of third party oversight in the current AI landscape. Second, we survey audit systems across domains - e.g., financial, environmental, and health regulation - and show that the institutional design of such audits are far from monolithic. Finally, we survey the evidence base around these design components and spell out the implications for algorithmic auditing. We conclude that the turn toward audits alone is unlikely to achieve actual algorithmic accountability, and sustained focus on institutional design will be required for meaningful third party involvement. 	
The Economics of Automated Market Makers	http://arxiv.org/abs/2206.04634v1	2022-06-09T17:29:32Z	2022-06-09T17:29:32Z	  This paper studies the question whether automated market maker protocols such as Uniswap can sustainably retain a portion of their trading fees for the protocol. We approach the problem by modelling how to optimally choose a pool's take rate, i.e\ the fraction of fee revenue that remains with the protocol, in order to maximize the protocol's revenue. The model suggest that if AMMs have a portion of loyal trade volume, they can sustainably set a non-zero take rate, even without losing liquidity to competitors with a zero take rate. Furthermore, we determine the optimal take rate depending on a number of model parameters including how much loyal trade volume pools have and how high the competitors' take rates are. 	
